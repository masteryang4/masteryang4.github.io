<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>flink系列08读写外部系统 | MasterYangBlog</title><meta name="description" content="flink系列08读写外部系统"><meta name="keywords" content="教程,大数据,flink"><meta name="author" content="Yang4"><meta name="copyright" content="Yang4"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="flink系列08读写外部系统"><meta name="twitter:description" content="flink系列08读写外部系统"><meta name="twitter:image" content="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><meta property="og:type" content="article"><meta property="og:title" content="flink系列08读写外部系统"><meta property="og:url" content="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/"><meta property="og:site_name" content="MasterYangBlog"><meta property="og:description" content="flink系列08读写外部系统"><meta property="og:image" content="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/"><link rel="prev" title="flink系列09搭建Flink运行流式应用" href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9709%E6%90%AD%E5%BB%BAFlink%E8%BF%90%E8%A1%8C%E6%B5%81%E5%BC%8F%E5%BA%94%E7%94%A8/"><link rel="next" title="flink系列07有状态算子和应用" href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9707%E6%9C%89%E7%8A%B6%E6%80%81%E7%AE%97%E5%AD%90%E5%92%8C%E5%BA%94%E7%94%A8/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://masteryang4.github.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="MasterYangBlog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">MasterYangBlog</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/n.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">72</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">51</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">27</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第八章，读写外部系统"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">第八章，读写外部系统</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#应用的一致性保证"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">应用的一致性保证</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#幂等性写入"><span class="toc_mobile_items-number">1.1.1.</span> <span class="toc_mobile_items-text">幂等性写入</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#事务性写入"><span class="toc_mobile_items-number">1.1.2.</span> <span class="toc_mobile_items-text">事务性写入</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Flink提供的连接器"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">Flink提供的连接器</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Apache-Kafka-Source连接器"><span class="toc_mobile_items-number">1.2.1.</span> <span class="toc_mobile_items-text">Apache Kafka Source连接器</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Apache-Kafka-Sink连接器"><span class="toc_mobile_items-number">1.2.2.</span> <span class="toc_mobile_items-text">Apache Kafka Sink连接器</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Kakfa-Sink的at-least-once保证"><span class="toc_mobile_items-number">1.2.3.</span> <span class="toc_mobile_items-text">Kakfa Sink的at-least-once保证</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Kafka-Sink的恰好处理一次语义保证"><span class="toc_mobile_items-number">1.2.4.</span> <span class="toc_mobile_items-text">Kafka Sink的恰好处理一次语义保证</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#文件系统source连接器"><span class="toc_mobile_items-number">1.2.5.</span> <span class="toc_mobile_items-text">文件系统source连接器</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#文件系统sink连接器"><span class="toc_mobile_items-number">1.2.6.</span> <span class="toc_mobile_items-text">文件系统sink连接器</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#实现自定义源函数"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">实现自定义源函数</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#可重置的源函数"><span class="toc_mobile_items-number">1.3.1.</span> <span class="toc_mobile_items-text">可重置的源函数</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#实现自定义sink函数"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">实现自定义sink函数</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#幂等sink连接器"><span class="toc_mobile_items-number">1.4.1.</span> <span class="toc_mobile_items-text">幂等sink连接器</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#事务性sink连接器"><span class="toc_mobile_items-number">1.4.2.</span> <span class="toc_mobile_items-text">事务性sink连接器</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第八章，读写外部系统"><span class="toc-number">1.</span> <span class="toc-text">第八章，读写外部系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#应用的一致性保证"><span class="toc-number">1.1.</span> <span class="toc-text">应用的一致性保证</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#幂等性写入"><span class="toc-number">1.1.1.</span> <span class="toc-text">幂等性写入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#事务性写入"><span class="toc-number">1.1.2.</span> <span class="toc-text">事务性写入</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink提供的连接器"><span class="toc-number">1.2.</span> <span class="toc-text">Flink提供的连接器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Apache-Kafka-Source连接器"><span class="toc-number">1.2.1.</span> <span class="toc-text">Apache Kafka Source连接器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Apache-Kafka-Sink连接器"><span class="toc-number">1.2.2.</span> <span class="toc-text">Apache Kafka Sink连接器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kakfa-Sink的at-least-once保证"><span class="toc-number">1.2.3.</span> <span class="toc-text">Kakfa Sink的at-least-once保证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Sink的恰好处理一次语义保证"><span class="toc-number">1.2.4.</span> <span class="toc-text">Kafka Sink的恰好处理一次语义保证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件系统source连接器"><span class="toc-number">1.2.5.</span> <span class="toc-text">文件系统source连接器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件系统sink连接器"><span class="toc-number">1.2.6.</span> <span class="toc-text">文件系统sink连接器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实现自定义源函数"><span class="toc-number">1.3.</span> <span class="toc-text">实现自定义源函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#可重置的源函数"><span class="toc-number">1.3.1.</span> <span class="toc-text">可重置的源函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实现自定义sink函数"><span class="toc-number">1.4.</span> <span class="toc-text">实现自定义sink函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#幂等sink连接器"><span class="toc-number">1.4.1.</span> <span class="toc-text">幂等sink连接器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#事务性sink连接器"><span class="toc-number">1.4.2.</span> <span class="toc-text">事务性sink连接器</span></a></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">flink系列08读写外部系统</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-07-02<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-07-02</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/">flink</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="第八章，读写外部系统"><a href="#第八章，读写外部系统" class="headerlink" title="第八章，读写外部系统"></a>第八章，读写外部系统</h1><p>数据可以存储在不同的系统中，例如：文件系统，对象存储系统（OSS），关系型数据库，Key-Value存储，搜索引擎索引，日志系统，消息队列，等等。每一种系统都是给特定的应用场景设计的，在某一个特定的目标上超越了其他系统。今天的数据架构，往往包含着很多不同的存储系统。在将一个组件加入到我们的系统中时，我们需要问一个问题：“这个组件和架构中的其他组件能多好的一起工作？”</p>
<p>添加一个像Flink这样的数据处理系统，需要仔细的考虑。因为Flink没有自己的存储层，而是读取数据和持久化数据都需要依赖外部存储。所以，对于Flink，针对外部系统提供良好的读取和写入的连接器就很重要了。尽管如此，仅仅能够读写外部系统对于Flink这样想要提供任务故障情况下一致性保证的流处理器来讲，是不够的。</p>
<p>在本章中，我们将会讨论source和sink的连接器。这些连接器影响了Flink的一致性保证，也提供了对于最流行的一些外部系统的读写的连接器。我们还将学习如何实现自定义source和sink连接器，以及如何实现可以向外部系统发送异步读写请求的函数。</p>
<h2 id="应用的一致性保证"><a href="#应用的一致性保证" class="headerlink" title="应用的一致性保证"></a>应用的一致性保证</h2><p>Flink的检查点和恢复机制定期的会保存应用程序状态的一致性检查点。在故障的情况下，应用程序的状态将会从最近一次完成的检查点恢复，并继续处理。尽管如此，可以使用检查点来重置应用程序的状态无法完全达到令人满意的一致性保证。相反，source和sink的连接器需要和Flink的检查点和恢复机制进行集成才能提供有意义的一致性保证。</p>
<p>为了给应用程序提供恰好处理一次语义的状态一致性保证，应用程序的source连接器需要能够将source的读位置重置到之前保存的检查点位置。当处理一次检查点时，source操作符将会把source的读位置持久化，并在恢复的时候从这些读位置开始重新读取。支持读位置的检查点的source连接器一般来说是基于文件的存储系统，如：文件流或者Kafka source（检查点会持久化某个正在消费的topic的读偏移量）。如果一个应用程序从一个无法存储和重置读位置的source连接器摄入数据，那么当任务出现故障的时候，数据就会丢失。也就是说我们只能提供at-most-once）的一致性保证。</p>
<p>Fink的检查点和恢复机制和可以重置读位置的source连接器结合使用，可以保证应用程序不会丢失任何数据。尽管如此，应用程序可能会发出两次计算结果，因为从上一次检查点恢复的应用程序所计算的结果将会被重新发送一次（一些结果已经发送出去了，这时任务故障，然后从上一次检查点恢复，这些结果将被重新计算一次然后发送出去）。所以，可重置读位置的source和Flink的恢复机制不足以提供端到端的恰好处理一次语义，即使应用程序的状态是恰好处理一次一致性级别。</p>
<p>一个志在提供端到端恰好处理一次语义一致性的应用程序需要特殊的sink连接器。sink连接器可以在不同的情况下使用两种技术来达到恰好处理一次一致性语义：幂等性写入和事务性写入。</p>
<h3 id="幂等性写入"><a href="#幂等性写入" class="headerlink" title="幂等性写入"></a>幂等性写入</h3><p>一个幂等操作无论执行多少次都会返回同样的结果。例如，重复的向hashmap中插入同样的key-value对就是幂等操作，因为头一次插入操作之后所有的插入操作都不会改变这个hashmap，因为hashmap已经包含这个key-value对了。另一方面，append操作就不是幂等操作了，因为多次append同一个元素将会导致列表每次都会添加一个元素。在流处理程序中，幂等写入操作是很有意思的，因为幂等写入操作可以执行多次但不改变结果。所以它们可以在某种程度上缓和Flink检查点机制带来的重播计算结果的效应。</p>
<p>需要注意的是，依赖于幂等性sink来达到exactly-once语义的应用程序，必须保证在从检查点恢复以后，它将会覆盖之前已经写入的结果。例如，一个包含有sink操作的应用在sink到一个key-value存储时必须保证它能够确定的计算出将要更新的key值。同时，从Flink程序sink到的key-value存储中读取数据的应用，在Flink从检查点恢复的过程中，可能会看到不想看到的结果。当重播开始时，之前已经发出的计算结果可能会被更早的结果所覆盖（因为在恢复过程中）。所以，一个消费Flink程序输出数据的应用，可能会观察到时间回退，例如读到了比之前小的计数。也就是说，当流处理程序处于恢复过程中时，流处理程序的结果将处于不稳定的状态，因为一些结果被覆盖掉，而另一些结果还没有被覆盖。一旦重播完成，也就是说应用程序已经通过了之前出故障的点，结果将会继续保持一致性。</p>
<h3 id="事务性写入"><a href="#事务性写入" class="headerlink" title="事务性写入"></a>事务性写入</h3><p>第二种实现端到端的恰好处理一次一致性语义的方法基于事务性写入。其思想是只将最近一次成功保存的检查点之前的计算结果写入到外部系统中去。这样就保证了在任务故障的情况下，端到端恰好处理一次语义。应用将被重置到最近一次的检查点，而在这个检查点之后并没有向外部系统发出任何计算结果。通过只有当检查点保存完成以后再写入数据这种方法，事务性的方法将不会遭受幂等性写入所遭受的重播不一致的问题。尽管如此，事务性写入却带来了延迟，因为只有在检查点完成以后，我们才能看到计算结果。</p>
<p>Flink提供了两种构建模块来实现事务性sink连接器：write-ahead-log（WAL，预写式日志）sink和两阶段提交sink。WAL式sink将会把所有计算结果写入到应用程序的状态中，等接到检查点完成的通知，才会将计算结果发送到sink系统。因为sink操作会把数据都缓存在状态后段，所以WAL可以使用在任何外部sink系统上。尽管如此，WAL还是无法提供刀枪不入的恰好处理一次语义的保证，再加上由于要缓存数据带来的状态后段的状态大小的问题，WAL模型并不十分完美。</p>
<p>与之形成对比的，2PC sink需要sink系统提供事务的支持或者可以模拟出事务特性的模块。对于每一个检查点，sink开始一个事务，然后将所有的接收到的数据都添加到事务中，并将这些数据写入到sink系统，但并没有提交（commit）它们。当事务接收到检查点完成的通知时，事务将被commit，数据将被真正的写入sink系统。这项机制主要依赖于一次sink可以在检查点完成之前开始事务，并在应用程序从一次故障中恢复以后再commit的能力。</p>
<p>2PC协议依赖于Flink的检查点机制。检查点屏障是开始一个新的事务的通知，所有操作符自己的检查点成功的通知是它们可以commit的投票，而JobManager通知一个检查点成功的消息是commit事务的指令。于WAL sink形成对比的是，2PC sinks依赖于sink系统和sink本身的实现可以实现恰好处理一次语义。更多的，2PC sink不断的将数据写入到sink系统中，而WAL写模型就会有之前所述的问题。</p>
<table>
<thead>
<tr>
<th></th>
<th>不可重置的源</th>
<th>可重置的源</th>
</tr>
</thead>
<tbody><tr>
<td>any sink</td>
<td>at-most-once</td>
<td>at-least-once</td>
</tr>
<tr>
<td>幂等性sink</td>
<td>at-most-once</td>
<td>exactly-once（当从任务失败中恢复时，存在暂时的不一致性）</td>
</tr>
<tr>
<td>预写式日志sink</td>
<td>at-most-once</td>
<td>at-least-once</td>
</tr>
<tr>
<td>2PC sink</td>
<td>at-most-once</td>
<td>exactly-once</td>
</tr>
</tbody></table>
<h2 id="Flink提供的连接器"><a href="#Flink提供的连接器" class="headerlink" title="Flink提供的连接器"></a>Flink提供的连接器</h2><p>Flink提供了读写很多存储系统的连接器。消息队列，日志系统，例如Apache Kafka, Kinesis, RabbitMQ等等这些是常用的数据源。在批处理环境中，数据流很可能是监听一个文件系统，而当新的数据落盘的时候，读取这些新数据。</p>
<p>在sink一端，数据流经常写入到消息队列中，以供接下来的流处理程序消费。数据流也可能写入到文件系统中做持久化，或者交给批处理程序来进行分析。数据流还可能被写入到key-value存储或者关系型数据库中，例如Cassandra，ElasticSearch或者MySQL中，这样数据可供查询，还可以在仪表盘中显示出来。</p>
<p>不幸的是，对于大多数存储系统并没有标准接口，除了针对DBMS的JDBC。相反，每一个存储系统都需要有自己的特定的连接器。所以，Flink需要维护针对不同存储系统（消息队列，日志系统，文件系统，k-v数据库，关系型数据库等等）的连接器实现。</p>
<p>Flink提供了针对Apache Kafka, Kinesis, RabbitMQ, Apache Nifi, 各种文件系统，Cassandra, Elasticsearch, 还有JDBC的连接器。除此之外，Apache Bahir项目还提供了额外的针对例如ActiveMQ, Akka, Flume, Netty, 和Redis等的连接器。</p>
<h3 id="Apache-Kafka-Source连接器"><a href="#Apache-Kafka-Source连接器" class="headerlink" title="Apache Kafka Source连接器"></a>Apache Kafka Source连接器</h3><p>Apache Kafka是一个分布式流式平台。它的核心是一个分布式的发布订阅消息系统。</p>
<p>Kafka将事件流组织为所谓的topics。一个主题就是一个事件日志系统，Kafka可以保证主题中的数据在被读取时和这些数据在被写入时相同的顺序。为了扩大读写的规模，主题可以分裂为多个分区，这些分区分布在一个集群上面。这时，读写顺序的保证就限制到了分区这个粒度， Kafka并没有提供从不同分区读取数据时的顺序保证。Kafka分区的读位置称为偏移量（offset）。</p>
<p>Kafka的依赖引入如下：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>Flink Kafka连接器并行的摄入事件流。每一个并行source任务可以从一个或者多个分区中读取数据。任务将会跟踪每一个分区当前的读偏移量，然后将读偏移量写入到检查点数据中。当从任务故障恢复时，读偏移量将被恢复，而source任务将从检查点保存的读偏移量开始重新读取数据。Flink Kafka连接器并不依赖Kafka自己的offset-tracking机制（基于消费者组实现）。下图展示了分区如何分配给source实例。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0801.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0801.png" class="lazyload"></a></p>
<p>Kafka source连接器使用如下代码创建</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">properties.setProperty(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"test"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.addSource(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](</span><br><span class="line">    <span class="string">"topic"</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),</span><br><span class="line">    properties))</span><br></pre></td></tr></table></figure></div>

<p>构造器接受三个参数。第一个参数定义了从哪些topic中读取数据，可以是一个topic，也可以是topic列表，还可以是匹配所有想要读取的topic的正则表达式。当从多个topic中读取数据时，Kafka连接器将会处理所有topic的分区，将这些分区的数据放到一条流中去。</p>
<p>第二个参数是一个DeserializationSchema或者KeyedDeserializationSchema。Kafka消息被存储为原始的字节数据，所以需要反序列化成Java或者Scala对象。上例中使用的SimpleStringSchema，是一个内置的DeserializationSchema，它仅仅是简单的将字节数组反序列化成字符串。DeserializationSchema和KeyedDeserializationSchema是公共的接口，所以我们可以自定义反序列化逻辑。</p>
<p>第三个参数是一个Properties对象，设置了用来读写的Kafka客户端的一些属性。</p>
<p>为了抽取事件时间的时间戳然后产生水印，我们可以通过调用</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">FlinkKafkaConsumer</span>.assignTimestampsAndWatermark()</span><br></pre></td></tr></table></figure></div>

<p>方法为Kafka消费者提供AssignerWithPeriodicWatermark或者AssignerWithPucntuatedWatermark。每一个assigner都将被应用到每个分区，来利用每一个分区的顺序保证特性。source实例将会根据水印的传播协议聚合所有分区的水印。</p>
<h3 id="Apache-Kafka-Sink连接器"><a href="#Apache-Kafka-Sink连接器" class="headerlink" title="Apache Kafka Sink连接器"></a>Apache Kafka Sink连接器</h3><p>添加依赖：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>下面的例子展示了如何创建一个Kafka sink</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> myProducer = <span class="keyword">new</span> <span class="type">FlinkKafkaProducer</span>[<span class="type">String</span>](</span><br><span class="line">  <span class="string">"localhost:9092"</span>,         <span class="comment">// broker list</span></span><br><span class="line">  <span class="string">"topic"</span>,                  <span class="comment">// target topic</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>)   <span class="comment">// serialization schema</span></span><br><span class="line"></span><br><span class="line">stream.addSink(myProducer)</span><br></pre></td></tr></table></figure></div>

<h3 id="Kakfa-Sink的at-least-once保证"><a href="#Kakfa-Sink的at-least-once保证" class="headerlink" title="Kakfa Sink的at-least-once保证"></a>Kakfa Sink的at-least-once保证</h3><p>Flink的Kafka sink提供了基于配置的一致性保证。Kafka sink使用下面的条件提供了至少处理一次保证：</p>
<ul>
<li>Flink检查点机制开启，所有的数据源都是可重置的。</li>
<li>当写入失败时，sink连接器将会抛出异常，使得应用程序挂掉然后重启。这是默认行为。应用程序内部的Kafka客户端还可以配置为重试写入，只要提前声明当写入失败时，重试几次这样的属性（retries property）。</li>
<li>sink连接器在完成它的检查点之前会等待Kafka发送已经将数据写入的通知。</li>
</ul>
<h3 id="Kafka-Sink的恰好处理一次语义保证"><a href="#Kafka-Sink的恰好处理一次语义保证" class="headerlink" title="Kafka Sink的恰好处理一次语义保证"></a>Kafka Sink的恰好处理一次语义保证</h3><p>Kafka 0.11版本引入了事务写特性。由于这个新特性，Flink Kafka sink可以为输出结果提供恰好处理一次语义的一致性保证，只要经过合适的配置就行。Flink程序必须开启检查点机制，并从可重置的数据源进行消费。FlinkKafkaProducer还提供了包含Semantic参数的构造器来控制sink提供的一致性保证。可能的取值如下：</p>
<ul>
<li>Semantic.NONE，不提供任何一致性保证。数据可能丢失或者被重写多次。</li>
<li>Semantic.AT_LEAST_ONCE，保证无数据丢失，但可能被处理多次。这个是默认设置。</li>
<li>Semantic.EXACTLY_ONCE，基于Kafka的事务性写入特性实现，保证每条数据恰好处理一次。</li>
</ul>
<h3 id="文件系统source连接器"><a href="#文件系统source连接器" class="headerlink" title="文件系统source连接器"></a>文件系统source连接器</h3><p>Apache Flink针对文件系统实现了一个可重置的source连接器，将文件看作流来读取数据。如下面的例子所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lineReader = <span class="keyword">new</span> <span class="type">TextInputFormat</span>(<span class="literal">null</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lineStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readFile[<span class="type">String</span>](</span><br><span class="line">  lineReader,                 <span class="comment">// The FileInputFormat</span></span><br><span class="line">  <span class="string">"hdfs:///path/to/my/data"</span>,  <span class="comment">// The path to read</span></span><br><span class="line">  <span class="type">FileProcessingMode</span></span><br><span class="line">    .<span class="type">PROCESS_CONTINUOUSLY</span>,    <span class="comment">// The processing mode</span></span><br><span class="line">  <span class="number">30000</span>L)                     <span class="comment">// The monitoring interval in ms</span></span><br></pre></td></tr></table></figure></div>

<p>StreamExecutionEnvironment.readFile()接收如下参数：</p>
<ul>
<li>FileInputFormat参数，负责读取文件中的内容。</li>
<li>文件路径。如果文件路径指向单个文件，那么将会读取这个文件。如果路径指向一个文件夹，FileInputFormat将会扫描文件夹中所有的文件。</li>
<li>PROCESS_CONTINUOUSLY将会周期性的扫描文件，以便扫描到文件新的改变。</li>
<li>30000L表示多久扫描一次监听的文件。</li>
</ul>
<p>FileInputFormat是一个特定的InputFormat，用来从文件系统中读取文件。FileInputFormat分两步读取文件。首先扫描文件系统的路径，然后为所有匹配到的文件创建所谓的input splits。一个input split将会定义文件上的一个范围，一般通过读取的开始偏移量和读取长度来定义。在将一个大的文件分割成一堆小的splits以后，这些splits可以分发到不同的读任务，这样就可以并行的读取文件了。FileInputFormat的第二步会接收一个input split，读取被split定义的文件范围，然后返回对应的数据。</p>
<p>DataStream应用中使用的FileInputFormat需要实现CheckpointableInputFormat接口。这个接口定义了方法来做检查点和重置文件片段的当前的读取位置。</p>
<p>在Flink 1.7中，Flink提供了一些类，这些类继承了FileInputFormat，并实现了CheckpointableInputFormat接口。TextInputFormat一行一行的读取文件，而CsvInputFormat使用逗号分隔符来读取文件。</p>
<h3 id="文件系统sink连接器"><a href="#文件系统sink连接器" class="headerlink" title="文件系统sink连接器"></a>文件系统sink连接器</h3><p>在将流处理应用配置成exactly-once检查点机制，以及配置成所有源数据都能在故障的情况下可以重置，Flink的StreamingFileSink提供了端到端的恰好处理一次语义保证。下面的例子展示了StreamingFileSink的使用方式。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[<span class="type">String</span>] = …</span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">StreamingFileSink</span>[<span class="type">String</span>] = <span class="type">StreamingFileSink</span></span><br><span class="line">  .forRowFormat(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Path</span>(<span class="string">"/base/path"</span>), </span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringEncoder</span>[<span class="type">String</span>](<span class="string">"UTF-8"</span>))</span><br><span class="line">  .build()</span><br><span class="line"></span><br><span class="line">input.addSink(sink)</span><br></pre></td></tr></table></figure></div>

<p>当StreamingFileSink接到一条数据，这条数据将被分配到一个桶（bucket）中。一个桶是我们配置的“/base/path”的子目录。</p>
<p>Flink使用BucketAssigner来分配桶。BucketAssigner是一个公共的接口，为每一条数据返回一个BucketId，BucketId决定了数据被分配到哪个子目录。如果没有指定BucketAssigner，Flink将使用DateTimeBucketAssigner来将每条数据分配到每个一个小时所产生的桶中去，基于数据写入的处理时间（机器时间，墙上时钟）。</p>
<p>StreamingFileSink提供了exactly-once输出的保证。sink通过一个commit协议来达到恰好处理一次语义的保证。这个commit协议会将文件移动到不同的阶段，有以下状态：in progress，pending，finished。这个协议基于Flink的检查点机制。当Flink决定roll a file时，这个文件将被关闭并移动到pending状态，通过重命名文件来实现。当下一个检查点完成时，pending文件将被移动到finished状态，同样是通过重命名来实现。</p>
<p>一旦任务故障，sink任务需要将处于in progress状态的文件重置到上一次检查点的写偏移量。这个可以通过关闭当前in progress的文件，并将文件结尾无效的部分丢弃掉来实现。</p>
<h2 id="实现自定义源函数"><a href="#实现自定义源函数" class="headerlink" title="实现自定义源函数"></a>实现自定义源函数</h2><p>DataStream API提供了两个接口来实现source连接器：</p>
<ul>
<li>SourceFunction和RichSourceFunction可以用来定义非并行的source连接器，source跑在单任务上。</li>
<li>ParallelSourceFunction和RichParallelSourceFunction可以用来定义跑在并行实例上的source连接器。</li>
</ul>
<p>除了并行于非并行的区别，这两种接口完全一样。就像process function的rich版本一样，RichSourceFunction和RichParallelSourceFunction的子类可以override open()和close()方法，也可以访问RuntimeContext，RuntimeContext提供了并行任务实例的数量，当前任务实例的索引，以及一些其他信息。</p>
<p>SourceFunction和ParallelSourceFunction定义了两种方法：</p>
<ul>
<li>void run(SourceContext ctx)</li>
<li>cancel()</li>
</ul>
<p>run()方法用来读取或者接收数据然后将数据摄入到Flink应用中。根据接收数据的系统，数据可能是推送的也可能是拉取的。Flink仅仅在特定的线程调用run()方法一次，通常情况下会是一个无限循环来读取或者接收数据并发送数据。任务可以在某个时间点被显式的取消，或者由于流是有限流，当数据被消费完毕时，任务也会停止。</p>
<p>当应用被取消或者关闭时，cancel()方法会被Flink调用。为了优雅的关闭Flink应用，run()方法需要在cancel()被调用以后，立即终止执行。下面的例子显示了一个简单的源函数的例子：从0数到Long.MaxValue。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountSource</span> <span class="keyword">extends</span> <span class="title">SourceFunction</span>[<span class="type">Long</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> isRunning: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">Long</span>]) = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> cnt: <span class="type">Long</span> = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning &amp;&amp; cnt &lt; <span class="type">Long</span>.<span class="type">MaxValue</span>) &#123;</span><br><span class="line">      cnt += <span class="number">1</span></span><br><span class="line">      ctx.collect(cnt)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>() = isRunning = <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="可重置的源函数"><a href="#可重置的源函数" class="headerlink" title="可重置的源函数"></a>可重置的源函数</h3><p>之前我们讲过，应用程序只有使用可以重播输出数据的数据源时，才能提供令人满意的一致性保证。如果外部系统暴露了获取和重置读偏移量的API，那么source函数就可以重播源数据。这样的例子包括一些能够提供文件流的偏移量的文件系统，或者提供seek方法用来移动到文件的特定位置的文件系统。或者Apache Kafka这种可以为每一个主题的分区提供偏移量并且可以设置分区的读位置的系统。一个反例就是source连接器连接的是socket，socket将会立即丢弃已经发送过的数据。</p>
<p>支持重播输出的源函数需要和Flink的检查点机制集成起来，还需要在检查点被处理时，持久化当前所有的读取位置。当应用从一个保存点（savepoint）恢复或者从故障恢复时，Flink会从最近一次的检查点或者保存点中获取读偏移量。如果程序开始时并不存在状态，那么读偏移量将会被设置到一个默认值。一个可重置的源函数需要实现CheckpointedFunction接口，还需要能够存储读偏移量和相关的元数据，例如文件的路径，分区的ID。这些数据将被保存在list state或者union list state中。</p>
<p>下面的例子将CountSource重写为可重置的数据源。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResettableCountSource</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">SourceFunction</span>[<span class="type">Long</span>] <span class="keyword">with</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> isRunning: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">var</span> cnt: <span class="type">Long</span> = _</span><br><span class="line">  <span class="keyword">var</span> offsetState: <span class="type">ListState</span>[<span class="type">Long</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">Long</span>]) = &#123;</span><br><span class="line">    <span class="keyword">while</span> (isRunning &amp;&amp; cnt &lt; <span class="type">Long</span>.<span class="type">MaxValue</span>) &#123;</span><br><span class="line">      <span class="comment">// synchronize data emission and checkpoints</span></span><br><span class="line">      ctx.getCheckpointLock.synchronized &#123;</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        ctx.collect(cnt)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>() = isRunning = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">snapshotState</span></span>(</span><br><span class="line">    snapshotCtx: <span class="type">FunctionSnapshotContext</span></span><br><span class="line">  ): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// remove previous cnt</span></span><br><span class="line">    offsetState.clear()</span><br><span class="line">    <span class="comment">// add current cnt</span></span><br><span class="line">    offsetState.add(cnt)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeState</span></span>(</span><br><span class="line">      initCtx: <span class="type">FunctionInitializationContext</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">val</span> desc = <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[<span class="type">Long</span>](</span><br><span class="line">      <span class="string">"offset"</span>, classOf[<span class="type">Long</span>])</span><br><span class="line">    offsetState = initCtx</span><br><span class="line">      .getOperatorStateStore</span><br><span class="line">      .getListState(desc)</span><br><span class="line">    <span class="comment">// initialize cnt variable</span></span><br><span class="line">    <span class="keyword">val</span> it = offsetState.get()</span><br><span class="line">    cnt = <span class="keyword">if</span> (<span class="literal">null</span> == it || !it.iterator().hasNext) &#123;</span><br><span class="line">      <span class="number">-1</span>L</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      it.iterator().next()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="实现自定义sink函数"><a href="#实现自定义sink函数" class="headerlink" title="实现自定义sink函数"></a>实现自定义sink函数</h2><p>DataStream API中，任何运算符或者函数都可以向外部系统发送数据。DataStream不需要最终流向sink运算符。例如，我们可能实现了一个FlatMapFunction，这个函数将每一个接收到的数据通过HTTP POST请求发送出去，而不使用Collector发送到下一个运算符。DataStream API也提供了SinkFunction接口以及对应的rich版本RichSinkFunction抽象类。SinkFunction接口提供了一个方法：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void invode(<span class="type">IN</span> value, <span class="type">Context</span> ctx)</span><br></pre></td></tr></table></figure></div>

<p>SinkFunction的Context可以访问当前处理时间，当前水位线，以及数据的时间戳。</p>
<p>下面的例子展示了一个简单的SinkFunction，可以将传感器读数写入到socket中去。需要注意的是，我们需要在启动Flink程序前启动一个监听相关端口的进程。否则将会抛出ConnectException异常。可以运行“nc -l localhost 9191”命令。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to a socket</span></span><br><span class="line">readings.addSink(<span class="keyword">new</span> <span class="type">SimpleSocketSink</span>(<span class="string">"localhost"</span>, <span class="number">9191</span>))</span><br><span class="line">  <span class="comment">// set parallelism to 1 because only one thread can write to a socket</span></span><br><span class="line">  .setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// -----</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleSocketSink</span>(<span class="params">val host: <span class="type">String</span>, val port: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> socket: <span class="type">Socket</span> = _</span><br><span class="line">  <span class="keyword">var</span> writer: <span class="type">PrintStream</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(config: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// open socket and writer</span></span><br><span class="line">    socket = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="type">InetAddress</span>.getByName(host), port)</span><br><span class="line">    writer = <span class="keyword">new</span> <span class="type">PrintStream</span>(socket.getOutputStream)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(</span><br><span class="line">      value: <span class="type">SensorReading</span>,</span><br><span class="line">      ctx: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// write sensor reading to socket</span></span><br><span class="line">    writer.println(value.toString)</span><br><span class="line">    writer.flush()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// close writer and socket</span></span><br><span class="line">    writer.close()</span><br><span class="line">    socket.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>之前我们讨论过，端到端的一致性保证建立在sink连接器的属性上面。为了达到端到端的恰好处理一次语义的目的，应用程序需要幂等性的sink连接器或者事务性的sink连接器。上面例子中的SinkFunction既不是幂等写入也不是事务性的写入。由于socket具有只能添加（append-only）这样的属性，所以不可能实现幂等性的写入。又因为socket不具备内置的事务支持，所以事务性写入就只能使用Flink的WAL sink特性来实现了。接下来我们将学习如何实现幂等sink连接器和事务sink连接器。</p>
<h3 id="幂等sink连接器"><a href="#幂等sink连接器" class="headerlink" title="幂等sink连接器"></a>幂等sink连接器</h3><p>对于大多数应用，SinkFunction接口足以实现一个幂等性写入的sink连接器了。需要以下两个条件：</p>
<ul>
<li>结果数据必须具有确定性的key，在这个key上面幂等性更新才能实现。例如一个计算每分钟每个传感器的平均温度值的程序，确定性的key值可以是传感器的ID和每分钟的时间戳。确定性的key值，对于在故障恢复的场景下，能够正确的覆盖结果非常的重要。</li>
<li>外部系统支持针对每个key的更新，例如关系型数据库或者key-value存储。</li>
</ul>
<p>下面的例子展示了如何实现一个针对JDBC数据库的幂等写入sink连接器，这里使用的是Apache Derby数据库。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to a Derby table</span></span><br><span class="line">readings.addSink(<span class="keyword">new</span> <span class="type">DerbyUpsertSink</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// -----</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DerbyUpsertSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> conn: <span class="type">Connection</span> = _</span><br><span class="line">  <span class="keyword">var</span> insertStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="keyword">var</span> updateStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// connect to embedded in-memory Derby</span></span><br><span class="line">    conn = <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">       <span class="string">"jdbc:derby:memory:flinkExample"</span>,</span><br><span class="line">       <span class="keyword">new</span> <span class="type">Properties</span>())</span><br><span class="line">    <span class="comment">// prepare insert and update statements</span></span><br><span class="line">    insertStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"INSERT INTO Temperatures (sensor, temp) VALUES (?, ?)"</span>)</span><br><span class="line">    updateStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"UPDATE Temperatures SET temp = ? WHERE sensor = ?"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(r: <span class="type">SensorReading</span>, context: <span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// set parameters for update statement and execute it</span></span><br><span class="line">    updateStmt.setDouble(<span class="number">1</span>, r.temperature)</span><br><span class="line">    updateStmt.setString(<span class="number">2</span>, r.id)</span><br><span class="line">    updateStmt.execute()</span><br><span class="line">    <span class="comment">// execute insert statement</span></span><br><span class="line">    <span class="comment">// if update statement did not update any row</span></span><br><span class="line">    <span class="keyword">if</span> (updateStmt.getUpdateCount == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// set parameters for insert statement</span></span><br><span class="line">      insertStmt.setString(<span class="number">1</span>, r.id)</span><br><span class="line">      insertStmt.setDouble(<span class="number">2</span>, r.temperature)</span><br><span class="line">      <span class="comment">// execute insert statement</span></span><br><span class="line">      insertStmt.execute()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    insertStmt.close()</span><br><span class="line">    updateStmt.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>由于Apache Derby并没有提供内置的UPSERT方法，所以这个sink连接器实现了UPSERT写。具体实现方法是首先去尝试更新一行数据，如果这行数据不存在，则插入新的一行数据。</p>
<h3 id="事务性sink连接器"><a href="#事务性sink连接器" class="headerlink" title="事务性sink连接器"></a>事务性sink连接器</h3><p>事务写入sink连接器需要和Flink的检查点机制集成，因为只有在检查点成功完成以后，事务写入sink连接器才会向外部系统commit数据。</p>
<p>为了简化事务性sink的实现，Flink提供了两个模版用来实现自定义sink运算符。这两个模版都实现了CheckpointListener接口。CheckpointListener接口将会从JobManager接收到检查点完成的通知。</p>
<ul>
<li>GenericWriteAheadSink模版会收集检查点之前的所有的数据，并将数据存储到sink任务的运算符状态中。状态保存到了检查点中，并在任务故障的情况下恢复。当任务接收到检查点完成的通知时，任务会将所有的数据写入到外部系统中。</li>
<li>TwoPhaseCommitSinkFunction模版利用了外部系统的事务特性。对于每一个检查点，任务首先开始一个新的事务，并将接下来所有的数据都写到外部系统的当前事务上下文中去。当任务接收到检查点完成的通知时，sink连接器将会commit这个事务。</li>
</ul>
<p><em>GENERICWRITEAHEADSINK</em></p>
<p>GenericWriteAheadSink使得sink运算符可以很方便的实现。这个运算符和Flink的检查点机制集成使用，目标是将每一条数据恰好一次写入到外部系统中去。需要注意的是，在发生故障的情况下，write-ahead log sink可能会不止一次的发送相同的数据。所以GenericWriteAheadSink无法提供完美无缺的恰好处理一次语义的一致性保证，而是仅能提供at-least-once这样的保证。我们接下来详细的讨论这些场景。</p>
<p>GenericWriteAheadSink的原理是将接收到的所有数据都追加到有检查点分割好的预写式日志中去。每当sink运算符碰到检查点屏障，运算符将会开辟一个新的section，并将接下来的所有数据都追加到新的section中去。WAL（预写式日志）将会保存到运算符状态中。由于log能被恢复，所有不会有数据丢失。</p>
<p>当GenericWriteAheadSink接收到检查点完成的通知时，将会发送对应检查点的WAL中存储的所有数据。当所有数据发送成功，对应的检查点必须在内部提交。</p>
<p>检查点的提交分两步。第一步，sink持久化检查点被提交的信息。第二步，删除WAL中所有的数据。我们不能将commit信息保存在Flink应用程序状态中，因为状态不是持久化的，会在故障恢复时重置状态。相反，GenericWriteAheadSink依赖于可插拔的组件在一个外部持久化存储中存储和查找提交信息。这个组件就是CheckpointCommitter。</p>
<p>继承GenericWriteAheadSink的运算符需要提供三个构造器函数。</p>
<ul>
<li>CheckpointCommitter</li>
<li>TypeSerializer，用来序列化输入数据。</li>
<li>一个job ID，传给CheckpointCommitter，当应用重启时可以识别commit信息。</li>
</ul>
<p>还有，write-ahead运算符需要实现一个单独的方法：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean sendValues(<span class="type">Iterable</span>&lt;<span class="type">IN</span>&gt; values, long chkpntId, long timestamp)</span><br></pre></td></tr></table></figure></div>

<p>当检查点完成时，GenericWriteAheadSink调用sendValues()方法来将数据写入到外部存储系统中。这个方法接收一个检查点对应的所有数据的迭代器，检查点的ID，检查点被处理时的时间戳。当数据写入成功时，方法必须返回true，写入失败返回false。</p>
<p>下面的例子展示了如何实现一个写入到标准输出的write-ahead sink。它使用了FileCheckpointCommitter。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to the standard out via a write-ahead log</span></span><br><span class="line">readings.transform(</span><br><span class="line">  <span class="string">"WriteAheadSink"</span>, <span class="keyword">new</span> <span class="type">SocketWriteAheadSink</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ```-</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StdOutWriteAheadSink</span> <span class="keyword">extends</span> <span class="title">GenericWriteAheadSink</span>[<span class="type">SensorReading</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    // <span class="type">CheckpointCommitter</span> that commits</span></span></span><br><span class="line"><span class="class"><span class="params">    // checkpoints to the local filesystem</span></span></span><br><span class="line"><span class="class"><span class="params">    new <span class="type">FileCheckpointCommitter</span>(<span class="type">System</span>.getProperty("java.io.tmpdir"</span>)),</span></span><br><span class="line"><span class="class">    <span class="title">//</span> <span class="title">Serializer</span> <span class="title">for</span> <span class="title">records</span></span></span><br><span class="line"><span class="class">    <span class="title">createTypeInformation</span>[<span class="type">SensorReading</span>]</span></span><br><span class="line"><span class="class">      .<span class="title">createSerializer</span>(<span class="params">new <span class="type">ExecutionConfig</span></span>),</span></span><br><span class="line"><span class="class">    <span class="title">//</span> <span class="title">Random</span> <span class="title">JobID</span> <span class="title">used</span> <span class="title">by</span> <span class="title">the</span> <span class="title">CheckpointCommitter</span></span></span><br><span class="line"><span class="class">    <span class="title">UUID</span>.<span class="title">randomUUID</span>.<span class="title">toString</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">sendValues</span></span>(</span><br><span class="line">      readings: <span class="type">Iterable</span>[<span class="type">SensorReading</span>],</span><br><span class="line">      checkpointId: <span class="type">Long</span>,</span><br><span class="line">      timestamp: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (r &lt;- readings.asScala) &#123;</span><br><span class="line">      <span class="comment">// write record to standard out</span></span><br><span class="line">      println(r)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>之前我们讲过，GenericWriteAheadSink无法提供完美的exactly-once保证。有两个故障状况会导致数据可能被发送不止一次。</p>
<ul>
<li>当任务执行sendValues()方法时，程序挂掉了。如果外部系统无法原子性的写入所有数据（要么都写入要么都不写），一些数据可能会写入，而另一些数据并没有被写入。由于checkpoint还没有commit，所以在任务恢复的过程中一些数据可能会被再次写入。</li>
<li>所有数据都写入成功了，sendValues()方法也返回true了；但在CheckpointCommitter方法被调用之前程序挂了，或者CheckpointCommitter在commit检查点时失败了。那么在恢复的过程中，所有未被提交的检查点将会被重新写入。</li>
</ul>
<p><em>TWOPHASECOMMITSINKFUNCTION</em></p>
<p>Flink提供了TwoPhaseCommitSinkFunction接口来简化sink函数的实现。这个接口保证了端到端的exactly-once语义。2PC sink函数是否提供这样的一致性保证取决于我们的实现细节。我们需要讨论一个问题：“2PC协议是否开销太大？”</p>
<p>通常来讲，为了保证分布式系统的一致性，2PC是一个非常昂贵的方法。尽管如此，在Flink的语境下，2PC协议针对每一个检查点只运行一次。TwoPhaseCommitSinkFunction和WAL sink很相似，不同点在于前者不会将数据收集到state中，而是会写入到外部系统事务的上下文中。</p>
<p>TwoPhaseCommitSinkFunction实现了以下协议。在sink任务发送出第一条数据之前，任务将在外部系统中开始一个事务，所有接下来的数据将被写入这个事务的上下文中。当JobManager初始化检查点并将检查点屏障插入到流中的时候，2PC协议的投票阶段开始。当运算符接收到检查点屏障，运算符将保存它的状态，当保存完成时，运算符将发送一个acknowledgement信息给JobManager。当sink任务接收到检查点屏障时，运算符将会持久化它的状态，并准备提交当前的事务，以及acknowledge JobManager中的检查点。发送给JobManager的acknowledgement信息类似于2PC协议中的commit投票。sink任务还不能提交事务，因为它还没有保证所有的任务都已经完成了它们的检查点操作。sink任务也会为下一个检查点屏障之前的所有数据开始一个新的事务。</p>
<p>当JobManager成功接收到所有任务实例发出的检查点操作成功的通知时，JobManager将会把检查点完成的通知发送给所有感兴趣的任务。这里的通知对应于2PC协议的提交命令。当sink任务接收到通知时，它将commit所有处于开启状态的事务。一旦sink任务acknowledge了检查点操作，它必须能够commit对应的事务，即使任务发生故障。如果commit失败，数据将会丢失。</p>
<p>让我们总结一下外部系统需要满足什么样的要求：</p>
<ul>
<li>外部系统必须提供事务支持，或者sink的实现能在外部系统上模拟事务功能。</li>
<li>在检查点操作期间，事务必须处于open状态，并接收这段时间数据的持续写入。</li>
<li>事务必须等到检查点操作完成的通知到来才可以提交。在恢复周期中，可能需要一段时间等待。如果sink系统关闭了事务（例如超时了），那么未被commit的数据将会丢失。</li>
<li>sink必须在进程挂掉后能够恢复事务。一些sink系统会提供事务ID，用来commit或者abort一个开始的事务。</li>
<li>commit一个事务必须是一个幂等性操作。sink系统或者外部系统能够观察到事务已经被提交，或者重复提交并没有副作用。</li>
</ul>
<p>下面的例子可能会让上面的一些概念好理解一些。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransactionalFileSink</span>(<span class="params">val targetPath: <span class="type">String</span>, val tempPath: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">TwoPhaseCommitSinkFunction</span>[(<span class="type">String</span>, <span class="type">Double</span>), <span class="type">String</span>, <span class="type">Void</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">      createTypeInformation[<span class="type">String</span>].createSerializer(new <span class="type">ExecutionConfig</span></span>),</span></span><br><span class="line"><span class="class">      <span class="title">createTypeInformation</span>[<span class="type">Void</span>].<span class="title">createSerializer</span>(<span class="params">new <span class="type">ExecutionConfig</span></span>)) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> transactionWriter: <span class="type">BufferedWriter</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Creates a temporary file for a transaction into</span></span><br><span class="line">  <span class="comment">// which the records are written.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">beginTransaction</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="comment">// path of transaction file</span></span><br><span class="line">    <span class="comment">// is built from current time and task index</span></span><br><span class="line">    <span class="keyword">val</span> timeNow = <span class="type">LocalDateTime</span>.now(<span class="type">ZoneId</span>.of(<span class="string">"UTC"</span>))</span><br><span class="line">      .format(<span class="type">DateTimeFormatter</span>.<span class="type">ISO_LOCAL_DATE_TIME</span>)</span><br><span class="line">    <span class="keyword">val</span> taskIdx = <span class="keyword">this</span>.getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line">    <span class="keyword">val</span> transactionFile = <span class="string">s"<span class="subst">$timeNow</span>-<span class="subst">$taskIdx</span>"</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// create transaction file and writer</span></span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transactionFile</span>"</span>)</span><br><span class="line">    <span class="type">Files</span>.createFile(tFilePath)</span><br><span class="line">    <span class="keyword">this</span>.transactionWriter = <span class="type">Files</span>.newBufferedWriter(tFilePath)</span><br><span class="line">    println(<span class="string">s"Creating Transaction File: <span class="subst">$tFilePath</span>"</span>)</span><br><span class="line">    <span class="comment">// name of transaction file is returned to</span></span><br><span class="line">    <span class="comment">// later identify the transaction</span></span><br><span class="line">    transactionFile</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Write record into the current transaction file. */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(</span><br><span class="line">      transaction: <span class="type">String</span>,</span><br><span class="line">      value: (<span class="type">String</span>, <span class="type">Double</span>),</span><br><span class="line">      context: <span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    transactionWriter.write(value.toString)</span><br><span class="line">    transactionWriter.write('\n')</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Flush and close the current transaction file. */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">preCommit</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    transactionWriter.flush()</span><br><span class="line">    transactionWriter.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Commit a transaction by moving</span></span><br><span class="line">  <span class="comment">// the precommitted transaction file</span></span><br><span class="line">  <span class="comment">// to the target directory.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">commit</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">    <span class="comment">// check if the file exists to ensure</span></span><br><span class="line">    <span class="comment">// that the commit is idempotent</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="type">Files</span>.exists(tFilePath)) &#123;</span><br><span class="line">      <span class="keyword">val</span> cFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$targetPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">      <span class="type">Files</span>.move(tFilePath, cFilePath)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Aborts a transaction by deleting the transaction file.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">abort</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">Files</span>.exists(tFilePath)) &#123;</span><br><span class="line">      <span class="type">Files</span>.delete(tFilePath)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>TwoPhaseCommitSinkFunction[IN, TXN, CONTEXT]包含如下三个范型参数：</p>
<ul>
<li>IN表示输入数据的类型。</li>
<li>TXN定义了一个事务的标识符，可以用来识别和恢复事务。</li>
<li>CONTEXT定义了自定义的上下文。</li>
</ul>
<p>TwoPhaseCommitSinkFunction的构造器需要两个TypeSerializer。一个是TXN的类型，另一个是CONTEXT的类型。</p>
<p>最后，TwoPhaseCommitSinkFunction定义了五个需要实现的方法：</p>
<ul>
<li>beginTransaction(): TXN开始一个事务，并返回事务的标识符。</li>
<li>invoke(txn: TXN, value: IN, context: Context[_]): Unit将值写入到当前事务中。</li>
<li>preCommit(txn: TXN): Unit预提交一个事务。一个预提交的事务不会接收新的写入。</li>
<li>commit(txn: TXN): Unit提交一个事务。这个操作必须是幂等的。</li>
<li>abort(txn: TXN): Unit终止一个事务。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Yang4</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/">https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://masteryang4.github.io">MasterYangBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%99%E7%A8%8B/">教程    </a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据    </a><a class="post-meta__tags" href="/tags/flink/">flink    </a></div><div class="post_share"><div class="social-share" data-image="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://pic.downk.cc/item/5ea1a251c2a9a83be535b287.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://pic.downk.cc/item/5ea1a33ac2a9a83be536f9bc.png" alt="支付宝"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/07/02/flink%E7%B3%BB%E5%88%9709%E6%90%AD%E5%BB%BAFlink%E8%BF%90%E8%A1%8C%E6%B5%81%E5%BC%8F%E5%BA%94%E7%94%A8/"><img class="prev_cover lazyload" data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>flink系列09搭建Flink运行流式应用</span></div></a></div><div class="next-post pull_right"><a href="/2020/07/02/flink%E7%B3%BB%E5%88%9707%E6%9C%89%E7%8A%B6%E6%80%81%E7%AE%97%E5%AD%90%E5%92%8C%E5%BA%94%E7%94%A8/"><img class="next_cover lazyload" data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>flink系列07有状态算子和应用</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/09/flink系列12电商用户行为分析/" title="flink系列12电商用户行为分析"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">flink系列12电商用户行为分析</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/flink系列11Table-API-和-Flink-SQL/" title="flink系列11Table API 和 Flink SQL"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">flink系列11Table API 和 Flink SQL</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/flink系列10Flink-CEP简介/" title="flink系列10Flink CEP简介"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">flink系列10Flink CEP简介</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/flink系列09搭建Flink运行流式应用/" title="flink系列09搭建Flink运行流式应用"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">flink系列09搭建Flink运行流式应用</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/flink系列07有状态算子和应用/" title="flink系列07有状态算子和应用"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">flink系列07有状态算子和应用</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/flink系列06基于时间和窗口的操作符/" title="flink系列06基于时间和窗口的操作符"><img class="relatedPosts_cover lazyload"data-src="https://pic.downk.cc/item/5ef7647614195aa59476f65a.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">flink系列06基于时间和窗口的操作符</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = false == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'IeiQD5I6g4Doamc68SctmEnW-gzGzoHsz',
  appKey:'ORWhRoGUBY02RR9DMa5OSIow',
  placeholder:'评论一下~（支持Markdown格式）',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Yang4</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>