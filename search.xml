<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>spark系列之spark-core</title>
    <url>/2020/06/19/spark%E7%B3%BB%E5%88%97%E4%B9%8Bspark-core/</url>
    <content><![CDATA[<h1 id="Spark内核概述"><a href="#Spark内核概述" class="headerlink" title="Spark内核概述"></a>Spark内核概述</h1><p>Spark内核泛指Spark的核心运行机制，包括Spark核心组件的运行机制、Spark任务调度机制、Spark内存管理机制、Spark核心功能的运行原理等，熟练掌握Spark内核原理，能够帮助我们更好地完成Spark代码设计，并能够帮助我们准确锁定项目运行过程中出现的问题的症结所在。</p>
<h2 id="Spark核心组件"><a href="#Spark核心组件" class="headerlink" title="Spark核心组件"></a>Spark核心组件</h2><p><strong>Driver</strong></p>
<p>Spark驱动器节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。Driver在Spark作业执行时主要负责：</p>
<p>1) 将用户程序转化为作业（Job）；</p>
<p>2) 在Executor之间调度任务（Task）；</p>
<p>3) 跟踪Executor的执行情况；</p>
<p>4) 通过UI展示查询运行情况；</p>
<p><strong>Executor</strong></p>
<p>Spark Executor节点是负责在Spark作业中运行具体任务，任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个Spark应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。</p>
<p>Executor有两个核心功能：</p>
<p>1) 负责运行组成Spark应用的任务，并将结果返回给驱动器（Driver）；</p>
<p>2) 它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p>
<h2 id="Spark通用运行流程"><a href="#Spark通用运行流程" class="headerlink" title="Spark通用运行流程"></a>Spark通用运行流程</h2><p><a href="https://pic.downk.cc/item/5eec244614195aa5949543db.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec244614195aa5949543db.png" class="lazyload"></a></p>
<p>上图为Spark通用运行流程图，体现了基本的Spark应用程序在部署中的基本提交流程。</p>
<p>这个流程是按照如下的核心步骤进行工作的：</p>
<p>1) 任务提交后，都会先启动Driver程序；</p>
<p>2) 随后Driver向集群管理器注册应用程序；</p>
<p>3) 之后集群管理器根据此任务的配置文件分配Executor并启动；</p>
<p>4) Driver开始执行main函数，Spark查询为懒执行，当执行到Action算子时开始反向推算，根据宽依赖进行Stage的划分，随后每一个Stage对应一个Taskset，Taskset中有多个Task，查找可用资源Executor进行调度；</p>
<p>5) 根据本地化原则，Task会被分发到指定的Executor去执行，在任务执行的过程中，Executor也会不断与Driver进行通信，报告任务运行情况。</p>
<h1 id="Spark部署模式"><a href="#Spark部署模式" class="headerlink" title="Spark部署模式"></a>Spark部署模式</h1><p>Spark支持多种集群管理器（Cluster Manager），分别为：</p>
<p>1) Standalone：独立模式，Spark原生的简单集群管理器，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统，使用Standalone可以很方便地搭建一个集群；</p>
<p>2) Hadoop YARN：统一的资源管理机制，在上面可以运行多套计算框架，如MR、Storm等。根据Driver在集群中的位置不同，分为yarn client和yarn cluster；</p>
<p>3) Apache Mesos：一个强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括Yarn。</p>
<p>4) K8S : 容器式部署环境。</p>
<p>实际上，除了上述这些通用的集群管理器外，Spark内部也提供了方便用户测试和学习的本地集群部署模式和Windows环境。由于在实际工厂环境下使用的绝大多数的集群管理器是Hadoop YARN，因此我们关注的重点是Hadoop YARN模式下的Spark集群部署。</p>
<h2 id="Yarn模式运行机制"><a href="#Yarn模式运行机制" class="headerlink" title="Yarn模式运行机制"></a>Yarn模式运行机制</h2><h3 id="YARN-Cluster模式"><a href="#YARN-Cluster模式" class="headerlink" title="YARN Cluster模式"></a>YARN Cluster模式</h3><p>1) 执行脚本提交任务，实际是启动一个SparkSubmit的JVM进程；</p>
<p>2) SparkSubmit类中的main方法反射调用YarnClusterApplication的main方法；</p>
<p>3) YarnClusterApplication创建Yarn客户端，然后向Yarn发送执行指令：bin/java ApplicationMaster；</p>
<p>4) Yarn框架收到指令后会在指定的NM中启动ApplicationMaster；</p>
<p>5) ApplicationMaster启动Driver线程，执行用户的作业；</p>
<p>6) AM向RM注册，申请资源；</p>
<p>7) 获取资源后AM向NM发送指令：bin/java CoarseGrainedExecutorBackend；</p>
<p>8) CoarseGrainedExecutorBackend进程会接收消息，跟Driver通信，注册已经启动的Executor；然后启动计算对象Executor等待接收任务</p>
<p>Driver分配任务并监控任务的执行。</p>
<blockquote>
<p>注意：SparkSubmit、ApplicationMaster和CoarseGrainedExecutorBackend是独立的进程；Driver是独立的线程；Executor和YarnClusterApplication是对象。</p>
</blockquote>
<p><strong>【9步】</strong></p>
<p><a href="https://pic.downk.cc/item/5eeb18e314195aa59476ee22.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eeb18e314195aa59476ee22.png" class="lazyload"></a></p>
<h3 id="YARN-Client模式"><a href="#YARN-Client模式" class="headerlink" title="YARN Client模式"></a>YARN Client模式</h3><p>1) 执行脚本提交任务，实际是启动一个SparkSubmit的JVM进程；</p>
<p>2) SparkSubmit类中的main方法反射调用用户代码的main方法；</p>
<p>3) 启动Driver线程，执行用户的作业，并创建ScheduleBackend；</p>
<p>4) YarnClientSchedulerBackend向RM发送指令：bin/java ExecutorLauncher；</p>
<p>5) Yarn框架收到指令后会在指定的NM中启动ExecutorLauncher（实际上还是调用ApplicationMaster的main方法）；</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ExecutorLauncher</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="type">ApplicationMaster</span>.main(args)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>6) AM向RM注册，申请资源；</p>
<p>7) 获取资源后AM向NM发送指令：bin/java CoarseGrainedExecutorBackend；</p>
<p>8) CoarseGrainedExecutorBackend进程会接收消息，跟Driver通信，注册已经启动的Executor；然后启动计算对象Executor等待接收任务</p>
<p>9) Driver分配任务并监控任务的执行。</p>
<blockquote>
<p>注意：SparkSubmit、ApplicationMaster和CoarseGrainedExecutorBackend是独立的进程；Executor和Driver是对象。</p>
</blockquote>
<p><a href="https://pic.downk.cc/item/5eecab6c14195aa59434d7ec.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eecab6c14195aa59434d7ec.png" class="lazyload"></a></p>
<h2 id="Standalone模式运行机制"><a href="#Standalone模式运行机制" class="headerlink" title="Standalone模式运行机制"></a>Standalone模式运行机制</h2><p>Standalone集群有2个重要组成部分，分别是：</p>
<p>1) Master(RM)：是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责；</p>
<p>2) Worker(NM)：是一个进程，一个Worker运行在集群中的一台服务器上，主要负责两个职责，一个是用自己的内存存储RDD的某个或某些partition；另一个是启动其他进程和线程（Executor），对RDD上的partition进行并行的处理和计算。</p>
<h3 id="Standalone-Cluster模式"><a href="#Standalone-Cluster模式" class="headerlink" title="Standalone Cluster模式"></a>Standalone Cluster模式</h3><p>在Standalone Cluster模式下，任务提交后，Master会找到一个Worker启动Driver。Driver启动后向Master注册应用程序，Master根据submit脚本的资源需求找到内部资源至少可以启动一个Executor的所有Worker，然后在这些Worker之间分配Executor，Worker上的Executor启动后会向Driver反向注册，所有的Executor注册完成后，Driver开始执行main函数，之后执行到Action算子时，开始划分Stage，每个Stage生成对应的taskSet，之后将Task分发到各个Executor上执行。</p>
<h3 id="Standalone-Client模式"><a href="#Standalone-Client模式" class="headerlink" title="Standalone Client模式"></a>Standalone Client模式</h3><p>在Standalone Client模式下，Driver在任务提交的本地机器上运行。Driver启动后向Master注册应用程序，Master根据submit脚本的资源需求找到内部资源至少可以启动一个Executor的所有Worker，然后在这些Worker之间分配Executor，Worker上的Executor启动后会向Driver反向注册，所有的Executor注册完成后，Driver开始执行main函数，之后执行到Action算子时，开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。</p>
<h1 id="Spark通讯架构"><a href="#Spark通讯架构" class="headerlink" title="Spark通讯架构"></a>Spark通讯架构</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Spark中通信框架的发展：</p>
<ul>
<li><p>Spark早期版本中采用Akka作为内部通信部件。</p>
</li>
<li><p>Spark1.3中引入Netty通信框架，为了解决Shuffle的大数据传输问题使用</p>
</li>
<li><p>Spark1.6中Akka和Netty可以配置使用。Netty完全实现了Akka在Spark中的功能。</p>
</li>
<li><p>Spark2系列中，Spark抛弃Akka，使用Netty。</p>
</li>
</ul>
<p>RPC通信协议原理图：</p>
<p><a href="https://i.loli.net/2020/06/19/18RpdelwZthvmG7.png" data-fancybox="group" data-caption="RPC1.png" class="fancybox"><img alt="RPC1.png" title="RPC1.png" data-src="https://i.loli.net/2020/06/19/18RpdelwZthvmG7.png" class="lazyload"></a></p>
<p>Spark通信终端</p>
<p>Driver:</p>
<p><code>class DriverEndpoint extends ThreadSafeRpcEndpoint</code></p>
<p>Executor</p>
<p><code>class CoarseGrainedExecutorBackend extends ThreadSafeRpcEndpoint</code></p>
<p><a href="https://pic.downk.cc/item/5eec269214195aa594979034.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec269214195aa594979034.png" class="lazyload"></a></p>
<h2 id="spark通讯架构解析"><a href="#spark通讯架构解析" class="headerlink" title="spark通讯架构解析"></a>spark通讯架构解析</h2><p><a href="https://pic.downk.cc/item/5eec26e514195aa59497cf6b.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec26e514195aa59497cf6b.png" class="lazyload"></a></p>
<ul>
<li><p>RpcEndpoint：RPC通信终端。Spark针对每个节点（Client/Master/Worker）都称之为一个RPC终端，且都实现RpcEndpoint接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用Dispatcher。在Spark中，所有的终端都存在生命周期：</p>
<ul>
<li>Constructor</li>
<li>onStart</li>
<li>receive*</li>
<li>onStop</li>
</ul>
</li>
<li><p>RpcEnv：RPC上下文环境，每个RPC终端运行时依赖的上下文环境称为RpcEnv；在把当前Spark版本中使用的NettyRpcEnv</p>
</li>
<li><p>Dispatcher：消息调度（分发）器，针对于RPC终端需要发送远程消息或者从远程RPC接收到的消息，分发至对应的指令收件箱（发件箱）。如果指令接收方是自己则存入收件箱，如果指令接收方不是自己，则放入发件箱；</p>
</li>
<li><p>Inbox：指令消息收件箱。一个本地RpcEndpoint对应一个收件箱，Dispatcher在每次向Inbox存入消息时，都将对应EndpointData加入内部ReceiverQueue中，另外Dispatcher创建时会启动一个单独线程进行轮询ReceiverQueue，进行收件箱消息消费；</p>
</li>
<li><p>RpcEndpointRef：RpcEndpointRef是对远程RpcEndpoint的一个引用。当我们需要向一个具体的RpcEndpoint发送消息时，一般我们需要获取到该RpcEndpoint的引用，然后通过该应用发送消息。</p>
</li>
<li><p>OutBox：指令消息发件箱。对于当前RpcEndpoint来说，一个目标RpcEndpoint对应一个发件箱，如果向多个目标RpcEndpoint发送信息，则有多个OutBox。当消息放入Outbox后，紧接着通过TransportClient将消息发送出去。消息放入发件箱以及发送过程是在同一个线程中进行；</p>
</li>
<li><p>RpcAddress：表示远程的RpcEndpointRef的地址，Host + Port。</p>
</li>
<li><p>TransportClient：Netty通信客户端，一个OutBox对应一个TransportClient，TransportClient不断轮询OutBox，根据OutBox消息的receiver信息，请求对应的远程TransportServer；</p>
</li>
<li><p>TransportServer：Netty通信服务端，一个RpcEndpoint对应一个TransportServer，接受远程消息后调用Dispatcher分发消息至对应收发件箱；</p>
</li>
</ul>
<h1 id="Spark任务调度机制"><a href="#Spark任务调度机制" class="headerlink" title="Spark任务调度机制"></a>Spark任务调度机制</h1><p>在生产环境下，Spark集群的部署方式一般为YARN-Cluster模式，之后的内核分析内容中我们默认集群的部署方式为YARN-Cluster模式。在上一章中我们讲解了Spark YARN-Cluster模式下的任务提交流程，但是我们并没有具体说明Driver的工作流程， Driver线程主要是初始化SparkContext对象，准备运行所需的上下文，然后一方面保持与ApplicationMaster的RPC连接，通过ApplicationMaster申请资源，另一方面根据用户业务逻辑开始调度任务，将任务下发到已有的空闲Executor上。</p>
<p>当ResourceManager向ApplicationMaster返回Container资源时，ApplicationMaster就尝试在对应的Container上启动Executor进程，Executor进程起来后，会向Driver反向注册，注册成功后保持与Driver的心跳，同时等待Driver分发任务，当分发的任务执行完毕后，将任务状态上报给Driver。</p>
<h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>当Driver起来后，Driver则会根据用户程序逻辑准备任务，并根据Executor资源情况逐步分发任务。在详细阐述任务调度前，首先说明下Spark里的几个概念。一个Spark应用程序包括Job、Stage以及Task三个概念：</p>
<p>1) Job是以Action方法为界，遇到一个Action方法则触发一个Job；</p>
<p>2) Stage是Job的子集，以RDD宽依赖(即Shuffle)为界，遇到Shuffle做一次划分；</p>
<p>3) Task是Stage的子集，以并行度(分区数)来衡量，分区数是多少，则有多少个task。</p>
<blockquote>
<p>Spark的任务调度总体来说分两路进行，一路是Stage级的调度，一路是Task级的调度。</p>
</blockquote>
<p><strong>【重点】总体调度流程</strong>如下图所示</p>
<p><a href="https://pic.downk.cc/item/5eece22914195aa5947d1eb5.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece22914195aa5947d1eb5.png" class="lazyload"></a></p>
<p>Spark RDD通过其Transactions操作，形成了RDD血缘（依赖）关系图，即DAG，最后通过Action的调用，触发Job并调度执行，执行过程中会创建两个调度器：DAGScheduler和TaskScheduler。</p>
<ul>
<li><p>DAGScheduler负责Stage级的调度，主要是将job切分成若干Stages，并将每个Stage打包成TaskSet交给TaskScheduler调度。</p>
</li>
<li><p>TaskScheduler负责Task级的调度，将DAGScheduler给过来的TaskSet按照指定的调度策略分发到Executor上执行，调度过程中SchedulerBackend负责提供可用资源，其中SchedulerBackend有多种实现，分别对接不同的资源管理系统。</p>
</li>
</ul>
<p><a href="https://pic.downk.cc/item/5eece28714195aa5947d9aaa.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece28714195aa5947d9aaa.png" class="lazyload"></a></p>
<blockquote>
<p>【扩展】EventQueue：双端（阻塞）队列；</p>
<p>​                BlockingQueue：阻塞队列</p>
</blockquote>
<p><strong>Driver初始化SparkContext过程中，会分别初始化DAGScheduler、TaskScheduler、SchedulerBackend以及HeartbeatReceiver，并启动SchedulerBackend以及HeartbeatReceiver。</strong></p>
<p>SchedulerBackend通过ApplicationMaster申请资源，并不断从TaskScheduler中拿到合适的Task分发到Executor执行。HeartbeatReceiver负责接收Executor的心跳信息，监控Executor的存活状况，并通知到TaskScheduler。</p>
<h2 id="Spark-Stage级调度"><a href="#Spark-Stage级调度" class="headerlink" title="Spark Stage级调度"></a>Spark Stage级调度</h2><p>Spark的任务调度是从DAG切割开始，主要是由DAGScheduler来完成。当遇到一个Action操作后就会触发一个Job的计算，并交给DAGScheduler来提交，下图是涉及到Job提交的相关方法调用流程图。</p>
<p><a href="https://pic.downk.cc/item/5eece2f214195aa5947e2440.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece2f214195aa5947e2440.png" class="lazyload"></a></p>
<p>1) Job由最终的RDD和Action方法封装而成；</p>
<p>2) SparkContext将Job交给DAGScheduler提交，它会根据RDD的血缘关系构成的DAG进行切分，将一个Job划分为若干Stages，具体划分策略是，由最终的RDD不断通过依赖回溯判断父依赖是否是宽依赖，即以Shuffle为界，划分Stage，窄依赖的RDD之间被划分到同一个Stage中，可以进行pipeline式的计算。划分的Stages分两类，一类叫做ResultStage，为DAG最下游的Stage，由Action方法决定，另一类叫做ShuffleMapStage，为下游Stage准备数据.，下面看一个简单的例子WordCount。</p>
<p><a href="https://pic.downk.cc/item/5eece31e14195aa5947e58cd.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece31e14195aa5947e58cd.png" class="lazyload"></a></p>
<p>Job由saveAsTextFile触发，该Job由RDD-3和saveAsTextFile方法组成，根据RDD之间的依赖关系从RDD-3开始回溯搜索，直到没有依赖的RDD-0，在回溯搜索过程中，RDD-3依赖RDD-2，并且是宽依赖，所以在RDD-2和RDD-3之间划分Stage，RDD-3被划到最后一个Stage，即ResultStage中，RDD-2依赖RDD-1，RDD-1依赖RDD-0，这些依赖都是窄依赖，所以将RDD-0、RDD-1和RDD-2划分到同一个Stage，形成pipeline操作。即ShuffleMapStage中，实际执行的时候，数据记录会一气呵成地执行RDD-0到RDD-2的转化。不难看出，其本质上是一个深度优先搜索（Depth First Search）算法。</p>
<p>一个Stage是否被提交，需要判断它的父Stage是否执行，只有在父Stage执行完毕才能提交当前Stage，如果一个Stage没有父Stage，那么从该Stage开始提交。Stage提交时会将Task信息（分区信息以及方法等）序列化并被打包成TaskSet交给TaskScheduler，一个Partition对应一个Task，另一方面TaskScheduler会监控Stage的运行状态，只有Executor丢失或者Task由于Fetch失败才需要重新提交失败的Stage以调度运行失败的任务，其他类型的Task失败会在TaskScheduler的调度过程中重试。</p>
<p>相对来说DAGScheduler做的事情较为简单，仅仅是在Stage层面上划分DAG，提交Stage并监控相关状态信息。TaskScheduler则相对较为复杂，下面详细阐述其细节。</p>
<h2 id="Spark-Task级调度"><a href="#Spark-Task级调度" class="headerlink" title="Spark Task级调度"></a>Spark Task级调度</h2><p>Spark Task的调度是由TaskScheduler来完成，由前文可知，DAGScheduler将Stage打包到TaskSet交给TaskScheduler，TaskScheduler会将TaskSet封装为TaskSetManager加入到调度队列中，TaskSetManager结构如下图所示。</p>
<p><a href="https://pic.downk.cc/item/5eece39914195aa5947eff2e.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece39914195aa5947eff2e.png" class="lazyload"></a></p>
<p><strong>TaskSetManager负责监控管理同一个Stage中的Tasks，TaskScheduler就是以TaskSetManager为单元来调度任务。</strong></p>
<p>前面也提到，TaskScheduler初始化后会启动SchedulerBackend，它负责跟外界打交道，接收Executor的注册信息，并维护Executor的状态，所以说SchedulerBackend是管“粮食”的，同时它在启动后会定期地去“询问”TaskScheduler有没有任务要运行，也就是说，它会定期地“问”TaskScheduler“我有这么余粮，你要不要啊”，TaskScheduler在SchedulerBackend“问”它的时候，会从调度队列中按照指定的调度策略选择TaskSetManager去调度运行，大致方法调用流程如下图所示：</p>
<p><a href="https://pic.downk.cc/item/5eece3e214195aa5947f601a.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece3e214195aa5947f601a.png" class="lazyload"></a></p>
<p>将<strong>TaskSetManager加入rootPool调度池中</strong>之后，调用SchedulerBackend的riviveOffers方法给driverEndpoint发送ReviveOffer消息；driverEndpoint收到ReviveOffer消息后调用makeOffers方法，过滤出活跃状态的Executor（这些Executor都是任务启动时反向注册到Driver的Executor），然后将Executor封装成WorkerOffer对象；准备好计算资源（WorkerOffer）后，taskScheduler基于这些资源调用resourceOffer在Executor上分配task。</p>
<h3 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h3><p>TaskScheduler支持两种调度策略，<strong>一种是FIFO，也是默认的调度策略</strong>，另一种是FAIR。在TaskScheduler初始化过程中会实例化rootPool，表示树的根节点，是Pool类型。</p>
<p>1) FIFO调度策略</p>
<p>如果是采用FIFO调度策略，则直接简单地将TaskSetManager按照先来先到的方式入队，出队时直接拿出最先进队的TaskSetManager，其树结构如下图所示，TaskSetManager保存在一个FIFO队列中。</p>
<p><a href="https://pic.downk.cc/item/5eece42314195aa5947fbfe5.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece42314195aa5947fbfe5.png" class="lazyload"></a></p>
<p>2) FAIR调度策略</p>
<p>FAIR调度策略的树结构如下图所示：</p>
<p><a href="https://pic.downk.cc/item/5eece44414195aa5947ff312.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece44414195aa5947ff312.png" class="lazyload"></a></p>
<p>FAIR模式中有一个rootPool和多个子Pool，各个子Pool中存储着所有待分配的TaskSetMagager。</p>
<p>在FAIR模式中，需要先对子Pool进行排序，再对子Pool里面的TaskSetManager进行排序，因为Pool和TaskSetMagager都继承了Schedulable特质，因此使用相同的排序算法。</p>
<p>排序过程的比较是基于Fair-share来比较的，<strong>每个要排序的对象包含三个属性: runningTasks值（正在运行的Task数）、minShare值（资源合理利用的值，比如核的利用率）、weight值</strong>，比较时会综合考量runningTasks值，minShare值以及weight值。</p>
<p>注意，minShare、weight的值均在公平调度配置文件fairscheduler.xml中被指定，调度池在构建阶段会读取此文件的相关配置。</p>
<ul>
<li><p>如果A对象的runningTasks大于它的minShare，B对象的runningTasks小于它的minShare，那么B排在A前面；（runningTasks比minShare小的先执行）</p>
</li>
<li><p>如果A、B对象的runningTasks都小于它们的minShare，那么就比较runningTasks与minShare的比值（minShare使用率），谁小谁排前面；（minShare使用率低的先执行）</p>
</li>
<li><p>如果A、B对象的runningTasks都大于它们的minShare，那么就比较runningTasks与weight的比值（权重使用率），谁小谁排前面。（权重使用率低的先执行）</p>
</li>
<li><p>如果上述比较均相等，则比较名字。</p>
</li>
</ul>
<p>整体上来说就是通过minShare和weight这两个参数控制比较过程，可以做到让minShare使用率和权重使用率少（实际运行task比例较少）的先运行。</p>
<p>FAIR模式排序完成后，所有的TaskSetManager被放入一个ArrayBuffer里，之后依次被取出并发送给Executor执行。</p>
<p>从调度队列中拿到TaskSetManager后，由于TaskSetManager封装了一个Stage的所有Task，并负责管理调度这些Task，那么接下来的工作就是TaskSetManager按照一定的规则一个个取出Task给TaskScheduler，TaskScheduler再交给SchedulerBackend去发到Executor上执行。</p>
<h3 id="本地化调度"><a href="#本地化调度" class="headerlink" title="本地化调度"></a>本地化调度</h3><p>WHY？【解决任务发给谁的问题】【其实就是计算和数据的相对位置】</p>
<blockquote>
<p>【移动数据不如移动计算】</p>
</blockquote>
<p>DAGScheduler切割Job，划分Stage, 通过调用submitStage来提交一个Stage对应的tasks，submitStage会调用submitMissingTasks，submitMissingTasks 确定每个需要计算的 task 的preferredLocations，通过调用getPreferrdeLocations()得到partition 的优先位置，由于一个partition对应一个Task，此partition的优先位置就是task的优先位置，对于要提交到TaskScheduler的TaskSet中的每一个Task，该task优先位置与其对应的partition对应的优先位置一致。</p>
<p>从调度队列中拿到TaskSetManager后，那么接下来的工作就是TaskSetManager按照一定的规则一个个取出task给TaskScheduler，TaskScheduler再交给SchedulerBackend去发到Executor上执行。前面也提到，TaskSetManager封装了一个Stage的所有Task，并负责管理调度这些Task。</p>
<p>根据每个Task的优先位置，确定Task的Locality级别，Locality一共有五种，优先级由高到低顺序：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>解析</th>
</tr>
</thead>
<tbody><tr>
<td>PROCESS_LOCAL</td>
<td>进程本地化，task和数据在同一个Executor中，性能最好。</td>
</tr>
<tr>
<td>NODE_LOCAL</td>
<td>节点本地化，task和数据在同一个节点中，但是task和数据不在同一个Executor中，数据需要在进程间进行传输。</td>
</tr>
<tr>
<td>RACK_LOCAL</td>
<td>机架本地化，task和数据在同一个机架的两个节点上，数据需要通过网络在节点之间进行传输。</td>
</tr>
<tr>
<td>NO_PREF</td>
<td>对于task来说，从哪里获取都一样，没有好坏之分。</td>
</tr>
<tr>
<td>ANY</td>
<td>task和数据可以在集群的任何地方，而且不在一个机架中，性能最差。</td>
</tr>
</tbody></table>
<p>在调度执行时，Spark调度总是会尽量让每个task以最高的本地性级别来启动，当一个task以X本地性级别启动，但是该本地性级别对应的所有节点都没有空闲资源而启动失败，此时并不会马上降低本地性级别启动而是在某个时间长度内再次以X本地性级别来启动该task，若超过限时时间则降级启动，去尝试下一个本地性级别，依次类推。</p>
<p><strong>可以通过调大每个类别的最大容忍延迟时间，在等待阶段对应的Executor可能就会有相应的资源去执行此task，这就在在一定程度上提到了运行性能。</strong></p>
<h3 id="失败重试与黑名单机制"><a href="#失败重试与黑名单机制" class="headerlink" title="失败重试与黑名单机制"></a>失败重试与黑名单机制</h3><p>除了选择合适的Task调度运行外，还需要监控Task的执行状态，前面也提到，与外部打交道的是SchedulerBackend，Task被提交到Executor启动执行后，Executor会将执行状态上报给SchedulerBackend，SchedulerBackend则告诉TaskScheduler，TaskScheduler找到该Task对应的TaskSetManager，并通知到该TaskSetManager，这样TaskSetManager就知道Task的失败与成功状态，对于失败的Task，会记录它失败的次数，如果失败次数还没有超过最大重试次数，那么就把它放回待调度的Task池子中，否则整个Application失败。</p>
<p><strong>在记录Task失败次数过程中，会记录它上一次失败所在的Executor Id和Host，这样下次再调度这个Task时，会使用黑名单机制，避免它被调度到上一次失败的节点上，起到一定的容错作用</strong>。黑名单记录Task上一次失败所在的Executor Id和Host，以及其对应的“拉黑”时间，“拉黑”时间是指这段时间内不要再往这个节点上调度这个Task了。</p>
<h1 id="Spark-shuffle解析"><a href="#Spark-shuffle解析" class="headerlink" title="Spark shuffle解析"></a>Spark shuffle解析</h1><blockquote>
<p>shuffle的本质就是落盘，关键是如何落盘，是排序后落盘还是不排序落盘</p>
</blockquote>
<h2 id="核心要点"><a href="#核心要点" class="headerlink" title="核心要点"></a>核心要点</h2><p><strong>ShuffleMapStage与ResultStage</strong></p>
<p><a href="https://pic.downk.cc/item/5eece31e14195aa5947e58cd.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece31e14195aa5947e58cd.png" class="lazyload"></a></p>
<p>在划分stage时，最后一个stage称为finalStage，它本质上是一个ResultStage对象，前面的所有stage被称为ShuffleMapStage。</p>
<p>ShuffleMapStage的结束伴随着shuffle文件的写磁盘。</p>
<p>ResultStage基本上对应代码中的action算子，即将一个函数应用在RDD的各个partition的数据集上，意味着一个job的运行结束。</p>
<h2 id="HashShuffle解析"><a href="#HashShuffle解析" class="headerlink" title="HashShuffle解析"></a>HashShuffle解析</h2><h3 id="未优化的HashShuffle"><a href="#未优化的HashShuffle" class="headerlink" title="未优化的HashShuffle"></a>未优化的HashShuffle</h3><p>这里我们先明确一个假设前提：每个Executor只有1个CPU core，也就是说，无论这个Executor上分配多少个task线程，同一时间都只能执行一个task线程。</p>
<p>如下图中有3个 Reducer，从Task 开始那边各自把自己进行 Hash 计算(分区器：hash/numreduce取模)，分类出3个不同的类别，每个 Task 都分成3种类别的数据，想把不同的数据汇聚然后计算出最终的结果，所以Reducer 会在每个 Task 中把属于自己类别的数据收集过来，汇聚成一个同类别的大集合，每1个 Task 输出3份本地文件，这里有4个 Mapper Tasks，所以总共输出了4个 Tasks x 3个分类文件 = 12个本地小文件。</p>
<p><a href="https://pic.downk.cc/item/5eec291b14195aa59499bc7c.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec291b14195aa59499bc7c.png" class="lazyload"></a></p>
<h3 id="优化的HashShuffle"><a href="#优化的HashShuffle" class="headerlink" title="优化的HashShuffle"></a>优化的HashShuffle</h3><p>优化的HashShuffle过程就是启用合并机制，合并机制就是复用buffer，开启合并机制的配置是spark.shuffle.consolidateFiles。该参数默认值为false，将其设置为true即可开启优化机制。通常来说，如果我们使用HashShuffleManager，那么都建议开启这个选项。</p>
<p>这里还是有4个Tasks，数据类别还是分成3种类型，因为Hash算法会根据你的 Key 进行分类，在同一个进程中，无论是有多少过Task，都会把同样的Key放在同一个Buffer里，然后把Buffer中的数据写入以Core数量为单位的本地文件中，(一个Core只有一种类型的Key的数据)，每1个Task所在的进程中，分别写入共同进程中的3份本地文件，这里有4个Mapper Tasks，所以总共输出是 2个Cores x 3个分类文件 = 6个本地小文件。</p>
<p><a href="https://pic.downk.cc/item/5eec293514195aa59499d446.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec293514195aa59499d446.png" class="lazyload"></a></p>
<h2 id="SortShuffle解析"><a href="#SortShuffle解析" class="headerlink" title="SortShuffle解析"></a>SortShuffle解析</h2><h3 id="普通SortShuffle"><a href="#普通SortShuffle" class="headerlink" title="普通SortShuffle"></a>普通SortShuffle</h3><p>在该模式下，数据会先写入一个数据结构，reduceByKey写入Map，一边通过Map局部聚合，一遍写入内存。Join算子写入ArrayList直接写入内存中。然后需要判断是否达到阈值，如果达到就会将内存数据结构的数据写入到磁盘，清空内存数据结构。</p>
<p>在溢写磁盘前，先根据key进行排序，排序过后的数据，会分批写入到磁盘文件中。默认批次为10000条，数据会以每批一万条写入到磁盘文件。写入磁盘文件通过缓冲区溢写的方式，每次溢写都会产生一个磁盘文件，也就是说一个Task过程会产生多个临时文件。</p>
<p>最后在每个Task中，将所有的临时文件合并，这就是merge过程，此过程将所有临时文件读取出来，一次写入到最终文件。意味着一个Task的所有数据都在这一个文件中。同时单独写一份索引文件，标识下游各个Task的数据在文件中的索引，start offset和end offset。</p>
<p><a href="https://pic.downk.cc/item/5eec294714195aa59499f0b0.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eec294714195aa59499f0b0.png" class="lazyload"></a></p>
<p><a href="https://pic.downk.cc/item/5eece5f014195aa594824296.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece5f014195aa594824296.png" class="lazyload"></a></p>
<h3 id="bypass-SortShuffle"><a href="#bypass-SortShuffle" class="headerlink" title="bypass SortShuffle"></a>bypass SortShuffle</h3><p>bypass运行机制的触发条件如下：</p>
<p><strong>1)不是聚合类的shuffle算子，比如reduceByKey。</strong></p>
<p><strong>2) shuffle reduce task数量小于spark.shuffle.sort.bypassMergeThreshold参数的值，默认为200。</strong></p>
<p>此时task会为每个reduce端的task都创建一个临时磁盘文件，并将数据按key进行hash然后根据key的hash值，将key写入对应的磁盘文件之中。当然，写入磁盘文件时也是先写入内存缓冲，缓冲写满之后再溢写到磁盘文件的。<strong>最后，同样会将所有临时磁盘文件都合并成一个磁盘文件，并创建一个单独的索引文件。</strong></p>
<p><strong>该过程的磁盘写机制其实跟未经优化的HashShuffleManager是一模一样的</strong>，因为都要创建数量惊人的磁盘文件，只是在最后会做一个磁盘文件的合并而已。因此少量的最终磁盘文件，也让该机制相对未经优化的HashShuffleManager来说，shuffle read的性能会更好。</p>
<p><strong>而该机制与普通SortShuffleManager运行机制的不同在于：不会进行排序。也就是说，启用该机制的最大好处在于，shuffle write过程中，不需要进行数据的排序操作，也就节省掉了这部分的性能开销。</strong></p>
<h1 id="Spark内存管理"><a href="#Spark内存管理" class="headerlink" title="Spark内存管理"></a>Spark内存管理</h1><h2 id="堆内和堆外内存规划"><a href="#堆内和堆外内存规划" class="headerlink" title="堆内和堆外内存规划"></a>堆内和堆外内存规划</h2><p>作为一个JVM 进程，Executor 的内存管理建立在JVM的内存管理之上，Spark对 JVM的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内内存受到JVM统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</p>
<p><a href="https://pic.downk.cc/item/5eece67e14195aa5948335f5.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece67e14195aa5948335f5.png" class="lazyload"></a></p>
<h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由Spark应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些Spark内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同。<br>Spark对堆内内存的管理是一种逻辑上的”规划式”的管理，因为对象实例占用内存的申请和释放都由JVM完成，Spark只能在申请后和释放前记录这些内存，我们来看其具体流程：<br>申请内存流程如下：<br>Spark 在代码中 new 一个对象实例；<br>JVM 从堆内内存分配空间，创建对象并返回对象引用；<br>Spark 保存该对象的引用，记录该对象占用的内存。<br>释放内存流程如下：</p>
<ol>
<li>Spark记录该对象释放的内存，删除该对象的引用；</li>
<li>等待JVM的垃圾回收机制释放该对象占用的堆内内存。<br>我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程——反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。<br>对于Spark中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被Spark标记为释放的对象实例，很有可能在实际上并没有被JVM回收，导致实际可用的内存小于Spark记录的可用内存。所以 Spark并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。<br>虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。</li>
</ol>
<h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p><strong>为了进一步优化内存的使用以及提高Shuffle时排序的效率，Spark引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。</strong><br>堆外内存意味着把内存对象分配在Java虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机）。这样做的结果就是能保持一个较小的堆，以减少垃圾收集对应用的影响。<br>利用JDK Unsafe API（从Spark 2.0开始，在管理堆外的存储内存时不再基于Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。<strong>堆外内存可以被精确地申请和释放（堆外内存之所以能够被精确的申请和释放，是由于内存的申请和释放不再通过JVM机制，而是直接向操作系统申请，JVM对于内存的清理是无法准确指定时间点的，因此无法实现精确的释放），而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。</strong><br><strong>在默认情况下堆外内存并不启用</strong>，可通过配置<code>spark.memory.offHeap.enabled</code> 参数启用，并由 <code>spark.memory.offHeap.size</code>参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p>
<h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在Spark最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在Spark应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置，堆内内存的分配如图所示：</p>
<p><a href="https://pic.downk.cc/item/5eece6fb14195aa59483f7f0.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece6fb14195aa59483f7f0.png" class="lazyload"></a></p>
<p>可以看到，可用的堆内内存的大小需要按照下列方式计算：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">可用的存储内存 &#x3D; systemMaxMemory * spark.storage.memoryFraction * spark.storage.safety Fraction</span><br><span class="line"></span><br><span class="line">可用的执行内存 &#x3D; systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safety Fraction</span><br></pre></td></tr></table></figure></div>

<p>其中systemMaxMemory取决于当前JVM堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的memoryFraction 参数和safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p>
<p>Storage内存和Execution内存都有预留空间，目的是防止OOM，因为Spark堆内内存大小的记录是不准确的，需要留出保险区域。</p>
<p><strong>堆外的空间分配较为简单，只有存储内存和执行内存</strong>，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。</p>
<p><a href="https://pic.downk.cc/item/5eece75d14195aa594849f09.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece75d14195aa594849f09.png" class="lazyload"></a></p>
<p>静态内存管理机制实现起来较为简单，但如果用户不熟悉Spark的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成”一半海水，一半火焰”的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p>
<h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域，统一内存管理的堆内内存结构如图所示：</p>
<p><a href="https://pic.downk.cc/item/5eece7a214195aa594850a7e.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece7a214195aa594850a7e.png" class="lazyload"></a></p>
<p>统一内存管理的堆外内存结构如下图所示：</p>
<p><a href="https://pic.downk.cc/item/5eece7ca14195aa594854ab4.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece7ca14195aa594854ab4.png" class="lazyload"></a></p>
<p>其中最重要的优化在于<strong>动态占用机制</strong>，其规则如下：</p>
<p>1) 设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；</p>
<p>2) 双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的Block）</p>
<p><strong>3) 执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后”归还”借用的空间；</strong></p>
<p><strong>4) 存储内存的空间被对方占用后，无法让对方”归还”，因为需要考虑 Shuffle过程中的很多因素，实现起来较为复杂。【为了让execution保证计算准确】</strong></p>
<p>统一内存管理的动态占用机制如图所示：</p>
<p>【重点】</p>
<p><a href="https://pic.downk.cc/item/5eece82214195aa59485e100.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eece82214195aa59485e100.png" class="lazyload"></a></p>
<p>凭借统一内存管理机制，Spark在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护Spark内存的难度，但并不意味着开发者可以高枕无忧。如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的RDD数据通常都是长期驻留内存的。所以要想充分发挥Spark的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。</p>
<h2 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h2><p>RDD的持久化机制</p>
<p>RDD的缓存过程</p>
<p>淘汰与落盘</p>
<h2 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h2><p>Shuffle Write</p>
<p>Shuffle Read</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">任务的划分：</span><br><span class="line">ShuffleMapStage(1) &#x3D;&gt; ShuffleMapTask(N) &#x3D;&gt; shuffle write</span><br><span class="line">                                        &#x3D;&gt; shuffle read</span><br><span class="line">ResultStage(1)     &#x3D;&gt; ResultTask(N)     &#x3D;&gt; shuffle read</span><br><span class="line"></span><br><span class="line">任务的封装：</span><br><span class="line">Task &#x3D;&gt; TaskSet &#x3D;&gt; TaskSetManager &#x3D;&gt; TaskPool</span><br><span class="line"></span><br><span class="line">任务调度器(默认使用FIFO)</span><br><span class="line">FIFO : 先进先出</span><br><span class="line">FAIR : 公平 （runningTasks, minShare, weight）sortWith</span><br><span class="line"></span><br><span class="line">任务本地化级别：</span><br><span class="line">PROCESS_LOCAL : 内存数据的数据处理</span><br><span class="line">NODE_LOCAL    : yarn集群的方式访问HDFS文件</span><br><span class="line">RACK_LOCAL</span><br><span class="line">Any</span><br><span class="line"></span><br><span class="line">任务的执行</span><br><span class="line">Driver &#x3D;&gt; encode(Task) &#x3D;&gt; RPC &#x3D;&gt; ExecutorBackend &#x3D;&gt; decode(Task) &#x3D;&gt; Executor</span><br><span class="line">Executor &#x3D;&gt; ThreadPool &#x3D;&gt; TaskRunner &#x3D;&gt; run &#x3D;&gt; Task.run &#x3D;&gt; XXXTask.runTask</span><br><span class="line"></span><br><span class="line">Shuffle管理器 :</span><br><span class="line">SortShuffleManager</span><br><span class="line"></span><br><span class="line">Shuffle Writer:</span><br><span class="line">1.UnsafeShuffleWriter &#x3D;&gt; SerializedShuffleHandle</span><br><span class="line">2.BypassMergeSortShuffleWriter &#x3D;&gt; BypassMergeSortShuffleHandle</span><br><span class="line"></span><br><span class="line">    没有预聚合功能 &amp; reduce阶段的分区数量 &lt;&#x3D; 阈值（200）</span><br><span class="line"></span><br><span class="line">    有预聚合功能的算子   : reduceByKey combineByKey, aggregateByKey, foldByKey</span><br><span class="line">    没有预聚合功能的算子 : groupByKey sortByKey</span><br><span class="line"></span><br><span class="line">    实现方式类似于HashShuffle</span><br><span class="line"></span><br><span class="line">3.SortShuffleWriter &#x3D;&gt; BaseShuffleHandle</span><br><span class="line"></span><br><span class="line">    写磁盘文件时，首席会按照分区进行排序，然后默认按照key.hashCode排序</span><br><span class="line">    排序时，如果超过内存阈值 ：5m</span><br><span class="line"></span><br><span class="line">预聚合的原理： 在shuffle落盘之前的聚合功能</span><br><span class="line">PartitionedAppendOnlyMap &#x3D;&gt; Hashtable &#x3D;&gt; ( (分区ID，Key)， value )</span><br><span class="line">不支持预聚合</span><br><span class="line">PartitionedPairBuffer &#x3D;&gt; ( (分区ID，Key)， value )</span><br><span class="line"></span><br><span class="line">Spark内存</span><br><span class="line">静态内存管理：</span><br><span class="line">    存储内存：</span><br><span class="line">    val systemMaxMemory &#x3D; conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)</span><br><span class="line">    val memoryFraction &#x3D; conf.getDouble(&quot;spark.storage.memoryFraction&quot;, 0.6)</span><br><span class="line">    val safetyFraction &#x3D; conf.getDouble(&quot;spark.storage.safetyFraction&quot;, 0.9)</span><br><span class="line">    (systemMaxMemory * memoryFraction * safetyFraction).toLong</span><br><span class="line">    执行内存：</span><br><span class="line">    val systemMaxMemory &#x3D; conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)</span><br><span class="line">    val memoryFraction &#x3D; conf.getDouble(&quot;spark.shuffle.memoryFraction&quot;, 0.2)</span><br><span class="line">    val safetyFraction &#x3D; conf.getDouble(&quot;spark.shuffle.safetyFraction&quot;, 0.8)</span><br><span class="line">    (systemMaxMemory * memoryFraction * safetyFraction).toLong</span><br><span class="line">统一内存管理</span><br><span class="line">    存储内存：</span><br><span class="line">     val usableMemory &#x3D; systemMemory - reservedMemory</span><br><span class="line">     val memoryFraction &#x3D; conf.getDouble(&quot;spark.memory.fraction&quot;, 0.6)</span><br><span class="line">     maxMemory &#x3D; (usableMemory * memoryFraction).toLong</span><br><span class="line">    onHeapStorageRegionSize &#x3D;</span><br><span class="line">        (maxMemory * conf.getDouble(&quot;spark.memory.storageFraction&quot;, 0.5)).toLong,</span><br><span class="line">    执行内存：</span><br><span class="line"></span><br><span class="line">Spark配置：</span><br><span class="line">spark.scheduler.mode : 任务调度器，默认为FIFO，可以改为FAIR</span><br><span class="line">spark.locality.wait: 本地化等待时间，默认3s</span><br><span class="line">spark.shuffle.sort.bypassMergeThreshold : 忽略排序的阈值</span><br><span class="line">spark.local.dir : 本地文件存储路径</span><br><span class="line">spark.shuffle.spill.batchSize : 溢写磁盘的数据量 10000</span><br><span class="line">spark.memory.useLegacyMode : 内存管理兼容模式</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>spark</tag>
        <tag>spark-core</tag>
      </tags>
  </entry>
  <entry>
    <title>spark系列之spark-streaming</title>
    <url>/2020/06/17/spark%E7%B3%BB%E5%88%97%E4%B9%8Bspark-streaming/</url>
    <content><![CDATA[<h1 id="SparkStreaming概述"><a href="#SparkStreaming概述" class="headerlink" title="SparkStreaming概述"></a>SparkStreaming概述</h1><h2 id="Spark-Streaming是什么"><a href="#Spark-Streaming是什么" class="headerlink" title="Spark Streaming是什么"></a>Spark Streaming是什么</h2><p>Spark Streaming用于流式数据的处理。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。</p>
<p>和Spark基于RDD的概念很相似，Spark Streaming使用<strong>离散化流(discretized stream)</strong>作为抽象表示，叫作DStream。DStream 是随时间推移而收到的数据的序列。在内部，每个时间区间收到的数据都作为 RDD 存在，而DStream是由这些RDD所组成的序列(因此得名“离散化”)。</p>
<h2 id="Spark-Streaming架构"><a href="#Spark-Streaming架构" class="headerlink" title="Spark Streaming架构"></a>Spark Streaming架构</h2><p>整体架构图</p>
<p><a href="https://pic.downk.cc/item/5ee9bd9ca240b370e3d63351.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5ee9bd9ca240b370e3d63351.png" class="lazyload"></a></p>
<p>spark-streaming架构图</p>
<p><a href="https://pic.downk.cc/item/5ee9bdaca240b370e3d646f8.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5ee9bdaca240b370e3d646f8.png" class="lazyload"></a></p>
<h2 id="背压机制"><a href="#背压机制" class="headerlink" title="背压机制"></a>背压机制</h2><p>Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。</p>
<p>为了更好的协调数据接收速率与资源处理能力，1.5版本开始Spark Streaming可以动态控制数据接收速率来适配集群数据处理能力。背压机制（即Spark Streaming Backpressure）: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。</p>
<p>通过属性<code>spark.streaming.backpressure.enabled</code>来控制是否启用backpressure机制，默认值false，即不启用。</p>
<h1 id="DStream入门"><a href="#DStream入门" class="headerlink" title="DStream入门"></a>DStream入门</h1><p>需求：使用netcat工具向9999端口不断的发送数据，通过SparkStreaming读取端口数据并统计不同单词出现的次数</p>
<p>maven依赖</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>WordCount案例代码</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.初始化Spark配置信息</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"StreamWordCount"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.初始化SparkStreamingContext</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.通过监控端口创建DStream，读进来的数据为一行行</span></span><br><span class="line">    <span class="keyword">val</span> lineStreams = ssc.socketTextStream(<span class="string">"linux1"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将每一行数据做切分，形成一个个单词</span></span><br><span class="line">    <span class="keyword">val</span> wordStreams = lineStreams.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将单词映射成元组（word,1）</span></span><br><span class="line">    <span class="keyword">val</span> wordAndOneStreams = wordStreams.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将相同的单词次数做统计</span></span><br><span class="line">    <span class="keyword">val</span> wordAndCountStreams = wordAndOneStreams.reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印</span></span><br><span class="line">    wordAndCountStreams.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//启动SparkStreamingContext</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>启动程序并通过netcat发送数据：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -lk 9999</span><br><span class="line">hello ysss</span><br></pre></td></tr></table></figure></div>

<p>WordCount解析</p>
<p>Discretized Stream是Spark Streaming的基础抽象，代表持续性的数据流和经过各种Spark原语操作后的结果数据流。在内部实现上，DStream是一系列连续的RDD来表示。<strong>每个RDD含有一段时间间隔内的数据。</strong></p>
<h1 id="DStream创建-数据源"><a href="#DStream创建-数据源" class="headerlink" title="DStream创建/数据源"></a>DStream创建/数据源</h1><h2 id="RDD队列"><a href="#RDD队列" class="headerlink" title="RDD队列"></a>RDD队列</h2><p>测试过程中，可以通过使用ssc.queueStream(queueOfRDDs)来创建DStream，每一个推送到这个队列中的RDD，都会作为一个DStream处理。</p>
<ul>
<li>需求：循环创建几个RDD，将RDD放入队列。通过SparkStream创建Dstream，计算WordCount</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming02_DStream_Queue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 环境对象</span></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="keyword">val</span> que = <span class="keyword">new</span> mutable.<span class="type">Queue</span>[<span class="type">RDD</span>[<span class="type">String</span>]]()</span><br><span class="line">        <span class="keyword">val</span> queDS: <span class="type">InputDStream</span>[<span class="type">String</span>] = ssc.queueStream(que)</span><br><span class="line">        queDS.print()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">        ssc.start()</span><br><span class="line"></span><br><span class="line">        println(<span class="string">"queue append item"</span>)</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="number">1</span> to <span class="number">5</span> ) &#123;</span><br><span class="line">            <span class="keyword">val</span> rdd = ssc.sparkContext.makeRDD(<span class="type">List</span>(<span class="string">"1"</span>,<span class="string">"2"</span>))</span><br><span class="line">            que += rdd</span><br><span class="line">            <span class="type">Thread</span>.sleep(<span class="number">2000</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// block</span></span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>结果</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-------------------------------------------</span><br><span class="line">Time: 1539075280000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(4,60)</span><br><span class="line">(0,60)</span><br><span class="line">(6,60)</span><br><span class="line">(8,60)</span><br><span class="line">(2,60)</span><br><span class="line">(1,60)</span><br><span class="line">(3,60)</span><br><span class="line">(7,60)</span><br><span class="line">(9,60)</span><br><span class="line">(5,60)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1539075284000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(4,60)</span><br><span class="line">(0,60)</span><br><span class="line">(6,60)</span><br><span class="line">(8,60)</span><br><span class="line">(2,60)</span><br><span class="line">(1,60)</span><br><span class="line">(3,60)</span><br><span class="line">(7,60)</span><br><span class="line">(9,60)</span><br><span class="line">(5,60)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1539075288000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(4,30)</span><br><span class="line">(0,30)</span><br><span class="line">(6,30)</span><br><span class="line">(8,30)</span><br><span class="line">(2,30)</span><br><span class="line">(1,30)</span><br><span class="line">(3,30)</span><br><span class="line">(7,30)</span><br><span class="line">(9,30)</span><br><span class="line">(5,30)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1539075292000 ms</span><br><span class="line">-------------------------------------------</span><br></pre></td></tr></table></figure></div>

<p>扩展，从文件中读取</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming03_DStream_File</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 环境对象</span></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 从文件夹中读取新的文件数据，功能不稳定 ，所以不推荐使用</span></span><br><span class="line">        <span class="comment">// flume更加专业，所以生产环境，监控文件或目录的变化，采集数据都使用flume</span></span><br><span class="line">        <span class="keyword">val</span> fileDS: <span class="type">DStream</span>[<span class="type">String</span>] = ssc.textFileStream(<span class="string">"in"</span>)</span><br><span class="line">        <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = fileDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map( (_, <span class="number">1</span>) )</span><br><span class="line">        <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line">        wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="自定义数据源"><a href="#自定义数据源" class="headerlink" title="自定义数据源"></a>自定义数据源</h2><p>需要继承Receiver，并实现onStart、onStop方法来自定义数据源采集。</p>
<ul>
<li>需求：自定义数据源，实现监控某个端口号，获取该端口号内容。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">BufferedReader</span>, <span class="type">InputStreamReader</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.net.<span class="type">Socket</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.<span class="type">StorageLevel</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">DStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.receiver.<span class="type">Receiver</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming04_DStream_DIY</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 环境对象</span></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 自定义数据采集器</span></span><br><span class="line">        <span class="keyword">val</span> myDS = ssc.receiverStream( <span class="keyword">new</span> <span class="type">MyReceiver</span>( <span class="string">"localhost"</span>, <span class="number">9999</span> ) )</span><br><span class="line">        <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = myDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map( (_, <span class="number">1</span>) )</span><br><span class="line">        <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line">        wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    自定义数据采集器</span></span><br><span class="line"><span class="comment">    模仿spark自带的socket采集器</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    1. 继承Receiver ,设定泛型（采集数据的类型）, 传递参数</span></span><br><span class="line"><span class="comment">    2. 重写方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// rdd cache, checkpoint</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">MyReceiver</span>(<span class="params">host:<span class="type">String</span>, port:<span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Receiver</span>[<span class="type">String</span>](<span class="params"><span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">var</span> socket: <span class="type">Socket</span> = _</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 接收数据</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> reader = <span class="keyword">new</span> <span class="type">BufferedReader</span>(</span><br><span class="line">                <span class="keyword">new</span> <span class="type">InputStreamReader</span>(</span><br><span class="line">                    socket.getInputStream,</span><br><span class="line">                    <span class="string">"UTF-8"</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">var</span> s : <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">            <span class="comment">// 网络编程中，获取的数据没有null的概念</span></span><br><span class="line">            <span class="comment">// 如果网络编程中，需要明确告知服务器，客户端不再传数据，需要发送特殊的指令</span></span><br><span class="line">            <span class="comment">// 文件读取时，如果读到结束的时候，获取的结果为null</span></span><br><span class="line">            <span class="keyword">while</span> ( (s = reader.readLine()) != <span class="literal">null</span> ) &#123;</span><br><span class="line">                <span class="comment">// 采集到数据后，进行封装(存储)</span></span><br><span class="line">                <span class="keyword">if</span> ( s != <span class="string">"-END-"</span> ) &#123;</span><br><span class="line">                    store(s)</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// stop</span></span><br><span class="line">                    <span class="comment">// close</span></span><br><span class="line">                    <span class="comment">// 重启</span></span><br><span class="line">                    <span class="comment">//restart("")</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 启动采集器</span></span><br><span class="line">        <span class="comment">// 采集 &amp; 封装</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">            socket = <span class="keyword">new</span> <span class="type">Socket</span>(host, port)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"Socket Receiver"</span>) &#123;</span><br><span class="line">                setDaemon(<span class="literal">true</span>)</span><br><span class="line">                <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123; receive() &#125;</span><br><span class="line">            &#125;.start()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> ( socket != <span class="literal">null</span> ) &#123;</span><br><span class="line">                socket.close()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="kakfa数据源-重点"><a href="#kakfa数据源-重点" class="headerlink" title="kakfa数据源[重点]"></a>kakfa数据源[重点]</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>ReceiverAPI：需要一个专门的Executor去接收数据，然后发送给其他的Executor做计算。存在的问题，接收数据的Executor和计算的Executor速度会有所不同，特别在接收数据的Executor速度大于计算的Executor速度，会导致计算数据的节点内存溢出。</p>
<p>DirectAPI：是由计算的Executor来主动消费Kafka的数据，速度由自身控制。</p>
<h3 id="kafka-0-8-Receiver-模式"><a href="#kafka-0-8-Receiver-模式" class="headerlink" title="kafka 0-8 Receiver 模式"></a>kafka 0-8 Receiver 模式</h3><p>这种方式使用Receiver来获取数据。Receiver是使用Kafka的高层次Consumer API来实现的。receiver从Kafka中获取的数据都是存储在Spark Executor的内存中的（如果突然数据暴增，大量batch堆积，很容易出现内存溢出的问题），然后Spark Streaming启动的job会去处理那些数据。 </p>
<p>然而，在默认的配置下，这种方式可能会因为底层的失败而丢失数据。<strong>如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。</strong>该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-8_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">BufferedReader</span>, <span class="type">InputStreamReader</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.net.<span class="type">Socket</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.<span class="type">StorageLevel</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.receiver.<span class="type">Receiver</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming05_DStream_Kafka</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 环境对象</span></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 使用0.8版本的kafka - 接收器方式</span></span><br><span class="line">        <span class="comment">// 访问kakfa会有相应的工具类</span></span><br><span class="line">        <span class="keyword">val</span> kafkaDS: <span class="type">ReceiverInputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createStream(</span><br><span class="line">            ssc,</span><br><span class="line">            <span class="string">"linux1:2181,linux2:2181,linux3:2181"</span>,</span><br><span class="line">            <span class="string">"ysss191125"</span>,</span><br><span class="line">            <span class="type">Map</span>(<span class="string">"ysss191125"</span> -&gt; <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Kafka消息传递的时候以k-v对</span></span><br><span class="line">        <span class="comment">// k - 传值的时候提供的，默认为null,主要用于分区</span></span><br><span class="line">        <span class="comment">// v - message</span></span><br><span class="line">        kafkaDS.map(_._2).print()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka-0-8-Direct-模式"><a href="#kafka-0-8-Direct-模式" class="headerlink" title="kafka 0-8 Direct 模式"></a>kafka 0-8 Direct 模式</h3><p>这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。替代掉使用Receiver来接收数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。 </p>
<p>自动维护 offset</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerConfig</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming07_DStream_Kafka_Direct1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 这种方式，可以保证数据不丢失，但是可能会出现数据重复消费</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 环境对象 - 从checkpoint中读取数据偏移量</span></span><br><span class="line">        <span class="comment">//                 checkpoint还保存了计算逻辑,不适合扩展功能</span></span><br><span class="line">        <span class="comment">//                 checkpoint会延续计算，但是可能会压垮内存</span></span><br><span class="line">        <span class="comment">//                 checkpoint一般的存储路径为HDFS，所以会导致小文件过多。性能受到影响</span></span><br><span class="line">        <span class="comment">// 不推荐使用</span></span><br><span class="line">        <span class="keyword">val</span> ssc: <span class="type">StreamingContext</span> = <span class="type">StreamingContext</span>.getActiveOrCreate(<span class="string">"scp"</span>, () =&gt; getStreamingContext)</span><br><span class="line">        <span class="comment">// TODO 关闭连接环境</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getStreamingContext</span> </span>() = &#123;</span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">        ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 使用0.8版本的kafka - Direct方式 - 自动维护Offset</span></span><br><span class="line">        <span class="comment">// TODO 默认情况下，SparkStreaming采用checkpoint来保存kafka的数据偏移量</span></span><br><span class="line">        <span class="comment">// 访问kakfa会有相应的工具类</span></span><br><span class="line">        <span class="keyword">val</span> kafkaParamMap = <span class="type">Map</span>(</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"linux1:9092,linux2:9092,linux3:9092"</span>,</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"ysss191125new"</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">val</span> kafkaDS: <span class="type">InputDStream</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](</span><br><span class="line">            ssc,</span><br><span class="line">            kafkaParamMap,</span><br><span class="line">            <span class="type">Set</span>(<span class="string">"ysss191125new"</span>)</span><br><span class="line">        )</span><br><span class="line">        kafkaDS.map(_._2).print()</span><br><span class="line">        kafkaDS.print()</span><br><span class="line"></span><br><span class="line">        ssc</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>手动维护 offset</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></span><br><span class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></span><br><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerConfig</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.&#123;<span class="type">HasOffsetRanges</span>, <span class="type">KafkaUtils</span>, <span class="type">OffsetRange</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming08_DStream_Kafka_Direc2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 使用0.8版本的kafka - Direct方式 - 手动维护Offset</span></span><br><span class="line">        <span class="comment">// 所谓的手动维护，其实就是开发人员自己获取偏移量，并进行保存处理。</span></span><br><span class="line">        <span class="comment">// 通过保存的偏移量，可以动态获取kafka中指定位置的数据</span></span><br><span class="line">        <span class="comment">// offset会保存到kakfa集群的系统主题中__consumer_offsets</span></span><br><span class="line">        <span class="keyword">val</span> kafkaMap = <span class="type">Map</span>(</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"linux1:9092,linux2:9092,linux3:9092"</span>,</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"ysss191125123"</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">val</span> fromOffsets = <span class="type">Map</span>(</span><br><span class="line">            (<span class="type">TopicAndPartition</span>(<span class="string">"ysss191125new"</span>, <span class="number">0</span>), <span class="number">0</span>L),</span><br><span class="line">            (<span class="type">TopicAndPartition</span>(<span class="string">"ysss191125new"</span>, <span class="number">1</span>), <span class="number">1</span>L),</span><br><span class="line">            (<span class="type">TopicAndPartition</span>(<span class="string">"ysss191125new"</span>, <span class="number">2</span>), <span class="number">2</span>L)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">// TODO 从kafka中获取指定topic中指定offset的数据</span></span><br><span class="line">        <span class="keyword">val</span> kafkaDS: <span class="type">InputDStream</span>[<span class="type">String</span>] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>, <span class="type">String</span>](</span><br><span class="line">            ssc,</span><br><span class="line">            kafkaMap,</span><br><span class="line">            fromOffsets,</span><br><span class="line">            (m:<span class="type">MessageAndMetadata</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; m.message()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> offsetRanges = <span class="type">Array</span>.empty[<span class="type">OffsetRange</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 转换</span></span><br><span class="line">        <span class="comment">// 获取偏移量，一定要在最初的逻辑中获取，防止数据处理完毕后，无偏移量信息</span></span><br><span class="line">        kafkaDS.transform(rdd =&gt; &#123;</span><br><span class="line">            <span class="comment">// 获取RDD中的偏移量范围</span></span><br><span class="line">            <span class="comment">// 默认Spark中的RDD是没有offsetRanges方法，所以必须转换类型后才能使用</span></span><br><span class="line">            <span class="comment">// RDD 和 HasOffsetRanges有关系</span></span><br><span class="line">            offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">            rdd</span><br><span class="line">        &#125;).foreachRDD(rdd=&gt;&#123;</span><br><span class="line">            <span class="keyword">for</span> (o &lt;- offsetRanges) &#123;</span><br><span class="line">                println(<span class="string">s"<span class="subst">$&#123;o.topic&#125;</span> <span class="subst">$&#123;o.partition&#125;</span> <span class="subst">$&#123;o.fromOffset&#125;</span> <span class="subst">$&#123;o.untilOffset&#125;</span>"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            rdd.foreach(println)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka-0-10-Direct-模式"><a href="#kafka-0-10-Direct-模式" class="headerlink" title="kafka 0-10 Direct 模式"></a>kafka 0-10 Direct 模式</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-10_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>



<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerConfig</span>, <span class="type">ConsumerRecord</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.&#123;<span class="type">ConsumerStrategies</span>, <span class="type">KafkaUtils</span>, <span class="type">LocationStrategies</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming08_DStream_Kafka_Direc2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// 使用0.10版本的kafka - Direct方式 - 自动维护Offset</span></span><br><span class="line">        <span class="comment">// LocationStrategy : 位置策略</span></span><br><span class="line">        <span class="comment">// ConsumerStrategies : 消费策略</span></span><br><span class="line">        <span class="comment">// TODO sealed : 用于修饰类的关键字，表示密封类</span></span><br><span class="line">        <span class="comment">//              要求子类如果是样例类，必须全部在同一个源码文件中</span></span><br><span class="line">        <span class="keyword">val</span> kafkaMap = <span class="type">Map</span>(</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; <span class="string">"linux1:9092,linux2:9092,linux3:9092"</span>,</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">"ysss191125123"</span>,</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">KEY_DESERIALIZER_CLASS_CONFIG</span> -&gt; <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>,</span><br><span class="line">            <span class="type">ConsumerConfig</span>.<span class="type">VALUE_DESERIALIZER_CLASS_CONFIG</span> -&gt; <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">val</span> kafkaDS: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">            ssc,</span><br><span class="line">            <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,</span><br><span class="line">            <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">                <span class="type">Set</span>(<span class="string">"ysss191125new"</span>), kafkaMap</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        kafkaDS.map(_.value()).print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>手动维护可参考官网，和0-8手动维护类似。</p>
<p><strong>spark-streaming如何保证数据精准一次性处理呢？</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></span><br><span class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></span><br><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerConfig</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.&#123;<span class="type">HasOffsetRanges</span>, <span class="type">KafkaUtils</span>, <span class="type">OffsetRange</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming09_DStream_Kafka_Direc3</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 配置对象</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 数据处理</span></span><br><span class="line">        <span class="comment">// SparkStreaming消费Kafka数据时，手动维护offset的思路</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 1. 从指定的位置获取当前业务中保存的数据偏移量</span></span><br><span class="line">        <span class="comment">// mysql =&gt; message offset =&gt; 5</span></span><br><span class="line">        <span class="comment">// TODO 2. 从kafka中对应的分区里根据偏移量获取数据</span></span><br><span class="line">        <span class="comment">// topicAndPartition =&gt; topic : xxx, partition : 0, offset : 5</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 3. 消费数据时，需要将消费数据的偏移量拿到。</span></span><br><span class="line">        <span class="comment">// KafkaRDD =&gt; offsetRange =&gt; (5, 100)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 4. 执行业务操作。要求，偏移量的更新和业务要求在同一个事务中</span></span><br><span class="line">        <span class="comment">// Tx start</span></span><br><span class="line">        <span class="comment">//    service</span></span><br><span class="line">        <span class="comment">//    commit - offset -&gt; mysql</span></span><br><span class="line">        <span class="comment">// Tx commit</span></span><br><span class="line">        <span class="comment">// TODO 4.1 如果不使用事务，那么可能业务成功，但是offset提交失败</span></span><br><span class="line">        <span class="comment">//          会导致数据重复消费</span></span><br><span class="line">        <span class="comment">// TODO 4.2 如果不使用事务，那么可能offset提交成功，但是业务失败</span></span><br><span class="line">        <span class="comment">//          会导致数据丢失</span></span><br><span class="line">        <span class="comment">// TODO 4.3 分布式事务， 如果中间出现shuffle，怎么办？</span></span><br><span class="line">        <span class="comment">//          所以需要将数据拉取到driver端进行事务操作，保证数据不会出现问题。</span></span><br><span class="line">        <span class="comment">//          这样会导致driver的性能下降，所以其实不是一个好的选择。</span></span><br><span class="line">        <span class="comment">// SparkStreaming =&gt; 基本要求： 不丢失数据</span></span><br><span class="line">        <span class="comment">// Flink =&gt; 数据精准一次性处理。</span></span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="消费kafka数据模式总结"><a href="#消费kafka数据模式总结" class="headerlink" title="消费kafka数据模式总结"></a>消费kafka数据模式总结</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 0-8 ReceiverAPI:</span><br><span class="line">	1) 专门的Executor读取数据，速度不统一</span><br><span class="line">	2) 跨机器传输数据</span><br><span class="line">	3) Executor读取数据通过多个线程的方式，想要增加并行度，则需要多个流union</span><br><span class="line">	4) offset存储在zookeeper中</span><br><span class="line"></span><br><span class="line">-  0-8 DirectAPI:</span><br><span class="line">	1) Executor读取数据并计算</span><br><span class="line">	2) 增加Executor个数来增加消费的并行度</span><br><span class="line">	3) offset存储</span><br><span class="line">			a. CheckPoint(getActiveOrCreate方式创建StreamingContext)</span><br><span class="line">			b. 手动维护(有事务的存储系统)</span><br><span class="line">	4) 获取offset必须在第一个调用的算子中：</span><br><span class="line">			offsetRanges &#x3D; rdd.asInstanceOf[HasOffsetRanges].offsetRanges</span><br><span class="line"></span><br><span class="line">- 0-10 DirectAPI:</span><br><span class="line">	1) Executor读取数据并计算</span><br><span class="line">	2) 增加Executor个数来增加消费的并行度</span><br><span class="line">	3) offset存储</span><br><span class="line">			a. __consumer_offsets系统主题中</span><br><span class="line">			b. 手动维护(有事务的存储系统)</span><br></pre></td></tr></table></figure></div>

<h1 id="DStream转换"><a href="#DStream转换" class="headerlink" title="DStream转换"></a>DStream转换</h1><p>DStream上的操作与RDD的类似，分为Transformations（转换）和Output Operations（输出）两种，此外转换操作中还有一些比较特殊的原语，如：updateStateByKey()、transform()以及各种Window相关的原语。</p>
<h2 id="无状态转化操作"><a href="#无状态转化操作" class="headerlink" title="无状态转化操作"></a>无状态转化操作</h2><p>无状态转化操作就是把简单的RDD转化操作应用到每个批次上，也就是转化DStream中的每一个RDD。部分无状态转化操作列在了下表中。注意，针对键值对的DStream转化操作(比如 reduceByKey())要添加import StreamingContext._才能在Scala中使用。</p>
<p><a href="https://pic.downk.cc/item/5ee9cb92a240b370e3e84b0a.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5ee9cb92a240b370e3e84b0a.png" class="lazyload"></a></p>
<p>需要记住的是，尽管这些函数看起来像作用在整个流上一样，但<strong>事实上每个DStream在内部是由许多RDD（批次）组成，且无状态转化操作是分别应用到每个RDD上的。</strong></p>
<p>例如：reduceByKey()会归约每个时间区间中的数据，但不会归约不同区间之间的数据。</p>
<h3 id="transform"><a href="#transform" class="headerlink" title="transform"></a>transform</h3><p><strong>transform允许DStream上执行任意的RDD-to-RDD函数。</strong>即使这些函数并没有在DStream的API中暴露出来，通过该函数可以方便的扩展Spark API。该函数每一批次调度一次。其实也就是对DStream中的RDD应用转换。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming10_DStream_WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 可以将DStream转换为RDD进行操作。</span></span><br><span class="line">        <span class="comment">// DStream =&gt; old RDD =&gt; new RDD =&gt; new DStream</span></span><br><span class="line">        <span class="keyword">val</span> resultDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS.transform(</span><br><span class="line">            rdd =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> flatRDD = rdd.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">                <span class="keyword">val</span> mapRDD = flatRDD.map((_, <span class="number">1</span>))</span><br><span class="line">                <span class="keyword">val</span> reduceRDD = mapRDD.reduceByKey(_ + _)</span><br><span class="line">                reduceRDD</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        resultDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>相比直接在DStream上进行操作，transform的优势</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming11_DStream_Transform</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO transform可以获取底层的RDD进行处理</span></span><br><span class="line">        <span class="comment">// TODO transform可以周期性的执行driver的代码逻辑</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Code =&gt; Driver</span></span><br><span class="line"><span class="comment">//        val newDS: DStream[String] = socketDS.map(</span></span><br><span class="line"><span class="comment">//            dataString =&gt; &#123;</span></span><br><span class="line"><span class="comment">//                // Code = Executor</span></span><br><span class="line"><span class="comment">//                "string : " + dataString</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"><span class="comment">//        )</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Code = Driver</span></span><br><span class="line">        <span class="comment">// JDBC.getData();</span></span><br><span class="line">        <span class="keyword">val</span> newDS1: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.transform(</span><br><span class="line">            rdd =&gt; &#123;</span><br><span class="line">                <span class="comment">// Code = Driver</span></span><br><span class="line">                <span class="comment">// JDBC.getData();</span></span><br><span class="line">                println(<span class="type">Thread</span>.currentThread().getName)</span><br><span class="line">                rdd.map(</span><br><span class="line">                    dataString =&gt; &#123;</span><br><span class="line">                        <span class="comment">// Code = Executor</span></span><br><span class="line">                        <span class="string">"string : "</span> + dataString</span><br><span class="line">                        <span class="comment">// JDBC.updateData();</span></span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        newDS1.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p><strong>两个流之间的join需要两个流的批次大小一致</strong>，这样才能做到同时触发计算。计算过程就是对当前批次的两个流中各自的RDD进行join，与两个RDD的join效果相同。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming12_DStream_Join</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">        <span class="keyword">val</span> socketDS1: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line">        <span class="keyword">val</span> socketDS2: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> ds1: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS1.map((_,<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">val</span> ds2: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS2.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> joinDS: <span class="type">DStream</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = ds1.join(ds2)</span><br><span class="line"></span><br><span class="line">        joinDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="有状态转化操作"><a href="#有状态转化操作" class="headerlink" title="有状态转化操作"></a>有状态转化操作</h2><h3 id="UpdateStateByKey"><a href="#UpdateStateByKey" class="headerlink" title="UpdateStateByKey"></a>UpdateStateByKey</h3><p>UpdateStateByKey原语用于记录历史记录，有时，我们需要在DStream中跨批次维护状态(例如流计算中累加wordcount)。针对这种情况，updateStateByKey()为我们提供了对一个状态变量的访问，用于键值对形式的DStream。给定一个由(键，事件)对构成的 DStream，并传递一个指定如何根据新的事件更新每个键对应状态的函数，它可以构建出一个新的 DStream，其内部数据为(键，状态) 对。</p>
<p>updateStateByKey() 的结果会是一个新的DStream，其内部的RDD 序列是由每个时间区间对应的(键，状态)对组成的。</p>
<p>updateStateByKey操作使得我们可以在用新信息进行更新时保持任意的状态。为使用这个功能，需要做下面两步：</p>
<ul>
<li><p>定义状态，状态可以是一个任意的数据类型。</p>
</li>
<li><p>定义状态更新函数，用此函数阐明如何使用之前的状态和来自输入流的新值对状态进行更新。</p>
</li>
</ul>
<p>使用updateStateByKey需要对检查点目录进行配置，会使用检查点来保存状态。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming13_DStream_State</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line">        ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line">        <span class="keyword">val</span> socketDS = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map((_,<span class="number">1</span>))</span><br><span class="line">        <span class="comment">// TODO 使用有状态操作updateStateByKey保存数据</span></span><br><span class="line">        <span class="comment">// SparkStreaming的状态保存依赖的是checkpoint,所以需要设定相关路径</span></span><br><span class="line">        <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = wordToOneDS.updateStateByKey[<span class="type">Long</span>](</span><br><span class="line">            <span class="comment">// 累加器 = 6</span></span><br><span class="line">            <span class="comment">// UDAF = 8</span></span><br><span class="line">            <span class="comment">// TODO 第一个参数表示相同key的value数据集合</span></span><br><span class="line">            <span class="comment">// TODO 第二个参数表示相同key的缓冲区的数据</span></span><br><span class="line">            (seq: <span class="type">Seq</span>[<span class="type">Int</span>], buffer: <span class="type">Option</span>[<span class="type">Long</span>]) =&gt; &#123;</span><br><span class="line">                <span class="comment">// TODO 返回值表示更新后的缓冲区的值</span></span><br><span class="line">                <span class="keyword">val</span> newBufferValue = buffer.getOrElse(<span class="number">0</span>L) + seq.sum</span><br><span class="line">                <span class="type">Option</span>(newBufferValue)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="WindowOperations"><a href="#WindowOperations" class="headerlink" title="WindowOperations"></a>WindowOperations</h3><p>Window Operations可以设置窗口的大小和滑动窗口的间隔来动态的获取当前Steaming的允许状态。所有基于窗口的操作都需要两个参数，分别为窗口时长以及滑动步长。</p>
<ul>
<li><p>窗口时长：计算内容的时间范围；</p>
</li>
<li><p>滑动步长：隔多久触发一次计算。</p>
</li>
</ul>
<p><strong>注意：这两者都必须为采集周期大小的整数倍。</strong></p>
<p>【回顾】scala语言中的window</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">DStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming14_DStream_Window</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// overflow : 滚动 -&gt; StackOverflowError -&gt; 栈溢出</span></span><br><span class="line">        <span class="comment">// 滑动</span></span><br><span class="line">        <span class="comment">// flatMap =&gt; 整体-&gt;个体</span></span><br><span class="line">        <span class="comment">// sliding =&gt; 整体连续部分（3） -&gt; 整体</span></span><br><span class="line">        <span class="comment">// 将sliding中的范围称之为窗口，其中的数据就称之为窗口数据</span></span><br><span class="line">        <span class="comment">// 窗口可以动态调整，向后滑动。</span></span><br><span class="line">        <span class="keyword">val</span> iterator: <span class="type">Iterator</span>[<span class="type">List</span>[<span class="type">Int</span>]] = list.sliding(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">while</span> ( iterator.hasNext ) &#123;</span><br><span class="line">            println(iterator.next())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><code>window(windowLength, slideInterval):</code></p>
<p>基于对源DStream窗化的批次进行计算返回一个新的Dstream；</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming15_DStream_Window1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 滑窗</span></span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设定窗口。将2个采集周期的数据当成一个整体进行处理</span></span><br><span class="line">        <span class="comment">// 默认窗口是可以滑动的。滑动的幅度为一个采集周期</span></span><br><span class="line">        <span class="comment">// 可以动态改变滑动幅度</span></span><br><span class="line">        <span class="comment">// 如果两个窗口移动过程中，没有重合的数据，称之为滚动窗口</span></span><br><span class="line">        <span class="comment">// window方法的第一个参数表示窗口的范围大小，以采集周期为单位</span></span><br><span class="line">        <span class="comment">// window方法的第二个参数表示窗口的滑动幅度，也表示计算的周期</span></span><br><span class="line">        <span class="keyword">val</span> windowDS: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.window(</span><br><span class="line">            <span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">        windowDS</span><br><span class="line">            .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">            .map((_,<span class="number">1</span>))</span><br><span class="line">            .reduceByKey(_+_)</span><br><span class="line">            .print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><code>reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks]):</code></p>
<p>当在一个(K,V)对的DStream上调用此函数，会返回一个新(K,V)对的DStream，此处通过对滑动窗口中批次数据使用reduce函数来整合每个key的value值。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming17_DStream_Window3</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 滑窗</span></span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS</span><br><span class="line">                .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">                .map((_, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">val</span> windowDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKeyAndWindow(</span><br><span class="line">            (x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x + y, <span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        windowDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><code>reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, [numTasks]):</code></p>
<p>这个函数是上述函数的变化版本，每个窗口的reduce值都是通过用前一个窗的reduce值来递增计算。通过reduce进入到滑动窗口数据并”反向reduce”离开窗口的旧数据来实现这个操作。一个例子是随着窗口滑动对keys的“加”“减”计数。通过前边介绍可以想到，这个函数只适用于”可逆的reduce函数”，也就是这些reduce函数有相应的”反reduce”函数(以参数invFunc形式传入)。如前述函数，reduce任务的数量通过可选参数来配置。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming19_DStream_Window5</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">        ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line">        <span class="comment">// 滑窗</span></span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = socketDS.map(num=&gt;(<span class="string">"a"</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">val</span> windowDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKeyAndWindow(</span><br><span class="line">            (x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> sum = x + y</span><br><span class="line">                println( sum + <span class="string">"="</span> + x + <span class="string">"+"</span> + y )</span><br><span class="line">                sum</span><br><span class="line">            &#125;,</span><br><span class="line">            (x:<span class="type">Int</span>, y:<span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> diff = x - y</span><br><span class="line">                println( diff + <span class="string">"="</span> + x + <span class="string">"-"</span> + y )</span><br><span class="line">                diff</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        windowDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><code>countByWindow(windowLength, slideInterval):</code></p>
<p>返回一个滑动窗口计数流中的元素个数；</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming18_DStream_Window4</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">        ssc.checkpoint(<span class="string">"scp"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 滑窗</span></span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对窗口的数据进行计数，会使用checkpoint进行保存</span></span><br><span class="line">        <span class="keyword">val</span> countDS: <span class="type">DStream</span>[<span class="type">Long</span>] = socketDS.countByWindow(<span class="type">Seconds</span>(<span class="number">6</span>), <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        countDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="DStream输出"><a href="#DStream输出" class="headerlink" title="DStream输出"></a>DStream输出</h1><p>输出操作指定了对流数据经转化操作得到的数据所要执行的操作(例如把结果推入外部数据库或输出到屏幕上)。与RDD中的惰性求值类似，如果一个DStream及其派生出的DStream都没有被执行输出操作，那么这些DStream就都不会被求值。如果StreamingContext中没有设定输出操作，整个context就都不会启动。</p>
<p>输出操作如下：</p>
<ul>
<li><p>print()：在运行流程序的驱动结点上打印DStream中每一批次数据的最开始10个元素。这用于开发和调试。在Python API中，同样的操作叫print()。</p>
</li>
<li><p>saveAsTextFiles(prefix, [suffix])：以text文件形式存储这个DStream的内容。每一批次的存储文件名基于参数中的prefix和suffix。”prefix-Time_IN_MS[.suffix]”。</p>
</li>
<li><p>saveAsObjectFiles(prefix, [suffix])：以Java对象序列化的方式将Stream中的数据保存为 SequenceFiles . 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”. Python中目前不可用。</p>
</li>
<li><p>saveAsHadoopFiles(prefix, [suffix])：将Stream中的数据保存为 Hadoop files. 每一批次的存储文件名基于参数中的为”prefix-TIME_IN_MS[.suffix]”。Python API 中目前不可用。</p>
</li>
<li><p><strong>foreachRDD(func)：这是最通用的输出操作，即将函数 func 用于产生于 stream的每一个RDD。其中参数传入的函数func应该实现将每一个RDD中数据推送到外部系统，如将RDD存入文件或者通过网络将其写入数据库。</strong></p>
</li>
</ul>
<p>通用的输出操作foreachRDD()，它用来对DStream中的RDD运行任意计算。这和transform() 有些类似，都可以让我们访问任意RDD。<strong>在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作。</strong>比如，常见的用例之一是把数据写到诸如MySQL的外部数据库中。 </p>
<blockquote>
<p>注意：</p>
<p>1) 连接不能写在driver层面（序列化）</p>
<p>2) 如果写在foreach则每个RDD中的每一条数据都创建，得不偿失；</p>
<p>3) 增加foreachPartition，在分区创建（获取）。</p>
</blockquote>
<p>方法一：性能低，每个RDD要连接一次</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming20_DStream_Output</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> socketDS = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将数据保存到MySQL数据库中</span></span><br><span class="line">        <span class="comment">// id, name, age</span></span><br><span class="line">        socketDS.foreachRDD(rdd=&gt;&#123;</span><br><span class="line">            rdd.foreach(data=&gt;&#123;</span><br><span class="line">                <span class="comment">// 解决性能问题</span></span><br><span class="line">                <span class="keyword">val</span> datas = data.split(<span class="string">","</span>)</span><br><span class="line">                <span class="keyword">val</span> id = datas(<span class="number">0</span>).toInt</span><br><span class="line">                <span class="keyword">val</span> name = datas(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">val</span> age = datas(<span class="number">2</span>).toInt</span><br><span class="line"></span><br><span class="line">                <span class="comment">// TODO 加载数据库驱动</span></span><br><span class="line">                <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">                <span class="comment">// TODO 建立链接和操作对象</span></span><br><span class="line">                <span class="keyword">val</span> conn =</span><br><span class="line">                    <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">                        <span class="string">"jdbc:mysql://linux1:3306/rdd"</span>,</span><br><span class="line">                        <span class="string">"root"</span>,<span class="string">"000000"</span>)</span><br><span class="line">                <span class="keyword">val</span> sql = <span class="string">"insert into user (id ,name, age) values (?, ?, ?)"</span></span><br><span class="line">                <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(sql)</span><br><span class="line">                statement.setInt(<span class="number">1</span>, id)</span><br><span class="line">                statement.setString(<span class="number">2</span>, name)</span><br><span class="line">                statement.setInt(<span class="number">3</span>, age)</span><br><span class="line">                <span class="comment">// TODO 操作数据</span></span><br><span class="line">                statement.executeUpdate()</span><br><span class="line">                <span class="comment">// TODO 关闭连接</span></span><br><span class="line">                statement.close()</span><br><span class="line">                conn.close()</span><br><span class="line">                println(<span class="string">"数据保存成功！！！"</span>)</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>方法二：把连接放到foreachRDD外面，但是根本执行不了，因为所有的连接对象都不支持序列化操作</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming21_DStream_Output1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> socketDS = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将数据保存到MySQL数据库中</span></span><br><span class="line">        <span class="comment">// id, name, age</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 加载数据库驱动</span></span><br><span class="line">        <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">        <span class="comment">// TODO 建立链接和操作对象</span></span><br><span class="line">        <span class="comment">// TODO 所有的连接对象都不支持序列化操作</span></span><br><span class="line">        <span class="keyword">val</span> conn =</span><br><span class="line">            <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">                <span class="string">"jdbc:mysql://linux1:3306/rdd"</span>,</span><br><span class="line">                <span class="string">"root"</span>,<span class="string">"000000"</span>)</span><br><span class="line">        <span class="keyword">val</span> sql = <span class="string">"insert into user (id ,name, age) values (?, ?, ?)"</span></span><br><span class="line">        <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(sql)</span><br><span class="line"></span><br><span class="line">        socketDS.foreachRDD(rdd=&gt;&#123;</span><br><span class="line">            <span class="comment">// TODO RDD的方法称之为算子，存在分布式计算，需要进行闭包检测</span></span><br><span class="line">            rdd.foreach(data=&gt;&#123;</span><br><span class="line">                <span class="comment">// 解决性能问题</span></span><br><span class="line">                <span class="keyword">val</span> datas = data.split(<span class="string">","</span>)</span><br><span class="line">                <span class="keyword">val</span> id = datas(<span class="number">0</span>).toInt</span><br><span class="line">                <span class="keyword">val</span> name = datas(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">val</span> age = datas(<span class="number">2</span>).toInt</span><br><span class="line"></span><br><span class="line">                statement.setInt(<span class="number">1</span>, id)</span><br><span class="line">                statement.setString(<span class="number">2</span>, name)</span><br><span class="line">                statement.setInt(<span class="number">3</span>, age)</span><br><span class="line">                <span class="comment">// TODO 操作数据</span></span><br><span class="line">                <span class="comment">//statement.addBatch()</span></span><br><span class="line">                <span class="comment">//statement.executeBatch()</span></span><br><span class="line">                statement.executeUpdate()</span><br><span class="line"></span><br><span class="line">                println(<span class="string">"数据保存成功！！！"</span>)</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// SparkException : Task not serializable</span></span><br><span class="line">        <span class="comment">// TODO 关闭连接</span></span><br><span class="line">        statement.close()</span><br><span class="line">        conn.close()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>方法三：<code>rdd.foreachPartition</code>,以分区为单位进行遍历</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming22_DStream_Output2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> socketDS = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将数据保存到MySQL数据库中</span></span><br><span class="line">        <span class="comment">// id, name, age</span></span><br><span class="line"></span><br><span class="line">        socketDS.foreachRDD(rdd=&gt;&#123;</span><br><span class="line">            <span class="comment">//【注意】mapPartitions和foreachPartition的区别：</span></span><br><span class="line">            <span class="comment">// 以分区为单位进行转换 =&gt; 返回</span></span><br><span class="line">            <span class="comment">//rdd.mapPartitions()</span></span><br><span class="line">            <span class="comment">// 以分区为单位进行遍历 =&gt; 不需要返回</span></span><br><span class="line">            rdd.foreachPartition(</span><br><span class="line">                datas =&gt; &#123;</span><br><span class="line">                    <span class="comment">// TODO 加载数据库驱动</span></span><br><span class="line">                    <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">                    <span class="comment">// TODO 建立链接和操作对象</span></span><br><span class="line">                    <span class="comment">// TODO 所有的连接对象都不支持序列化操作</span></span><br><span class="line">                    <span class="keyword">val</span> conn =</span><br><span class="line">                    <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">                        <span class="string">"jdbc:mysql://linux1:3306/rdd"</span>,</span><br><span class="line">                        <span class="string">"root"</span>,<span class="string">"000000"</span>)</span><br><span class="line">                    <span class="keyword">val</span> sql = <span class="string">"insert into user (id ,name, age) values (?, ?, ?)"</span></span><br><span class="line">                    <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(sql)</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// datas 其实是scala的集合，所以不存在分布式计算的概念</span></span><br><span class="line">                    datas.foreach(</span><br><span class="line">                        data =&gt; &#123;</span><br><span class="line">                            <span class="comment">// 解决性能问题</span></span><br><span class="line">                            <span class="keyword">val</span> datas = data.split(<span class="string">","</span>)</span><br><span class="line">                            <span class="keyword">val</span> id = datas(<span class="number">0</span>).toInt</span><br><span class="line">                            <span class="keyword">val</span> name = datas(<span class="number">1</span>)</span><br><span class="line">                            <span class="keyword">val</span> age = datas(<span class="number">2</span>).toInt</span><br><span class="line"></span><br><span class="line">                            statement.setInt(<span class="number">1</span>, id)</span><br><span class="line">                            statement.setString(<span class="number">2</span>, name)</span><br><span class="line">                            statement.setInt(<span class="number">3</span>, age)</span><br><span class="line">                            <span class="comment">// TODO 操作数据</span></span><br><span class="line">                            <span class="comment">//statement.addBatch()</span></span><br><span class="line">                            <span class="comment">//statement.executeBatch()</span></span><br><span class="line">                            statement.executeUpdate()</span><br><span class="line"></span><br><span class="line">                            println(<span class="string">"数据保存成功！！！"</span>)</span><br><span class="line">                        &#125;</span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// TODO 关闭连接</span></span><br><span class="line">                    statement.close()</span><br><span class="line">                    conn.close()</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h1><p>流式任务需要7*24小时执行，但是有时涉及到升级代码需要主动停止程序，但是分布式程序，没办法做到一个个进程去杀死，所有配置优雅的关闭就显得至关重要了。</p>
<p>使用外部文件系统来控制内部程序关闭。</p>
<p>把<code>spark.streaming.stopGracefullyOnShutdown</code>参数设置成ture,Spark会在JVM关闭时正常关闭StreamingContext,而不是立马关闭</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">sparkConf.set(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="string">"true"</span>)</span><br></pre></td></tr></table></figure></div>

<p>案例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>, <span class="type">ResultSet</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">ReceiverInputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>, <span class="type">StreamingContextState</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkStreaming23_Stop</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"wordcount"</span>)</span><br><span class="line">        <span class="comment">// TODO 配置优雅地关闭</span></span><br><span class="line">        sparkConf.set(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="string">"true"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> socketDS: <span class="type">ReceiverInputDStream</span>[<span class="type">String</span>] = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> wordDS: <span class="type">DStream</span>[<span class="type">String</span>] = socketDS.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">        <span class="keyword">val</span> wordToOneDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordDS.map( (_, <span class="number">1</span>) )</span><br><span class="line">        <span class="keyword">val</span> wordToCountDS: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToOneDS.reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line">        wordToCountDS.print()</span><br><span class="line"></span><br><span class="line">        ssc.start()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="type">Thread</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">                <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">                    <span class="comment">// TODO SparkStreaming是可以停止。但是停止的逻辑代码的位置？</span></span><br><span class="line">                    <span class="comment">// TODO stop方法不能放置在driver的主线程中。</span></span><br><span class="line">                    <span class="comment">// TODO 直接调用ssc的stop方法是不可以的。需要循环判断sparkStreaming是否应该关闭</span></span><br><span class="line">                    <span class="keyword">while</span> ( <span class="literal">true</span> ) &#123;</span><br><span class="line">                        <span class="comment">// TODO 在Driver端应该设置标记，让当前关闭线程可以访问。可以动态改变状态。</span></span><br><span class="line">                        <span class="comment">// TODO 但是Driver端的标记何时更新，由谁更新都是不确定的。</span></span><br><span class="line">                        <span class="comment">// TODO 所以一般标记不是放置在Driver端，而是在第三方软件中：redis,zk,mysql,hdfs</span></span><br><span class="line"></span><br><span class="line">                        <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">                        <span class="comment">// TODO 建立链接和操作对象</span></span><br><span class="line">                        <span class="comment">// TODO 所有的连接对象都不支持序列化操作</span></span><br><span class="line">                        <span class="keyword">val</span> conn =</span><br><span class="line">                        <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">                            <span class="string">"jdbc:mysql://linux1:3306/rdd"</span>,</span><br><span class="line">                            <span class="string">"root"</span>,<span class="string">"000000"</span>)</span><br><span class="line">                        <span class="keyword">val</span> sql = <span class="string">"select age from user where id = 1"</span></span><br><span class="line">                        <span class="keyword">val</span> statement: <span class="type">PreparedStatement</span> = conn.prepareStatement(sql)</span><br><span class="line">                        <span class="keyword">val</span> rs: <span class="type">ResultSet</span> = statement.executeQuery()</span><br><span class="line">                        rs.next()</span><br><span class="line">                        <span class="keyword">val</span> age: <span class="type">Int</span> = rs.getInt(<span class="number">1</span>)</span><br><span class="line">                        <span class="keyword">if</span> ( age &lt;= <span class="number">20</span> ) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// TODO 判断SSC的状态</span></span><br><span class="line">                            <span class="keyword">val</span> state: <span class="type">StreamingContextState</span> = ssc.getState()</span><br><span class="line">                            <span class="keyword">if</span> ( state == <span class="type">StreamingContextState</span>.<span class="type">ACTIVE</span> ) &#123;</span><br><span class="line">                                println(<span class="string">"SparkStreaming的环境准备关闭..."</span>)</span><br><span class="line">                                <span class="comment">// TODO 优雅地关闭SSC</span></span><br><span class="line">                                <span class="comment">// 将现有的数据处理完再关闭就是优雅地关闭</span></span><br><span class="line">                                ssc.stop(<span class="literal">true</span>, <span class="literal">true</span>)</span><br><span class="line">                                <span class="type">System</span>.exit(<span class="number">0</span>)</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="type">Thread</span>.sleep(<span class="number">1000</span> * <span class="number">5</span>)</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ).start()</span><br><span class="line"></span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">        <span class="comment">// TODO Thread 线程停止的方式？run方法执行完毕</span></span><br><span class="line">        <span class="comment">// 为什么不调用stop方法停止线程？因为会出现数据安全问题</span></span><br><span class="line">        <span class="comment">// i++ =&gt; 1), 2)</span></span><br><span class="line">        <span class="comment">// new Thread().stop()</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>spark</tag>
        <tag>spark-streaming</tag>
        <tag>实时大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>[精]Redis总结与思考</title>
    <url>/2020/05/12/%E7%B2%BE-Redis%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="Redis介绍及安装"><a href="#Redis介绍及安装" class="headerlink" title="Redis介绍及安装"></a>Redis介绍及安装</h1><h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>1、Redis是最常用的非关系型数据库（NoSQL）——不依赖业务逻辑方式存储，而以简单的key-value模式存储。</p>
<blockquote>
<p>常见的NoSQL数据库：</p>
<p>​         Memcached,Redis,MongoDB,HBase</p>
</blockquote>
<p>2、Redis有16个库，编号为0~15，默认使用0号库。</p>
<p>3、Redis使用的是<strong>单线程+多路IO复用技术</strong>（Linux系统特有）。</p>
<h2 id="Redis安装及启动"><a href="#Redis安装及启动" class="headerlink" title="Redis安装及启动"></a>Redis安装及启动</h2><p><strong>1、Redis安装步骤：</strong></p>
<ul>
<li>首先保证有gcc-c++工具，否则先执行：yum install gcc-c++</li>
<li>下载获得redis-3.2.5.tar.gz后将它放入Linux目录</li>
<li>解压命令:tar -zxvf redis-3.2.5.tar.gz</li>
<li>解压完成后进入目录:cd redis-3.2.5</li>
<li>在redis-3.2.5目录下执行make命令</li>
<li>在redis-3.2.5目录下执行make install命令</li>
</ul>
<p><strong>2、Redis默认安装目录：/usr/local/bin</strong></p>
<ul>
<li>redis-benchmark：性能测试工具，可以在自己本子运行，看看自己本子性能如何(服务启动起来后执行)</li>
<li>redis-check-aof：修复有问题的AOF文件</li>
<li>redis-check-rdb：修复有问题RDB文件</li>
<li>redis-sentinel：Redis集群使用</li>
<li>redis-server：Redis服务器启动命令</li>
<li>redis-cli：客户端，操作入口</li>
</ul>
<p><strong>3、Redis启动：</strong></p>
<ul>
<li>备份redis.conf：拷贝一份redis.conf到其他目录</li>
<li>修改redis.conf文件将里面的daemonize no 改成 yes(128行)，让服务在后台启动</li>
<li>启动命令：执行  redis-server  /root/myredis/redis.conf</li>
<li>用客户端访问: redis-cli -p  <strong>6379</strong></li>
<li>关闭：客户端中输入shutdown，redis-server进程就已关闭。之后Ctrl+c退出客户端即可。</li>
</ul>
<h1 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h1><blockquote>
<p><strong>常用</strong>五大数据类型：String,list,set,hash,zset</p>
</blockquote>
<p>五大数据类型常用指令：</p>
<h2 id="0、Key"><a href="#0、Key" class="headerlink" title="0、Key"></a>0、Key</h2><table>
<thead>
<tr>
<th>Key常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>keys *</td>
<td>查询当前库的所有键</td>
</tr>
<tr>
<td>exists <code>&lt;key&gt;</code></td>
<td>判断某个键是否存在</td>
</tr>
<tr>
<td>type  <code>&lt;key&gt;</code></td>
<td>查看键对应的数据的类型</td>
</tr>
<tr>
<td>del  <code>&lt;key&gt;</code></td>
<td>删除某个键</td>
</tr>
<tr>
<td>expire   <code>&lt;key&gt; &lt;seconds&gt;</code></td>
<td>为键值设置过期时间，单位秒</td>
</tr>
<tr>
<td>ttl   <code>&lt;key&gt;</code></td>
<td>查看还有多少秒过期，-1表示永不过期，-2表示已过期</td>
</tr>
<tr>
<td>dbsize</td>
<td>查看当前数据库的key的数量</td>
</tr>
<tr>
<td>flushdb</td>
<td>清空当前库</td>
</tr>
<tr>
<td>flushall</td>
<td>通杀全部库</td>
</tr>
</tbody></table>
<h2 id="1、String"><a href="#1、String" class="headerlink" title="1、String"></a>1、String</h2><ul>
<li>String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。</li>
<li>String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M</li>
</ul>
<table>
<thead>
<tr>
<th>String常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>get   <code>&lt;key&gt;</code></td>
<td>查询对应键值</td>
</tr>
<tr>
<td>set   <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>添加键值对</td>
</tr>
<tr>
<td>append  <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>将给定的<code>&lt;value&gt;</code>追加到原值的末尾</td>
</tr>
<tr>
<td>strlen  <code>&lt;key&gt;</code></td>
<td>获得值的长度</td>
</tr>
<tr>
<td>setnx  <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>只有在 key 不存在时设置 key 的值</td>
</tr>
<tr>
<td>incr <code>&lt;key&gt;</code></td>
<td>将 key 中储存的数字值增1。<br>只能对数字值操作，如果为空，新增值为1</td>
</tr>
<tr>
<td>decr  <code>&lt;key&gt;</code></td>
<td>将 key 中储存的数字值减1。<br>只能对数字值操作，如果为空，新增值为-1</td>
</tr>
<tr>
<td>incrby / decrby  <code>&lt;key&gt;</code>  <code>&lt;步长&gt;</code></td>
<td>将 key 中储存的数字值增减。自定义步长</td>
</tr>
<tr>
<td>mset  <code>&lt;key1&gt;  &lt;value1&gt;  &lt;key2&gt;  &lt;value2&gt;</code>  …</td>
<td>同时设置一个或多个 key-value对</td>
</tr>
<tr>
<td>mget  <code>&lt;key1&gt;   &lt;key2&gt;   &lt;key3&gt;</code> …</td>
<td>同时获取一个或多个 value</td>
</tr>
<tr>
<td>msetnx <code>&lt;key1&gt;  &lt;value1&gt;  &lt;key2&gt;  &lt;value2&gt;</code>  …</td>
<td>同时设置一个或多个 key-value 对，<br>当且仅当所有给定 key 都不存在。</td>
</tr>
<tr>
<td>getrange  <code>&lt;key&gt;  &lt;起始位置&gt;  &lt;结束位置&gt;</code></td>
<td>获得值的范围，类似java中的substring</td>
</tr>
<tr>
<td>setrange  <code>&lt;key&gt;   &lt;起始位置&gt;   &lt;value&gt;</code></td>
<td>用 <code>&lt;value&gt;</code>覆写<code>&lt;key&gt;</code>所储存的字符串值<br>，从<code>&lt;起始位置&gt;</code>开始</td>
</tr>
<tr>
<td>setex  <code>&lt;key&gt;  &lt;过期时间&gt;   &lt;value&gt;</code></td>
<td>设置键值的同时，设置过期时间，单位秒</td>
</tr>
<tr>
<td>getset <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>以新换旧，设置了新值同时获得旧值</td>
</tr>
</tbody></table>
<h2 id="2、List"><a href="#2、List" class="headerlink" title="2、List"></a>2、List</h2><ul>
<li>单键多值</li>
<li>Redis 列表是简单的字符串列表，按照插入顺序排序。</li>
<li>它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。</li>
</ul>
<table>
<thead>
<tr>
<th>List常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>lpush/rpush  <code>&lt;key&gt;  &lt;value1&gt;  &lt;value2&gt;</code> …</td>
<td>从左边/右边插入一个或多个值</td>
</tr>
<tr>
<td>lpop/rpop  <code>&lt;key&gt;</code></td>
<td>从左边/右边吐出一个值。值在键在，值亡键亡。</td>
</tr>
<tr>
<td>rpoplpush  <code>&lt;key1&gt;  &lt;key2&gt;</code></td>
<td>从<code>&lt;key1&gt;</code>列表右边吐出一个值，插到<code>&lt;key2&gt;</code>列表左边</td>
</tr>
<tr>
<td>lrange <code>&lt;key&gt; &lt;start&gt; &lt;stop&gt;</code></td>
<td>按照索引下标获得元素(从左到右)</td>
</tr>
<tr>
<td>lindex <code>&lt;key&gt; &lt;index&gt;</code></td>
<td>按照索引下标获得元素(从左到右)</td>
</tr>
<tr>
<td>llen <code>&lt;key&gt;</code></td>
<td>获得列表长度</td>
</tr>
<tr>
<td>linsert <code>&lt;key&gt;</code>  before <code>&lt;value&gt;  &lt;newvalue&gt;</code></td>
<td>在<code>&lt;value&gt;</code>的前面插入<code>&lt;newvalue&gt;</code></td>
</tr>
<tr>
<td>lrem <code>&lt;key&gt; &lt;n&gt;  &lt;value&gt;</code></td>
<td>从左边删除n个value(从左到右)</td>
</tr>
</tbody></table>
<h2 id="3、Set"><a href="#3、Set" class="headerlink" title="3、Set"></a>3、Set</h2><ul>
<li>Redis的Set是string类型的无序集合</li>
<li>它底层其实是一个value为null的hash表,所以添加，删除，查找的复杂度都是O(1)。</li>
</ul>
<table>
<thead>
<tr>
<th>Set常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>sadd <code>&lt;key&gt;  &lt;value1&gt;  &lt;value2&gt;</code> …</td>
<td>将一个或多个 member 元素加入到集合 key 当中，<br>已经存在于集合的 member 元素将被忽略。</td>
</tr>
<tr>
<td>smembers <code>&lt;key&gt;</code></td>
<td>取出该集合的所有值</td>
</tr>
<tr>
<td>sismember <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>判断集合<code>&lt;key&gt;</code>是否为含有该<code>&lt;value&gt;</code>值，有返回1，没有返回0</td>
</tr>
<tr>
<td>scard   <code>&lt;key&gt;</code></td>
<td>返回该集合的元素个数。</td>
</tr>
<tr>
<td>srem <code>&lt;key&gt; &lt;value1&gt; &lt;value2&gt;</code> …</td>
<td>删除集合中的某个元素。</td>
</tr>
<tr>
<td>spop <code>&lt;key&gt; &lt;n&gt;</code></td>
<td>随机从该集合中吐出一个或多个值。</td>
</tr>
<tr>
<td>srandmember <code>&lt;key&gt; &lt;n&gt;</code></td>
<td>随机从该集合中取出n个值。不会从集合中删除。</td>
</tr>
<tr>
<td>sinter <code>&lt;key1&gt; &lt;key2&gt;</code></td>
<td>返回两个集合的交集元素。</td>
</tr>
<tr>
<td>sunion <code>&lt;key1&gt; &lt;key2&gt;</code></td>
<td>返回两个集合的并集元素。</td>
</tr>
<tr>
<td>sdiff <code>&lt;key1&gt; &lt;key2&gt;</code></td>
<td>返回两个集合的差集元素。</td>
</tr>
</tbody></table>
<h2 id="4、Hash"><a href="#4、Hash" class="headerlink" title="4、Hash"></a>4、Hash</h2><ul>
<li>Redis  hash 是一个键值对集合。</li>
<li>Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储<strong>对象</strong>。</li>
<li>类似Java里面的Map&lt;String,Object&gt;</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Hash常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td align="left">hset <code>&lt;key&gt;  &lt;field&gt;  &lt;value&gt;</code></td>
<td>给<code>&lt;key&gt;</code>集合中的<code>&lt;field&gt;</code>键赋值<code>&lt;value&gt;</code></td>
</tr>
<tr>
<td align="left">hget <code>&lt;key&gt;  &lt;field&gt;</code></td>
<td>从<code>&lt;key&gt;</code>集合<code>&lt;field&gt;</code>取出 value</td>
</tr>
<tr>
<td align="left">hmset <code>&lt;key&gt;  &lt;field1&gt; &lt;value1&gt; &lt;field2&gt; &lt;value2&gt;</code>…</td>
<td>批量设置hash的值</td>
</tr>
<tr>
<td align="left">hexists key  <code>&lt;field&gt;</code></td>
<td>查看哈希表 key 中，给定域 field 是否存在</td>
</tr>
<tr>
<td align="left">hkeys <code>&lt;key&gt;</code></td>
<td>列出该hash集合的所有field</td>
</tr>
<tr>
<td align="left">hvals <code>&lt;key&gt;</code></td>
<td>列出该hash集合的所有value</td>
</tr>
<tr>
<td align="left">hincrby <code>&lt;key&gt; &lt;field&gt;  &lt;increment&gt;</code></td>
<td>为哈希表 key 中的域 field 的值加上增量 increment</td>
</tr>
<tr>
<td align="left">hsetnx <code>&lt;key&gt;  &lt;field&gt; &lt;value&gt;</code></td>
<td>将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在</td>
</tr>
</tbody></table>
<h2 id="5、zset-sorted-set"><a href="#5、zset-sorted-set" class="headerlink" title="5、zset  (sorted set)"></a>5、zset  (sorted set)</h2><ul>
<li><p>Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。</p>
</li>
<li><p>有序集合的所有成员都关联了一个评分（score） ，这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。（集合的成员是唯一的，但是评分可以是重复了的）</p>
</li>
<li><p>因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>zset常用指令</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>zadd  <code>&lt;key&gt; &lt;score1&gt; &lt;value1&gt;  &lt;score2&gt; &lt;value2&gt;</code>…</td>
<td>将一个或多个 member 元素及其 score 值加入到有序集 key 当中</td>
</tr>
<tr>
<td>zrange <code>&lt;key&gt;  &lt;start&gt; &lt;stop&gt;</code>  [WITHSCORES]</td>
<td>返回有序集 key 中，下标在<code>&lt;start&gt; &lt;stop&gt;</code>之间的元素。<br>带WITHSCORES，可以让分数一起和值返回到结果集。</td>
</tr>
<tr>
<td>zrangebyscore key min max [withscores] [limit offset count]</td>
<td>返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列</td>
</tr>
<tr>
<td>zrevrangebyscore key max min [withscores] [limit offset count]</td>
<td>同上，改为从大到小排列</td>
</tr>
<tr>
<td>zincrby <code>&lt;key&gt; &lt;increment&gt; &lt;value&gt;</code></td>
<td>为元素的score加上增量</td>
</tr>
<tr>
<td>zrem  <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>删除该集合下，指定值的元素</td>
</tr>
<tr>
<td>zcount <code>&lt;key&gt;  &lt;min&gt;  &lt;max&gt;</code></td>
<td>统计该集合，分数区间内的元素个数</td>
</tr>
<tr>
<td>zrank <code>&lt;key&gt;  &lt;value&gt;</code></td>
<td>返回该值在集合中的排名，从0开始</td>
</tr>
</tbody></table>
<h1 id="Redis的Java客户端Jedis"><a href="#Redis的Java客户端Jedis" class="headerlink" title="Redis的Java客户端Jedis"></a>Redis的Java客户端Jedis</h1><p>maven依赖：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>注意事项：</p>
<ul>
<li>禁用Linux的防火墙：</li>
<li>临时禁用：service iptables stop</li>
<li>关闭开机自启：chkconfig iptables off</li>
<li>redis.conf中注释掉bind 127.0.0.1（61行） ,然后 protect-mode（80行）设置为 no。</li>
</ul>
<p>Jedis测试连通性</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo01</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//连接本地的 Redis 服务</span></span><br><span class="line">    Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line">    <span class="comment">//查看服务是否运行，打出pong表示OK</span></span><br><span class="line">    System.out.println(<span class="string">"connection is OK==========&gt;: "</span>+jedis.ping());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    Key</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//key</span></span><br><span class="line">Set&lt;String&gt; keys = jedis.keys(<span class="string">"*"</span>);</span><br><span class="line"><span class="keyword">for</span> (Iterator iterator = keys.iterator(); iterator.hasNext();) &#123;</span><br><span class="line">    String key = (String) iterator.next();</span><br><span class="line">    System.out.println(key);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"jedis.exists====&gt;"</span>+jedis.exists(<span class="string">"k2"</span>));</span><br><span class="line">System.out.println(jedis.ttl(<span class="string">"k1"</span>));</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    String</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.out.println(jedis.get(<span class="string">"k1"</span>));</span><br><span class="line">jedis.set(<span class="string">"k4"</span>,<span class="string">"k4_Redis"</span>);</span><br><span class="line">System.out.println(<span class="string">"----------------------------------------"</span>);</span><br><span class="line">jedis.mset(<span class="string">"str1"</span>,<span class="string">"v1"</span>,<span class="string">"str2"</span>,<span class="string">"v2"</span>,<span class="string">"str3"</span>,<span class="string">"v3"</span>);</span><br><span class="line">System.out.println(jedis.mget(<span class="string">"str1"</span>,<span class="string">"str2"</span>,<span class="string">"str3"</span>));</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    List</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; list = jedis.lrange(<span class="string">"mylist"</span>,<span class="number">0</span>,-<span class="number">1</span>);</span><br><span class="line">     <span class="keyword">for</span> (String element : list) &#123;</span><br><span class="line">       System.out.println(element);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    Set</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jedis.sadd(<span class="string">"orders"</span>,<span class="string">"jd001"</span>);</span><br><span class="line">jedis.sadd(<span class="string">"orders"</span>,<span class="string">"jd002"</span>);</span><br><span class="line">jedis.sadd(<span class="string">"orders"</span>,<span class="string">"jd003"</span>);</span><br><span class="line">Set&lt;String&gt; set1 = jedis.smembers(<span class="string">"orders"</span>);</span><br><span class="line"><span class="keyword">for</span> (Iterator iterator = set1.iterator(); iterator.hasNext();) &#123;</span><br><span class="line">    String string = (String) iterator.next();</span><br><span class="line">    System.out.println(string);</span><br><span class="line">&#125;</span><br><span class="line">jedis.srem(<span class="string">"orders"</span>,<span class="string">"jd002"</span>);</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    hash[注意]</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jedis.hset(<span class="string">"hash1"</span>,<span class="string">"userName"</span>,<span class="string">"lisi"</span>);</span><br><span class="line">System.out.println(jedis.hget(<span class="string">"hash1"</span>,<span class="string">"userName"</span>));</span><br><span class="line">Map&lt;String,String&gt; map = <span class="keyword">new</span> HashMap&lt;String,String&gt;(); <span class="comment">//【注意】</span></span><br><span class="line">map.put(<span class="string">"telphone"</span>,<span class="string">"13810169999"</span>);</span><br><span class="line">map.put(<span class="string">"address"</span>,<span class="string">"atguigu"</span>);</span><br><span class="line">map.put(<span class="string">"email"</span>,<span class="string">"abc@163.com"</span>);</span><br><span class="line">jedis.hmset(<span class="string">"hash2"</span>,map);</span><br><span class="line">List&lt;String&gt; result = jedis.hmget(<span class="string">"hash2"</span>, <span class="string">"telphone"</span>,<span class="string">"email"</span>);</span><br><span class="line"><span class="keyword">for</span> (String element : result) &#123;</span><br><span class="line">    System.out.println(element);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>Jedis-API:    zset</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jedis.zadd(<span class="string">"zset01"</span>,<span class="number">60</span>d,<span class="string">"v1"</span>);</span><br><span class="line">jedis.zadd(<span class="string">"zset01"</span>,<span class="number">70</span>d,<span class="string">"v2"</span>);</span><br><span class="line">jedis.zadd(<span class="string">"zset01"</span>,<span class="number">80</span>d,<span class="string">"v3"</span>);</span><br><span class="line">jedis.zadd(<span class="string">"zset01"</span>,<span class="number">90</span>d,<span class="string">"v4"</span>);</span><br><span class="line">Set&lt;String&gt; s1 = jedis.zrange(<span class="string">"zset01"</span>,<span class="number">0</span>,-<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> (Iterator iterator = s1.iterator(); iterator.hasNext();) &#123;</span><br><span class="line">    String string = (String) iterator.next();</span><br><span class="line">    System.out.println(string);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h1><ul>
<li>Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li>
<li>Redis事务的主要作用就是串联多个命令防止别的命令插队</li>
</ul>
<blockquote>
<p>悲观锁(Pessimistic Lock)，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。</p>
<p>乐观锁(Optimistic Lock)， 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。</p>
</blockquote>
<p>三特性：</p>
<p>1、单独的隔离操作 </p>
<ul>
<li>事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 </li>
</ul>
<p>2、没有隔离级别的概念 </p>
<ul>
<li>队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在“事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 </li>
</ul>
<p>3、不保证原子性 </p>
<ul>
<li>Redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 </li>
</ul>
<h1 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h1><h2 id="1、RDB-（Redis-DataBase）"><a href="#1、RDB-（Redis-DataBase）" class="headerlink" title="1、RDB （Redis DataBase）"></a>1、RDB （Redis DataBase）</h2><ul>
<li>在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。</li>
</ul>
<blockquote>
<p>备份是如何执行的：</p>
<p>Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。</p>
</blockquote>
<blockquote>
<p>关于fork：在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“写时复制技术”，一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。</p>
</blockquote>
<ul>
<li>在redis.conf中配置文件名称，默认为dump.rdb</li>
</ul>
<p><strong>RDB优缺点：</strong></p>
<ul>
<li><p>优点</p>
<ul>
<li>节省磁盘空间</li>
<li>恢复速度快</li>
</ul>
</li>
<li><p>rdb的缺点</p>
<ul>
<li>虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。</li>
<li>在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</li>
</ul>
</li>
</ul>
<h2 id="2、AOF-（Append-Of-File）"><a href="#2、AOF-（Append-Of-File）" class="headerlink" title="2、AOF （Append Of File）"></a>2、AOF （Append Of File）</h2><ul>
<li>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。</li>
<li>AOF默认不开启，需要手动在配置文件中配置</li>
<li>可以在redis.conf中配置文件名称，默认为 appendonly.aof </li>
<li>AOF和RDB同时开启，系统默认取AOF的数据</li>
</ul>
<p>AOF文件故障恢复：</p>
<ul>
<li>AOF文件的保存路径，同RDB的路径一致。</li>
<li>如遇到AOF文件损坏，可通过 <code>redis-check-aof  --fix  appendonly.aof</code>  进行恢复</li>
</ul>
<p>Rewrite：</p>
<ul>
<li>AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof。</li>
</ul>
<p><strong>AOF优缺点：</strong></p>
<ul>
<li><p>优点：</p>
<ul>
<li>备份机制更稳健，丢失数据概率更低。</li>
<li>可读的日志文本，通过操作AOF稳健，可以处理误操作。</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>比起RDB占用更多的磁盘空间。</li>
<li>恢复备份速度要慢。</li>
<li>每次读写都同步的话，有一定的性能压力。</li>
<li>存在个别Bug，造成恢复不能。</li>
</ul>
</li>
</ul>
<p><strong>用哪个好呢</strong></p>
<ul>
<li>官方推荐两个都启用。</li>
<li>如果对数据不敏感，可以选单独用RDB。</li>
<li>不建议单独用 AOF，因为可能会出现Bug。</li>
<li>如果只是做纯内存缓存，可以都不用。</li>
</ul>
<h1 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a>Redis主从复制</h1><p>概念：主从复制，就是主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主。</p>
<p>用处：读写分离，性能扩展。容灾快速回复。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">配从(服务器)不配主(服务器):</span><br><span class="line">- 拷贝多个redis.conf文件include</span><br><span class="line">- 开启daemonize yes</span><br><span class="line">- Pid文件名字pidfile</span><br><span class="line">- 指定端口port</span><br><span class="line">- Log文件名字</span><br><span class="line">- Dump.rdb名字dbfilename</span><br><span class="line">- Appendonly 关掉或者换名字</span><br><span class="line"></span><br><span class="line">info replication:打印主从复制的相关信息</span><br><span class="line">slaveof  &lt;ip&gt;  &lt;port&gt;  :成为某个实例的从服务器</span><br></pre></td></tr></table></figure></div>

<h2 id="一主二仆模式："><a href="#一主二仆模式：" class="headerlink" title="一主二仆模式："></a>一主二仆模式：</h2><blockquote>
<p>复制原理：</p>
<ul>
<li>每次从机联通后，都会给主机发送sync指令</li>
<li>主机立刻进行存盘操作，发送RDB文件，给从机</li>
<li>从机收到RDB文件后，进行全盘加载</li>
<li>之后每次主机的写操作，都会立刻发送给从机，从机执行相同的命令</li>
</ul>
</blockquote>
<p>薪火相传：</p>
<ul>
<li>上一个slave可以是下一个slave的Master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。</li>
<li>用 slaveof <code>&lt;ip&gt;</code> <code>&lt;port&gt;</code></li>
<li>中途变更转向:会清除之前的数据，重新建立拷贝最新的</li>
<li>风险是一旦某个slave宕机，后面的slave都没法备份</li>
</ul>
<p>反客为主：</p>
<ul>
<li>当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改。。</li>
<li>用 slaveof  no one  将从机变为主机。</li>
</ul>
<h2 id="哨兵模式-sentinel"><a href="#哨兵模式-sentinel" class="headerlink" title="哨兵模式(sentinel)"></a>哨兵模式(sentinel)</h2><p>反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、配置哨兵：</span><br><span class="line">调整为一主二仆模式</span><br><span class="line">自定义的&#x2F;myredis目录下新建sentinel.conf文件</span><br><span class="line">在配置文件中填写内容：</span><br><span class="line">        sentinel  monitor  mymaster  127.0.0.1  6379  1</span><br><span class="line">其中mymaster为监控对象起的服务器名称， 1 为 至少有多少个哨兵同意迁移的数量。 </span><br><span class="line"></span><br><span class="line">2、启动哨兵</span><br><span class="line">执行redis-sentinel  &#x2F;myredis&#x2F;sentinel.conf</span><br></pre></td></tr></table></figure></div>

<p><strong>故障恢复：</strong></p>
<p>1、新主登基</p>
<p>从下线的主服务的所有从服务里面挑选一个从服务，将其转成主服务<br>选择条件依次为：<br>（1）选择优先级靠前的<br>（2）选择偏移量最大的<br>（3）选择runid最小的从服务</p>
<p>2、群仆俯首</p>
<p>挑选出新的主服务之后，sentinel 向原主服务的从服务发送 slaveof 新主服务 的命令，复制新master</p>
<p>3、旧主俯首</p>
<p>当已下线的服务重新上线时，sentinel会向其发送slaveof命令，让其成为新主的从</p>
<blockquote>
<p>优先级在redis.conf中slave-priority 100<br>偏移量是指获得原主数据最多的<br>每个redis实例启动后都会随机生成一个40位的runid</p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>数据库</tag>
        <tag>面试</tag>
        <tag>Redis</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title>flink系列05Flink DataStream API</title>
    <url>/2020/06/27/flink%E7%B3%BB%E5%88%9705Flink-DataStream-API/</url>
    <content><![CDATA[<h1 id="第五章，Flink-DataStream-API"><a href="#第五章，Flink-DataStream-API" class="headerlink" title="第五章，Flink DataStream API"></a>第五章，Flink DataStream API</h1><p>本章介绍了Flink DataStream API的基本知识。我们展示了典型的Flink流处理程序的结构和组成部分，还讨论了Flink的类型系统以及支持的数据类型，还展示了数据和分区转换操作。窗口操作符，基于时间语义的转换操作，有状态的操作符，以及和外部系统的连接器将在接下来的章节进行介绍。阅读完这一章后，我们将会知道如何去实现一个具有基本功能的流处理程序。我们的示例程序采用Scala语言，因为Scala语言相对比较简洁。但Java API也是十分类似的（特殊情况，我们将会指出）。在我们的Github仓库里，我们所写的应用程序具有Scala和Java两种版本。</p>
<h2 id="你好，Flink！"><a href="#你好，Flink！" class="headerlink" title="你好，Flink！"></a>你好，Flink！</h2><p>让我们写一个简单的例子来获得使用DataStream API编写流处理应用程序的粗浅印象。我们将使用这个简单的示例来展示一个Flink程序的基本结构，以及介绍一些DataStream API的重要特性。我们的示例程序摄取了一条（来自多个传感器的）温度测量数据流。</p>
<p>首先让我们看一下表示传感器读数的数据结构：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  timestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  temperature: <span class="type">Double</span></span>)</span></span><br></pre></td></tr></table></figure></div>

<p>示例程序5-1将温度从华氏温度读数转换成摄氏温度读数，然后针对每一个传感器，每5秒钟计算一次平均温度纸。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Scala object that defines</span></span><br><span class="line"><span class="comment">// the DataStream program in the main() method.</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AverageSensorReadings</span> </span>&#123;</span><br><span class="line">  <span class="comment">// main() defines and executes the DataStream program</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">// set up the streaming execution environment</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="comment">// use event time for the application</span></span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="comment">// create a DataStream[SensorReading] from a stream source</span></span><br><span class="line">    <span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">      <span class="comment">// ingest sensor readings with a SensorSource SourceFunction</span></span><br><span class="line">      .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">      <span class="comment">// assign timestamps and watermarks (required for event time)</span></span><br><span class="line">    <span class="keyword">val</span> avgTemp: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = sensorData</span><br><span class="line">      <span class="comment">// convert Fahrenheit to Celsius with an inline lambda function</span></span><br><span class="line">      .map( r =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> celsius = (r.temperature - <span class="number">32</span>) * (<span class="number">5.0</span> / <span class="number">9.0</span>)</span><br><span class="line">        <span class="type">SensorReading</span>(r.id, r.timestamp, celsius)</span><br><span class="line">      &#125;)</span><br><span class="line">      <span class="comment">// organize readings by sensor id</span></span><br><span class="line">      .keyBy(_.id)</span><br><span class="line">      <span class="comment">// group readings in 5 second tumbling windows</span></span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">      <span class="comment">// compute average temperature using a user-defined function</span></span><br><span class="line">      .apply(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line">      <span class="comment">// print result stream to standard out</span></span><br><span class="line">      avgTemp.print()</span><br><span class="line">    <span class="comment">// execute application</span></span><br><span class="line">    env.execute(<span class="string">"Compute average sensor temperature"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>你可能已经注意到Flink程序的定义和提交执行使用的就是正常的Scala或者Java的方法。大多数情况下，这些代码都写在一个静态main方法中。在我们的例子中，我们定义了AverageSensorReadings对象，然后将大多数的应用程序逻辑放在了main()中。</p>
<p>Flink流处理程序的结构如下：</p>
<ol>
<li>创建Flink程序执行环境。</li>
<li>从数据源读取一条或者多条流数据</li>
<li>使用流转换算子实现业务逻辑</li>
<li>将计算结果输出到一个或者多个外部设备（可选）</li>
<li>执行程序</li>
</ol>
<p>接下来我们详细的学习一下这些部分。</p>
<h2 id="搭建执行环境"><a href="#搭建执行环境" class="headerlink" title="搭建执行环境"></a>搭建执行环境</h2><p>编写Flink程序的第一件事情就是搭建执行环境。执行环境决定了程序是运行在单机上还是集群上。在DataStream API中，程序的执行环境是由StreamExecutionEnvironment设置的。在我们的例子中，我们通过调用静态getExecutionEnvironment()方法来获取执行环境。这个方法根据调用方法的上下文，返回一个本地的或者远程的环境。如果这个方法是一个客户端提交到远程集群的代码调用的，那么这个方法将会返回一个远程的执行环境。否则，将返回本地执行环境。</p>
<p>也可以用下面的方法来显式的创建本地或者远程执行环境：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// create a local stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> localEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createLocalEnvironment()</span><br><span class="line"><span class="comment">// create a remote stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> remoteEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createRemoteEnvironment(</span><br><span class="line">    <span class="string">"host"</span>, <span class="comment">// hostname of JobManager</span></span><br><span class="line">    <span class="number">1234</span>, <span class="comment">// port of JobManager process</span></span><br><span class="line">    <span class="string">"path/to/jarFile.jar"</span></span><br><span class="line">  ) <span class="comment">// JAR file to ship to the JobManager</span></span><br></pre></td></tr></table></figure></div>

<p>接下来，我们使用<code>env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>来将我们程序的时间语义设置为事件时间。执行环境提供了很多配置选项，例如：设置程序的并行度和程序是否开启容错机制。</p>
<h2 id="读取输入流"><a href="#读取输入流" class="headerlink" title="读取输入流"></a>读取输入流</h2><p>一旦执行环境设置好，就该写业务逻辑了。<code>StreamExecutionEnvironment</code>提供了创建数据源的方法，这些方法可以从数据流中将数据摄取到程序中。数据流可以来自消息队列或者文件系统，也可能是实时产生的（例如socket）。</p>
<p>在我们的例子里面，我们这样写：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br></pre></td></tr></table></figure></div>

<p>这样就可以连接到传感器测量数据的数据源并创建一个类型为<code>SensorReading</code>的<code>DataStream</code>了。Flink支持很多数据类型，我们将在接下来的章节里面讲解。在我们的例子里面，我们的数据类型是一个定义好的Scala样例类。<code>SensorReading</code>样例类包含了传感器ID，数据的测量时间戳，以及测量温度值。<code>assignTimestampsAndWatermarks(new SensorTimeAssigner)</code>方法指定了如何设置事件时间语义的时间戳和水位线。有关<code>SensorTimeAssigner</code>我们后面再讲。</p>
<h2 id="转换算子的使用"><a href="#转换算子的使用" class="headerlink" title="转换算子的使用"></a>转换算子的使用</h2><p>一旦我们有一条DataStream，我们就可以在这条数据流上面使用转换算子了。转换算子有很多种。一些转换算子可以产生一条新的DataStream，当然这个DataStream的类型可能是新类型。还有一些转换算子不会改变原有DataStream的数据，但会将数据流分区或者分组。业务逻辑就是由转换算子串起来组合而成的。</p>
<p>在我们的例子中，我们首先使用<code>map()</code>转换算子将传感器的温度值转换成了摄氏温度单位。然后，我们使用<code>keyBy()</code>转换算子将传感器读数流按照传感器ID进行分区。接下来，我们定义了一个<code>timeWindow()</code>转换算子，这个算子将每个传感器ID所对应的分区的传感器读数分配到了5秒钟的滚动窗口中。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> avgTemp: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = sensorData</span><br><span class="line">  .map(r =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> celsius = (r.temperature - <span class="number">32</span>) * (<span class="number">5.0</span> / <span class="number">9.0</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(r.id, r.timestamp, celsius)</span><br><span class="line">  &#125;)</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">  .apply(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br></pre></td></tr></table></figure></div>

<p>窗口转换算子将在“窗口操作符”一章中讲解。最后，我们使用了一个UDF函数来计算每个窗口的温度的平均值。我们稍后将会讨论UDF函数的实现。</p>
<h2 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h2><p>流处理程序经常将它们的计算结果发送到一些外部系统中去，例如：Apache Kafka，文件系统，或者数据库中。Flink提供了一个维护的很好的sink算子的集合，这些sink算子可以用来将数据写入到不同的系统中去。我们也可以实现自己的sink算子。也有一些Flink程序并不会向第三方外部系统发送数据，而是将数据存储到Flink系统内部，然后可以使用Flink的可查询状态的特性来查询数据。</p>
<p>在我们的例子中，计算结果是一个<code>DataStream[SensorReading]</code>数据记录。每一条数据记录包含了一个传感器在5秒钟的周期里面的平均温度。计算结果组成的数据流将会调用<code>print()</code>将计算结果写到标准输出。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">avgTemp.print()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>要注意一点，流的Sink算子的选择将会影响应用程序端到端(<code>end-to-end</code>)的一致性，具体就是应用程序的计算提供的到底是<code>at-least-once</code>还是<code>exactly-once</code>的一致性语义。应用程序端到端的一致性依赖于所选择的流的Sink算子和Flink的检查点算法的集成使用。</p>
</blockquote>
<h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><p>当应用程序完全写好时，我们可以调用<code>StreamExecutionEnvironment.execute()</code>来执行应用程序。在我们的例子中就是我们的最后一行调用：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">env.execute(<span class="string">"Compute average sensor temperature"</span>)</span><br></pre></td></tr></table></figure></div>

<p>Flink程序是惰性执行的。也就是说创建数据源和转换算子的API调用并不会立刻触发任何数据处理逻辑。API调用仅仅是在执行环境中构建了一个执行计划，这个执行计划包含了执行环境创建的数据源和所有的将要用在数据源上的转换算子。只有当<code>execute()</code>被调用时，系统才会触发程序的执行。</p>
<p>构建好的执行计划将被翻译成一个<code>JobGraph</code>并提交到<code>JobManager</code>上面去执行。根据执行环境的种类，一个<code>JobManager</code>将会运行在一个本地线程中（如果是本地执行环境的化）或者<code>JobGraph</code>将会被发送到一个远程的<code>JobManager</code>上面去。如果<code>JobManager</code>远程运行，那么<code>JobGraph</code>必须和一个包含有所有类和应用程序的依赖的JAR包一起发送到远程<code>JobManager</code>。</p>
<h2 id="产生传感器读数代码编写"><a href="#产生传感器读数代码编写" class="headerlink" title="产生传感器读数代码编写"></a>产生传感器读数代码编写</h2><h3 id="从批读取数据"><a href="#从批读取数据" class="headerlink" title="从批读取数据"></a>从批读取数据</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  .fromCollection(<span class="type">List</span>(</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_1"</span>, <span class="number">1547718199</span>, <span class="number">35.80018327300259</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_6"</span>, <span class="number">1547718199</span>, <span class="number">15.402984393403084</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_7"</span>, <span class="number">1547718199</span>, <span class="number">6.720945201171228</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_10"</span>, <span class="number">1547718199</span>, <span class="number">38.101067604893444</span>)</span><br><span class="line">  ))</span><br></pre></td></tr></table></figure></div>

<h3 id="从文件读取数据"><a href="#从文件读取数据" class="headerlink" title="从文件读取数据"></a>从文件读取数据</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = env.readTextFile(filePath)</span><br></pre></td></tr></table></figure></div>

<h3 id="以Kafka消息队列的数据为数据来源"><a href="#以Kafka消息队列的数据为数据来源" class="headerlink" title="以Kafka消息队列的数据为数据来源"></a>以Kafka消息队列的数据为数据来源</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">properties.setProperty(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"consumer-group"</span>)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"key.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"value.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>)</span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">env.setParallelism(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  <span class="comment">// source为来自Kafka的数据，这里我们实例化一个消费者，topic为hotitems</span></span><br><span class="line">  .addSource(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](</span><br><span class="line">      <span class="string">"hotitems"</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),</span><br><span class="line">      properties</span><br><span class="line">    )</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意，Kafka的版本为<code>2.2</code>。</p>
</blockquote>
<h3 id="自定义数据源"><a href="#自定义数据源" class="headerlink" title="自定义数据源"></a>自定义数据源</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Calendar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">RichParallelSourceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">SourceFunction</span>.<span class="type">SourceContext</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 传感器id，时间戳，温度</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params">id: <span class="type">String</span>, timestamp: <span class="type">Long</span>, temperature: <span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">需要extends</span> <span class="title">RichParallelSourceFunction</span>, <span class="title">泛型为SensorReading</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">SensorSource</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// flag indicating whether source is still running.</span></span><br><span class="line">  <span class="comment">// flag: 表示数据源是否还在正常运行</span></span><br><span class="line">  <span class="keyword">var</span> running: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// run()函数连续的发送SensorReading数据，使用SourceContext</span></span><br><span class="line">  <span class="comment">// 需要override</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(srcCtx: <span class="type">SourceContext</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialize random number generator</span></span><br><span class="line">    <span class="comment">// 初始化随机数发生器</span></span><br><span class="line">    <span class="keyword">val</span> rand = <span class="keyword">new</span> <span class="type">Random</span>()</span><br><span class="line">    <span class="comment">// look up index of this parallel task</span></span><br><span class="line">    <span class="comment">// 查找当前运行时上下文的任务的索引</span></span><br><span class="line">    <span class="keyword">val</span> taskIdx = <span class="keyword">this</span>.getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialize sensor ids and temperatures</span></span><br><span class="line">    <span class="comment">// 初始化10个(温度传感器的id, 温度值)元组</span></span><br><span class="line">    <span class="keyword">var</span> curFTemp = (<span class="number">1</span> to <span class="number">10</span>).map &#123;</span><br><span class="line">      <span class="comment">// nextGaussian产生高斯随机数</span></span><br><span class="line">      i =&gt; (<span class="string">"sensor_"</span> + (taskIdx * <span class="number">10</span> + i), <span class="number">65</span> + (rand.nextGaussian() * <span class="number">20</span>))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// emit data until being canceled</span></span><br><span class="line">    <span class="comment">// 无限循环，产生数据流</span></span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// update temperature</span></span><br><span class="line">      <span class="comment">// 更新温度</span></span><br><span class="line">      curFTemp = curFTemp.map(t =&gt; (t._1, t._2 + (rand.nextGaussian() * <span class="number">0.5</span>)) )</span><br><span class="line">      <span class="comment">// get current time</span></span><br><span class="line">      <span class="comment">// 获取当前时间戳</span></span><br><span class="line">      <span class="keyword">val</span> curTime = <span class="type">Calendar</span>.getInstance.getTimeInMillis</span><br><span class="line"></span><br><span class="line">      <span class="comment">// emit new SensorReading</span></span><br><span class="line">      <span class="comment">// 发射新的传感器数据, 注意这里srcCtx.collect</span></span><br><span class="line">      curFTemp.foreach(t =&gt; srcCtx.collect(<span class="type">SensorReading</span>(t._1, curTime, t._2)))</span><br><span class="line"></span><br><span class="line">      <span class="comment">// wait for 100 ms</span></span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">100</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// override cancel函数</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    running = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>使用方法</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ingest sensor stream</span></span><br><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">  <span class="comment">// SensorSource generates random temperature readings</span></span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意，在我们本教程中，我们一直会使用这个自定义的数据源。</p>
</blockquote>
<h2 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a>转换算子</h2><p>在这一小节我们将大概看一下DataStream API的基本转换算子。与时间有关的操作符（例如窗口操作符和其他特殊的转换算子）将会在后面的章节叙述。一个流的转换操作将会应用在一个或者多个流上面，这些转换操作将流转换成一个或者多个输出流。编写一个DataStream API简单来说就是将这些转换算子组合在一起来构建一个数据流图，这个数据流图就实现了我们的业务逻辑。</p>
<p>大部分的流转换操作都基于用户自定义函数UDF。UDF函数打包了一些业务逻辑并定义了输入流的元素如何转换成输出流的元素。像<code>MapFunction</code>这样的函数，将会被定义为类，这个类实现了Flink针对特定的转换操作暴露出来的接口。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMapFunction</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">Int</span>, <span class="type">Int</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">Int</span>): <span class="type">Int</span> = value + <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>函数接口定义了需要由用户实现的转换方法，例如上面例子中的<code>map()</code>方法。</p>
<p>大部分函数接口被设计为<code>Single Abstract Method</code>（单独抽象方法）接口，并且接口可以使用Java 8匿名函数来实现。Scala DataStream API也内置了对匿名函数的支持。当讲解DataStream API的转换算子时，我们展示了针对所有函数类的接口，但为了简洁，大部分接口的实现使用匿名函数而不是函数类的方式。</p>
<p>DataStream API针对大多数数据转换操作提供了转换算子。如果你很熟悉批处理API、函数式编程语言或者SQL，那么你将会发现这些API很容易学习。我们会将DataStream API的转换算子分成四类：</p>
<ul>
<li>基本转换算子：将会作用在数据流中的每一条单独的数据上。</li>
<li>KeyedStream转换算子：在数据有key的情况下，对数据应用转换算子。</li>
<li>多流转换算子：合并多条流为一条流或者将一条流分割为多条流。</li>
<li>分布式转换算子：将重新组织流里面的事件。</li>
</ul>
<h3 id="基本转换算子"><a href="#基本转换算子" class="headerlink" title="基本转换算子"></a>基本转换算子</h3><p>基本转换算子会针对流中的每一个单独的事件做处理，也就是说每一个输入数据会产生一个输出数据。单值转换，数据的分割，数据的过滤，都是基本转换操作的典型例子。我们将解释这些算子的语义并提供示例代码。</p>
<p><em>MAP</em></p>
<p><code>map</code>算子通过调用<code>DataStream.map()</code>来指定。<code>map</code>算子的使用将会产生一条新的数据流。它会将每一个输入的事件传送到一个用户自定义的mapper，这个mapper只返回一个输出事件，这个输出事件和输入事件的类型可能不一样。图5-1展示了一个map算子，这个map将每一个正方形转化成了圆形。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0501.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0501.png" class="lazyload"></a></p>
<p><code>MapFunction</code>的类型与输入事件和输出事件的类型相关，可以通过实现<code>MapFunction</code>接口来定义。接口包含<code>map()</code>函数，这个函数将一个输入事件恰好转换为一个输出事件。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// T: the type of input elements</span></span><br><span class="line"><span class="comment">// O: the type of output elements</span></span><br><span class="line"><span class="type">MapFunction</span>[<span class="type">T</span>, <span class="type">O</span>]</span><br><span class="line">    &gt; map(<span class="type">T</span>): <span class="type">O</span></span><br></pre></td></tr></table></figure></div>

<p>下面的代码实现了将SensorReading中的id字段抽取出来的功能。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = readings.map(<span class="keyword">new</span> <span class="type">MyMapFunction</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMapFunction</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(r: <span class="type">SensorReading</span>): <span class="type">String</span> = r.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>当然我们更推荐匿名函数的写法。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = readings.map(r =&gt; r.id)</span><br></pre></td></tr></table></figure></div>

<p><em>FILTER</em></p>
<p><code>filter</code>转换算子通过在每个输入事件上对一个布尔条件进行求值来过滤掉一些元素，然后将剩下的元素继续发送。一个<code>true</code>的求值结果将会把输入事件保留下来并发送到输出，而如果求值结果为<code>false</code>，则输入事件会被抛弃掉。我们通过调用<code>DataStream.filter()</code>来指定流的<code>filter</code>算子，<code>filter</code>操作将产生一条新的流，其类型和输入流中的事件类型是一样的。图5-2展示了只产生白色方框的<code>filter</code>操作。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0502.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0502.png" class="lazyload"></a></p>
<p>布尔条件可以使用函数、FilterFunction接口或者匿名函数来实现。FilterFunction中的泛型是输入事件的类型。定义的<code>filter()</code>方法会作用在每一个输入元素上面，并返回一个布尔值。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// T: the type of elements</span></span><br><span class="line"><span class="type">FilterFunction</span>[<span class="type">T</span>]</span><br><span class="line">    &gt; filter(<span class="type">T</span>): <span class="type">Boolean</span></span><br></pre></td></tr></table></figure></div>

<p>下面的例子展示了如何使用filter来从传感器数据中过滤掉温度值小于25华氏温度的读数。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> filteredSensors = readings.filter(r =&gt; r.temperature &gt;= <span class="number">25</span>)</span><br></pre></td></tr></table></figure></div>

<p><em>FLATMAP</em></p>
<p><code>flatMap</code>算子和<code>map</code>算子很类似，不同之处在于针对每一个输入事件<code>flatMap</code>可以生成0个、1个或者多个输出元素。事实上，<code>flatMap</code>转换算子是<code>filter</code>和<code>map</code>的泛化。所以<code>flatMap</code>可以实现<code>map</code>和<code>filter</code>算子的功能。图5-3展示了<code>flatMap</code>如何根据输入事件的颜色来做不同的处理。如果输入事件是白色方框，则直接输出。输入元素是黑框，则复制输入。灰色方框会被过滤掉。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0503.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0503.png" class="lazyload"></a></p>
<p>flatMap算子将会应用在每一个输入事件上面。对应的<code>FlatMapFunction</code>定义了<code>flatMap()</code>方法，这个方法返回0个、1个或者多个事件到一个<code>Collector</code>集合中，作为输出结果。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// T: the type of input elements</span></span><br><span class="line"><span class="comment">// O: the type of output elements</span></span><br><span class="line"><span class="type">FlatMapFunction</span>[<span class="type">T</span>, <span class="type">O</span>]</span><br><span class="line">    &gt; flatMap(<span class="type">T</span>, <span class="type">Collector</span>[<span class="type">O</span>]): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></div>

<p>下面的例子展示了在数据分析教程中经常用到的例子，我们用<code>flatMap</code>来实现。这个函数应用在一个语句流上面，将每个句子用空格切分，然后把切分出来的单词作为单独的事件发送出去。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sentences: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> words: <span class="type">DataStream</span>[<span class="type">String</span>] = sentences</span><br><span class="line">  .flatMap(id =&gt; id.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure></div>

<h3 id="键控流转换算子"><a href="#键控流转换算子" class="headerlink" title="键控流转换算子"></a>键控流转换算子</h3><p>很多流处理程序的一个基本要求就是要能对数据进行分组，分组后的数据共享某一个相同的属性。DataStream API提供了一个叫做<code>KeyedStream</code>的抽象，此抽象会从逻辑上对DataStream进行分区，分区后的数据拥有同样的<code>Key</code>值，分区后的流互不相关。</p>
<p>针对KeyedStream的状态转换操作可以读取数据或者写入数据到当前事件Key所对应的状态中。这表明拥有同样Key的所有事件都可以访问同样的状态，也就是说所以这些事件可以一起处理。</p>
<blockquote>
<p>要小心使用状态转换操作和基于Key的聚合操作。如果Key的值越来越多，例如：Key是订单ID，我们必须及时清空Key所对应的状态，以免引起内存方面的问题。稍后我们会详细讲解。</p>
</blockquote>
<p>KeyedStream可以使用map，flatMap和filter算子来处理。接下来我们会使用keyBy算子来将DataStream转换成KeyedStream，并讲解基于key的转换操作：滚动聚合和reduce算子。</p>
<p><em>KEYBY</em></p>
<p>keyBy通过指定key来将DataStream转换成KeyedStream。基于不同的key，流中的事件将被分配到不同的分区中去。所有具有相同key的事件将会在接下来的操作符的同一个子任务槽中进行处理。拥有不同key的事件可以在同一个任务中处理。但是算子只能访问当前事件的key所对应的状态。</p>
<p>如图5-4所示，把输入事件的颜色作为key，黑色的事件输出到了一个分区，其他颜色输出到了另一个分区。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0504.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0504.png" class="lazyload"></a></p>
<p><code>keyBy()</code>方法接收一个参数，这个参数指定了key或者keys，有很多不同的方法来指定key。我们将在后面讲解。下面的代码声明了<code>id</code>这个字段为SensorReading流的key。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyed: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = readings</span><br><span class="line">  .keyBy(r =&gt; r.id)</span><br></pre></td></tr></table></figure></div>

<p>匿名函数<code>r =&gt; r.id</code>抽取了传感器读数SensorReading的id值。</p>
<p><em>滚动聚合</em></p>
<p>滚动聚合算子由<code>KeyedStream</code>调用，并生成一个聚合以后的DataStream，例如：sum，minimum，maximum。一个滚动聚合算子会为每一个观察到的key保存一个聚合的值。针对每一个输入事件，算子将会更新保存的聚合结果，并发送一个带有更新后的值的事件到下游算子。滚动聚合不需要用户自定义函数，但需要接受一个参数，这个参数指定了在哪一个字段上面做聚合操作。DataStream API提供了以下滚动聚合方法。</p>
<blockquote>
<p>滚动聚合算子只能用在滚动窗口，不能用在滑动窗口。</p>
</blockquote>
<ul>
<li>sum()：在输入流上对指定的字段做滚动相加操作。</li>
<li>min()：在输入流上对指定的字段求最小值。</li>
<li>max()：在输入流上对指定的字段求最大值。</li>
<li>minBy()：在输入流上针对指定字段求最小值，并返回包含当前观察到的最小值的事件。</li>
<li>maxBy()：在输入流上针对指定字段求最大值，并返回包含当前观察到的最大值的事件。</li>
</ul>
<p>滚动聚合算子无法组合起来使用，每次计算只能使用一个单独的滚动聚合算子。</p>
<p>下面的例子根据第一个字段来对类型为<code>Tuple3[Int, Int, Int]</code>的流做分流操作，然后针对第二个字段做滚动求和操作。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>)] = env.fromElements(</span><br><span class="line">  (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>)] = inputStream</span><br><span class="line">  .keyBy(<span class="number">0</span>) <span class="comment">// key on first field of the tuple</span></span><br><span class="line">  .sum(<span class="number">1</span>)   <span class="comment">// sum the second field of the tuple in place</span></span><br></pre></td></tr></table></figure></div>

<p>在这个例子里面，输入流根据第一个字段来分流，然后在第二个字段上做计算。对于key 1，输出结果是(1,2,2),(1,7,2)。对于key 2，输出结果是(2,3,1),(2,5,1)。第一个字段是key，第二个字段是求和的数值，第三个字段未定义。</p>
<blockquote>
<p>滚动聚合操作会对每一个key都保存一个状态。因为状态从来不会被清空，所以我们在使用滚动聚合算子时只能使用在含有有限个key的流上面。</p>
</blockquote>
<p><em>REDUCE</em></p>
<p>reduce算子是滚动聚合的泛化实现。它将一个ReduceFunction应用到了一个KeyedStream上面去。reduce算子将会把每一个输入事件和当前已经reduce出来的值做聚合计算。reduce操作不会改变流的事件类型。输出流数据类型和输入流数据类型是一样的。</p>
<p>reduce函数可以通过实现接口ReduceFunction来创建一个类。ReduceFunction接口定义了<code>reduce()</code>方法，此方法接收两个输入事件，输入一个相同类型的事件。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// T: the element type</span></span><br><span class="line"><span class="type">ReduceFunction</span>[<span class="type">T</span>]</span><br><span class="line">    &gt; reduce(<span class="type">T</span>, <span class="type">T</span>): <span class="type">T</span></span><br></pre></td></tr></table></figure></div>

<p>下面的例子，流根据语言这个key来分区，输出结果为针对每一种语言都实时更新的单词列表。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])] = env.fromElements(</span><br><span class="line">  (<span class="string">"en"</span>, <span class="type">List</span>(<span class="string">"tea"</span>)), (<span class="string">"fr"</span>, <span class="type">List</span>(<span class="string">"vin"</span>)), (<span class="string">"en"</span>, <span class="type">List</span>(<span class="string">"cake"</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])] = inputStream</span><br><span class="line">  .keyBy(<span class="number">0</span>)</span><br><span class="line">  .reduce((x, y) =&gt; (x._1, x._2 ::: y._2))</span><br></pre></td></tr></table></figure></div>

<p>reduce匿名函数将连续两个tuple的第一个字段(key字段)继续发送出去，然后将两个tuple的第二个字段List[String]连接。</p>
<blockquote>
<p>reduce作为滚动聚合的泛化实现，同样也要针对每一个key保存状态。因为状态从来不会清空，所以我们需要将reduce算子应用在一个有限key的流上。</p>
</blockquote>
<h3 id="多流转换算子"><a href="#多流转换算子" class="headerlink" title="多流转换算子"></a>多流转换算子</h3><p>许多应用需要摄入多个流并将流合并处理，还可能需要将一条流分割成多条流然后针对每一条流应用不同的业务逻辑。接下来，我们将讨论DataStream API中提供的能够处理多条输入流或者发送多条输出流的操作算子。</p>
<p><em>UNION</em></p>
<p>DataStream.union()方法将两条或者多条DataStream合并成一条具有与输入流相同类型的输出DataStream。接下来的转换算子将会处理输入流中的所有元素。图5-5展示了union操作符如何将黑色和白色的事件流合并成一个单一输出流。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0505.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0505.png" class="lazyload"></a></p>
<p>事件合流的方式为FIFO方式。操作符并不会产生一个特定顺序的事件流。union操作符也不会进行去重。每一个输入事件都被发送到了下一个操作符。</p>
<p>下面的例子展示了如何将三条类型为SensorReading的数据流合并成一条流。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> parisStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> tokyoStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> rioStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> allCities: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = parisStream</span><br><span class="line">  .union(tokyoStream, rioStream)</span><br></pre></td></tr></table></figure></div>

<p><em>CONNECT, COMAP和COFLATMAP</em></p>
<p>联合两条流的事件是非常常见的流处理需求。例如监控一片森林然后发出高危的火警警报。报警的Application接收两条流，一条是温度传感器传回来的数据，一条是烟雾传感器传回来的数据。当两条流都超过各自的阈值时，报警。</p>
<p>DataStream API提供了<code>connect</code>操作来支持以上的应用场景。<code>DataStream.connect()</code>方法接收一条<code>DataStream</code>，然后返回一个<code>ConnectedStreams</code>类型的对象，这个对象表示了两条连接的流。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// first stream</span></span><br><span class="line"><span class="keyword">val</span> first: <span class="type">DataStream</span>[<span class="type">Int</span>] = ...</span><br><span class="line"><span class="comment">// second stream</span></span><br><span class="line"><span class="keyword">val</span> second: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// connect streams</span></span><br><span class="line"><span class="keyword">val</span> connected: <span class="type">ConnectedStreams</span>[<span class="type">Int</span>, <span class="type">String</span>] = first.connect(second)</span><br></pre></td></tr></table></figure></div>

<p>ConnectedStreams提供了<code>map()</code>和<code>flatMap()</code>方法，分别需要接收类型为<code>CoMapFunction</code>和<code>CoFlatMapFunction</code>的参数。</p>
<p>以上两个函数里面的泛型是第一条流的事件类型和第二条流的事件类型，以及输出流的事件类型。还定义了两个方法，每一个方法针对一条流来调用。<code>map1()</code>和<code>flatMap1()</code>会调用在第一条流的元素上面，<code>map2()</code>和<code>flatMap2()</code>会调用在第二条流的元素上面。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// IN1: 第一条流的事件类型</span></span><br><span class="line"><span class="comment">// IN2: 第二条流的事件类型</span></span><br><span class="line"><span class="comment">// OUT: 输出流的事件类型</span></span><br><span class="line"><span class="type">CoMapFunction</span>[<span class="type">IN1</span>, <span class="type">IN2</span>, <span class="type">OUT</span>]</span><br><span class="line">    &gt; map1(<span class="type">IN1</span>): <span class="type">OUT</span></span><br><span class="line">    &gt; map2(<span class="type">IN2</span>): <span class="type">OUT</span></span><br><span class="line"></span><br><span class="line"><span class="type">CoFlatMapFunction</span>[<span class="type">IN1</span>, <span class="type">IN2</span>, <span class="type">OUT</span>]</span><br><span class="line">    &gt; flatMap1(<span class="type">IN1</span>, <span class="type">Collector</span>[<span class="type">OUT</span>]): <span class="type">Unit</span></span><br><span class="line">    &gt; flatMap2(<span class="type">IN2</span>, <span class="type">Collector</span>[<span class="type">OUT</span>]): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>函数无法选择读某一条流。我们是无法控制函数中的两个方法的调用顺序的。当一条流中的元素到来时，将会调用相对应的方法。</p>
</blockquote>
<p>对两条流做连接查询通常需要这两条流基于某些条件被确定性的路由到操作符中相同的并行实例里面去。在默认情况下，connect()操作将不会对两条流的事件建立任何关系，所以两条流的事件将会随机的被发送到下游的算子实例里面去。这样的行为会产生不确定性的计算结果，显然不是我们想要的。为了针对ConnectedStreams进行确定性的转换操作，connect()方法可以和keyBy()或者broadcast()组合起来使用。我们首先看一下keyBy()的示例。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> one: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> two: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// keyBy two connected streams</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect1: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = one</span><br><span class="line">  .connect(two)</span><br><span class="line">  .keyBy(<span class="number">0</span>, <span class="number">0</span>) <span class="comment">// key both input streams on first attribute</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// alternative: connect two keyed streams</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect2: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = one</span><br><span class="line">  .keyBy(<span class="number">0</span>)</span><br><span class="line">  .connect(two.keyBy(<span class="number">0</span>))</span><br></pre></td></tr></table></figure></div>

<p>无论使用keyBy()算子操作ConnectedStreams还是使用connect()算子连接两条KeyedStreams，connect()算子会将两条流的含有相同Key的所有事件都发送到相同的算子实例。两条流的key必须是一样的类型和值，就像SQL中的JOIN。在connected和keyed stream上面执行的算子有访问keyed state的权限。</p>
<p>下面的例子展示了如何连接一条DataStream和广播过的流。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> first: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> second: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// connect streams with broadcast</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = first</span><br><span class="line">  <span class="comment">// broadcast second input stream</span></span><br><span class="line">  .connect(second.broadcast())</span><br></pre></td></tr></table></figure></div>

<p>一条被广播过的流中的所有元素将会被复制然后发送到下游算子的所有并行实例中去。未被广播过的流仅仅向前发送。所以两条流的元素显然会被连接处理。</p>
<p><em>SPLIT和SELECT</em></p>
<p>Split是Union的反函数。Split将输入的流分成两条或者多条流。每一个输入的元素都可以被路由到0、1或者多条流中去。所以，split可以用来过滤或者复制元素。图5-6展示了split操作符将所有的白色事件都路由到同一条流中去了，剩下的元素去往另一条流。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0506.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0506.png" class="lazyload"></a></p>
<p>DataStream.split()方法接受<code>OutputSelector</code>类型，此类型定义了输入流中的元素被分配到哪个名字的流中去。<code>OutputSelector</code>定义了<code>select()</code>方法，此方法将被每一个元素调用，并返回<code>java.lang.Iterable[String]</code>类型的数据。返回的<code>String</code>类型的值将指定元素将被路由到哪一条流。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; IN: the type of the split elements</span><br><span class="line">OutputSelector[IN]</span><br><span class="line">    &gt; select(IN): Iterable[String]</span><br></pre></td></tr></table></figure></div>

<p>DataStream.split()方法返回<code>SplitStream</code>类型，此类型提供<code>select()</code>方法，可以根据分流后不同流的名字，将某个名字对应的流提取出来。</p>
<p>例5-2将一条整数流分成了不同的流，大的整数一条流，小的整数一条流。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> splitted: <span class="type">SplitStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = inputStream</span><br><span class="line">  .split(t =&gt; <span class="keyword">if</span> (t._1 &gt; <span class="number">1000</span>) <span class="type">Seq</span>(<span class="string">"large"</span>) <span class="keyword">else</span> <span class="type">Seq</span>(<span class="string">"small"</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> large: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"large"</span>)</span><br><span class="line"><span class="keyword">val</span> small: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"small"</span>)</span><br><span class="line"><span class="keyword">val</span> all: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"small"</span>, <span class="string">"large"</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>不推荐使用split方法，推荐使用Flink的侧输出（side-output）特性。</p>
</blockquote>
<h3 id="分布式转换算子"><a href="#分布式转换算子" class="headerlink" title="分布式转换算子"></a>分布式转换算子</h3><p>分区操作对应于我们之前讲过的“数据交换策略”这一节。这些操作定义了事件如何分配到不同的任务中去。当我们使用DataStream API来编写程序时，系统将自动的选择数据分区策略，然后根据操作符的语义和设置的并行度将数据路由到正确的地方去。有些时候，我们需要在应用程序的层面控制分区策略，或者自定义分区策略。例如，如果我们知道会发生数据倾斜，那么我们想要针对数据流做负载均衡，将数据流平均发送到接下来的操作符中去。又或者，应用程序的业务逻辑可能需要一个算子所有的并行任务都需要接收同样的数据。再或者，我们需要自定义分区策略的时候。在这一小节，我们将展示DataStream的一些方法，可以使我们来控制或者自定义数据分区策略。</p>
<blockquote>
<p>keyBy()方法不同于分布式转换算子。所有的分布式转换算子将产生DataStream数据类型。而keyBy()产生的类型是KeyedStream，它拥有自己的keyed state。</p>
</blockquote>
<p><em>Random</em></p>
<p>随机数据交换由<code>DataStream.shuffle()</code>方法实现。shuffle方法将数据随机的分配到下游算子的并行任务中去。</p>
<p><em>Round-Robin</em></p>
<p><code>rebalance()</code>方法使用Round-Robin负载均衡算法将输入流平均分配到随后的并行运行的任务中去。图5-7为round-robin分布式转换算子的示意图。</p>
<p><em>Rescale</em></p>
<p><code>rescale()</code>方法使用的也是round-robin算法，但只会将数据发送到接下来的并行运行的任务中的一部分任务中。本质上，当发送者任务数量和接收者任务数量不一样时，rescale分区策略提供了一种轻量级的负载均衡策略。如果接收者任务的数量是发送者任务的数量的倍数时，rescale操作将会效率更高。</p>
<p><code>rebalance()</code>和<code>rescale()</code>的根本区别在于任务之间连接的机制不同。 <code>rebalance()</code>将会针对所有发送者任务和所有接收者任务之间建立通信通道，而<code>rescale()</code>仅仅针对每一个任务和下游算子的一部分子并行任务之间建立通信通道。rescale的示意图为图5-7。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0507.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0507.png" class="lazyload"></a></p>
<p><em>Broadcast</em></p>
<p><code>broadcast()</code>方法将输入流的所有数据复制并发送到下游算子的所有并行任务中去。</p>
<p><em>Global</em></p>
<p><code>global()</code>方法将所有的输入流数据都发送到下游算子的第一个并行任务中去。这个操作需要很谨慎，因为将所有数据发送到同一个task，将会对应用程序造成很大的压力。</p>
<p><em>Custom</em></p>
<p>当Flink提供的分区策略都不适用时，我们可以使用<code>partitionCustom()</code>方法来自定义分区策略。这个方法接收一个<code>Partitioner</code>对象，这个对象需要实现分区逻辑以及定义针对流的哪一个字段或者key来进行分区。下面的例子将一条整数流做partition，使得所有的负整数都发送到第一个任务中，剩下的数随机分配。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers: <span class="type">DataStream</span>[(<span class="type">Int</span>)] = ...</span><br><span class="line">numbers.partitionCustom(myPartitioner, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">myPartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>[<span class="type">Int</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> r = scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">partition</span></span>(key: <span class="type">Int</span>, numPartitions: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (key &lt; <span class="number">0</span>) <span class="number">0</span> <span class="keyword">else</span> r.nextInt(numPartitions)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="设置并行度"><a href="#设置并行度" class="headerlink" title="设置并行度"></a>设置并行度</h2><p>Flink应用程序在一个像集群这样的分布式环境中并行执行。当一个数据流程序提交到JobManager执行时，系统将会创建一个数据流图，然后准备执行需要的操作符。每一个操作符将会并行化到一个或者多个任务中去。每个算子的并行任务都会处理这个算子的输入流中的一份子集。一个算子并行任务的个数叫做算子的并行度。它决定了算子执行的并行化程度，以及这个算子能处理多少数据量。</p>
<p>算子的并行度可以在执行环境这个层级来控制，也可以针对每个不同的算子设置不同的并行度。默认情况下，应用程序中所有算子的并行度都将设置为执行环境的并行度。执行环境的并行度（也就是所有算子的默认并行度）将在程序开始运行时自动初始化。如果应用程序在本地执行环境中运行，并行度将被设置为CPU的核数。当我们把应用程序提交到一个处于运行中的Flink集群时，执行环境的并行度将被设置为集群默认的并行度，除非我们在客户端提交应用程序时显式的设置好并行度。</p>
<p>通常情况下，将算子的并行度定义为和执行环境并行度相关的数值会是个好主意。这允许我们通过在客户端调整应用程序的并行度就可以将程序水平扩展了。我们可以使用以下代码来访问执行环境的默认并行度。</p>
<p>我们还可以重写执行环境的默认并行度，但这样的话我们将再也不能通过客户端来控制应用程序的并行度了。</p>
<p>算子默认的并行度也可以通过重写来明确指定。在下面的例子里面，数据源的操作符将会按照环境默认的并行度来并行执行，map操作符的并行度将会是默认并行度的2倍，sink操作符的并行度为2。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> defaultP = env.getParallelism</span><br><span class="line"><span class="keyword">val</span> result = env.addSource(<span class="keyword">new</span> <span class="type">CustomSource</span>)</span><br><span class="line">  .map(<span class="keyword">new</span> <span class="type">MyMapper</span>).setParallelism(defaultP * <span class="number">2</span>)</span><br><span class="line">  .print().setParallelism(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></div>

<p>当我们通过客户端将应用程序的并行度设置为16并提交执行时，source操作符的并行度为16，mapper并行度为32，sink并行度为2。如果我们在本地环境运行应用程序的话，例如在IDE中运行，机器是8核，那么source任务将会并行执行在8个任务上面，mapper运行在16个任务上面，sink运行在2个任务上面。</p>
<blockquote>
<p>并行度是动态概念，任务槽数量是静态概念。并行度&lt;=任务槽数量。一个任务槽最多运行一个并行度。</p>
</blockquote>
<h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><p>Flink程序所处理的流中的事件一般是对象类型。操作符接收对象输出对象。所以Flink的内部机制需要能够处理事件的类型。在网络中传输数据，或者将数据写入到状态后端、检查点和保存点中，都需要我们对数据进行序列化和反序列化。为了高效的进行此类操作，Flink需要流中事件类型的详细信息。Flink使用了<code>Type Information</code>的概念来表达数据类型，这样就能针对不同的数据类型产生特定的序列化器，反序列化器和比较操作符。</p>
<blockquote>
<p>有点像泛型。</p>
</blockquote>
<p>Flink也能够通过分析输入数据和输出数据来自动获取数据的类型信息以及序列化器和反序列化器。尽管如此，在一些特定的情况下，例如匿名函数或者使用泛型的情况下，我们需要明确的提供数据的类型信息，来提高我们程序的性能。</p>
<p>在这一节中，我们将讨论Flink支持的类型，以及如何为数据类型创建相应的类型信息，还有就是在Flink无法推断函数返回类型的情况下，如何帮助Flink的类型系统去做类型推断。</p>
<h3 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h3><p>Flink支持Java和Scala提供的所有普通数据类型。最常用的数据类型可以做以下分类：</p>
<ul>
<li>Primitives（原始数据类型）</li>
<li>Java和Scala的Tuples（元组）</li>
<li>Scala的样例类</li>
<li>POJO类型</li>
<li>一些特殊的类型</li>
</ul>
<p>接下来让我们一探究竟。</p>
<p><em>Primitives</em></p>
<p>Java和Scala提供的所有原始数据类型都支持，例如<code>Int</code>(Java的<code>Integer</code>)，String，Double等等。下面举一个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers: <span class="type">DataStream</span>[<span class="type">Long</span>] = env.fromElements(<span class="number">1</span>L, <span class="number">2</span>L, <span class="number">3</span>L, <span class="number">4</span>L)</span><br><span class="line">numbers.map(n =&gt; n + <span class="number">1</span>)</span><br></pre></td></tr></table></figure></div>

<p><em>Tuples</em></p>
<p>元组是一种组合数据类型，由固定数量的元素组成。</p>
<p>DataStream的Scala API直接使用Scala内置的Tuple。举个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> persons: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Integer</span>)] =</span><br><span class="line">env.fromElements(</span><br><span class="line">  (<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">  (<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">persons.filter(p =&gt; p._2 &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure></div>

<p>Flink为Java的Tuple同样提供了高效的实现。Flink实现的Java Tuple最多可以有25个元素，根据元素数量的不同，Tuple都被实现成了不同的类：Tuple1，Tuple2，一直到Tuple25。Tuple类是强类型。</p>
<p>我们可以将上面的例子用Java的DataStream API重写：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt; persons = env</span><br><span class="line">  .fromElements(</span><br><span class="line">    <span class="type">Tuple2</span>.of(<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">    <span class="type">Tuple2</span>.of(<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">persons.filter(p -&gt; p.f1 &gt; <span class="number">18</span>);</span><br></pre></td></tr></table></figure></div>

<p>Tuple的元素可以通过它们的public属性访问–f0，f1，f2等等。或者使用<code>getField(int pos)</code>方法来访问，元素下标从0开始：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.<span class="type">Tuple2</span></span><br><span class="line"></span><br><span class="line"><span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt; personTuple = <span class="type">Tuple2</span>.of(<span class="string">"Alex"</span>, <span class="number">42</span>);</span><br><span class="line"><span class="type">Integer</span> age = personTuple.getField(<span class="number">1</span>); <span class="comment">// age = 42</span></span><br></pre></td></tr></table></figure></div>

<p>不同于Scala的Tuple，Java的Tuple是可变数据结构，所以Tuple中的元素可以重新进行赋值。重复利用Java的Tuple可以减轻垃圾收集的压力。举个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">personTuple.f1 = <span class="number">42</span>; <span class="comment">// set the 2nd field to 42</span></span><br><span class="line">personTuple.setField(<span class="number">43</span>, <span class="number">1</span>); <span class="comment">// set the 2nd field to 43</span></span><br></pre></td></tr></table></figure></div>

<p><em>Scala case classes</em></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">persons</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = env.fromElements(</span><br><span class="line">  <span class="type">Person</span>(<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">  <span class="type">Person</span>(<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">persons.filter(p =&gt; p.age &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure></div>

<p><em>POJO</em></p>
<p>POJO类的定义：</p>
<ul>
<li>公有类</li>
<li>无参数的公有构造器</li>
<li>所有的字段都是公有的，可以通过getters和setters访问。</li>
<li>所有字段的数据类型都必须是Flink支持的数据类型。</li>
</ul>
<p>举个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">  public <span class="type">String</span> name;</span><br><span class="line">  public int age;</span><br><span class="line"></span><br><span class="line">  public <span class="type">Person</span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  public <span class="type">Person</span>(<span class="type">String</span> name, int age) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Person</span>&gt; persons = env.fromElements(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">"Alex"</span>, <span class="number">42</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">"Wendy"</span>, <span class="number">23</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></div>

<p><em>其他数据类型</em></p>
<ul>
<li>Array, ArrayList, HashMap, Enum</li>
<li>Hadoop Writable types</li>
<li>Either, Option, Try</li>
</ul>
<h3 id="为数据类型创建类型信息"><a href="#为数据类型创建类型信息" class="headerlink" title="为数据类型创建类型信息"></a>为数据类型创建类型信息</h3><p>Flink类型系统的核心类是<code>TypeInformation</code>。它为系统在产生序列化器和比较操作符时，提供了必要的类型信息。例如，如果我们想使用某个key来做联结查询或者分组操作，<code>TypeInformation</code>可以让Flink做更严格的类型检查。</p>
<p>Flink针对Java和Scala分别提供了类来产生类型信息。在Java中，类是</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">org.apache.flink.api.common.typeinfo.<span class="type">Types</span></span><br></pre></td></tr></table></figure></div>

<p>举个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Integer</span>&gt; intType = <span class="type">Types</span>.<span class="type">INT</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Long</span>, <span class="type">String</span>&gt;&gt; tupleType = <span class="type">Types</span></span><br><span class="line">  .<span class="type">TUPLE</span>(<span class="type">Types</span>.<span class="type">LONG</span>, <span class="type">Types</span>.<span class="type">STRING</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Person</span>&gt; personType = <span class="type">Types</span></span><br><span class="line">  .<span class="type">POJO</span>(<span class="type">Person</span><span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure></div>

<p>在Scala中，类是 <code>org.apache.flink.api.scala.typeutils.Types</code> ，举个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// TypeInformation for primitive types</span></span><br><span class="line"><span class="keyword">val</span> stringType: <span class="type">TypeInformation</span>[<span class="type">String</span>] = <span class="type">Types</span>.<span class="type">STRING</span></span><br><span class="line"><span class="comment">// TypeInformation for Scala Tuples</span></span><br><span class="line"><span class="keyword">val</span> tupleType: <span class="type">TypeInformation</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = <span class="type">Types</span>.<span class="type">TUPLE</span>[(<span class="type">Int</span>, <span class="type">Long</span>)]</span><br><span class="line"><span class="comment">// TypeInformation for case classes</span></span><br><span class="line"><span class="keyword">val</span> caseClassType: <span class="type">TypeInformation</span>[<span class="type">Person</span>] = <span class="type">Types</span>.<span class="type">CASE_CLASS</span>[<span class="type">Person</span>]</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>别忘了导入<code>import org.apache.flink.streaming.api.scala._</code></p>
</blockquote>
<h2 id="定义Key以及引用字段"><a href="#定义Key以及引用字段" class="headerlink" title="定义Key以及引用字段"></a>定义Key以及引用字段</h2><p>在Flink中，我们必须明确指定输入流中的元素中的哪一个字段是key。</p>
<h3 id="使用字段位置进行keyBy"><a href="#使用字段位置进行keyBy" class="headerlink" title="使用字段位置进行keyBy"></a>使用字段位置进行keyBy</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyed = input.keyBy(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意，要么明确写清楚类型注释，要么让Scala去做类型推断，不要用IDEA的类型推断功能。</p>
</blockquote>
<p>如果我们想要用元组的第2个字段和第3个字段做keyBy，可以看下面的例子。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> keyed2 = input.keyBy(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div>

<h3 id="使用字段表达式来进行keyBy"><a href="#使用字段表达式来进行keyBy" class="headerlink" title="使用字段表达式来进行keyBy"></a>使用字段表达式来进行keyBy</h3><p>对于样例类：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  timestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  temperature: <span class="type">Double</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">sensorStream</span></span>: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyedSensors = sensorStream.keyBy(<span class="string">"id"</span>)</span><br></pre></td></tr></table></figure></div>

<p>对于元组：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyed1 = input.keyBy(<span class="string">"2"</span>) <span class="comment">// key by 3rd field</span></span><br><span class="line"><span class="keyword">val</span> keyed2 = input.keyBy(<span class="string">"_1"</span>) <span class="comment">// key by 1st field</span></span><br><span class="line"></span><br><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Tuple3</span>&lt;<span class="type">Integer</span>, <span class="type">String</span>, <span class="type">Long</span>&gt;&gt; javaInput = ...</span><br><span class="line">javaInput.keyBy(<span class="string">"f2"</span>) <span class="comment">// key Java tuple by 3rd field</span></span><br></pre></td></tr></table></figure></div>

<p>对于存在嵌套的样例类：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Address</span> (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  address: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  zip: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  country: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Person</span> (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  birthday: (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span></span>), <span class="title">//</span> <span class="title">year</span>, <span class="title">month</span>, <span class="title">day</span></span></span><br><span class="line"><span class="class">  <span class="title">address</span></span>: <span class="type">Address</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> persons: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line">persons.keyBy(<span class="string">"address.zip"</span>) <span class="comment">// key by nested POJO field</span></span><br><span class="line">persons.keyBy(<span class="string">"birthday._1"</span>) <span class="comment">// key by field of nested tuple</span></span><br><span class="line">persons.keyBy(<span class="string">"birthday._"</span>) <span class="comment">// key by all fields of nested tuple</span></span><br></pre></td></tr></table></figure></div>

<h3 id="Key选择器"><a href="#Key选择器" class="headerlink" title="Key选择器"></a>Key选择器</h3><p>方法类型</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KeySelector[IN, KEY]</span><br><span class="line">  &gt; getKey(IN): KEY</span><br></pre></td></tr></table></figure></div>

<p>两个例子</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> byId: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = sensorData.keyBy(r =&gt; r.id)</span><br><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyedStream = input.keyBy(value =&gt; math.max(value._1, value._2))</span><br></pre></td></tr></table></figure></div>

<h2 id="实现UDF函数，更细粒度的控制流"><a href="#实现UDF函数，更细粒度的控制流" class="headerlink" title="实现UDF函数，更细粒度的控制流"></a>实现UDF函数，更细粒度的控制流</h2><h3 id="函数类-Function-Classes"><a href="#函数类-Function-Classes" class="headerlink" title="函数类(Function Classes)"></a>函数类(Function Classes)</h3><p>Flink暴露了所有udf函数的接口(实现方式为接口或者抽象类)。例如MapFunction, FilterFunction, ProcessFunction等等。</p>
<p>例子实现了FilterFunction接口</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FilterFilter</span> <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    value.contains(<span class="string">"flink"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(<span class="keyword">new</span> <span class="type">FlinkFilter</span>)</span><br></pre></td></tr></table></figure></div>

<p>还可以将函数实现成匿名类</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">RichFilterFunction</span>[<span class="type">String</span>] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">      value.contains(<span class="string">"flink"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<p>我们filter的字符串“flink”还可以当作参数传进去。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> tweets: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(<span class="keyword">new</span> <span class="type">KeywordFilter</span>(<span class="string">"flink"</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KeywordFilter</span>(<span class="params">keyWord: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    value.contains(keyWord)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="匿名函数-Lambda-Functions"><a href="#匿名函数-Lambda-Functions" class="headerlink" title="匿名函数(Lambda Functions)"></a>匿名函数(Lambda Functions)</h3><p>匿名函数可以实现一些简单的逻辑，但无法实现一些高级功能，例如访问状态等等。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> tweets: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(_.contains(<span class="string">"flink"</span>))</span><br></pre></td></tr></table></figure></div>

<h3 id="富函数-Rich-Functions"><a href="#富函数-Rich-Functions" class="headerlink" title="富函数(Rich Functions)"></a>富函数(Rich Functions)</h3><p>我们经常会有这样的需求：在函数处理数据之前，需要做一些初始化的工作；或者需要在处理数据时可以获得函数执行上下文的一些信息；以及在处理完数据时做一些清理工作。而DataStream API就提供了这样的机制。</p>
<p>DataStream API提供的所有转换操作函数，都拥有它们的“富”版本，并且我们在使用常规函数或者匿名函数的地方来使用富函数。例如下面就是富函数的一些例子，可以看出，只需要在常规函数的前面加上<code>Rich</code>前缀就是富函数了。</p>
<ul>
<li>RichMapFunction</li>
<li>RichFlatMapFunction</li>
<li>RichFilterFunction</li>
<li>…</li>
</ul>
<p>当我们使用富函数时，我们可以实现两个额外的方法：</p>
<ul>
<li>open()方法是rich function的初始化方法，当一个算子例如map或者filter被调用之前open()会被调用。open()函数通常用来做一些只需要做一次即可的初始化工作。</li>
<li>close()方法是生命周期中的最后一个调用的方法，通常用来做一些清理工作。</li>
</ul>
<p>另外，getRuntimeContext()方法提供了函数的RuntimeContext的一些信息，例如函数执行的并行度，当前子任务的索引，当前子任务的名字。同时还它还包含了访问<strong>分区状态</strong>的方法。下面看一个例子：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyFlatMap</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>[<span class="type">Int</span>, (<span class="type">Int</span>, <span class="type">Int</span>)] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> subTaskIndex = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(configuration: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    subTaskIndex = getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line">    <span class="comment">// 做一些初始化工作</span></span><br><span class="line">    <span class="comment">// 例如建立一个和HDFS的连接</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(in: <span class="type">Int</span>, out: <span class="type">Collector</span>[(<span class="type">Int</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (in % <span class="number">2</span> == subTaskIndex) &#123;</span><br><span class="line">      out.collect((subTaskIndex, in))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 清理工作，断开和HDFS的连接。</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><p>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。所有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">stream.addSink(<span class="keyword">new</span> <span class="type">MySink</span>(xxxx))</span><br></pre></td></tr></table></figure></div>

<p>官方提供了一部分的框架的sink。除此以外，需要用户自定义实现sink。</p>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>Kafka版本为0.11</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka-0.11_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>Kafka版本为2.0以上</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>主函数中添加sink：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> union = high</span><br><span class="line">  .union(low)</span><br><span class="line">  .map(_.temperature.toString)</span><br><span class="line"></span><br><span class="line">union.addSink(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FlinkKafkaProducer011</span>[<span class="type">String</span>](</span><br><span class="line">    <span class="string">"localhost:9092"</span>,</span><br><span class="line">    <span class="string">"test"</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>

<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.bahir<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-redis_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>定义一个redis的mapper类，用于定义保存到redis时调用的命令：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRedisMapper</span> <span class="keyword">extends</span> <span class="title">RedisMapper</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getCommandDescription</span></span>: <span class="type">RedisCommandDescription</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">RedisCommandDescription</span>(<span class="type">RedisCommand</span>.<span class="type">HSET</span>, <span class="string">"sensor_temperature"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValueFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    t.temperature.toString</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKeyFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = t.id</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>在主函数中调用：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>在主函数中调用：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> httpHosts = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">HttpHost</span>]()</span><br><span class="line">httpHosts.add(<span class="keyword">new</span> <span class="type">HttpHost</span>(<span class="string">"localhost"</span>, <span class="number">9200</span>))</span><br><span class="line"><span class="keyword">val</span> esSinkBuilder = <span class="keyword">new</span> <span class="type">ElasticsearchSink</span>.<span class="type">Builder</span>[<span class="type">SensorReading</span>](</span><br><span class="line">  httpHosts,</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ElasticsearchSinkFunction</span>[<span class="type">SensorReading</span>] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(t: <span class="type">SensorReading</span>,</span><br><span class="line">                         runtimeContext: <span class="type">RuntimeContext</span>,</span><br><span class="line">                         requestIndexer: <span class="type">RequestIndexer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">"saving data: "</span> + t)</span><br><span class="line">      <span class="keyword">val</span> json = <span class="keyword">new</span> util.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line">      json.put(<span class="string">"data"</span>, t.toString)</span><br><span class="line">      <span class="keyword">val</span> indexRequest = <span class="type">Requests</span></span><br><span class="line">        .indexRequest()</span><br><span class="line">        .index(<span class="string">"sensor"</span>)</span><br><span class="line">        .`<span class="class"><span class="keyword">type</span>`(<span class="params">"readingData"</span>)</span></span><br><span class="line"><span class="class">        .<span class="title">source</span>(<span class="params">json</span>)</span></span><br><span class="line"><span class="class">      <span class="title">requestIndexer</span>.<span class="title">add</span>(<span class="params">indexRequest</span>)</span></span><br><span class="line"><span class="class">      <span class="title">println</span>(<span class="params">"saved successfully"</span>)</span></span><br><span class="line"><span class="class">    &#125;</span></span><br><span class="line"><span class="class">  &#125;)</span></span><br><span class="line"><span class="class"><span class="title">dataStream</span>.<span class="title">addSink</span>(<span class="params">esSinkBuilder.build(</span>))</span></span><br></pre></td></tr></table></figure></div>

<h3 id="JDBC自定义sink"><a href="#JDBC自定义sink" class="headerlink" title="JDBC自定义sink"></a>JDBC自定义sink</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.44<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>添加MyJdbcSink</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyJdbcSink</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> conn: <span class="type">Connection</span> = _</span><br><span class="line">  <span class="keyword">var</span> insertStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="keyword">var</span> updateStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="comment">// open 主要是创建连接</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">super</span>.open(parameters)</span><br><span class="line">    conn = <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">      <span class="string">"jdbc:mysql://localhost:3306/test"</span>,</span><br><span class="line">      <span class="string">"root"</span>,</span><br><span class="line">      <span class="string">"123456"</span>)</span><br><span class="line">    insertStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"INSERT INTO temperatures (sensor, temp) VALUES (?, ?)"</span></span><br><span class="line">    )</span><br><span class="line">    updateStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"UPDATE temperatures SET temp = ? WHERE sensor = ?"</span></span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用连接，执行sql</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: <span class="type">SensorReading</span>,</span><br><span class="line">                      context: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    updateStmt.setDouble(<span class="number">1</span>, value.temperature)</span><br><span class="line">    updateStmt.setString(<span class="number">2</span>, value.id)</span><br><span class="line">    updateStmt.execute()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (updateStmt.getUpdateCount == <span class="number">0</span>) &#123;</span><br><span class="line">      insertStmt.setString(<span class="number">1</span>, value.id)</span><br><span class="line">      insertStmt.setDouble(<span class="number">2</span>, value.temperature)</span><br><span class="line">      insertStmt.execute()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    insertStmt.close()</span><br><span class="line">    updateStmt.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>在main方法中增加，把明细保存到mysql中</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">dataStream.addSink(<span class="keyword">new</span> <span class="type">MyJdbcSink</span>())</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>flink</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>flink系列04第一个Flink程序</title>
    <url>/2020/06/27/flink%E7%B3%BB%E5%88%9704%E7%AC%AC%E4%B8%80%E4%B8%AAFlink%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="第四章，编写第一个Flink程序"><a href="#第四章，编写第一个Flink程序" class="headerlink" title="第四章，编写第一个Flink程序"></a>第四章，编写第一个Flink程序</h1><h2 id="在IDEA中编写Flink程序"><a href="#在IDEA中编写Flink程序" class="headerlink" title="在IDEA中编写Flink程序"></a>在IDEA中编写Flink程序</h2><p>本项目使用的Flink版本为最新版本，也就是1.10.0。现在提供maven项目的配置文件。</p>
<ol>
<li>使用Intellij IDEA创建一个Maven新项目</li>
<li>勾选<code>Create from archetype</code>，然后点击<code>Add Archetype</code>按钮</li>
<li><code>GroupId</code>中输入<code>org.apache.flink</code>，<code>ArtifactId</code>中输入<code>flink-quickstart-scala</code>，<code>Version</code>中输入<code>1.10.0</code>，然后点击<code>OK</code></li>
<li>点击向右箭头，出现下拉列表，选中<code>flink-quickstart-scala:1.10.0</code>，点击<code>Next</code></li>
<li><code>Name</code>中输入<code>FlinkTutorial</code>，<code>GroupId</code>中输入<code>com.atguigu</code>，<code>ArtifactId</code>中输入<code>FlinkTutorial</code>，点击<code>Next</code></li>
<li>最好使用IDEA默认的Maven工具：Bundled（Maven 3），点击<code>Finish</code>，等待一会儿，项目就创建好了</li>
</ol>
<p>编写<code>WordCount.scala</code>程序</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StreamingJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Main program method */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) : <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get the execution environment</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">      .getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get input data by connecting to the socket</span></span><br><span class="line">    <span class="keyword">val</span> text: <span class="type">DataStream</span>[<span class="type">String</span>] = env</span><br><span class="line">      .socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>, '\n')</span><br><span class="line"></span><br><span class="line">    <span class="comment">// parse the data, group it, window it, and aggregate the counts</span></span><br><span class="line">    <span class="keyword">val</span> windowCounts = text</span><br><span class="line">      .flatMap &#123; w =&gt; w.split(<span class="string">"\\s"</span>) &#125;</span><br><span class="line">      .map &#123; w =&gt; <span class="type">WordWithCount</span>(w, <span class="number">1</span>) &#125;</span><br><span class="line">      .keyBy(<span class="string">"word"</span>)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">      .sum(<span class="string">"count"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// print the results with a single thread, rather than in parallel</span></span><br><span class="line">    windowCounts</span><br><span class="line">      .print()</span><br><span class="line">      .setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"Socket Window WordCount"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Data type for words with count */</span></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">WordWithCount</span>(<span class="params">word: <span class="type">String</span>, count: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class">&#125;</span></span><br></pre></td></tr></table></figure></div>

<p>打开一个终端（Terminal），运行以下命令</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ nc -lk 9999</span><br></pre></td></tr></table></figure></div>

<p>接下来使用<code>IDEA</code>运行就可以了。</p>
<h2 id="下载Flink运行时环境，提交Jar包的运行方式"><a href="#下载Flink运行时环境，提交Jar包的运行方式" class="headerlink" title="下载Flink运行时环境，提交Jar包的运行方式"></a>下载Flink运行时环境，提交Jar包的运行方式</h2><p>下载链接：<a href="http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz</a></p>
<p>然后解压</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tar xvfz flink-1.10.0-bin-scala_2.11.tgz</span><br></pre></td></tr></table></figure></div>

<p>启动Flink集群</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd flink-1.10.0</span><br><span class="line">$ .&#x2F;bin&#x2F;start-cluster.sh</span><br></pre></td></tr></table></figure></div>

<p>可以打开Flink WebUI查看集群状态：<a href="http://localhost:8081" target="_blank" rel="noopener">http://localhost:8081</a></p>
<p>在<code>IDEA</code>中使用<code>maven package</code>打包。</p>
<p>提交打包好的<code>JAR</code>包</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd flink-1.10.0</span><br><span class="line">$ .&#x2F;bin&#x2F;flink run 打包好的JAR包的绝对路径</span><br></pre></td></tr></table></figure></div>

<p>停止Flink集群</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;stop-cluster.sh</span><br></pre></td></tr></table></figure></div>

<p>查看标准输出日志的位置，在<code>log</code>文件夹中。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd flink-1.10.0&#x2F;log</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>flink</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>flink系列03Flink运行架构</title>
    <url>/2020/06/27/flink%E7%B3%BB%E5%88%9703Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h1 id="第三章，Flink运行架构"><a href="#第三章，Flink运行架构" class="headerlink" title="第三章，Flink运行架构"></a>第三章，Flink运行架构</h1><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>Flink是一个用于有状态的并行数据流处理的分布式系统。它由多个进程构成，这些进程一般会分布运行在不同的机器上。对于分布式系统来说，面对的常见问题有：集群中资源的分配和管理、进程协调调度、持久化和高可用的数据存储，以及故障恢复。</p>
<p>对于这些分布式系统的经典问题，业内已有比较成熟的解决方案和服务。所以Flink并不会自己去处理所有的问题，而是利用了现有的集群架构和服务，这样它就可以把精力集中在核心工作——分布式数据流处理上了。Flink与一些集群资源管理工具有很好的集成，比如Apache Mesos、YARN和Kubernetes；同时，也可以配置为独立（stand-alone）集群运行。Flink自己并不提供持久化的分布式存储，而是直接利用了已有的分布式文件系统（比如HDFS）或者对象存储（比如S3）。对于高可用的配置，Flink需要依靠Apache ZooKeeper来完成。</p>
<p>在本节中，我们将介绍Flink的不同组件，以及在运行程序时它们如何相互作用。我们会讨论部署Flink应用程序的两种模式，并且了解每种模式下分发和执行任务的方式。最后，我们还会解释一下Flink的高可用性模式是如何工作的。</p>
<h3 id="Flink运行时组件"><a href="#Flink运行时组件" class="headerlink" title="Flink运行时组件"></a>Flink运行时组件</h3><p>Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机（JVMs）上。每个组件的职责如下：</p>
<ul>
<li>作业管理器（JobManager）是控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。JobManager会先接收到要执行的应用程序。这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</li>
<li>ResourceManager主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger插槽是Flink中定义的处理资源单元。Flink为不同的环境和资源管理工具提供了不同资源管理器（ResourceManager），比如YARN、Mesos、K8s，以及standalone部署。当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。另外，ResourceManager还负责终止空闲的TaskManager，释放计算资源。</li>
<li>任务管理器（TaskManager）是Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。任务的执行和插槽的概念会在“任务执行”一节做具体讨论。</li>
<li>分发器（Dispatcher）可以跨作业运行，它为应用提交提供了REST接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。由于是REST接口，所以Dispatcher可以作为集群的一个HTTP接入点，这样就能够不受防火墙阻挡。Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。</li>
</ul>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0301.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0301.png" class="lazyload"></a></p>
<blockquote>
<p>上图是从一个较为高层级的视角，来看应用中各组件的交互协作。如果部署的集群环境不同（例如YARN，Mesos，Kubernetes，standalone等），其中一些步骤可以被省略，或是有些组件会运行在同一个JVM进程中。</p>
</blockquote>
<h3 id="应用部署"><a href="#应用部署" class="headerlink" title="应用部署"></a>应用部署</h3><p>Flink应用程序可以用以下两种不同的方式部署：</p>
<p><em>框架（Framework）方式</em></p>
<p>在这个模式下，Flink应用被打包成一个Jar文件，并由客户端提交给一个运行服务（running service）。这个服务可以是一个Flink的Dispatcher，也可以是一个Flink的JobManager，或是Yarn的ResourceManager。如果application被提交给一个JobManager，则它会立即开始执行这个application。如果application被提交给了一个Dispatcher，或是Yarn ResourceManager，则它会启动一个JobManager，然后将application交给它，再由JobManager开始执行此应用。</p>
<p><em>库（Library）方式</em></p>
<p>在这个模式下，Flink Application 会被打包在一个容器（container） 镜像里，例如一个Docker 镜像。此镜像包含了运行JobManager和ResourceManager的代码。当一个容器从镜像启动后，它会自动启动ResourceManager和JobManager，并提交打包好的应用。另一种方法是：将应用打包到镜像后，只用于部署TaskManager容器。从镜像启动的容器会自动启动一个TaskManager，然后连接ResourceManager并注册它的slots。这些镜像的启动以及失败重启，通常都会由一个外部的资源管理器管理（比如Kubernetes）。</p>
<p>框架模式遵循了传统的任务提交方式，从客户端提交到Flink运行服务。而在库模式下，没有运行的Flink服务。它是将Flink作为一个库，与应用程序一同打包到了一个容器镜像。这种部署方式在微服务架构中较为常见。我们会在“运行管理流式应用程序”一节对这个话题做详细讨论。</p>
<h3 id="任务执行"><a href="#任务执行" class="headerlink" title="任务执行"></a>任务执行</h3><p>一个TaskManager可以同时执行多个任务（tasks）。这些任务可以是同一个算子（operator）的子任务（数据并行），也可以是来自不同算子的（任务并行），甚至可以是另一个不同应用程序的（作业并行）。TaskManager提供了一定数量的处理插槽（processing slots），用于控制可以并行执行的任务数。一个slot可以执行应用的一个分片，也就是应用中每一个算子的一个并行任务。图3-2展示了TaskManagers，slots，tasks以及operators之间的关系：</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0302.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0302.png" class="lazyload"></a></p>
<p>最左边是一个“作业图”（JobGraph），包含了5个算子——它是应用程序的非并行表示。其中算子A和C是数据源（source），E是输出端（sink）。C和E并行度为2，而其他的算子并行度为4。因为最高的并行度是4，所以应用需要至少四个slot来执行任务。现在有两个TaskManager，每个又各有两个slot，所以我们的需求是满足的。JobManager将JobGraph转化为“执行图”（ExecutionGraph），并将任务分配到四个可用的slot上。对于有4个并行任务的算子，它的task会分配到每个slot上。而对于并行度为2的operator C和E，它们的任务被分配到slot 1.1、2.1 以及 slot 1.2、2.2。将tasks调度到slots上，可以让多个tasks跑在同一个TaskManager内，也就可以是的tasks之间的数据交换更高效。然而将太多任务调度到同一个TaskManager上会导致TaskManager过载，继而影响效率。之后我们会在“控制任务调度”一节继续讨论如何控制任务的调度。</p>
<p>TaskManager在同一个JVM中以多线程的方式执行任务。线程较进程会更轻量级，但是线程之间并没有对任务进行严格隔离。所以，单个任务的异常行为有可能会导致整个TaskManager进程挂掉，当然也同时包括运行在此进程上的所有任务。通过为每个TaskManager配置单独的slot，就可以将应用在TaskManager上相互隔离开来。TaskManager内部有多线程并行的机制，而且在一台主机上可以部署多个TaskManager，所以Flink在资源配置上非常灵活，在部署应用时可以充分权衡性能和资源的隔离。我们将会在第九章对Flink集群的配置和搭建继续做详细讨论。</p>
<h3 id="高可用配置"><a href="#高可用配置" class="headerlink" title="高可用配置"></a>高可用配置</h3><p>流式应用程序一般被设计为7 x 24小时运行。所以很重要的一点是：即使出现了进程挂掉的情况，应用仍需要继续保持运行。为了从故障恢复，系统首先需要重启进程、然后重启应用并恢复它的状态。接下来，我们就来了解Flink如何重启失败的进程。</p>
<p><em>TaskManager故障</em></p>
<p>如前所述，Flink需要足够数目的slot，来执行一个应用的所有任务。假设一个Flink环境有4个TaskManager，每个提供2个插槽，那么流应用程序执行的最高并行度为8。如果其中一个TaskManager挂掉了，那么可用的slots会降到6。在这种情况下，JobManager会请求ResourceManager提供更多的slots。如果此请求无法满足——例如应用跑在一个standalone集群——那么JobManager在有足够的slots之前，无法重启应用。应用的重启策略决定了JobManager的重启频率，以及两次重启尝试之间的时间间隔。</p>
<p><em>JobManager故障</em></p>
<p>比TaskManager故障更严重的问题是JobManager故障。JobManager控制整个流应用程序的执行，并维护执行中的元数据——例如指向已完成检查点的指针。若是对应的JobManager挂掉，则流程序无法继续运行。所以这就导致在Flink应用中，JobManager是单点故障。为了解决这个问题，Flink提供了高可用模式。在原先的JobManager挂掉后，可以将一个作业的状态和元数据迁移到另一个JobManager，并继续执行。</p>
<p>Flink的高可用模式基于Apache ZooKeeper，我们知道，ZooKeeper是用来管理需要协调和共识的分布式服务的系统。Flink主要利用ZooKeeper来进行领导者（leader）的选举，并把它作为一个高可用和持久化的数据存储。当在高可用模式下运行时，JobManager会将JobGraph以及所有需要的元数据（例如应用程序的jar文件），写入到一个远程的持久化存储系统中。而且，JobManager会将指向存储位置的指针，写入到ZooKeeper的数据存储中。在执行一个应用的过程中，JobManager会接收每个独立任务检查点的状态句柄（也就是存储位置）。当一个检查点完成时（所有任务已经成功地将它们的状态写入到远程存储）， JobManager把状态句柄写入远程存储，并将指向这个远程存储的指针写入ZooKeeper。这样，一个JobManager挂掉之后再恢复，所需要的所有数据信息已经都保存在了远程存储，而ZooKeeper里存有指向此存储位置的指针。图3-3描述了这个设计：</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0303.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0303.png" class="lazyload"></a></p>
<p>当一个JobManager失败，所有属于这个应用的任务都会自动取消。一个新的JobManager接管工作，会执行以下操作：</p>
<ul>
<li>从ZooKeeper请求存储位置（storage location），从远端存储获取JobGraph，Jar文件，以及应用最近一次检查点（checkpoint）的状态句柄（state handles）</li>
<li>从ResourceManager请求slots，用来继续运行应用</li>
<li>重启应用，并将所有任务的状态，重设为最近一次已完成的检查点</li>
</ul>
<p>如果我们是在容器环境里运行应用（如Kubernetes），故障的JobManager或TaskManager 容器通常会由容器服务自动重启。当运行在YARN或Mesos之上时，JobManager或TaskManager进程会由Flink的保留进程自动触发重启。而在standalone模式下，Flink并未提供重启故障进程的工具。所以，此模式下我们可以增加备用（standby）的 JobManager和TaskManager，用于接管故障的进程。我们将会在“高可用配置”一节中做进一步讨论。</p>
<h2 id="Flink中的数据传输"><a href="#Flink中的数据传输" class="headerlink" title="Flink中的数据传输"></a>Flink中的数据传输</h2><p>运行中的应用任务，会持续不断地交换数据。TaskManager负责将数据从“发送任务”（sending tasks）传递到“接收任务”（receiving tasks）。TaskManager的网络组件会在缓冲区中收集数据，然后再将其发送，也就是说，数据不是逐条发送的，而是在缓冲区中“攒”成了一批。这种技术是有效利用网络资源和实现高吞吐量的基础，机制类似于网络或磁盘I/O协议中使用的缓冲技术。</p>
<blockquote>
<p>通过缓冲区来传递数据，意味着Flink的处理模型是基于微批的。</p>
</blockquote>
<p>每个TaskManager都有一个网络缓冲池（默认大小为32KB），用于发送和接收数据。如果发送任务和接收任务运行在不同的TaskManager进程中，那么它们会通过操作系统的网络栈来进行通信。流应用程序需要以管道方式传递数据，所以每对TaskManager之间都需要维护一个永久TCP连接，用来交换数据。在无序连接模式下，每个发送任务都需要能向任何接收任务传递数据。所以我们发现，TaskManager需要为每一个接收任务设置一个专用的网络缓冲区，因为其中的每一个任务都需要接收数据。图3-4展示了这种架构。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0304.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0304.png" class="lazyload"></a></p>
<p>如图3-4所示，四个发送任务中的每一个都需要至少四个网络缓冲区，用来向每个接收任务发送数据，而每个接收任务也需要至少四个缓冲区来接收数据。需要发送到另一个TaskManager的缓冲数据，会复用同一网络连接。为了实现平滑的管道数据传输，TaskManager必须能够提供足够的缓冲，来同时为所有传出和传入连接提供服务。对于无序或广播连接，每个发送任务都需要为每个接收任务提供一个缓冲；所以，所需缓冲区的数量是相关算子任务数量的平方。Flink网络缓冲区的默认配置足以满足中小型应用；对于更大的应用场景，就需要按照“主内存和网络缓冲区”一节中的叙述调整配置了。</p>
<p>当发送任务和接收任务在同一个TaskManager进程中运行时，发送任务会将传出的数据序列化，放入字节缓冲区，并在缓冲区填满后将其放入队列。接收任务从队列中提取缓冲数据并对其进行反序列化。因此，在同一个TaskManager上运行的任务，它们之间的数据传输不会导致网络通信。</p>
<p>Flink采用不同的技术来降低任务之间的通信成本。在下面的部分中，我们会简要讨论基于信任度（Credit）的流控制和任务链。</p>
<h3 id="基于信任度（credit）的流控制"><a href="#基于信任度（credit）的流控制" class="headerlink" title="基于信任度（credit）的流控制"></a>基于信任度（credit）的流控制</h3><p>通过网络连接来发送每条数据的效率很低，会导致很大的开销。为了充分利用网络连接的带宽，就需要进行缓冲了。在流处理的上下文中，缓冲的一个缺点是会增加延迟，因为数据需要在缓冲区中进行收集，而不是立即发送。</p>
<p>Flink实现了一个基于信任度的流量控制机制，其工作原理如下。接收任务授予发送任务一些“信任度”（credit），也就是为了接收其数据而保留的网络缓冲区数。当发送者收到一个信任度通知，它就会按照被授予的信任度，发送尽可能多的缓冲数据，并且同时发送目前积压数据的大小——也就是已填满并准备发送的网络缓冲的数量。接收者用保留的缓冲区处理发来的数据，并对发送者传来的积压量进行综合考量，为其所有连接的发送者确定下一个信用度授权的优先级。</p>
<p>基于信用度的流控制可以减少延迟，因为发送者可以在接收者有足够的资源接受数据时立即发送数据。此外，在数据倾斜的情况下，这样分配网络资源是一种很有效的机制，因为信用度是根据发送者积压数据量的规模授予的。因此，基于信用的流量控制是Flink实现高吞吐量和低延迟的重要组成部分。</p>
<h3 id="任务链（Task-Chaining）"><a href="#任务链（Task-Chaining）" class="headerlink" title="任务链（Task Chaining）"></a>任务链（Task Chaining）</h3><p>Flink采用了一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将两个或多个算子设为相同的并行度，并通过本地转发（local forward）的方式进行连接。图3-5所示的算子管道满足这些要求。它由三个算子组成，这些算子的任务并行度都被设为2，并且通过本地转发方式相连接。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0305.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0305.png" class="lazyload"></a></p>
<p>图3-6展示了管道以任务链方式运行的过程。算子的函数被融合成了一个单一的任务，由一个线程执行。由函数生成的数据通过一个简单的方法调用移交给下一个函数；这样在函数之间直接传递数据，基本上没有序列化和通信成本。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0306.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0306.png" class="lazyload"></a></p>
<p>任务链可以显著降低本地任务之间的通信成本，但也有一些场景，在没有链接的情况下运行管道操作是有意义的。例如，如果任务链中某个函数执行的开销巨大，那就可以将一条长的任务链管道断开，或者将一条链断开为两个任务，从而可以将这个开销大的函数调度到不同的槽（slots）中。图3-7显示了在没有任务链的情况下相同管道操作的执行情况。所有函数都由独立的单个任务来评估，每个任务都在专有的线程中运行。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0307.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0307.png" class="lazyload"></a></p>
<p>任务链在Flink中默认会启用。在“控制任务链”一节中，我们展示了如何禁用应用程序的任务链，以及如何控制各个算子的链接行为。</p>
<h2 id="事件时间（Event-Time）处理"><a href="#事件时间（Event-Time）处理" class="headerlink" title="事件时间（Event-Time）处理"></a>事件时间（Event-Time）处理</h2><p>在“时间语义”一节，我们重点强调了时间语义在流处理应用中的重要性，并且解释了处理时间（processing time）和事件时间（event time）的不同。处理时间比较好理解，因为它是基于处理器本地时间的；但同时，它会带来比较混乱、不一致、并且不可重现的结果。相比之下，事件时间语义能够产生可重现且一致的结果，这也是许多流处理场景希望解决的一大难题。但是，与处理时间应用程序相比，事件时间应用程序会更复杂，需要额外的配置。另外，支持事件时间的流处理器，也比纯粹在处理时间中运行的系统内部更为复杂。</p>
<p>Flink为常见的事件时间处理操作提供了直观且易于使用的原语，同时暴露了表达性很强的API，用户可以使用自定义算子实现更高级的事件时间应用程序。很好地理解Flink的内部时间处理，对于实现这样的高级应用程序会有很大帮助，有时也是必需的。上一章介绍了Flink利用两个概念来支持事件时间语义：记录时间戳（timestamps）和水位线（watermarks）。接下来，我们将描述Flink如何在内部实现并处理时间戳和水位线，进而支持具有事件时间语义的流式应用程序。</p>
<h3 id="时间戳（Timestamps）"><a href="#时间戳（Timestamps）" class="headerlink" title="时间戳（Timestamps）"></a>时间戳（Timestamps）</h3><p>由Flink事件时间流应用程序处理的所有记录都必须伴有时间戳。时间戳将数据与特定时间点相关联，通常就是数据所表示的事件发生的时间点。而只要时间戳大致跟数据流保持一致，基本上随着数据流的前进而增大，应用程序就可以自由选择时间戳的含义。不过正如“时间语义”一节中所讨论的，在现实场景中，时间戳基本上都是乱序的，所以采用“事件时间”而非“处理事件”往往会显得更为重要。</p>
<p>当Flink以事件时间模式处理数据流时，它会根据数据记录的时间戳来处理基于时间的算子。例如，时间窗口算子根据相关时间戳将数据分配给不同的时间窗口。Flink将时间戳编码为16字节的长整型值，并将其作为元数据附加到数据记录中。它的内置运算符会将这个长整型值解释为一个具有毫秒精度的Unix时间戳，也就是1970-01-01-00:00:00.000以来的毫秒数。当然，如果用户进行了自定义，那么运算符可以有自己的解释，例如，可以将精度调整到微秒。</p>
<h3 id="水位线-Watermarks"><a href="#水位线-Watermarks" class="headerlink" title="水位线(Watermarks)"></a>水位线(Watermarks)</h3><p>除了时间戳，基于事件时间的Flink应用程序还必须支持水位线（watermark）。在基于事件时间的应用中，水位线用于生成每个任务的当前事件时间。基于时间的算子使用这个“当前事件时间”来触发计算和处理操作。例如，一个时间窗口任务（time-window task）会在任务的事件时间超出窗口的关闭边界时，完成窗口计算，并输出计算结果。</p>
<p>在Flink中，水位线被实现为一条特殊的数据记录，它里面以长整型值保存了一个时间戳。水位线在带有时间戳的数据流中，跟随着其它数据一起流动，如图3-8所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0308.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0308.png" class="lazyload"></a></p>
<p>水位线有两个基本属性：</p>
<ul>
<li>必须单调递增，以确保任务的事件时间时钟在向前推进，而不是在后退。</li>
<li>它们与数据的时间戳相关。带有时间戳T的水位线表示，所有后续数据的时间戳都应该大于T。</li>
</ul>
<p>上面的第二个属性用于处理带有乱序时间戳的数据流，比如图3-8中时间戳3和5的数据。基于时间的算子任务会收集和处理数据（这些数据可能具有乱序的时间戳），并在事件时间时钟到达某个时刻时完成计算。这个时刻就表示数据收集的截止，具有之前时间戳的数据应该都已经到达、不再需要了；而其中的事件时间时钟，正是由当前接收到的水位线来指示的。如果任务再接收到的数据违反了watermark的这一属性，也就是时间戳小于以前接收到的水位线时，它所属的那部分计算可能已经完成了。这种数据被称为延迟数据（late records）。Flink提供了处理延迟数据的不同方式，我们会在“处理延迟数据”一节中讨论。</p>
<p>水位线还有一个很有趣的特性，它允许应用程序自己来平衡结果的完整性和延迟。如果水位线与数据的时间戳非常接近，那么我们可以得到较低的处理延迟，因为任务在完成计算之前只会短暂地等待更多数据到达。而同时，结果的完整性可能会受到影响，因为相关数据可能因为迟到而被视为“延迟数据”，这样就不会包含在结果中。相反，非常保守的水位线提供了足够的时间去等待所有数据到达，这样会增加处理延迟，但提高了结果的完整性。</p>
<h3 id="watermark的传递和事件时间"><a href="#watermark的传递和事件时间" class="headerlink" title="watermark的传递和事件时间"></a>watermark的传递和事件时间</h3><p>在本节中，我们将讨论算子如何处理水位线。Flink把watermark作为一条特殊的数据来实现，它也会由算子任务接收和发送。任务会有一个内部的时间服务，它会维护定时器，并在收到watermark时触发。任务可以在计时器服务中注册定时器，以便在将来特定的时间点执行计算。例如，窗口算子为每个活动窗口注册一个定时器，当事件时间超过窗口的结束时间时，该计时器将清除窗口的状态。</p>
<p>当任务收到watermark时，将执行以下操作：</p>
<ul>
<li>任务根据watermark的时间戳更新其内部事件时钟。</li>
<li>任务的时间服务会将所有过期的计时器标识出来，它们的时间小于当前的事件时间。对于每个过期的计时器，任务调用一个回调函数，该函数可以执行计算并发送结果。</li>
<li>任务会发出一个带有更新后的事件时间的watermark。</li>
</ul>
<blockquote>
<p>Flink限制通过DataStream API访问时间戳和watermark。函数不能读取或修改数据的时间戳和watermark，但底层的“处理函数”（process functions）除外，它们可以读取当前处理数据的时间戳、请求算子的当前事件时间，还可以注册定时器。通常的函数都不会暴露这些可以设置时间戳、操作任务事件时间时钟、或者发出水位线的API。而基于时间的数据流算子任务则会配置发送出的数据的时间戳，以确保它们能够与已到达的水位线平齐。例如，窗口计算完成后，时间窗口的算子任务会将窗口的结束时间作为时间戳附加到将要发送出的结果数据上，然后再使用触发窗口计算的时间戳发出watermark。</p>
</blockquote>
<p>现在，让我们更详细地解释一下任务在接收到新的watermark时，如何继续发送watermark并更新其事件时钟。正如我们在“数据并发和任务并发”中所了解的，Flink将数据流拆分为多个分区，并通过单独的算子任务并行地处理每个分区。每个分区都是一个流，里面包含了带着时间戳的数据和watermark。一个算子与它前置或后续算子的连接方式有多种情况，所以它对应的任务可以从一个或多个“输入分区”接收数据和watermark，同时也可以将数据和watermark发送到一个或多个“输出分区”。接下来，我们将详细描述一个任务如何向多个输出任务发送watermark，以及如何通过接收到的watermark来驱动事件时间时钟前进。</p>
<p>任务为每个输入分区维护一个分区水位线（watermark）。当从一个分区接收到watermark时，它会比较新接收到的值和当前水位值，然后将相应的分区watermark更新为两者的最大值。然后，任务会比较所有分区watermark的大小，将其事件时钟更新为所有分区watermark的最小值。如果事件时间时钟前进了，任务就将处理所有被触发的定时器操作，并向所有连接的输出分区发送出相应的watermark，最终将新的事件时间广播给所有下游任务。</p>
<p>图3-9显示了具有四个输入分区和三个输出分区的任务如何接收watermark、更新分区watermark和事件时间时钟，以及向下游发出watermark。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0309.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0309.png" class="lazyload"></a></p>
<p>具有两个或多个输入流（如Union或CoFlatMap）的算子任务（参见“多流转换”一节）也会以所有分区watermark的最小值作为事件时间时钟。它们并不区分不同输入流的分区watermark，所以两个输入流的数据都是基于相同的事件时间时钟进行处理的。当然我们可以想到，如果应用程序的各个输入流的事件时间不一致，那么这种处理方式可能会导致问题。</p>
<p>Flink的水位处理和传递算法，确保了算子任务发出的时间戳和watermark是“对齐”的。不过它依赖一个条件，那就是所有分区都会提供不断增长的watermark。一旦一个分区不再推进水位线的上升，或者完全处于空闲状态、不再发送任何数据和watermark，任务的事件时间时钟就将停滞不前，任务的定时器也就无法触发了。对于基于时间的算子来说，它们需要依赖时钟的推进来执行计算和清除状态，这种情况显然就会有问题。如果任务没有定期从所有输入任务接收到新的watermark，那么基于时间的算子的处理延迟和状态空间的大小都会显著增加。</p>
<p>对于具有两个输入流而且watermark明显不同的算子，也会出现类似的情况。具有两个输入流的任务的事件时间时钟，将会同较慢的那条流的watermark保持一致，而通常较快流的数据或者中间结果会在state中缓冲，直到事件时间时钟达到这条流的watermark，才会允许处理它们。</p>
<h3 id="时间戳的分配和水位线的产生"><a href="#时间戳的分配和水位线的产生" class="headerlink" title="时间戳的分配和水位线的产生"></a>时间戳的分配和水位线的产生</h3><p>我们已经解释了什么是时间戳和水位线，以及它们是如何由Flink内部处理的；然而我们还没有讨论它们的产生。流应用程序接收到数据流时，通常就会先分配时间戳并生成水位线（watermark）。因为时间戳的选择是由不同的应用程序决定的，而且watermark取决于时间戳和流的特性，所以应用程序必须首先显式地分配时间戳并生成watermark。Flink流应用程序可以通过三种方式分配时间戳和生成watermark：</p>
<ul>
<li>在数据源（source）处分配：当数据流被摄入到应用程序中时，可以由“源函数”SourceFunction分配和生成时间戳和watermark。SourceFunction可以产生并发送一个数据流；数据会与相关的时间戳一起发送出去，而watermark可以作为一条特殊数据在任何时间点发出。如果SourceFunction（暂时）不再发出watermark，它可以声明自己处于“空闲”（idle）状态。Flink会在后续算子的水位计算中，把空闲的SourceFunction产生的流分区排除掉。source的这一空闲机制，可以用来解决前面提到的水位不再上升的问题。源函数（Source Function）在“实现自定义源函数”一节中进行了更详细的讨论。</li>
<li>定期分配：在Flink中，DataStream API提供一个名为AssignerWithPeriodicWatermarks的用户定义函数，它可以从每个数据中提取时间戳，并被定期调用以生成当前watermark。提取出的时间戳被分配给相应的数据，而生成的watermark也会添加到流中。这个函数将在“分配时间戳和生成水位线”一节中讨论。</li>
<li>间断分配：AssignerWithPunctuatedWatermarks是另一个用户定义的函数，它同样会从每个数据中提取一个时间戳。它可以用于生成特殊输入数据中的watermark。与AssignerWithPeriodicWatermarks相比，此函数可以（但不是必须）从每个记录中提取watermark。我们在“分配时间戳和生成水位线”一节中同样讨论了该函数。</li>
</ul>
<p>用户定义的时间戳分配函数并没有严格的限制，通常会放在尽可能靠近source算子的位置，因为当经过一些算子处理后，数据及其时间戳的顺序就更加难以解释了。所以尽管我们可以在流应用程序的中段覆盖已有的时间戳和watermark——Flink通过用户定义的函数提供了这种灵活性，但这显然并不是推荐的做法。</p>
<h2 id="状态管理"><a href="#状态管理" class="headerlink" title="状态管理"></a>状态管理</h2><p>在第2章中，我们已经知道大多数流应用程序都是有状态的。许多算子会不断地读取和更新状态，例如在窗口中收集的数据、读取输入源的位置，或者像机器学习模型那样的用户定制化的算子状态。 Flink用同样的方式处理所有的状态，无论是内置的还是用户自定义的算子。本节我们将会讨论Flink支持的不同类型的状态，并解释“状态后端”是如何存储和维护状态的。</p>
<p>一般来说，由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状态。你可以认为状态就是一个本地变量，可以被任务的业务逻辑访问。图3-10显示了任务与其状态之间的交互。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0310.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0310.png" class="lazyload"></a></p>
<p>任务会接收一些输入数据。在处理数据时，任务可以读取和更新状态，并根据输入数据和状态计算结果。最简单的例子，就是统计接收到多少条数据的任务。当任务收到新数据时，它会访问状态以获取当前的计数，然后让计数递增，更新状态并发送出新的计数。</p>
<p>应用程序里，读取和写入状态的逻辑一般都很简单直接，而有效可靠的状态管理会复杂一些。这包括如何处理很大的状态——可能会超过内存，并且保证在发生故障时不会丢失任何状态。幸运的是，Flink会帮我们处理这相关的所有问题，包括状态一致性、故障处理以及高效存储和访问，以便开发人员可以专注于应用程序的逻辑。</p>
<p>在Flink中，状态始终与特定算子相关联。为了使运行时的Flink了解算子的状态，算子需要预先注册其状态。总的说来，有两种类型的状态：算子状态（operator state）和键控状态（keyed state），它们有着不同的范围访问，我们将在下面展开讨论。</p>
<h3 id="算子状态"><a href="#算子状态" class="headerlink" title="算子状态"></a>算子状态</h3><p>算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由相同或不同算子的另一个任务访问。图3-11显示了任务如何访问算子状态。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0311.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0311.png" class="lazyload"></a></p>
<p>Flink为算子状态提供三种基本数据结构：</p>
<h4 id="列表状态（List-state）"><a href="#列表状态（List-state）" class="headerlink" title="列表状态（List state）"></a>列表状态（List state）</h4><p>将状态表示为一组数据的列表。</p>
<h4 id="联合列表状态（Union-list-state）"><a href="#联合列表状态（Union-list-state）" class="headerlink" title="联合列表状态（Union list state）"></a>联合列表状态（Union list state）</h4><p>也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故障时，或者从保存点（savepoint）启动应用程序时如何恢复。我们将在后面继续讨论。</p>
<h4 id="广播状态（Broadcast-state）"><a href="#广播状态（Broadcast-state）" class="headerlink" title="广播状态（Broadcast state）"></a>广播状态（Broadcast state）</h4><p>如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特殊情况最适合应用广播状态。在保存检查点和重新调整算子并行度时，会用到这个特性。这两部分内容将在本章后面讨论。</p>
<h3 id="键控状态（Keyed-State）"><a href="#键控状态（Keyed-State）" class="headerlink" title="键控状态（Keyed State）"></a>键控状态（Keyed State）</h3><p>顾名思义，键控状态是根据输入数据流中定义的键（key）来维护和访问的。Flink为每个键值维护一个状态实例，并将具有相同键的所有数据，都分区到同一个算子任务中，这个任务会维护和处理这个key对应的状态。当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的key。因此，具有相同key的所有数据都会访问相同的状态。图3-12显示了任务如何与键控状态进行交互。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0312.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0312.png" class="lazyload"></a></p>
<p>我们可以将键控状态看成是在算子所有并行任务上，对键进行分区（或分片）之后的一个键值映射（key-value map）。 Flink为键控状态提供不同的数据结构，用于确定map中每个key存储的值的类型。我们简单了解一下最常见的键控状态。</p>
<h4 id="值状态（Value-state）"><a href="#值状态（Value-state）" class="headerlink" title="值状态（Value state）"></a>值状态（Value state）</h4><p>为每个键存储一个任意类型的单个值。复杂数据结构也可以存储为值状态。</p>
<h4 id="列表状态（List-state）-1"><a href="#列表状态（List-state）-1" class="headerlink" title="列表状态（List state）"></a>列表状态（List state）</h4><p>为每个键存储一个值的列表。列表里的每个数据可以是任意类型。</p>
<h4 id="映射状态（Map-state）"><a href="#映射状态（Map-state）" class="headerlink" title="映射状态（Map state）"></a>映射状态（Map state）</h4><p>为每个键存储一个键值映射（map）。map的key和value可以是任意类型。</p>
<p>状态的数据结构可以让Flink实现更有效的状态访问。我们将在“在运行时上下文（RuntimeContext）中声明键控状态”中做进一步讨论。</p>
<h3 id="状态后端（State-Backends）"><a href="#状态后端（State-Backends）" class="headerlink" title="状态后端（State Backends）"></a>状态后端（State Backends）</h3><p>每传入一条数据，有状态的算子任务都会读取和更新状态。由于有效的状态访问对于处理数据的低延迟至关重要，因此每个并行任务都会在本地维护其状态，以确保快速的状态访问。状态到底是如何被存储、访问以及维护的？这件事由一个可插入的组件决定，这个组件就叫做状态后端（state backend）。状态后端主要负责两件事：本地的状态管理，以及将检查点（checkpoint）状态写入远程存储。</p>
<p>对于本地状态管理，状态后端会存储所有键控状态，并确保所有的访问都被正确地限定在当前键范围。 Flink提供了默认的状态后端，会将键控状态作为内存中的对象进行管理，将它们存储在JVM堆上。另一种状态后端则会把状态对象进行序列化，并将它们放入RocksDB中，然后写入本地硬盘。第一种方式可以提供非常快速的状态访问，但它受内存大小的限制；而访问RocksDB状态后端存储的状态速度会较慢，但其状态可以增长到非常大。</p>
<p>状态检查点的写入也非常重要，这是因为Flink是一个分布式系统，而状态只能在本地维护。 TaskManager进程（所有任务在其上运行）可能在任何时间点挂掉。因此，它的本地存储只能被认为是不稳定的。状态后端负责将任务的状态检查点写入远程的持久存储。写入检查点的远程存储可以是分布式文件系统，也可以是数据库。不同的状态后端在状态检查点的写入机制方面有所不同。例如，RocksDB状态后端支持增量的检查点，这对于非常大的状态来说，可以显著减少状态检查点写入的开销。</p>
<p>我们将在“选择状态后端”一节中更详细地讨论不同的状态后端及其优缺点。</p>
<h3 id="调整有状态算子的并行度"><a href="#调整有状态算子的并行度" class="headerlink" title="调整有状态算子的并行度"></a>调整有状态算子的并行度</h3><p>流应用程序的一个常见要求是，为了增大或较小输入数据的速率，需要灵活地调整算子的并行度。对于无状态算子而言，并行度的调整没有任何问题，但更改有状态算子的并行度显然就没那么简单了，因为它们的状态需要重新分区并分配给更多或更少的并行任务。 Flink支持四种模式来调整不同类型的状态。</p>
<p>具有键控状态的算子通过将键重新分区为更少或更多任务来缩放并行度。不过，并行度调整时任务之间会有一些必要的状态转移。为了提高效率，Flink并不会对单独的key做重新分配，而是用所谓的“键组”（key group）把键管理起来。键组是key的分区形式，同时也是Flink为任务分配key的方式。图3-13显示了如何在键组中重新分配键控状态。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0313.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0313.png" class="lazyload"></a></p>
<p>具有算子列表状态的算子，会通过重新分配列表中的数据项目来进行并行度缩放。从概念上讲，所有并行算子任务的列表项目会被收集起来，并将其均匀地重新分配给更少或更多的任务。如果列表条目少于算子的新并行度，则某些任务将以空状态开始。图3-14显示了算子列表状态的重新分配。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0314.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0314.png" class="lazyload"></a></p>
<p>具有算子联合列表状态的算子，会通过向每个任务广播状态的完整列表，来进行并行度的缩放。然后，任务可以选择要使用的状态项和要丢弃的状态项。图3-15显示了如何重新分配算子联合列表状态。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0315.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0315.png" class="lazyload"></a></p>
<p>具有算子广播状态的算子，通过将状态复制到新任务，来增大任务的并行度。这是没问题的，因为广播状态保证了所有任务都具有相同的状态。而对于缩小并行度的情况，我们可以直接取消剩余任务，因为状态是相同的，已经被复制并且不会丢失。图3-16显示了算子广播状态的重新分配。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0316.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0316.png" class="lazyload"></a></p>
<h2 id="检查点，保存点和状态恢复"><a href="#检查点，保存点和状态恢复" class="headerlink" title="检查点，保存点和状态恢复"></a>检查点，保存点和状态恢复</h2><p>Flink是一个分布式数据处理系统，因此必须有一套机制处理各种故障，比如被杀掉的进程，故障的机器和中断的网络连接。任务都是在本地维护状态的，所以Flink必须确保状态不会丢失，并且在发生故障时能够保持一致。</p>
<p>在本节中，我们将介绍Flink的检查点（checkpoint）和恢复机制，这保证了“精确一次”（exactly-once）的状态一致性。我们还会讨论Flink独特的保存点（savepoint）功能，这是一个“瑞士军刀”式的工具，可以解决许多操作数据流时面对的问题。</p>
<h3 id="一致的检查点（Checkpoints）"><a href="#一致的检查点（Checkpoints）" class="headerlink" title="一致的检查点（Checkpoints）"></a>一致的检查点（Checkpoints）</h3><p>Flink的恢复机制的核心，就是应用状态的一致检查点。有状态流应用的一致检查点，其实就是所有任务状态在某个时间点的一份拷贝，而这个时间点应该是所有任务都恰好处理完一个相同的输入数据的时候。这个过程可以通过一致检查点的一个简单算法步骤来解释。这个算法的步骤是：</p>
<ul>
<li>暂停所有输入流的摄取，也就是不再接收新数据的输入。</li>
<li>等待所有正在处理的数据计算完毕，这意味着结束时，所有任务都已经处理了所有输入数据。</li>
<li>通过将每个任务的状态复制到远程持久存储，来得到一个检查点。所有任务完成拷贝操作后，检查点就完成了。</li>
<li>恢复所有输入流的摄取。</li>
</ul>
<p>需要注意，Flink实现的并不是这种简单的机制。我们将在本节后面介绍Flink更精妙的检查点算法。</p>
<p>图3-17显示了一个简单应用中的一致检查点。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0317.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0317.png" class="lazyload"></a></p>
<p>上面的应用程序中具有单一的输入源（source）任务，输入数据就是一组不断增长的数字的流——1,2,3等。数字流被划分为偶数流和奇数流。求和算子（sum）的两个任务会分别实时计算当前所有偶数和奇数的总和。源任务会将其输入流的当前偏移量存储为状态，而求和任务则将当前的总和值存储为状态。在图3-17中，Flink在输入偏移量为5时，将检查点写入了远程存储，当前的总和为6和9。</p>
<h3 id="从一致检查点中恢复状态"><a href="#从一致检查点中恢复状态" class="headerlink" title="从一致检查点中恢复状态"></a>从一致检查点中恢复状态</h3><p>在执行流应用程序期间，Flink会定期检查状态的一致检查点。如果发生故障，Flink将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程。图3-18显示了恢复过程。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0318.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0318.png" class="lazyload"></a></p>
<p>应用程序从检查点的恢复分为三步：</p>
<ul>
<li>重新启动整个应用程序。</li>
<li>将所有的有状态任务的状态重置为最近一次的检查点。</li>
<li>恢复所有任务的处理。</li>
</ul>
<p>这种检查点的保存和恢复机制可以为应用程序状态提供“精确一次”（exactly-once）的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一来所有的输入流就都会被重置到检查点完成时的位置。至于数据源是否可以重置它的输入流，这取决于其实现方式和消费流数据的外部接口。例如，像Apache Kafka这样的事件日志系统可以提供流上之前偏移位置的数据，所以我们可以将源重置到之前的偏移量，重新消费数据。而从套接字（socket）消费数据的流就不能被重置了，因为套接字的数据一旦被消费就会丢弃掉。因此，对于应用程序而言，只有当所有的输入流消费的都是可重置的数据源时，才能确保在“精确一次”的状态一致性下运行。</p>
<p>从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同。然后它就会开始消费并处理检查点和发生故障之间的所有数据。尽管这意味着Flink会对一些数据处理两次（在故障之前和之后），我们仍然可以说这个机制实现了精确一次的一致性语义，因为所有算子的状态都已被重置，而重置后的状态下还不曾看到这些数据。</p>
<p>我们必须指出，Flink的检查点保存和恢复机制仅仅可以重置流应用程序的内部状态。对于应用中的一些的输出（sink）算子，在恢复期间，某些结果数据可能会多次发送到下游系统，比如事件日志、文件系统或数据库。对于某些存储系统，Flink提供了具有精确一次输出功能的sink函数，比如，可以在检查点完成时提交发出的记录。另一种适用于许多存储系统的方法是幂等更新。在“应用程序一致性保证”一节中，我们还会详细讨论如何解决应用程序端到端的精确一次一致性问题。</p>
<h3 id="Flink的检查点算法"><a href="#Flink的检查点算法" class="headerlink" title="Flink的检查点算法"></a>Flink的检查点算法</h3><p>Flink的恢复机制，基于它的一致性检查点。前面我们已经了解了从流应用中创建检查点的简单方法——先暂停应用，保存检查点，然后再恢复应用程序，这种方法很好理解，但它的理念是“停止一切”，这对于即使是中等延迟要求的应用程序而言也是不实用的。所以Flink没有这么简单粗暴，而是基于Chandy-Lamport算法实现了分布式快照的检查点保存。该算法并不会暂停整个应用程序，而是将检查点的保存与数据处理分离，这样就可以实现在其它任务做检查点状态保存状态时，让某些任务继续进行而不受影响。接下来我们将解释此算法的工作原理。</p>
<p>Flink的检查点算法用到了一种称为“检查点分界线”（checkpoint barrier）的特殊数据形式。与水位线（watermark）类似，检查点分界线由source算子注入到常规的数据流中，它的位置是限定好的，不能超过其他数据，也不能被后面的数据超过。检查点分界线带有检查点ID，用来标识它所属的检查点；这样，这个分界线就将一条流逻辑上分成了两部分。分界线之前到来的数据导致的状态更改，都会被包含在当前分界线所属的检查点中；而基于分界线之后的数据导致的所有更改，就会被包含在之后的检查点中。</p>
<p>我们用一个简单的流应用程序作为示例，来一步一步解释这个算法。该应用程序有两个源（source）任务，每个任务都消费一个增长的数字流。源任务的输出被划分为两部分：偶数和奇数的流。每个分区由一个任务处理，该任务计算所有收到的数字的总和，并将更新的总和转发给输出（sink）任务。这个应用程序的结构如图3-19所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0319.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0319.png" class="lazyload"></a></p>
<p>JobManager会向每个数据源（source）任务发送一条带有新检查点ID的消息，通过这种方式来启动检查点，如图3-20所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0320.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0320.png" class="lazyload"></a></p>
<p>当source任务收到消息时，它会暂停发出新的数据，在状态后端触发本地状态的检查点保存，并向所有传出的流分区广播带着检查点ID的分界线（barriers）。状态后端在状态检查点完成后会通知任务，而任务会向JobManager确认检查点完成。在发出所有分界线后，source任务就可以继续常规操作，发出新的数据了。通过将分界线注入到输出流中，源函数（source function）定义了检查点在流中所处的位置。图3-21显示了两个源任务将本地状态保存到检查点，并发出检查点分界线之后的流应用程序。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0321.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0321.png" class="lazyload"></a></p>
<p>源任务发出的检查点分界线（barrier），将被传递给所连接的任务。与水位线（watermark）类似，barrier会被广播到所有连接的并行任务，以确保每个任务从它的每个输入流中都能接收到。当任务收到一个新检查点的barrier时，它会等待这个检查点的所有输入分区的barrier到达。在等待的过程中，任务并不会闲着，而是会继续处理尚未提供barrier的流分区中的数据。对于那些barrier已经到达的分区，如果继续有新的数据到达，它们就不会被立即处理，而是先缓存起来。这个等待所有分界线到达的过程，称为“分界线对齐”（barrier alignment），如图3-22所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0322.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0322.png" class="lazyload"></a></p>
<p>当任务从所有输入分区都收到barrier时，它就会在状态后端启动一个检查点的保存，并继续向所有下游连接的任务广播检查点分界线，如图3-23所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0323.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0323.png" class="lazyload"></a></p>
<p>所有的检查点barrier都发出后，任务就开始处理之前缓冲的数据。在处理并发出所有缓冲数据之后，任务就可以继续正常处理输入流了。图3-24显示了此时的应用程序。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0324.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0324.png" class="lazyload"></a></p>
<p>最终，检查点分界线会到达输出（sink）任务。当sink任务接收到barrier时，它也会先执行“分界线对齐”，然后将自己的状态保存到检查点，并向JobManager确认已接收到barrier。一旦从应用程序的所有任务收到一个检查点的确认信息，JobManager就会将这个检查点记录为已完成。图3-25显示了检查点算法的最后一步。这样，当发生故障时，我们就可以用已完成的检查点恢复应用程序了。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0325.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0325.png" class="lazyload"></a></p>
<h3 id="检查点的性能影响"><a href="#检查点的性能影响" class="headerlink" title="检查点的性能影响"></a>检查点的性能影响</h3><p>Flink的检查点算法可以在不停止整个应用程序的情况下，生成一致的分布式检查点。但是，它可能会增加应用程序的处理延迟。Flink对此有一些调整措施，可以在某些场景下显得对性能的影响没那么大。</p>
<p>当任务将其状态保存到检查点时，它其实处于一个阻塞状态，而此时新的输入会被缓存起来。由于状态可能变得非常大，而且检查点需要通过网络将数据写入远程存储系统，检查点的写入很容易就会花费几秒到几分钟的时间——这对于要求低延迟的应用程序而言，显然是不可接受的。在Flink的设计中，真正负责执行检查点写入的，其实是状态后端。具体怎样复制任务的状态，取决于状态后端的实现方式。例如，文件系统（FileSystem）状态后端和RocksDB状态后端都支持了异步（asynchronous）检查点。触发检查点操作时，状态后端会先创建状态的本地副本。本地拷贝完成后，任务就将继续常规的数据处理，这往往并不会花费太多时间。一个后台线程会将本地快照异步复制到远程存储，并在完成检查点后再回来通知任务。异步检查点的机制，显著减少了任务继续处理数据之前的等待时间。此外，RocksDB状态后端还实现了增量的检查点，这样可以大大减少要传输的数据量。</p>
<p>为了减少检查点算法对处理延迟的影响，另一种技术是调整分界线对齐的步骤。对于需要非常低的延迟、并且可以容忍“至少一次”（at-least-once）状态保证的应用程序，Flink可以将检查点算法配置为，在等待barrier对齐期间处理所有到达的数据，而不是把barrier已经到达的那些分区的数据缓存起来。当检查点的所有barrier到达，算子任务就会将状态写入检查点——当然，现在的状态中，就可能包括了一些“提前”的更改，这些更改由本该属于下一个检查点的数据到来时触发。如果发生故障，从检查点恢复时，就将再次处理这些数据：这意味着检查点现在提供的是“至少一次”（at-least-once）而不是“精确一次”（exactly-once）的一致性保证。</p>
<h3 id="保存点（Savepoints）"><a href="#保存点（Savepoints）" class="headerlink" title="保存点（Savepoints）"></a>保存点（Savepoints）</h3><p>Flink的恢复算法是基于状态检查点的。Flink根据可配置的策略，定期保存并自动丢弃检查点。检查点的目的是确保在发生故障时可以重新启动应用程序，所以当应用程序被显式地撤销（cancel）时，检查点会被删除掉。除此之外，应用程序状态的一致性快照还可用于除故障恢复之外的更多功能。</p>
<p>Flink中一个最有价值，也是最独特的功能是保存点（savepoints）。原则上，创建保存点使用的算法与检查点完全相同，因此保存点可以认为就是具有一些额外元数据的检查点。 Flink不会自动创建保存点，因此用户（或者外部调度程序）必须明确地触发创建操作。同样，Flink也不会自动清理保存点。第10章将会具体介绍如何触发和处理保存点。</p>
<h4 id="使用保存点"><a href="#使用保存点" class="headerlink" title="使用保存点"></a>使用保存点</h4><p>有了应用程序和与之兼容的保存点，我们就可以从保存点启动应用程序了。这会将应用程序的状态初始化为保存点的状态，并从保存点创建时的状态开始运行应用程序。虽然看起来这种行为似乎与用检查点从故障中恢复应用程序完全相同，但实际上故障恢复只是一种特殊情况，它只是在相同的集群上以相同的配置启动相同的应用程序。而从保存点启动应用程序会更加灵活，这就可以让我们做更多事情了。</p>
<ul>
<li>可以从保存点启动不同但兼容的应用程序。这样一来，我们就可以及时修复应用程序中的逻辑bug，并让流式应用的源尽可能多地提供之前发生的事件，然后重新处理，以便修复之前的计算结果。修改后的应用程序还可用于运行A / B测试，或者具有不同业务逻辑的假设场景。这里要注意，应用程序和保存点必须兼容才可以这么做——也就是说，应用程序必须能够加载保存点的状态。</li>
<li>可以使用不同的并行度来启动相同的应用程序，可以将应用程序的并行度增大或减小。</li>
<li>可以在不同的集群上启动同样的应用程序。这非常有意义，意味着我们可以将应用程序迁移到较新的Flink版本或不同的集群上去。</li>
<li>可以使用保存点暂停应用程序，稍后再恢复。这样做的意义在于，可以为更高优先级的应用程序释放集群资源，或者在输入数据不连续生成时释放集群资源。</li>
<li>还可以将保存点设置为某一版本，并归档（archive）存储应用程序的状态。</li>
</ul>
<p>保存点是非常强大的功能，所以许多用户会定期创建保存点以便能够及时退回之前的状态。我们见到的各种场景中，保存点一个最有趣的应用是不断将流应用程序迁移到更便宜的数据中心上去。</p>
<h4 id="从保存点启动应用程序"><a href="#从保存点启动应用程序" class="headerlink" title="从保存点启动应用程序"></a>从保存点启动应用程序</h4><p>前面提到的保存点的所有用例，都遵循相同的模式。那就是首先创建正在运行的应用程序的保存点，然后在一个新启动的应用程序中用它来恢复状态。之前我们已经知道，保存点的创建和检查点非常相似，而接下来我们就将介绍对于一个从保存点启动的应用程序，Flink如何初始化其状态。</p>
<p>应用程序由多个算子组成。每个算子可以定义一个或多个键控状态和算子状态。算子由一个或多个算子任务并行执行。因此，一个典型的应用程序会包含多个状态，这些状态分布在多个算子任务中，这些任务可以运行在不同的TaskManager进程上。</p>
<p>图3-26显示了一个具有三个算子的应用程序，每个算子执行两个算子任务。一个算子（OP-1）具有单一的算子状态（OS-1），而另一个算子（OP-2）具有两个键控状态（KS-1和KS-2）。当保存点创建时，会将所有任务的状态复制到持久化的存储位置。</p>
<p>保存点中的状态拷贝会以算子标识符（operator ID）和状态名称（state name）组织起来。算子ID和状态名称必须能够将保存点的状态数据，映射到一个正在启动的应用程序的算子状态。从保存点启动应用程序时，Flink会将保存点的数据重新分配给相应的算子任务。</p>
<blockquote>
<p>请注意，保存点不包含有关算子任务的信息。这是因为当应用程序以不同的并行度启动时，任务数量可能会更改。</p>
</blockquote>
<p>如果我们要从保存点启动一个修改过的应用程序，那么保存点中的状态只能映射到符合标准的应用程序——它里面的算子必须具有相应的ID和状态名称。默认情况下，Flink会自动分配唯一的算子ID。然而，一个算子的ID，是基于它之前算子的ID确定性地生成的。因此，算子的ID会在其前序算子改变时改变，比如，当我们添加了新的或移除掉一个算子时，前序算子ID改变，当前算子ID就会变化。所以对于具有默认算子ID的应用程序而言，如果想在不丢失状态的前提下升级，就会受到极大的限制。因此，我们强烈建议在程序中为算子手动分配唯一ID，而不是依靠Flink的默认分配。我们将在“指定唯一的算子标识符”一节中详细说明如何分配算子标识符。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>flink</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>flink系列02流处理基础</title>
    <url>/2020/06/27/flink%E7%B3%BB%E5%88%9702%E6%B5%81%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="第二章，流处理基础"><a href="#第二章，流处理基础" class="headerlink" title="第二章，流处理基础"></a>第二章，流处理基础</h1><h2 id="数据流编程简介"><a href="#数据流编程简介" class="headerlink" title="数据流编程简介"></a>数据流编程简介</h2><p>在我们深入研究流处理的基础知识之前，让我们来看看在数据流程编程的背景和使用的术语。</p>
<h3 id="数据流图-dataflow-graph"><a href="#数据流图-dataflow-graph" class="headerlink" title="数据流图(dataflow graph)"></a>数据流图(dataflow graph)</h3><p>顾名思义，数据流程序描述了数据如何在算子之间流动。数据流程序通常表示为有向图，其中节点称为算子，用来表示计算，边表示数据之间的依赖性。算子是数据流程序的基本功能单元。他们从输入消耗数据，对它们执行计算，并生成数据输出用于进一步处理。一个数据流图必须至少有一个数据源和一个数据接收器。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0201.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0201.png" class="lazyload"></a></p>
<p>像图2-1中的数据流图被称为逻辑流图，因为它们表示了计算逻辑的高级视图。为了执行一个数据流程序，Flink会将逻辑流图转换为物理数据流图，详细说明程序的执行方式。例如，如果我们使用分布式处理引擎，每个算子在不同的物理机器可能有几个并行的任务运行。图2-2显示了图2-1逻辑图的物理数据流图。而在逻辑数据流图中节点表示算子，在物理数据流图中，节点是任务。“Extract hashtags”和“Count”算子有两个并行算子任务，每个算子任务对输入数据的子集执行计算。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0202.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0202.png" class="lazyload"></a></p>
<h3 id="数据并行和任务并行"><a href="#数据并行和任务并行" class="headerlink" title="数据并行和任务并行"></a>数据并行和任务并行</h3><p>我们可以以不同方式利用数据流图中的并行性。第一，我们可以对输入数据进行分区，并在数据的子集上并行执行具有相同算子的任务并行。这种类型的并行性被称为数据并行性。数据并行是有用的，因为它允许处理大量数据，并将计算分散到不同的计算节点上。第二，我们可以将不同的算子在相同或不同的数据上并行执行。这种并行性称为任务并行性。使用任务并行性，我们可以更好地利用计算资源。</p>
<h3 id="数据交换策略"><a href="#数据交换策略" class="headerlink" title="数据交换策略"></a>数据交换策略</h3><p>数据交换策略定义了在物理执行流图中如何将数据分配给任务。数据交换策略可以由执行引擎自动选择，具体取决于算子的语义或我们明确指定的语义。在这里，我们简要回顾一些常见的数据交换策略，如图2-3所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0203.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0203.png" class="lazyload"></a></p>
<ul>
<li>前向策略将数据从一个任务发送到接收任务。如果两个任务都位于同一台物理计算机上（这通常由任务调度器确保），这种交换策略可以避免网络通信。</li>
<li>广播策略将所有数据发送到算子的所有的并行任务上面去。因为这种策略会复制数据和涉及网络通信，所以代价相当昂贵。</li>
<li>基于键控的策略通过Key值(键)对数据进行分区保证具有相同Key的数据将由同一任务处理。在图2-2中，输出“Extract hashtags”算子使用键来分区（hashtag），以便count算子的任务可以正确计算每个#标签的出现次数。</li>
<li>随机策略统一将数据分配到算子的任务中去，以便均匀地将负载分配到不同的计算任务。</li>
</ul>
<h2 id="并行处理流数据"><a href="#并行处理流数据" class="headerlink" title="并行处理流数据"></a>并行处理流数据</h2><p>既然我们熟悉了数据流编程的基础知识，现在是时候看看这些概念如何应用于并行的处理数据流了。但首先，让我们定义术语数据流：数据流是一个可能无限的事件序列。</p>
<p>数据流中的事件可以表示监控数据，传感器测量数据，信用卡交易数据，气象站观测数据，在线用户交互数据，网络搜索数据等。在本节中，我们将学习如何并行处理无限流，使用数据流编程范式。</p>
<h3 id="延迟和吞吐量"><a href="#延迟和吞吐量" class="headerlink" title="延迟和吞吐量"></a>延迟和吞吐量</h3><p>流处理程序不同与批处理程序。在评估性能时，要求也有所不同。对于批处理程序，我们通常关心一个作业的总的执行时间，或我们的处理引擎读取输入所需的时间，执行计算，并回写结果。由于流处理程序是连续运行的，输入可能是无界的，所以数据流处理中没有总执行时间的概念。 相反，流处理程序必须尽可能快的提供输入数据的计算结果。我们使用延迟和吞吐量来表征流处理的性能要求。</p>
<h3 id="延迟"><a href="#延迟" class="headerlink" title="延迟"></a>延迟</h3><p>延迟表示处理事件所需的时间。它是接收事件和看到在输出中处理此事件的效果之间的时间间隔。要直观的理解延迟，考虑去咖啡店买咖啡。当你进入咖啡店时，可能还有其他顾客在里面。因此，你排队等候直到轮到你下订单。收银员收到你的付款并通知准备饮料的咖啡师。一旦你的咖啡准备好了，咖啡师会叫你的名字，你可以到柜台拿你的咖啡。服务延迟是从你进入咖啡店的那一刻起，直到你喝上第一口咖啡之间的时间间隔。</p>
<p>在数据流中，延迟是以时间为单位测量的，例如毫秒。根据应用程序，我们可能会关心平均延迟，最大延迟或百分位延迟。例如，平均延迟值为10ms意味着处理事件的平均时间在10毫秒内。或者，延迟值为95%，10ms表示95%的事件在10ms内处理完毕。平均值隐藏了处理延迟的真实分布，可能会让人难以发现问题。如果咖啡师在准备卡布奇诺之前用完了牛奶，你必须等到他们从供应室带来一些。虽然你可能会因为这么长时间的延迟而生气，但大多数其他客户仍然会感到高兴。</p>
<p>确保低延迟对于许多流应用程序来说至关重要，例如欺诈检测，系统警报，网络监控和提供具有严格服务水平协议的服务。低延迟是流处理的关键特性，它实现了我们所谓的实时应用程序。像Apache Flink这样的现代流处理器可以提供低至几毫秒的延迟。相比之下，传统批处理程序延迟通常从几分钟到几个小时不等。在批处理中，首先需要收集事件批次，然后才能处理它们。因此，延迟是受每个批次中最后一个事件的到达时间的限制。所以自然而然取决于批的大小。真正的流处理不会引入这样的人为延迟，因此可以实现真正的低延迟。真的流模型，事件一进入系统就可以得到处理。延迟更密切地反映了在每个事件上必须进行的实际工作。</p>
<h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p>吞吐量是衡量系统处理能力的指标，也就是处理速率。也就是说，吞吐量告诉我们每个时间单位系统可以处理多少事件。重温咖啡店的例子，如果商店营业时间为早上7点至晚上7点。当天为600个客户提供了服务，它的平均吞吐量将是每小时50个客户。虽然我们希望延迟尽可能低，但我们通常也需要吞吐量尽可能高。</p>
<p>吞吐量以每个时间单位系统所能处理的事件数量或操作数量来衡量。值得注意的是，事件处理速率取决于事件到达的速率，低吞吐量并不一定表示性能不佳。 在流式系统中，我们通常希望确保我们的系统可以处理最大的预期事件到达的速率。也就是说，我们主要的关注点在于确定的峰值吞吐量是多少，当系统处于最大负载时性能怎么样。为了更好地理解峰值吞吐量的概念，让我们考虑一个流处理 程序没有收到任何输入的数据，因此没有消耗任何系统资源。当第一个事件进来时，它会尽可能以最小延迟立即处理。例如，如果你是第一个出现在咖啡店的顾客，在早上开门后，你将立即获得服务。理想情况下，您希望此延迟保持不变 ，并且独立于传入事件的速率。但是，一旦我们达到使系统资源被完全使用的事件传入速率，我们将不得不开始缓冲事件。在咖啡店里 ，午餐后会看到这种情况发生。许多人出现在同一时间，必须排队等候。在此刻，咖啡店系统已达到其峰值吞吐量，进一步增加 事件传入的速率只会导致更糟糕的延迟。如果系统继续以可以处理的速率接收数据，缓冲区可能变为不可用，数据可能会丢失。这种情况是众所周知的 作为背压，有不同的策略来处理它。</p>
<h3 id="延迟与吞吐量的对比"><a href="#延迟与吞吐量的对比" class="headerlink" title="延迟与吞吐量的对比"></a>延迟与吞吐量的对比</h3><p>此时，应该清楚延迟和吞吐量不是独立指标。如果事件需要在处理流水线中待上很长时间，我们不能轻易确保高吞吐量。同样，如果系统容量很小，事件将被缓冲，而且必须等待才能得到处理。</p>
<p>让我们重温一下咖啡店的例子来阐明一下延迟和吞吐量如何相互影响。首先，应该清楚存在没有负载时的最佳延迟。也就是说，如果你是咖啡店的唯一客户，会很快得到咖啡。然而，在繁忙时期，客户将不得不排队等待，并且会有延迟增加。另一个影响延迟和吞吐量的因素是处理事件所花费的时间或为每个客户提供服务所花费的时间。想象一下，期间圣诞节假期，咖啡师不得不为每杯咖啡画圣诞老人。这意味着准备一杯咖啡需要的时间会增加，导致每个人花费 更多的时间在等待咖啡师画圣诞老人，从而降低整体吞吐量。</p>
<p>那么，你可以同时获得低延迟和高吞吐量吗？或者这是一个无望的努力？我们可以降低得到咖啡的延迟 ，方法是：聘请一位更熟练的咖啡师来准备咖啡。在高负载时，这种变化也会增加吞吐量，因为会在相同的时间内为更多的客户提供服务。 实现相同结果的另一种方法是雇用第二个咖啡师来利用并行性。这里的主要想法是降低延迟来增加吞吐量。当然，如果系统可以更快的执行操作，它可以在相同的时间内执行更多操作。 事实上，在流中利用并行性时也会发生这种情况。通过并行处理多个流，在同时处理更多事件的同时降低延迟。</p>
<h2 id="数据流上的操作"><a href="#数据流上的操作" class="headerlink" title="数据流上的操作"></a>数据流上的操作</h2><p>流处理引擎通常提供一组内置操作：摄取(ingest)，转换(transform)和输出流(output)。这些操作可以 结合到数据流图中来实现逻辑流处理程序。在本节中，我们描述最常见的流处理操作。</p>
<p>操作可以是无状态的或有状态的。无状态操作不保持任何内部状态。也就是说，事件的处理不依赖于过去看到的任何事件，也没有保留历史。 无状态操作很容易并行化，因为事件可以彼此独立地处理，也独立于事件到达的顺序(和事件到达顺序没有关系)。 而且，在失败的情况下，无状态操作可以是简单的重新启动并从中断处继续处理。相反， 有状态操作可能会维护之前收到的事件的信息。此状态可以通过传入事件更新，也可以用于未来事件的处理逻辑。有状态的流 处理应用程序更难以并行化和以容错的方式来运行，因为状态需要有效的进行分区和在发生故障的情况下可靠地恢复。</p>
<h3 id="数据摄入和数据吞吐量"><a href="#数据摄入和数据吞吐量" class="headerlink" title="数据摄入和数据吞吐量"></a>数据摄入和数据吞吐量</h3><p>数据摄取和数据出口操作允许流处理程序与外部系统通信。数据摄取是操作从外部源获取原始数据并将其转换为其他格式(ETL)。实现数据提取逻辑的运算符被称为数据源。数据源可以从TCP Socket，文件，Kafka Topic或传感器数据接口中提取数据。数据出口是以适合消费的形式产出到外部系统。执行数据出口的运算符称为数据接收器，包括文件，数据库，消息队列和监控接口。</p>
<h3 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a>转换算子</h3><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0204.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0204.png" class="lazyload"></a></p>
<p>转换算子是单遍处理算子，碰到一个事件处理一个事件。这些操作在使用后会消费一个事件，然后对事件数据做一些转换，产生一个新的输出流。转换逻辑可以集成在 操作符中或由UDF函数提供，如图所示图2-4。程序员编写实现自定义计算逻辑。</p>
<p>操作符可以接受多个输入流并产生多个输出流。他们还可以通过修改数据流图的结构要么将流分成多个流，要么将流合并为一条流。</p>
<h3 id="滚动聚合"><a href="#滚动聚合" class="headerlink" title="滚动聚合"></a>滚动聚合</h3><p>滚动聚合是一种聚合，例如sum，minimum和maximum，为每个输入事件不断更新。 聚合操作是有状态的，并将当前状态与传入事件一起计算以产生更新的聚合值。请注意能够有效地将当前状态与事件相结合 产生单个值，聚合函数必须是关联的和可交换的。否则，操作符必须存储完整的流数据历史。图2-5显示了最小滚动 聚合。操作符保持当前的最小值和相应地为每个传入的事件来更新最小值。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0205.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0205.png" class="lazyload"></a></p>
<h3 id="窗口操作符"><a href="#窗口操作符" class="headerlink" title="窗口操作符"></a>窗口操作符</h3><p>转换和滚动聚合一次处理一个事件产生输出事件并可能更新状态。但是，有些操作必须收集并缓冲数据以计算其结果。 例如，考虑不同流之间的连接或整体聚合这样的操作，例如中值函数。为了在无界流上高效运行这些操作符，我们需要限制 这些操作维护的数据量。在本节中，我们将讨论窗口操作，提供此服务。</p>
<p>窗口还可以在语义上实现关于流的比较复杂的查询。我们已经看到了滚动聚合的方式，以聚合值编码整个流的历史数据来为每个事件提供低延迟的结果。 但如果我们只对最近的数据感兴趣的话会怎样？考虑给司机提供实时交通信息的应用程序。这个程序可以使他们避免拥挤的路线。在这种场景下，你想知道某个位置在最近几分钟内是否有事故发生。 另一方面，了解所有发生过的事故在这个应用场景下并没有什么卵用。更重要的是，通过将流历史缩减为单一聚合值，我们将丢失这段时间内数据的变化。例如，我们可能想知道每5分钟有多少车辆穿过 某个路口。</p>
<p>窗口操作不断从无限事件流中创建有限的事件集，好让我们执行有限集的计算。通常会基于数据属性或基于时间的窗口来分配事件。 要正确定义窗口运算符语义，我们需要确定如何给窗口分配事件以及对窗口中的元素进行求值的频率是什么样的。 窗口的行为由一组策略定义。窗口策略决定何时创建新的窗口以及要分配的事件属于哪个窗口，以及何时对窗口中的元素进行求值。 而窗口的求值基于触发条件。一旦触发条件得到满足，窗口的内容将会被发送到求值函数，求值函数会将计算逻辑应用于窗口中的元素。 求值函数可以是sum或minimal或自定义的聚合函数。 求值策略可以根据时间或者数据属性计算(例如，在过去五秒内收到的事件或者最近的一百个事件等等)。 接下来，我们描述常见窗口类型的语义。</p>
<ul>
<li>滚动窗口是将事件分配到固定大小的不重叠的窗口中。当通过窗口的结尾时，全部事件被发送到求值函数进行处理。基于计数的滚动窗口定义了在触发求值之前需要收集多少事件。图2-6显示了一个基于计数的翻滚窗口，每四个元素一个窗口。基于时间的滚动窗口定义一个时间间隔，包含在此时间间隔内的事件。图2-7显示了基于时间的滚动窗口，将事件收集到窗口中每10分钟触发一次计算。</li>
</ul>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0206.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0206.png" class="lazyload"></a></p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0207.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0207.png" class="lazyload"></a></p>
<ul>
<li>滑动窗口将事件分配到固定大小的重叠的窗口中去。因此，事件可能属于多个桶。我们通过提供窗口的长度和滑动距离来定义滑动窗口。滑动距离定义了创建新窗口的间隔。基于滑动计数的窗口，图2-8的长度为四个事件，三个为滑动距离。</li>
</ul>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0208.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0208.png" class="lazyload"></a></p>
<ul>
<li>会话窗口在常见的真实场景中很有用，一些场景既不能使用滚动窗口也不能使用滑动窗口。考虑一个分析在线用户行为的应用程序。在应用程序里，我们想把源自同一时期的用户活动或会话事件分组在一起。会话由一系列相邻时间发生的事件组成，接下来有一段时间没有活动。例如，用户在App上浏览一系列的新闻，然后关掉App，那么浏览新闻这段时间的浏览事件就是一个会话。会话窗口事先没有定义窗口的长度，而是取决于数据的实际情况，滚动窗口和滑动窗口无法应用于这个场景。相反，我们需要将同一会话中的事件分配到同一个窗口中去，而不同的会话可能窗口长度不一样。会话窗口会定义一个间隙值来区分不同的会话。间隙值的意思是：用户一段时间内不活动，就认为用户的会话结束了。图2-9显示了一个会话窗口。</li>
</ul>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0209.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0209.png" class="lazyload"></a></p>
<p>到目前为止，所有窗口类型都是在整条流上去做窗口操作。但实际上你可能想要将一条流分流成多个逻辑流并定义并行窗口。 例如，如果我们正在接收来自不同传感器的测量结果，那么可能想要在做窗口计算之前按传感器ID对流进行分流操作。 在并行窗口中，每条流都独立于其他流，然后应用了窗口逻辑。图2-10显示了一个基于计数的长度为2的并行滚动窗口，根据事件颜色分流。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0210.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0210.png" class="lazyload"></a></p>
<p>在流处理中，窗口操作与两个主要概念密切相关：时间语义和状态管理。时间也许是流处理最重要的方面。即使低延迟是流处理的一个有吸引力的特性，它的真正价值不仅仅是快速分析。真实世界的系统，网络和通信渠道远非完美，流数据经常被推迟或无序(乱序)到达。理解如何在这种条件下提供准确和确定的结果是至关重要的。 更重要的是，流处理程序可以按原样处理事件制作的也应该能够处理相同的历史事件方式，从而实现离线分析甚至时间旅行分析。 当然，前提是我们的系统可以保存状态，因为可能有故障发生。到目前为止，我们看到的所有窗口类型在产生结果前都需要保存之前的数据。实际上，如果我们想计算任何指标，即使是简单的计数，我们也需要保存状态。考虑到流处理程序可能会运行几天，几个月甚至几年，我们需要确保状态可以在发生故障的情况下可靠地恢复。 并且即使程序崩溃，我们的系统也能保证计算出准确的结果。本章，我们将在流处理应用可能发生故障的语境下，深入探讨时间和状态的概念。</p>
<h2 id="时间语义"><a href="#时间语义" class="headerlink" title="时间语义"></a>时间语义</h2><p>在本节中，我们将介绍时间语义，并描述流中不同的时间概念。我们将讨论流处理器在乱序事件流的情况下如何提供准确的计算结果，以及我们如何处理历史事件流，如何在流中进行时间旅行。</p>
<h3 id="在流处理中一分钟代表什么？"><a href="#在流处理中一分钟代表什么？" class="headerlink" title="在流处理中一分钟代表什么？"></a>在流处理中一分钟代表什么？</h3><p>在处理可能是无限的事件流（包含了连续到达的事件），时间成为流处理程序的核心方面。假设我们想要连续的计算结果，可能每分钟就要计算一次。在我们的流处理程序上下文中，一分钟的意思是什么？</p>
<p>考虑一个程序需要分析一款移动端的在线游戏的用户所产生的事件流。游戏中的用户分了组，而应用程序将收集每个小组的活动数据，基于小组中的成员多快达到了游戏设定的目标，然后在游戏中提供奖励。例如额外的生命和用户升级。例如，如果一个小组中的所有用户在一分钟之内都弹出了500个泡泡，他们将升一级。Alice是一个勤奋的玩家，她在每天早晨的通勤时间玩游戏。问题在于Alice住在柏林，并且乘地铁去上班。而柏林的地铁手机信号很差。我们设想一个这样的场景，Alice当她的手机连上网时，开始弹泡泡，然后游戏会将数据发送到我们编写的应用程序中，这时地铁突然进入了隧道，她的手机也断网了。Alice还在玩这个游戏，而产生的事件将会缓存在手机中。当地铁离开隧道，Alice的手机又在线了，而手机中缓存的游戏事件将发送到应用程序。我们的应用程序应该如何处理这些数据？在这个场景中一分钟的意思是什么？这个一分钟应该包含Alice离线的那段时间吗？下图展示了这个问题。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0211.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0211.png" class="lazyload"></a></p>
<p>在线手游是一个简单的场景，展示了应用程序的运算应该取决于事件实际发生的时间，而不是应用程序收到事件的时间。如果我们按照应用程序收到事件的时间来进行处理的话，最糟糕的后果就是，Alice和她的朋友们再也不玩这个游戏了。但是还有很多时间语义非常关键的应用程序，我们需要保证时间语义的正确性。如果我们只考虑我们在一分钟之内收到了多少数据，我们的结果会变化，因为结果取决于网络连接的速度或处理的速度。相反，定义一分钟之内的事件数量，这个一分钟应该是数据本身的时间。</p>
<p>在Alice的这个例子中，流处理程序可能会碰到两个不同的时间概念：处理时间和事件时间。我们将在接下来的部分，讨论这两个概念。</p>
<h3 id="处理时间"><a href="#处理时间" class="headerlink" title="处理时间"></a>处理时间</h3><p>处理时间是处理流的应用程序的机器的本地时钟的时间（墙上时钟）。处理时间的窗口包含了一个时间段内来到机器的所有事件。这个时间段指的是机器的墙上时钟。如下图所示，在Alice的这个例子中，处理时间窗口在Alice的手机离线的情况下，时间将会继续行走。但这个处理时间窗口将不会收集Alice的手机离线时产生的事件。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0212.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0212.png" class="lazyload"></a></p>
<h3 id="事件时间"><a href="#事件时间" class="headerlink" title="事件时间"></a>事件时间</h3><p>事件时间是流中的事件实际发生的时间。事件时间基于流中的事件所包含的时间戳。通常情况下，在事件进入流处理程序前，事件数据就已经包含了时间戳。下图展示了事件时间窗口将会正确的将事件分发到窗口中去。可以如实反应事情是怎么发生的。即使事件可能存在延迟。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0213.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0213.png" class="lazyload"></a></p>
<p>事件时间使得计算结果的过程不需要依赖处理数据的速度。基于事件时间的操作是可以预测的，而计算结果也是确定的。无论流处理程序处理流数据的速度快或是慢，无论事件到达流处理程序的速度快或是慢，事件时间窗口的计算结果都是一样的。</p>
<p>可以处理迟到的事件只是我们使用事件时间所克服的一个挑战而已。普遍存在的事件乱序问题可以使用事件时间得到解决。考虑和Alice玩同样游戏的Bob，他恰好和Alice在同一趟地铁上。Alice和Bob虽然玩的游戏一样，但他们的手机信号是不同的运营商提供的。当Alice的手机没信号时，Bob的手机依然有信号，游戏数据可以正常发送出去。</p>
<p>如果使用事件时间，即使碰到了事件乱序到达的情况，我们也可以保证结果的正确性。还有，当我们在处理可以重播的流数据时，由于时间戳的确定性，我们可以快进过去。也就是说，我们可以重播一条流，然后分析历史数据，就好像流中的事件是实时发生一样。另外，我们可以快进历史数据来使我们的应用程序追上现在的事件，然后应用程序仍然是一个实时处理程序，而且业务逻辑不需要改变。</p>
<h3 id="水位线（Watermarks）"><a href="#水位线（Watermarks）" class="headerlink" title="水位线（Watermarks）"></a>水位线（Watermarks）</h3><p>在我们对事件时间窗口的讨论中，我们忽略了一个很重要的方面：我们应该怎样去决定何时触发事件时间窗口的计算？也就是说，在我们可以确定一个时间点之前的所有事件都已经到达之前，我们需要等待多久？我们如何知道事件是迟到的？在分布式系统无法准确预测行为的现实条件下，以及外部组件所引发的事件的延迟，以上问题并没有准确的答案。在本小节中，我们将会看到如何使用水位线来设置事件时间窗口的行为。</p>
<p>水位线是全局进度的度量标准。系统可以确信在一个时间点之后，不会有早于这个时间点发生的事件到来了。本质上，水位线提供了一个逻辑时钟，这个逻辑时钟告诉系统当前的事件时间。当一个运算符接收到含有时间T的水位线时，这个运算符会认为早于时间T的发生的事件已经全部都到达了。对于事件时间窗口和乱序事件的处理，水位线非常重要。运算符一旦接收到水位线，运算符会认为一段时间内发生的所有事件都已经观察到，可以触发针对这段时间内所有事件的计算了。</p>
<p>水位线提供了一种结果可信度和延时之间的妥协。激进的水位线设置可以保证低延迟，但结果的准确性不够。在这种情况下，迟到的事件有可能晚于水位线到达，我们需要编写一些代码来处理迟到事件。另一方面，如果水位线设置的过于宽松，计算的结果准确性会很高，但可能会增加流处理程序不必要的延时。</p>
<p>在很多真实世界的场景里面，系统无法获得足够的知识来完美的确定水位线。在手游这个场景中，我们无法得知一个用户离线时间会有多长，他们可能正在穿越一条隧道，可能正在乘飞机，可能永远不会再玩儿了。水位线无论是用户自定义的或者是自动生成的，在一个分布式系统中追踪全局的时间进度都不是很容易。所以仅仅依靠水位线可能并不是一个很好的主意。流处理系统还需要提供一些机制来处理迟到的元素（在水位线之后到达的事件）。根据应用场景，我们可能需要把迟到事件丢弃掉，或者写到日志里，或者使用迟到事件来更新之前已经计算好的结果。</p>
<h3 id="处理时间-vs-事件时间"><a href="#处理时间-vs-事件时间" class="headerlink" title="处理时间 vs 事件时间"></a>处理时间 vs 事件时间</h3><p>大家可能会有疑问，既然事件时间已经可以解决我们的所有问题，为什么我们还要对比这两个时间概念？真相是，处理时间在很多情况下依然很有用。处理时间窗口将会带来理论上最低的延迟。因为我们不需要考虑迟到事件以及乱序事件，所以一个窗口只需要简单的缓存窗口内的数据即可，一旦机器时间超过指定的处理时间窗口的结束时间，就会触发窗口的计算。所以对于一些处理速度比结果准确性更重要的流处理程序，处理时间就派上用场了。另一个应用场景是，当我们需要在真实的时间场景下，周期性的报告结果时，同时不考虑结果的准确性。一个例子就是一个实时监控的仪表盘，负责显示当事件到达时立即聚合的结果。最后，处理时间窗口可以提供流本身数据的忠实表达，对于一些案例可能是很必要的特性。例如我们可能对观察流和对每分钟事件的计数（检测可能存在的停电状况）很感兴趣。简单的说，处理时间提供了低延迟，同时结果也取决于处理速度，并且也不能保证确定性。另一方面，事件时间保证了结果的确定性，同时还可以使我们能够处理迟到的或者乱序的事件流。</p>
<h2 id="状态和持久化模型"><a href="#状态和持久化模型" class="headerlink" title="状态和持久化模型"></a>状态和持久化模型</h2><p>我们现在转向另一个对于流处理程序非常重要的话题：状态。在数据处理中，状态是普遍存在的。任何稍微复杂一点的计算，都涉及到状态。为了产生计算结果，一个函数在一段时间内的一定数量的事件上来累加状态（例如，聚合计算或者模式匹配）。有状态的运算符使用输入的事件以及内部保存的状态来计算得到输出。例如，一个滚动聚合运算符需要输出这个运算符所观察到的所有事件的累加和。这个运算符将会在内部保存当前观察到的所有事件的累加和，同时每输入一个事件就更新一次累加和的计算结果。相似的，当一个运算符检测到一个“高温”事件紧接着十分钟以内检测到一个“烟雾”事件时，将会报警。直到运算符观察到一个“烟雾”事件或者十分钟的时间段已经过去，这个运算符需要在内部状态中一直保存着“高温”事件。</p>
<p>当我们考虑一下使用批处理系统来分析一个无界数据集时，会发现状态的重要性显而易见。在现代流处理器兴起之前，处理无界数据集的一个通常做法是将输入的事件攒成微批，然后交由批处理器来处理。当一个任务结束时，计算结果将被持久化，而所有的运算符状态就丢失了。一旦一个任务在计算下一个微批次的数据时，这个任务是无法访问上一个任务的状态的（都丢掉了）。这个问题通常使用将状态代理到外部系统（例如数据库）的方法来解决。相反，在一个连续不间断运行的流处理任务中，事件的状态是一直存在的，我们可以将状态暴露出来作为编程模型中的一等公民。当然，我们的确可以使用外部系统来管理流的状态，即使这个解决方案会带来额外的延迟。</p>
<p>由于流处理运算符默认处理的是无界数据流。所以我们必须要注意不要让内部状态无限的增长。为了限制状态的大小，运算符通常情况下会保存一些之前所观察到的事件流的总结或者概要。这个总结可能是一个计数值，一个累加和，或者事件流的采样，窗口的缓存操作，或者是一个自定义的数据结构，这个数据结构用来保存数据流中感兴趣的一些特性。</p>
<p>我们可以想象的到，支持有状态的运算符可能会碰到一些实现上的挑战：</p>
<p><em>状态管理</em></p>
<p>系统需要高效的管理状态，并保证针对状态的并发更新，不会产生竞争条件（race condition）。</p>
<p><em>状态分区</em></p>
<p>并行会带来复杂性。因为计算结果同时取决于已经保存的状态和输入的事件流。幸运的是，大多数情况下，我们可以使用Key来对状态进行分区，然后独立的管理每一个分区。例如，当我们处理一组传感器的测量事件流时，我们可以使用分区的运算符状态来针对不同的传感器独立的保存状态。</p>
<p><em>状态恢复</em></p>
<p>第三个挑战是有状态的运算符如何保证状态可以恢复，即使出现任务失败的情况，计算也是正确的。</p>
<p>下一节，我们将讨论任务失败和计算结果的保证。</p>
<h3 id="任务失败"><a href="#任务失败" class="headerlink" title="任务失败"></a>任务失败</h3><p>流任务中的运算符状态是很宝贵的，也需要抵御任务失败带来的问题。如果在任务失败的情况下，状态丢失的话，在任务恢复以后计算的结果将是不正确的。流任务会连续不断的运行很长时间，而状态可能已经收集了几天甚至几个月。在失败的情况下，重新处理所有的输入并重新生成一个丢失的状态，将会很浪费时间，开销也很大。</p>
<p>在本章开始时，我们看到如何将流的编程建模成数据流模型。在执行之前，流程序将会被翻译成物理层数据流图，物理层数据流图由连接的并行任务组成，而一个并行任务运行一些运算符逻辑，消费输入流数据，并为其他任务产生输出流数据。真实场景下，可能有数百个这样的任务并行运行在很多的物理机器上。在长时间的运行中，流任务中的任意一个任务在任意时间点都有可能失败。我们如何保证任务的失败能被正确的处理，以使任务能继续的运行下去呢？事实上，我们可能希望我们的流处理器不仅能在任务失败的情况下继续处理数据，还能保证计算结果的正确性以及运算符状态的安全。我们在本小节来讨论这些问题。</p>
<h4 id="什么是任务失败？"><a href="#什么是任务失败？" class="headerlink" title="什么是任务失败？"></a>什么是任务失败？</h4><p>对于流中的每一个事件，一个处理任务分为以下步骤：（1）接收事件，并将事件存储在本地的缓存中；（2）可能会更新内部状态；（3）产生输出记录。这些步骤都能失败，而系统必须对于在失败的场景下如何处理有清晰的定义。如果任务在第一步就失败了，事件会丢失吗？如果当更新内部状态的时候任务失败，那么内部状态会在任务恢复以后更新吗？在以上这些场景中，输出是确定性的吗？</p>
<p>在批处理场景下，所有的问题都不是问题。因为我们可以很方便的重新计算。所以不会有事件丢失，状态也可以得到完全恢复。在流的世界里，处理失败不是一个小问题。流系统在失败的情况下需要保证结果的准确性。接下来，我们需要看一下现代流处理系统所提供的一些保障，以及实现这些保障的机制。</p>
<h4 id="结果的保证"><a href="#结果的保证" class="headerlink" title="结果的保证"></a>结果的保证</h4><p>当我们讨论保证计算的结果时，我们的意思是流处理器的内部状态需要保证一致性。也就是说我们关心的是应用程序的代码在故障恢复以后看到的状态值是什么。要注意保证应用程序状态的一致性并不是保证应用程序的输出结果的一致性。一旦输出结果被持久化，结果的准确性就很难保证了。除非持久化系统支持事务。</p>
<p><em>AT-MOST-ONCE</em></p>
<p>当任务故障时，最简单的做法是什么都不干，既不恢复丢失的状态，也不重播丢失的事件。At-most-once语义的含义是最多处理一次事件。换句话说，事件可以被丢弃掉，也没有任何操作来保证结果的准确性。这种类型的保证也叫“没有保证”，因为一个丢弃掉所有事件的系统其实也提供了这样的保障。没有保障听起来是一个糟糕的主意，但如果我们能接受近似的结果，并且希望尽可能低的延迟，那么这样也挺好。</p>
<p><em>AT-LEAST-ONCE</em></p>
<p>在大多数的真实应用场景，我们希望不丢失事件。这种类型的保障成为at-least-once，意思是所有的事件都得到了处理，而且一些事件还可能被处理多次。如果结果的正确性仅仅依赖于数据的完整性，那么重复处理是可以接受的。例如，判断一个事件是否在流中出现过，at-least-once这样的保证完全可以正确的实现。在最坏的情况下，我们多次遇到了这个事件。而如果我们要对一个特定的事件进行计数，计算结果就可能是错误的了。</p>
<p>为了保证在at-least-once语义的保证下，计算结果也能正确。我们还需要另一套系统来从数据源或者缓存中重新播放数据。持久化的事件日志系统将会把所有的事件写入到持久化存储中。所以如果任务发生故障，这些数据可以重新播放。还有一种方法可以获得同等的效果，就是使用结果承认机制。这种方法将会把每一条数据都保存在缓存中，直到数据的处理等到所有的任务的承认。一旦得到所有任务的承认，数据将被丢弃。</p>
<p><em>EXACTLY-ONCE</em></p>
<p>恰好处理一次是最严格的保证，也是最难实现的。恰好处理一次语义不仅仅意味着没有事件丢失，还意味着针对每一个数据，内部状态仅仅更新一次。本质上，恰好处理一次语义意味着我们的应用程序可以提供准确的结果，就好像从未发生过故障。</p>
<p>提供恰好处理一次语义的保证必须有至少处理一次语义的保证才行，同时还需要数据重放机制。另外，流处理器还需要保证内部状态的一致性。也就是说，在故障恢复以后，流处理器应该知道一个事件有没有在状态中更新。事务更新是达到这个目标的一种方法，但可能引入很大的性能问题。Flink使用了一种轻量级快照机制来保证恰好处理一次语义。</p>
<p><em>端到端恰好处理一次</em></p>
<p>目前我们看到的一致性保证都是由流处理器实现的，也就是说都是在Flink流处理器内部保证的。而在真实世界中，流处理应用除了流处理器以外还包含了数据源（例如Kafka）和持久化系统。端到端的一致性保证意味着结果的正确性贯穿了整个流处理应用的始终。每一个组件都保证了它自己的一致性。而整个端到端的一致性级别取决于所有组件中一致性最弱的组件。要注意的是，我们可以通过弱一致性来实现更强的一致性语义。例如，当任务的操作具有幂等性时，比如流的最大值或者最小值的计算。在这种场景下，我们可以通过最少处理一次这样的一致性来实现恰好处理一次这样的最高级别的一致性。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>flink</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>flink系列01有状态的流式处理简介</title>
    <url>/2020/06/27/flink%E7%B3%BB%E5%88%9701%E6%9C%89%E7%8A%B6%E6%80%81%E7%9A%84%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h1 id="第一章，有状态的流式处理简介"><a href="#第一章，有状态的流式处理简介" class="headerlink" title="第一章，有状态的流式处理简介"></a>第一章，有状态的流式处理简介</h1><p>Apache Flink是一个分布式流处理器，具有直观和富有表现力的API，可实现有状态的流处理应用程序。它以容错的方式有效地大规模运行这些应用程序。 Flink于2014年4月加入Apache软件基金会作为孵化项目，并于2015年1月成为顶级项目。从一开始，Flink就拥有一个非常活跃且不断增长的用户和贡献者社区。到目前为止，已有超过五百人为Flink做出贡献，并且它已经发展成为最复杂的开源流处理引擎之一，并得到了广泛采用的证明。 Flink为不同行业和全球的许多公司和企业提供大规模的商业关键应用。</p>
<p>流处理技术在大大小小的公司中越来越受欢迎，因为它为许多已建立的用例（如数据分析，ETL和事务应用程序）提供了卓越的解决方案，同时也促进了新颖的应用程序，软件架构和商机。接下来我们将讨论，为什么有状态流处理变得如此受欢迎并评估其潜力。我们首先回顾传统的数据应用程序架构并指出它们的局限性。接下来，我们介绍基于状态流处理的应用程序设计 与传统方法相比，它具有许多有趣的特征最后，我们简要讨论开源流处理器的发展，并在本地Flink实例上运行流应用程序。</p>
<h2 id="传统数据处理架构"><a href="#传统数据处理架构" class="headerlink" title="传统数据处理架构"></a>传统数据处理架构</h2><p>数十年来，数据和数据处理在企业中无处不在。多年来，数据的收集和使用一直在增长，公司已经设计并构建了基础架构来管理数据。大多数企业实施的传统架构区分了两种类型的数据处理：事务处理（OLTP）和分析处理（OLAP）。</p>
<h3 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h3><p>公司将各种应用程序用于日常业务活动，例如企业资源规划（ERP）系统，客户关系管理（CRM）软件和基于Web的应用程序。这些系统通常设计有单独的层，用于数据处理（应用程序本身）和数据存储（事务数据库系统），如图1-1所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0101.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0101.png" class="lazyload"></a></p>
<p>应用程序通常连接到外部服务或直接面向用户，并持续处理传入的事件，如网站上的订单，电子邮件或点击。处理事件时，应用程序将会读取远程数据库的状态，或者通过运行事务来更新它。通常，一个数据库系统可以服务于多个应用程序，它们有时会访问相同的数据库或表。</p>
<p>当应用程序需要扩展时，这样的设计可能会导致问题。由于多个应用程序可能会同时用到相同的数据表示，或者共享相同的基础设施，因此想要更改表的结构或扩展数据库，就需要仔细的规划和大量的工作。克服紧耦合应用程序的最新方法是微服务设计模式。微服务被设计为小型、完备且独立的应用程序。他们遵循UNIX的理念，即“只做一件事并且把它做好”。通过将几个微服务相互连接来构建更复杂的应用程序，这些微服务仅通过标准化接口（例如RESTful HTTP连接）进行通信。由于微服务严格地彼此分离并且仅通过明确定义的接口进行通信，因此每个微服务都可以用不同技术栈来实现，包括编程语言、类库和数据存储。微服务和所有必需的软件和服务通常捆绑在一起并部署在独立的容器中。图1-2描绘了一种微服务架构。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0102.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0102.png" class="lazyload"></a></p>
<h3 id="分析处理"><a href="#分析处理" class="headerlink" title="分析处理"></a>分析处理</h3><p>大量数据存储在公司的各种事务数据库系统中，它们可以为公司业务运营提供宝贵的参考意见。例如，分析订单处理系统的数据，可以获得销量随时间的增长曲线；可以识别延迟发货的原因；还可以预测未来的销量以便提前调整库存。但是，事务数据通常分布在多个数据库中，它们往往汇总起来联合分析时更有价值。而且，数据通常需要转换为通用格式。</p>
<p>所以我们一般不会直接在事务数据库上运行分析查询，而是复制数据到数据仓库。数据仓库是对工作负载进行分析和查询的专用数据存储。为了填充数据仓库，需要将事务数据库系统管理的数据复制过来。将数据复制到数据仓库的过程称为extract-transform-load（ETL）。 ETL过程从事务数据库中提取数据，将其转换为某种通用的结构表示，可能包括验证，值的规范化，编码，重复数据删除（去重）和模式转换，最后将其加载到分析数据库中。 ETL过程可能非常复杂，并且通常需要技术复杂的解决方案来满足性能要求。 ETL过程需要定期运行以保持数据仓库中的数据同步。</p>
<p>将数据导入数据仓库后，可以查询和分析数据。通常，在数据仓库上执行两类查询。第一种类型是定期报告查询，用于计算与业务相关的统计信息，比如收入、用户增长或者输出的产量。这些指标汇总到报告中，帮助管理层评估业务的整体健康状况。第二种类型是即席查询，旨在提供特定问题的答案并支持关键业务决策，例如收集统计在投放商业广告上的花费，和获取的相应收入，以评估营销活动的有效性。两种查询由批处理方式由数据仓库执行，如图1-3所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0103.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0103.png" class="lazyload"></a></p>
<p>如今，Apache Hadoop生态系统的组件，已经是许多企业IT基础架构中不可或缺的组成部分。现在的做法不是直接将所有数据都插入关系数据库系统，而是将大量数据（如日志文件，社交媒体或Web点击日志）写入Hadoop的分布式文件系统（HDFS）、S3或其他批量数据存储库，如Apache HBase，以较低的成本提供大容量存储容量。驻留在此类存储系统中的数据可以通过SQL-on-Hadoop引擎查询和处理，例如Apache Hive，Apache Drill或Apache Impala。但是，基础结构与传统数据仓库架构基本相同。</p>
<h2 id="有状态的流式处理"><a href="#有状态的流式处理" class="headerlink" title="有状态的流式处理"></a>有状态的流式处理</h2><p>日常生活中，所有数据都是作为连续的事件流创建的。比如网站或者移动应用中的用户交互动作，订单的提交，服务器日志或传感器测量数据：所有这些都是事件流。实际上，很少有应用场景，能一次性地生成所需要的完整（有限）数据集。实际应用中更多的是无限事件流。有状态的流处理就是用于处理这种无限事件流的应用程序设计模式，在公司的IT基础设施中有广泛的应用场景。在我们讨论其用例之前，我们将简要介绍有状态流处理的工作原理。</p>
<p>如果我们想要无限处理事件流，并且不愿意繁琐地每收到一个事件就记录一次，那这样的应用程序就需要是有状态的，也就是说能够存储和访问中间数据。当应用程序收到一个新事件时，它可以从状态中读取数据，或者向该状态写入数据，总之可以执行任何计算。原则上讲，我们可以在各种不同的地方存储和访问状态，包括程序变量（内存）、本地文件，还有嵌入式或外部数据库。</p>
<p>Apache Flink将应用程序状态，存储在内存或者嵌入式数据库中。由于Flink是一个分布式系统，因此需要保护本地状态以防止在应用程序或计算机故障时数据丢失。 Flink通过定期将应用程序状态的一致性检查点（check point）写入远程且持久的存储，来保证这一点。状态、状态一致性和Flink的检查点将在后面的章节中更详细地讨论，但是，现在，图1-4显示了有状态的流式Flink应用程序。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0104.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0104.png" class="lazyload"></a></p>
<p>有状态的流处理应用程序，通常从事件日志中提取输入事件。事件日志就用来存储和分发事件流。事件被写入持久的仅添加（append-only）日志，这意味着无法更改写入事件的顺序。写入事件日志的流，可以被相同或不同的消费者多次读取。由于日志的仅附加（append-only）属性，事件始终以完全相同的顺序发布给所有消费者。现在已有几种事件日志系统，其中Apache Kafka是最受欢迎的，可以作为开源软件使用，或者是云计算提供商提供的集成服务。</p>
<p>在Flink上运行的有状态的流处理应用程序，是很有意思的一件事。在这个架构中，事件日志会按顺序保留输入事件，并且可以按确定的顺序重播它们。如果发生故障，Flink将从先前的检查点（check point）恢复其状态，并重置事件日志上的读取位置，这样就可以恢复整个应用。应用程序将重放（并快进）事件日志中的输入事件，直到它到达流的尾部。此技术一般用于从故障中恢复，但也可用于更新应用程序、修复bug或者修复以前发出的结果，另外还可以用于将应用程序迁移到其他群集，或使用不同的应用程序版本执行A / B测试。</p>
<p>如前所述，有状态的流处理是一种通用且灵活的设计架构，可用于许多不同的场景。在下文中，我们提出了三类通常使用有状态流处理实现的应用程序：（1）事件驱动应用程序，（2）数据管道应用程序，以及（3）数据分析应用程序。</p>
<p>我们将应用程序分类描述，是为了强调有状态流处理适用于多种业务场景；而实际的应用中，往往会具有以上多种情况的特征。</p>
<h3 id="事件驱动应用程序（Event-Driven-Applications）"><a href="#事件驱动应用程序（Event-Driven-Applications）" class="headerlink" title="事件驱动应用程序（Event-Driven Applications）"></a>事件驱动应用程序（Event-Driven Applications）</h3><p>事件驱动的应用程序是有状态的流应用程序，它们使用特定的业务逻辑来提取事件流并处理事件。根据业务逻辑，事件驱动的应用程序可以触发诸如发送警报、或电子邮件之类的操作，或者将事件写入向外发送的事件流以供另一个应用程序使用。</p>
<p>事件驱动应用程序的典型场景包括：</p>
<ul>
<li>实时推荐（例如，在客户浏览零售商网站时推荐产品）</li>
<li>行为模式检测或复杂事件处理（例如，用于信用卡交易中的欺诈检测）</li>
<li>异常检测（例如，检测侵入计算机网络的尝试</li>
</ul>
<p>事件驱动应用程序是微服务的演变。它们通过事件日志而不是REST调用进行通信，并将应用程序数据保存为本地状态，而不是将其写入外部数据存储区（例如关系数据库或键值数据库）。图1-5显示了由事件驱动的流应用程序组成的服务架构。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0105.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0105.png" class="lazyload"></a></p>
<p>图1-5中的应用程序通过事件日志连接。一个应用程序将其输出发送到事件日志通道（kafka），另一个应用程序使用其他应用程序发出的事件。事件日志通道将发送者和接收者分离，并提供异步、非阻塞的事件传输。每个应用程序都可以是有状态的，并且可以本地管理自己的状态而无需访问外部数据存储。应用程序也可以单独处理和扩展。</p>
<p>与事务性应用程序或微服务相比，事件驱动的应用程序具有多种优势。与读写远程数据库相比，本地状态访问提供了非常好的性能。扩展性和容错性都由流处理器来保证，并且以事件日志作为输入源，应用程序的整个输入数据可以可靠地存储，并且可以确定性地重放。此外，Flink可以将应用程序的状态重置为先前的保存点（save point），从而可以在不丢失状态的情况下更新或重新扩展应用程序。</p>
<p>事件驱动的应用程序对运行它们的流处理器有很高的要求，并不是所有流处理器都适合运行事件驱动的应用程序。 API的表现力，以及对状态处理和事件时间支持的程度，决定了可以实现和执行的业务逻辑。这方面取决于流处理器的API，主要看它能提供什么样的状态类型，以及它对事件时间处理的支持程度。此外，精确一次（exactly-once）的状态一致性和扩展应用程序的能力是事件驱动应用程序的基本要求。 Apache Flink符合所有的这些要求，是运行此类应用程序的一个非常好的选择。</p>
<h3 id="数据管道（Data-Pipelines）"><a href="#数据管道（Data-Pipelines）" class="headerlink" title="数据管道（Data Pipelines）"></a>数据管道（Data Pipelines）</h3><p>当今的IT架构包括许多不同的数据存储，例如关系型数据库和专用数据库系统、事件日志、分布式文件系统，内存中的缓存和搜索索引。所有这些系统都以不同的格式和数据结构存储数据，为其特定的访问模式提供最佳性能。公司通常将相同的数据存储在多个不同的系统中，以提高数据访问的性能。例如，网上商店中提供的产品的信息，可以存储在交易数据库中，同时也存储在缓存（如redis）和搜索索引（如ES）中。由于数据的这种复制，数据存储必须保持同步。</p>
<p>在不同存储系统中同步数据的传统方法是定期ETL作业。但是，它们不能满足当今许多场景的延迟要求。另一种方法是使用事件日志（event log）来发布更新。更新将写入事件日志并由事件日志分发。日志的消费者获取到更新之后，将更新合并到受影响的数据存储中。根据使用情况，传输的数据可能需要标准化、使用外部数据进行扩展，或者在目标数据存储提取之前进行聚合。</p>
<p>以较低的延迟，来提取、转换和插入数据是有状态流处理应用程序的另一个常见应用场景。这种类型的应用程序称为数据管道（data pipeline）。数据管道必须能够在短时间内处理大量数据。操作数据管道的流处理器还应具有许多源（source）和接收器（sink）的连接器，以便从各种存储系统读取数据并将数据写入各种存储系统。当然，同样地，Flink完成了所有这些功能。</p>
<h3 id="流分析"><a href="#流分析" class="headerlink" title="流分析"></a>流分析</h3><p>ETL作业定期将数据导入数据存储区，数据的处理是由即席查询（用户自定义查询）或设定好的通常查询来做的。无论架构是基于数据仓库还是基于Hadoop生态系统的组件，这都是批处理。多年来最好的处理方式就是，定期将数据加载到数据分析系统中，但它给分析管道带了的延迟相当大，而且无法避免。</p>
<p>根据设定好的时间间隔，可能需要数小时或数天才能将数据点包含在报告中。我们前面已经提到，数据管道可以实现低延迟的ETL，所以在某种程度上，可以通过使用数据管道将数据导入存储区来减少延迟。但是，即使持续不停地进行ETL操作，在用查询来处理事件之前总会有延迟。虽然这种延迟在过去可能是可以接受的，但是今天的应用程序，往往要求必须能够实时收集数据，并立即对其进行操作（例如，在手机游戏中去适应不断变化的条件，或者在电商网站中提供个性化的用户体验）。</p>
<p>流式分析应用程序不是等待定期触发，而是连续地提取事件流，并且通过纳入最新事件来更新其计算结果，这个过程是低延迟的。这有些类似于数据库中用于更新视图（views）的技术。通常，流应用程序将其结果存储在支持更新的外部数据存储中，例如数据库或键值（key-value）存储。流分析应用程序的实时更新结果可用于驱动监控仪表板（dashboard）应用程序，如图1-6所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0106.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0106.png" class="lazyload"></a></p>
<p>流分析应用程序最大的优势就是，将每个事件纳入到分析结果所需的时间短得多。除此之外，流分析应用程序还有另一个不太明显的优势。传统的分析管道由几个独立的组件组成，例如ETL过程、存储系统、对于基于Hadoop的环境，还包括用于触发任务（jobs）的数据处理和调度程序。相比之下，如果我们运行一个有状态流应用程序，那么流处理器就会负责所有这些处理步骤，包括事件提取、带有状态维护的连续计算以及更新结果。此外，流处理器可以从故障中恢复，并且具有精确一次（exactly-once）的状态一致性保证，还可以调整应用程序的计算资源。像Flink这样的流处理器还支持事件时间（event-time）处理，这可以保证产生正确和确定的结果，并且能够在很短的时间内处理大量数据。</p>
<p>流分析应用程序通常用于：</p>
<ul>
<li>监控手机网络的质量分析</li>
<li>移动应用中的用户行为</li>
<li>实时数据的即席分析</li>
</ul>
<p>虽然我们不在此处介绍，但Flink还提供对流上的分析SQL查询的支持。</p>
<h2 id="开源流处理的演进"><a href="#开源流处理的演进" class="headerlink" title="开源流处理的演进"></a>开源流处理的演进</h2><p>数据流处理并不是一项新技术。一些最初的研究原型和商业产品可以追溯到20世纪90年代（1990s）。然而，在很大程度上，过去采用的流处理技术是由成熟的开源流处理器驱动的。如今，分布式开源流处理器在不同行业的许多企业中，处理着核心业务应用，比如电商、社交媒体、电信、游戏和银行等。开源软件是这一趋势的主要驱动力，主要原因有两个：</p>
<ul>
<li>开源流处理软件是大家每一个人都可以评估和使用的产品。</li>
<li>由于许多开源社区的努力，可扩展流处理技术正在迅速成熟和发展</li>
</ul>
<p>仅仅一个Apache软件基金会就支持了十几个与流处理相关的项目。新的分布式流处理项目不断进入开源阶段，并不断增加新的特性和功能。开源社区不断改进其项目的功能，并正在推动流处理的技术边界。我们将简要介绍一下过去，看看开源流处理的起源和今天的状态。</p>
<h3 id="流处理的历史"><a href="#流处理的历史" class="headerlink" title="流处理的历史"></a>流处理的历史</h3><p>第一代分布式开源流处理器（2011）专注于具有毫秒延迟的事件处理，并提供了在发生故障时防止事件丢失的保证。这些系统具有相当低级的API，并且对于流应用程序的准确性和结果的一致性，不提供内置支持，因为结果会取决于到达事件的时间和顺序。另外，即使事件没有丢失，也可能不止一次地处理它们。与批处理器相比，第一代开源流处理器牺牲了结果准确性，用来获得更低的延迟。为了让当时的数据处理系统，可以同时提供快速和准确的结果，人们设计了所谓的lambda架构，如图1-7所示。</p>
<p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0107.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0107.png" class="lazyload"></a></p>
<p>lambda架构增强了传统的批处理架构，其“快速层”（speed layer）由低延迟的流处理器来支持。数据到达之后由流处理器提取出来，并写入批处理存储。流处理器近乎实时地计算近似结果并将它们写入“快速表”（speed table）。批处理器定期处理批量存储中的数据，将准确的结果写入批处理表，并从速度表中删除相应的不准确结果。应用程序会合并快速表中的近似结果和批处理表中的准确结果，然后消费最终的结果。</p>
<p>lambda架构现在已经不再是最先进的，但仍在许多地方使用。该体系结构的最初目标是改善原始批处理分析体系结构的高延迟。但是，它有一些明显的缺点。首先，它需要对一个应用程序，做出两个语义上等效的逻辑实现，用于两个独立的、具有不同API的处理系统。其次，流处理器计算的结果只是近似的。第三，lambda架构很难建立和维护。</p>
<p>通过在第一代基础上进行改进，下一代分布式开源流处理器（2013）提供了更好的故障保证，并确保在发生故障时，每个输入记录仅对结果产生一次影响（exactly -once）。此外，编程API从相当低级的操作符接口演变为高级API。但是，一些改进（例如更高的吞吐量和更好的故障保证）是以将处理延迟从毫秒增加到几秒为代价的。此外，结果仍然取决于到达事件的时间和顺序。</p>
<p>第三代分布式开源流处理器（2015）解决了结果对到达事件的时间和顺序的依赖性。结合精确一次（exactly-once）的故障语义，这一代系统是第一个具有计算一致性和准确结果的开源流处理器。通过基于实际数据来计算结果（“重演”数据），这些系统还能够以与“实时”数据相同的方式处理历史数据。另一个改进是解决了延迟/吞吐量无法同时保证的问题。先前的流处理器仅能提供高吞吐量或者低延迟（其中之一），而第三代系统能够同时提供这两个特性。这一代的流处理器使得lambda架构过时了。当然，这一代流处理以flink为代表。</p>
<p>除了目前讨论的特性，例如容错、性能和结果准确性之外，流处理器还不断添加新的操作功能，例如高可用性设置，与资源管理器（如YARN或Kubernetes）的紧密集成，以及能够动态扩展流应用程序。其他功能包括：支持升级应用程序代码，或将作业迁移到其他群集或新版本的流处理器，而不会丢失当前状态。</p>
<h2 id="Flink-简介"><a href="#Flink-简介" class="headerlink" title="Flink 简介"></a>Flink 简介</h2><p>Apache Flink是第三代分布式流处理器，它拥有极富竞争力的功能。它提供准确的大规模流处理，具有高吞吐量和低延迟。特别的是，以下功能使Flink脱颖而出：</p>
<ul>
<li>事件时间（event-time）和处理时间（processing-tme）语义。即使对于无序事件流，事件时间（event-time）语义仍然能提供一致且准确的结果。而处理时间（processing-time）语义可用于具有极低延迟要求的应用程序。</li>
<li>精确一次（exactly-once）的状态一致性保证。</li>
<li>每秒处理数百万个事件，毫秒级延迟。 Flink应用程序可以扩展为在数千个核（cores）上运行。</li>
<li>分层API，具有不同的权衡表现力和易用性。本书介绍了DataStream API和过程函数（process function），为常见的流处理操作提供原语，如窗口和异步操作，以及精确控制状态和时间的接口。本书不讨论Flink的关系API，SQL和LINQ风格的Table API。</li>
<li>连接到最常用的存储系统，如Apache Kafka，Apache Cassandra，Elasticsearch，JDBC，Kinesis和（分布式）文件系统，如HDFS和S3。</li>
<li>由于其高可用的设置（无单点故障），以及与Kubernetes，YARN和Apache Mesos的紧密集成，再加上从故障中快速恢复和动态扩展任务的能力，Flink能够以极少的停机时间7*24全天候运行流应用程序。</li>
<li>能够更新应用程序代码并将作业（jobs）迁移到不同的Flink集群，而不会丢失应用程序的状态。</li>
<li>详细且可自定义的系统和应用程序指标集合，以提前识别问题并对其做出反应。</li>
<li>最后但同样重要的是，Flink也是一个成熟的批处理器。</li>
</ul>
<p>除了这些功能之外，Flink还是一个非常易于开发的框架，因为它易于使用的API。嵌入式执行模式，可以在单个JVM进程中启动应用程序和整个Flink系统，这种模式一般用于在IDE中运行和调试Flink作业。在开发和测试Flink应用程序时，此功能非常有用。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>flink</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql的binlog</title>
    <url>/2020/06/23/mysql%E7%9A%84binlog/</url>
    <content><![CDATA[<h1 id="什么是Binlog"><a href="#什么是Binlog" class="headerlink" title="什么是Binlog"></a>什么是Binlog</h1><p>MySQL的二进制日志可以说是MySQL最重要的日志了，它记录了所有的DDL和DML(除了数据查询语句)语句，以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</p>
<p>  一般来说开启二进制日志大概会有1%的性能损耗 。二进制有两个最重要的使用场景: </p>
<p>  <strong>其一：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到master-slave数据一致的目的。</strong></p>
<p>  <strong>其二：自然就是数据恢复了，通过使用MySQLBinlog工具来使恢复数据。</strong></p>
<p>二进制日志包括两类文件：二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件，二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句)语句事件。</p>
<h1 id="Binlog的开启"><a href="#Binlog的开启" class="headerlink" title="Binlog的开启"></a>Binlog的开启</h1><p>在MySQL的配置文件(Linux: <code>/etc/my.cnf</code> ,  Windows:<code>\my.ini</code>)下,修改配置在[mysqld] 区块设置/添加</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log-bin&#x3D;mysql-bin</span><br></pre></td></tr></table></figure></div>

<p>这个表示binlog日志的前缀是mysql-bin，以后生成的日志文件就是 mysql-bin.123456 的文件后面的数字按顺序生成。每次mysql重启或者到达单个文件大小的阈值时，新生一个文件，按顺序编号。</p>
<h1 id="Binlog的分类设置"><a href="#Binlog的分类设置" class="headerlink" title="Binlog的分类设置"></a>Binlog的分类设置</h1><p>MySQL Binlog的格式，那就是有三种，分别是STATEMENT,MIXED,ROW。</p>
<p>在配置文件中选择配置</p>
<blockquote>
<p>canal无执行引擎，一般row</p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">binlog_format&#x3D;row</span><br></pre></td></tr></table></figure></div>

<p>区别：</p>
<ul>
<li><p>statement</p>
<p><strong>语句级，binlog会记录每次一执行写操作的语句。</strong></p>
<p>相对row模式节省空间，但是可能产生不一致性，比如1</p>
</li>
</ul>
<p>update  tt set create_date=<code>now()</code></p>
<p>  如果用binlog日志进行恢复，由于执行时间不同可能产生的数据就不同。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">优点：节省空间</span><br><span class="line">缺点：有可能造成数据不一致。</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>row</p>
<p><strong>行级，binlog会记录每次操作后每行记录的变化。</strong></p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">优点：保持数据的绝对一致性。因为不管sql是什么，引用了什么函数，他只记录执行后的效果。</span><br><span class="line">缺点：占用较大空间。</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>mixed</p>
<p>statement的升级版，一定程度上解决了，因为一些情况而造成的statement模式不一致问题</p>
<p>在某些情况下譬如：</p>
<p>当函数中包含 UUID() 时；</p>
<p>包含 AUTO_INCREMENT 字段的表被更新时；</p>
<p>执行 INSERT DELAYED 语句时；</p>
<p>用 UDF 时；</p>
<p>会按照 ROW的方式进行处理</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">优点：节省空间，同时兼顾了一定的一致性。</span><br><span class="line">缺点：还有些极个别情况依旧会造成不一致，</span><br></pre></td></tr></table></figure></div>

<p>另外statement和mixed对于需要对binlog的监控的情况都不方便。</p>
]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka事务</title>
    <url>/2020/06/18/kafka%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<h1 id="kafka事务"><a href="#kafka事务" class="headerlink" title="kafka事务"></a>kafka事务</h1><p>Kafka从【0.11】版本开始引入了事务支持。</p>
<p>事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<h2 id="Producer事务"><a href="#Producer事务" class="headerlink" title="Producer事务"></a>Producer事务</h2><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。</p>
<p>为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。</p>
<p>Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h2 id="Consumer事务"><a href="#Consumer事务" class="headerlink" title="Consumer事务"></a>Consumer事务</h2><p>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。</p>
<p>这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka_exactly_once语义</title>
    <url>/2020/06/18/kafka-exactly-once%E8%AF%AD%E4%B9%89/</url>
    <content><![CDATA[<h1 id="Exactly-Once语义"><a href="#Exactly-Once语义" class="headerlink" title="Exactly Once语义"></a>Exactly Once语义</h1><blockquote>
<p>kafka 每个分区内的 Exactly Once</p>
</blockquote>
<p>将服务器的ACK级别设置为<code>-1</code>，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。</p>
<p>相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p>
<p>At Least Once可以保证数据不丢失，但是不能保证数据不重复；</p>
<p>相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。</p>
<p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p>
<blockquote>
<p>【0.11】版本的Kafka，引入了一项重大特性：幂等性。</p>
</blockquote>
<p>开启幂等性<code>enable.idempotence=true</code>。</p>
<p>所谓的<strong>幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条</strong>。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：</p>
<blockquote>
<p>At Least Once + 幂等性 = Exactly Once</p>
</blockquote>
<p>要启用幂等性，只需要将Producer的参数中<code>enable.idompotence</code>设置为<code>true</code>即可。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。</span><br><span class="line">开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。</span><br><span class="line">而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</span><br></pre></td></tr></table></figure></div>

<p>但是<strong>PID重启就会变化</strong>，同时不同的Partition也具有不同主键，</p>
<p>所以幂等性无法保证<strong>跨分区跨会话</strong>的Exactly Once。</p>
<blockquote>
<p>保证 kafka 数据无重复</p>
<p>​    1、幂等性+<code>ack=-1</code>+事务</p>
<p>​    2、可以在下一级：SparkStreaming、redis 或者 hive 中 dwd 层去重，</p>
<p>​          去重的手段：分组、按照id开窗只取第一个值；</p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL练习题</title>
    <url>/2020/06/18/MySQL%E7%BB%83%E4%B9%A0%E9%A2%98/</url>
    <content><![CDATA[<h1 id="MySQL练习题"><a href="#MySQL练习题" class="headerlink" title="MySQL练习题"></a>MySQL练习题</h1><h2 id="1-组合两个表"><a href="#1-组合两个表" class="headerlink" title="1. 组合两个表"></a>1. 组合两个表</h2><p>需求：编写一个 SQL 查询，对两表进行关联，展示列为：<br>FirstName, LastName, City, State</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>FirstName</th>
<th>LastName</th>
<th>City</th>
<th>State</th>
</tr>
</thead>
<tbody><tr>
<td>Allen</td>
<td>Wang</td>
<td>New York City</td>
<td>New York</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table Person (PersonId int, FirstName varchar(255), LastName varchar(255));</span><br><span class="line"></span><br><span class="line">Create table Address (AddressId int, PersonId int, City varchar(255), State varchar(255));</span><br><span class="line"></span><br><span class="line">insert into Person (PersonId, LastName, FirstName) values (1, &#39;Wang&#39;, &#39;Allen&#39;);</span><br><span class="line">insert into Address (AddressId, PersonId, City, State) values (1, 1, &#39;New York City&#39;, &#39;New York&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">     p.FirstName,</span><br><span class="line">     p.LastName,</span><br><span class="line">     a.City,</span><br><span class="line">     a.State</span><br><span class="line">from </span><br><span class="line">     Person as p </span><br><span class="line">left join </span><br><span class="line">     Address as a </span><br><span class="line">on </span><br><span class="line">     p.PersonId &#x3D; a.PersonId;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-第二高的薪水"><a href="#2-第二高的薪水" class="headerlink" title="2. 第二高的薪水"></a>2. 第二高的薪水</h2><p><strong>需求二</strong>：编写一个 SQL 查询，获取 Employee 表中第二高的薪水（Salary）。如果不存在第二高的薪水，那么查询应返回 null。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>SecondHighestSalary</th>
</tr>
</thead>
<tbody><tr>
<td>200</td>
</tr>
</tbody></table>
<p>建表语句：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (Id int, Salary int);</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Salary) values (1, 100);</span><br><span class="line">insert into Employee (Id, Salary) values (2, 200);</span><br><span class="line">insert into Employee (Id, Salary) values (3, 300);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">方法一：</span><br><span class="line">select (</span><br><span class="line">	     select </span><br><span class="line">               DISTINCT Salary</span><br><span class="line">	     from  </span><br><span class="line">               Employee</span><br><span class="line">	     order by</span><br><span class="line">               Salary DESC</span><br><span class="line">	     limit 1,1</span><br><span class="line">      )  as SecondHighestSalary;</span><br><span class="line">方法二：</span><br><span class="line">select </span><br><span class="line">       max(Salary) as SecondHighestSalary </span><br><span class="line">from </span><br><span class="line">       Employee</span><br><span class="line">where </span><br><span class="line">       Salary &lt; (select</span><br><span class="line">                       max(Salary) </span><br><span class="line">                 from </span><br><span class="line">                       Employee</span><br><span class="line">                );</span><br></pre></td></tr></table></figure></div>

<p>提示：LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。</p>
<p><strong>需求二</strong>：编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">方法一：</span><br><span class="line">CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT</span><br><span class="line">BEGIN</span><br><span class="line">  SET n &#x3D; N-1;</span><br><span class="line">  RETURN (     </span><br><span class="line">  SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT n,1</span><br><span class="line">  );</span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">select getNthHighestSalary(2) ;</span><br><span class="line"></span><br><span class="line">方案二：</span><br><span class="line">CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT</span><br><span class="line">BEGIN</span><br><span class="line">  RETURN (     </span><br><span class="line">  SELECT  IF(count&lt;N,NULL,min) </span><br><span class="line">  FROM</span><br><span class="line">    (SELECT MIN(Salary) AS min, COUNT(1) AS count</span><br><span class="line">    FROM</span><br><span class="line">      (SELECT DISTINCT Salary</span><br><span class="line">      FROM Employee ORDER BY Salary DESC LIMIT N) AS a</span><br><span class="line">    ) as b</span><br><span class="line">  );</span><br><span class="line">END</span><br></pre></td></tr></table></figure></div>

<h2 id="3-分数排名"><a href="#3-分数排名" class="headerlink" title="3. 分数排名"></a>3. 分数排名</h2><p>需求：编写一个 SQL 查询来实现分数排名。如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Score</th>
<th>Rank</th>
</tr>
</thead>
<tbody><tr>
<td>4.00</td>
<td>1</td>
</tr>
<tr>
<td>4.00</td>
<td>1</td>
</tr>
<tr>
<td>3.85</td>
<td>2</td>
</tr>
<tr>
<td>3.65</td>
<td>3</td>
</tr>
<tr>
<td>3.65</td>
<td>3</td>
</tr>
<tr>
<td>3.50</td>
<td>4</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Scores (Id int, Score DECIMAL(3,2));</span><br><span class="line"></span><br><span class="line">insert into Scores (Id, Score) values (1, 3.5);</span><br><span class="line">insert into Scores (Id, Score) values (2, 3.65);</span><br><span class="line">insert into Scores (Id, Score) values (3, 4.0);</span><br><span class="line">insert into Scores (Id, Score) values (4, 3.85);</span><br><span class="line">insert into Scores (Id, Score) values (5, 4.0);</span><br><span class="line">insert into Scores (Id, Score) values (6, 3.65);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      a.Score as score , </span><br><span class="line">      (select </span><br><span class="line">              count(distinct b.Score) </span><br><span class="line">       from </span><br><span class="line">              Scores b </span><br><span class="line">       where </span><br><span class="line">              b.Score &gt;&#x3D;a.Score) as rank</span><br><span class="line">from </span><br><span class="line">     Scores a </span><br><span class="line">order by </span><br><span class="line">     Score DESC;</span><br></pre></td></tr></table></figure></div>

<h2 id="4-连续出现的数字"><a href="#4-连续出现的数字" class="headerlink" title="4. 连续出现的数字"></a>4. 连续出现的数字</h2><p>需求：编写一个 SQL 查询，查找所有至少连续出现三次的数字。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>ConsecutiveNums</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Logs (Id int, Num int);</span><br><span class="line"></span><br><span class="line">insert into Logs (Id, Num) values (1, 1);</span><br><span class="line">insert into Logs (Id, Num) values (2, 1);</span><br><span class="line">insert into Logs (Id, Num) values (3, 1);</span><br><span class="line">insert into Logs (Id, Num) values (4, 2);</span><br><span class="line">insert into Logs (Id, Num) values (5, 1);</span><br><span class="line">insert into Logs (Id, Num) values (6, 2);</span><br><span class="line">insert into Logs (Id, Num) values (7, 2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM</span><br><span class="line">    Logs l1,</span><br><span class="line">    Logs l2,</span><br><span class="line">    Logs l3</span><br><span class="line">WHERE</span><br><span class="line">    l1.Id &#x3D; l2.Id - 1 AND l1.Num &#x3D; l2.Num</span><br><span class="line">    AND l2.Id &#x3D; l3.Id - 1 AND l2.Num &#x3D; l3.Num;</span><br></pre></td></tr></table></figure></div>

<h2 id="5-超过经理收入的员工"><a href="#5-超过经理收入的员工" class="headerlink" title="5. 超过经理收入的员工"></a>5. 超过经理收入的员工</h2><p>需求：Employee 表包含所有员工，他们的经理也属于员工。每个员工都有一个 Id，此外还有一列对应员工的经理的 Id。</p>
<p>数据样式：</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Salary</th>
<th>ManagerId</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Joe</td>
<td>70000</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>Henry</td>
<td>80000</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>Sam</td>
<td>60000</td>
<td>null</td>
</tr>
<tr>
<td>4</td>
<td>Max</td>
<td>90000</td>
<td>null</td>
</tr>
</tbody></table>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Employee</th>
</tr>
</thead>
<tbody><tr>
<td>Joe</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table If Not Exists Employee (Id int, Name varchar(255), Salary int, ManagerId int);</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Name, Salary, ManagerId) values (1, &#39;Joe&#39;, 70000, 3);</span><br><span class="line">insert into Employee (Id, Name, Salary, ManagerId) values (2, &#39;Henry&#39;, 80000, 4);</span><br><span class="line">insert into Employee (Id, Name, Salary, ManagerId) values (3, &#39;Sam&#39;, 60000, null);</span><br><span class="line">insert into Employee (Id, Name, Salary, ManagerId) values (4, &#39;Max&#39;, 90000, null);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">     a.NAME AS Employee</span><br><span class="line">FROM </span><br><span class="line">     Employee AS a </span><br><span class="line">JOIN </span><br><span class="line">     Employee AS b</span><br><span class="line">ON </span><br><span class="line">     a.ManagerId &#x3D; b.Id </span><br><span class="line">AND </span><br><span class="line">     a.Salary &gt; b.Salary;</span><br></pre></td></tr></table></figure></div>

<h2 id="6-查找重复的邮箱"><a href="#6-查找重复的邮箱" class="headerlink" title="6. 查找重复的邮箱"></a>6. 查找重复的邮箱</h2><p>需求：编写一个 SQL 查询，查找 Person 表中所有重复的电子邮箱。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Email</th>
</tr>
</thead>
<tbody><tr>
<td><a href="mailto:a@b.com">a@b.com</a></td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Person (Id int, Email varchar(255))</span><br><span class="line"></span><br><span class="line">insert into Person (Id, Email) values (1, &#39;a@b.com&#39;)</span><br><span class="line">insert into Person (Id, Email) values (2, &#39;c@d.com&#39;)</span><br><span class="line">insert into Person (Id, Email) values (3, &#39;a@b.com&#39;)</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      Email</span><br><span class="line">from </span><br><span class="line">      Person</span><br><span class="line">group by </span><br><span class="line">      Email</span><br><span class="line">having </span><br><span class="line">      count(Email) &gt; 1;</span><br></pre></td></tr></table></figure></div>

<h2 id="7-从不订购的客户"><a href="#7-从不订购的客户" class="headerlink" title="7. 从不订购的客户"></a>7. 从不订购的客户</h2><p>需求：某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Customers</th>
</tr>
</thead>
<tbody><tr>
<td>Henry</td>
</tr>
<tr>
<td>Max</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Customers (Id int, Name varchar(255));</span><br><span class="line">Create table If Not Exists Orders (Id int, CustomerId int);</span><br><span class="line"></span><br><span class="line">insert into Customers (Id, Name) values (1, &#39;Joe&#39;);</span><br><span class="line">insert into Customers (Id, Name) values (2, &#39;Henry&#39;);</span><br><span class="line">insert into Customers (Id, Name) values (3, &#39;Sam&#39;);</span><br><span class="line">insert into Customers (Id, Name) values (4, &#39;Max&#39;);</span><br><span class="line"></span><br><span class="line">insert into Orders (Id, CustomerId) values (1, 3);</span><br><span class="line">insert into Orders (Id, CustomerId) values (2, 1);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">     customers.name as &#39;Customers&#39;</span><br><span class="line">from </span><br><span class="line">     customers</span><br><span class="line">where </span><br><span class="line">     customers.id not in(</span><br><span class="line">        select</span><br><span class="line">              customerid </span><br><span class="line">        from </span><br><span class="line">              orders</span><br><span class="line">     );</span><br></pre></td></tr></table></figure></div>

<h2 id="8-部门工资最高的员工"><a href="#8-部门工资最高的员工" class="headerlink" title="8. 部门工资最高的员工"></a>8. 部门工资最高的员工</h2><p><strong>需求一</strong>：编写一个 SQL 查询，找出每个部门工资最高的员工。例如，根据上述给定的表格，Max 在 IT 部门有最高工资，Henry 在 Sales 部门有最高工资。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Department</th>
<th>Employee</th>
<th>Salary</th>
</tr>
</thead>
<tbody><tr>
<td>IT</td>
<td>Jim</td>
<td>90000</td>
</tr>
<tr>
<td>IT</td>
<td>Max</td>
<td>90000</td>
</tr>
<tr>
<td>Sales</td>
<td>Henry</td>
<td>80000</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (Id int, Name varchar(255), Salary int, DepartmentId int);</span><br><span class="line">Create table If Not Exists Department (Id int, Name varchar(255));</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (1, &#39;Joe&#39;, 70000, 1);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (2, &#39;Jim&#39;, 90000, 1);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (3, &#39;Henry&#39;, 80000, 2);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (4, &#39;Sam&#39;, 60000, 2);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (5, &#39;Max&#39;, 90000, 1);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (6, &#39;Randy&#39;, 85000, 1);</span><br><span class="line">insert into Employee (Id, Name, Salary, DepartmentId) values (7, &#39;Will&#39;, 70000, 1);</span><br><span class="line"></span><br><span class="line">insert into Department (Id, Name) values (1, &#39;IT&#39;);</span><br><span class="line">insert into Department (Id, Name) values (2, &#39;Sales&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    Department.name AS &#39;Department&#39;,</span><br><span class="line">    Employee.name AS &#39;Employee&#39;,</span><br><span class="line">    Salary</span><br><span class="line">FROM</span><br><span class="line">    Employee</span><br><span class="line">        JOIN</span><br><span class="line">    Department ON Employee.DepartmentId &#x3D; Department.Id</span><br><span class="line">WHERE</span><br><span class="line">    (Employee.DepartmentId , Salary) IN</span><br><span class="line">    (   SELECT</span><br><span class="line">            DepartmentId, MAX(Salary)</span><br><span class="line">        FROM</span><br><span class="line">            Employee</span><br><span class="line">        GROUP BY DepartmentId</span><br><span class="line">	);</span><br></pre></td></tr></table></figure></div>

<p><strong>需求二</strong>：编写一个 SQL 查询，找出每个部门获得前三高工资的所有员工。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Department</th>
<th>Employee</th>
<th>Salary</th>
</tr>
</thead>
<tbody><tr>
<td>IT</td>
<td>Max</td>
<td>90000</td>
</tr>
<tr>
<td>IT</td>
<td>Randy</td>
<td>85000</td>
</tr>
<tr>
<td>IT</td>
<td>Joe</td>
<td>85000</td>
</tr>
<tr>
<td>IT</td>
<td>Will</td>
<td>70000</td>
</tr>
<tr>
<td>Sales</td>
<td>Henry</td>
<td>80000</td>
</tr>
<tr>
<td>Sales</td>
<td>Sam</td>
<td>60000</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    d.Name AS &#39;Department&#39;, e1.Name AS &#39;Employee&#39;, e1.Salary</span><br><span class="line">FROM</span><br><span class="line">    Employee e1</span><br><span class="line">        JOIN</span><br><span class="line">    Department d ON e1.DepartmentId &#x3D; d.Id</span><br><span class="line">WHERE</span><br><span class="line">    3 &gt; (SELECT</span><br><span class="line">            COUNT(DISTINCT e2.Salary)</span><br><span class="line">        FROM</span><br><span class="line">            Employee e2</span><br><span class="line">        WHERE</span><br><span class="line">            e2.Salary &gt; e1.Salary</span><br><span class="line">                AND e1.DepartmentId &#x3D; e2.DepartmentId</span><br><span class="line">        );</span><br></pre></td></tr></table></figure></div>

<h2 id="9-删除重复的电子邮箱"><a href="#9-删除重复的电子邮箱" class="headerlink" title="9. 删除重复的电子邮箱"></a>9. 删除重复的电子邮箱</h2><p>需求：编写一个 SQL 查询，来删除 Person 表中所有重复的电子邮箱，重复的邮箱里只保留 Id 最小 的那个。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Email</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><a href="mailto:john@example.com">john@example.com</a></td>
</tr>
<tr>
<td>2</td>
<td><a href="mailto:bob@example.com">bob@example.com</a></td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Person (Id int, email varchar(255));</span><br><span class="line"></span><br><span class="line">insert into Person (Id, email) values (1, &#39;john@example.com&#39;);</span><br><span class="line">insert into Person (Id, email) values (2, &#39;bob@example.com&#39;);</span><br><span class="line">insert into Person (Id, email) values (3, &#39;john@example.com&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DELETE </span><br><span class="line">      p1 </span><br><span class="line">FROM </span><br><span class="line">      Person p1,</span><br><span class="line">      Person p2</span><br><span class="line">WHERE</span><br><span class="line">      p1.Email &#x3D; p2.Email AND p1.Id &gt; p2.Id;</span><br></pre></td></tr></table></figure></div>

<h2 id="10-上升的温度"><a href="#10-上升的温度" class="headerlink" title="10. 上升的温度"></a>10. 上升的温度</h2><p>需求：编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 Id。</p>
<table>
<thead>
<tr>
<th>Id</th>
</tr>
</thead>
<tbody><tr>
<td>2</td>
</tr>
<tr>
<td>4</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Weather (Id int, RecordDate date, Temperature int);</span><br><span class="line"></span><br><span class="line">insert into Weather (Id, RecordDate, Temperature) values (1, &#39;2015-01-01&#39;, 10);</span><br><span class="line">insert into Weather (Id, RecordDate, Temperature) values (2, &#39;2015-01-02&#39;, 25);</span><br><span class="line">insert into Weather (Id, RecordDate, Temperature) values (3, &#39;2015-01-03&#39;, 20);</span><br><span class="line">insert into Weather (Id, RecordDate, Temperature) values (4, &#39;2015-01-04&#39;, 30);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    weather.id AS &#39;Id&#39;</span><br><span class="line">FROM</span><br><span class="line">    weather</span><br><span class="line">JOIN</span><br><span class="line">    weather w </span><br><span class="line">ON </span><br><span class="line">    DATEDIFF(weather.RecordDate, w.RecordDate) &#x3D; 1</span><br><span class="line">AND weather.Temperature &gt; w.Temperature;</span><br></pre></td></tr></table></figure></div>

<h2 id="11-行程和用户"><a href="#11-行程和用户" class="headerlink" title="11. 行程和用户"></a>11. 行程和用户</h2><p>需求：写一段 SQL 语句查出 2019年10月1日 至 2019年10月3日 期间非禁止用户的取消率。基于上表，你的 SQL 语句应返回如下结果，取消率（Cancellation Rate）保留两位小数。</p>
<p>取消率的计算方式如下：(被司机或乘客取消的非禁止用户生成的订单数量) / (非禁止用户生成的订单总数)</p>
<p>Trips表：所有出租车的行程信息。每段行程有唯一键 Id，Client_Id 和 Driver_Id 是 Users 表中 Users_Id 的外键。Status 是枚举类型，枚举成员为 (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’)。</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Client_Id</th>
<th>Driver_Id</th>
<th>City_Id</th>
<th>Status</th>
<th>Request_at</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
<td>10</td>
<td>1</td>
<td>completed</td>
<td>2019-10-01</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>11</td>
<td>1</td>
<td>cancelled_by_driver</td>
<td>2019-10-01</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>12</td>
<td>6</td>
<td>completed</td>
<td>2019-10-01</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>13</td>
<td>6</td>
<td>cancelled_by_client</td>
<td>2019-10-01</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>10</td>
<td>1</td>
<td>completed</td>
<td>2019-10-02</td>
</tr>
<tr>
<td>6</td>
<td>2</td>
<td>11</td>
<td>6</td>
<td>completed</td>
<td>2019-10-02</td>
</tr>
<tr>
<td>7</td>
<td>3</td>
<td>12</td>
<td>6</td>
<td>completed</td>
<td>2019-10-02</td>
</tr>
<tr>
<td>8</td>
<td>2</td>
<td>12</td>
<td>12</td>
<td>completed</td>
<td>2019-10-03</td>
</tr>
<tr>
<td>9</td>
<td>3</td>
<td>10</td>
<td>12</td>
<td>completed</td>
<td>2019-10-03</td>
</tr>
<tr>
<td>10</td>
<td>4</td>
<td>13</td>
<td>12</td>
<td>cancelled_by_driver</td>
<td>2019-10-03</td>
</tr>
</tbody></table>
<p>Users 表存所有用户。每个用户有唯一键 Users_Id。Banned 表示这个用户是否被禁止，Role 则是一个表示（‘client’, ‘driver’, ‘partner’）的枚举类型。</p>
<table>
<thead>
<tr>
<th>Users_Id</th>
<th>Banned</th>
<th>Cancellation Rate</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>No</td>
<td>client</td>
</tr>
<tr>
<td>2</td>
<td>Yes</td>
<td>client</td>
</tr>
<tr>
<td>3</td>
<td>No</td>
<td>client</td>
</tr>
<tr>
<td>4</td>
<td>No</td>
<td>client</td>
</tr>
<tr>
<td>10</td>
<td>No</td>
<td>driver</td>
</tr>
<tr>
<td>11</td>
<td>No</td>
<td>driver</td>
</tr>
<tr>
<td>12</td>
<td>No</td>
<td>driver</td>
</tr>
<tr>
<td>13</td>
<td>No</td>
<td>driver</td>
</tr>
</tbody></table>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Day</th>
<th>Cancellation Rate</th>
</tr>
</thead>
<tbody><tr>
<td>2019-10-01</td>
<td>0.33</td>
</tr>
<tr>
<td>2019-10-02</td>
<td>0.00</td>
</tr>
<tr>
<td>2019-10-03</td>
<td>0.50</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Trips (Id int, Client_Id int, Driver_Id int, City_Id int, Status ENUM(&#39;completed&#39;, &#39;cancelled_by_driver&#39;, &#39;cancelled_by_client&#39;), Request_at varchar(50));</span><br><span class="line"></span><br><span class="line">Create table If Not Exists Users (Users_Id int, Banned varchar(50), Role ENUM(&#39;client&#39;, &#39;driver&#39;, &#39;partner&#39;));</span><br><span class="line"></span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (1, 1, 10, 1, &#39;completed&#39;, &#39;2019-10-01&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (2, 2, 11, 1, &#39;cancelled_by_driver&#39;, &#39;2019-10-01&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (3, 3, 12, 6, &#39;completed&#39;, &#39;2019-10-01&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (4, 4, 13, 6, &#39;cancelled_by_client&#39;, &#39;2019-10-01&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (5, 1, 10, 1, &#39;completed&#39;, &#39;2019-10-02&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (6, 2, 11, 6, &#39;completed&#39;, &#39;2019-10-02&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (7, 3, 12, 6, &#39;completed&#39;, &#39;2019-10-02&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (8, 2, 12, 12, &#39;completed&#39;, &#39;2019-10-03&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (9, 3, 10, 12, &#39;completed&#39;, &#39;2019-10-03&#39;);</span><br><span class="line">insert into Trips (Id, Client_Id, Driver_Id, City_Id, Status, Request_at) values (10, 4, 13, 12, &#39;cancelled_by_driver&#39;, &#39;2019-10-03&#39;);</span><br><span class="line"></span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (1, &#39;No&#39;, &#39;client&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (2, &#39;Yes&#39;, &#39;client&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (3, &#39;No&#39;, &#39;client&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (4, &#39;No&#39;, &#39;client&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (10, &#39;No&#39;, &#39;driver&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (11, &#39;No&#39;, &#39;driver&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (12, &#39;No&#39;, &#39;driver&#39;);</span><br><span class="line">insert into Users (Users_Id, Banned, Role) values (13, &#39;No&#39;, &#39;driver&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">方法一：</span><br><span class="line">SELECT </span><br><span class="line">      T.request_at AS &#96;Day&#96;, </span><br><span class="line">	  ROUND(</span><br><span class="line">            SUM(IF(T.STATUS &#x3D; &#39;completed&#39;,0,1))&#x2F; COUNT(T.STATUS),</span><br><span class="line">            2</span><br><span class="line">            ) AS &#96;Cancellation Rate&#96;</span><br><span class="line">FROM </span><br><span class="line">      Trips AS T</span><br><span class="line">JOIN </span><br><span class="line">      Users AS U1 </span><br><span class="line">ON </span><br><span class="line">      T.client_id &#x3D; U1.users_id AND U1.banned &#x3D;&#39;No&#39;</span><br><span class="line">JOIN </span><br><span class="line">      Users AS U2 </span><br><span class="line">ON </span><br><span class="line">      T.driver_id &#x3D; U2.users_id AND U2.banned &#x3D;&#39;No&#39;</span><br><span class="line">WHERE </span><br><span class="line">      T.request_at BETWEEN &#39;2019-10-01&#39; AND &#39;2019-10-03&#39;</span><br><span class="line">GROUP BY </span><br><span class="line">      T.request_at;</span><br><span class="line"></span><br><span class="line">方法二：</span><br><span class="line">SELECT </span><br><span class="line">      T.request_at AS &#96;Day&#96;, </span><br><span class="line">	  ROUND(</span><br><span class="line">			SUM(IF(T.STATUS &#x3D; &#39;completed&#39;,0,1))&#x2F; COUNT(T.STATUS),</span><br><span class="line">			2</span><br><span class="line">	        ) AS &#96;Cancellation Rate&#96;</span><br><span class="line">FROM </span><br><span class="line">     trips AS T </span><br><span class="line">LEFT JOIN (</span><br><span class="line">	        SELECT</span><br><span class="line">                  users_id</span><br><span class="line">	        FROM</span><br><span class="line">                  users</span><br><span class="line">	        WHERE  </span><br><span class="line">                  banned &#x3D; &#39;Yes&#39;</span><br><span class="line">           ) AS A </span><br><span class="line">ON </span><br><span class="line">     T.Client_Id &#x3D; A.users_id</span><br><span class="line">LEFT JOIN (</span><br><span class="line">	        SELECT</span><br><span class="line">                  users_id</span><br><span class="line">	        FROM </span><br><span class="line">                  users</span><br><span class="line">	        WHERE </span><br><span class="line">                  banned &#x3D; &#39;Yes&#39;</span><br><span class="line">           ) AS A1</span><br><span class="line">ON </span><br><span class="line">     T.Driver_Id &#x3D; A1.users_id</span><br><span class="line">WHERE </span><br><span class="line">     A.users_id IS NULL </span><br><span class="line">     AND A1.users_id IS NULL </span><br><span class="line">     AND T.request_at BETWEEN &#39;2019-10-01&#39; AND &#39;2019-10-03&#39;</span><br><span class="line">GROUP BY </span><br><span class="line">     T.request_at;</span><br><span class="line"></span><br><span class="line">方法三：</span><br><span class="line">SELECT </span><br><span class="line">     T.request_at AS &#96;Day&#96;, </span><br><span class="line">	 ROUND(</span><br><span class="line">           SUM(IF(T.STATUS &#x3D; &#39;completed&#39;,0,1))&#x2F; COUNT(T.STATUS),</span><br><span class="line">		   2</span><br><span class="line">	       ) AS &#96;Cancellation Rate&#96;</span><br><span class="line">FROM</span><br><span class="line">     trips AS T</span><br><span class="line">WHERE </span><br><span class="line">     T.Client_Id NOT IN (</span><br><span class="line">	                      SELECT </span><br><span class="line">                                 users_id</span><br><span class="line">	                      FROM </span><br><span class="line">                                 users</span><br><span class="line">	                      WHERE </span><br><span class="line">                                 banned &#x3D; &#39;Yes&#39;</span><br><span class="line">     )</span><br><span class="line">AND</span><br><span class="line">     T.Driver_Id NOT IN (</span><br><span class="line">     	                  SELECT </span><br><span class="line">                                 users_id</span><br><span class="line">     	                  FROM  </span><br><span class="line">                                 users</span><br><span class="line">     	                  WHERE </span><br><span class="line">                                 banned &#x3D; &#39;Yes&#39;</span><br><span class="line">     )</span><br><span class="line">AND </span><br><span class="line">     T.request_at BETWEEN &#39;2019-10-01&#39; AND &#39;2019-10-03&#39;;</span><br></pre></td></tr></table></figure></div>

<h2 id="12-游戏玩法分析"><a href="#12-游戏玩法分析" class="headerlink" title="12. 游戏玩法分析"></a>12. 游戏玩法分析</h2><p><strong>需求一</strong>：写一条 SQL 查询语句获取每位玩家 第一次登陆平台的日期。</p>
<p> Activity表：显示了某些游戏的玩家的活动情况。</p>
<table>
<thead>
<tr>
<th>player_id</th>
<th>device_id</th>
<th>event_date</th>
<th>games_played</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2</td>
<td>2016-03-01</td>
<td>5</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2016-05-02</td>
<td>6</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>2017-06-25</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>2016-03-02</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>2018-07-03</td>
<td>5</td>
</tr>
</tbody></table>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>player_id</th>
<th>first_login</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2016-03-01</td>
</tr>
<tr>
<td>2</td>
<td>2017-06-25</td>
</tr>
<tr>
<td>3</td>
<td>2016-03-02</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Activity (player_id int, device_id int, event_date date, games_played int);</span><br><span class="line"></span><br><span class="line">insert into Activity (player_id, device_id, event_date, games_played) values (1, 2, &#39;2016-03-01&#39;, 5);</span><br><span class="line">insert into Activity (player_id, device_id, event_date, games_played) values (1, 2, &#39;2016-05-02&#39;, 6);</span><br><span class="line">insert into Activity (player_id, device_id, event_date, games_played) values (2, 3, &#39;2017-06-25&#39;, 1);</span><br><span class="line">insert into Activity (player_id, device_id, event_date, games_played) values (3, 1, &#39;2016-03-02&#39;, 0);</span><br><span class="line">insert into Activity (player_id, device_id, event_date, games_played) values (3, 4, &#39;2018-07-03&#39;, 5);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      player_id, </span><br><span class="line">      min(event_date) as first_login </span><br><span class="line">from </span><br><span class="line">      Activity </span><br><span class="line">group by </span><br><span class="line">      player_id;</span><br></pre></td></tr></table></figure></div>

<p><strong>需求二</strong>：描述每一个玩家首次登陆的设备名称</p>
<table>
<thead>
<tr>
<th>player_id</th>
<th>device_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      player_id,</span><br><span class="line">      device_id </span><br><span class="line">from</span><br><span class="line">     (select *  </span><br><span class="line">      from </span><br><span class="line">          Activity</span><br><span class="line">      where</span><br><span class="line">          (player_id,event_date) in (select</span><br><span class="line">                                           player_id, </span><br><span class="line">                                           device_id</span><br><span class="line">                                           min(event_date)</span><br><span class="line">                                      from</span><br><span class="line">                                           Activity </span><br><span class="line">                                      group by </span><br><span class="line">                                           player_id</span><br><span class="line">                                      )</span><br><span class="line">      ) as t;</span><br></pre></td></tr></table></figure></div>

<p><strong>需求三</strong>：编写一个 SQL 查询，同时报告每组玩家和日期，以及玩家到目前为止玩了多少游戏。也就是说，在此日期之前玩家所玩的游戏总数。详细情况请查看示例。</p>
<table>
<thead>
<tr>
<th>player_id</th>
<th>event_date</th>
<th>games_played_so_far</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2016-03-01</td>
<td>5</td>
</tr>
<tr>
<td>1</td>
<td>2016-05-02</td>
<td>11</td>
</tr>
<tr>
<td>2</td>
<td>2017-06-25</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2016-03-02</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>2018-07-03</td>
<td>5</td>
</tr>
</tbody></table>
<p>提示：对于 ID 为 3 的玩家，2018-07-03 共玩了 0+5=5 个游戏。</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;方法一</span><br><span class="line">SELECT C.player_id,C.event_date,C.games_played_so_far</span><br><span class="line">FROM (</span><br><span class="line">      SELECT </span><br><span class="line">      	A.player_id,</span><br><span class="line">      	A.event_date,</span><br><span class="line">          @sum_cnt:&#x3D;</span><br><span class="line">      		if(A.player_id &#x3D; @pre_id AND A.event_date !&#x3D; @pre_date,</span><br><span class="line">      			@sum_cnt + A.games_played,</span><br><span class="line">      			A.games_played </span><br><span class="line">      		)</span><br><span class="line">      		AS &#96;games_played_so_far&#96;,</span><br><span class="line">          @pre_id:&#x3D;A.player_id AS &#96;player_ids&#96;,</span><br><span class="line">          @pre_date:&#x3D;A.event_date AS &#96;event_dates&#96;</span><br><span class="line">      FROM </span><br><span class="line">          activity AS A,</span><br><span class="line">          (SELECT @pre_id:&#x3D;NULL,@pre_date:&#x3D;NULL,@sum_cnt:&#x3D;0) AS B</span><br><span class="line">      order BY </span><br><span class="line">          A.player_id,A.event_date</span><br><span class="line">) AS C</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;方法二</span><br><span class="line">SELECT </span><br><span class="line">      B.player_id,</span><br><span class="line">      B.event_date,</span><br><span class="line">      SUM(A.games_played) AS &#96;games_played_so_far&#96;</span><br><span class="line">FROM </span><br><span class="line">      Activity AS A</span><br><span class="line">JOIN </span><br><span class="line">      Activity AS B </span><br><span class="line">ON </span><br><span class="line">      A.player_id &#x3D; B.player_id </span><br><span class="line">      AND A.event_date &lt;&#x3D; B.event_date</span><br><span class="line">GROUP BY </span><br><span class="line">      B.player_id,B.event_date;</span><br></pre></td></tr></table></figure></div>

<p><strong>需求四</strong>：编写一个 SQL 查询，报告在首次登录的第二天再次登录的玩家的百分比，四舍五入到小数点后两位。换句话说，您需要计算从首次登录日期开始至少连续两天登录的玩家的数量，然后除以玩家总数。</p>
<table>
<thead>
<tr>
<th>fraction</th>
</tr>
</thead>
<tbody><tr>
<td>0.00</td>
</tr>
</tbody></table>
<p>提示：对于 ID 为 1 的玩家，2016-05-02 共玩了 5+6=11 个游戏.<br>对于 ID 为 3 的玩家，2018-07-03 共玩了 0+5=5 个游戏。</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      round(</span><br><span class="line">            sum(case when datediff(a.event_date,b.first_date)&#x3D;1 then 1 else 0 end)</span><br><span class="line">               &#x2F;</span><br><span class="line">               (select count(distinct(player_id)) from activity)</span><br><span class="line">            ,2 ) as fraction</span><br><span class="line">from </span><br><span class="line">      activity a,</span><br><span class="line">     (select </span><br><span class="line">             player_id,</span><br><span class="line">             min(event_date) first_date </span><br><span class="line">      from </span><br><span class="line">             activity </span><br><span class="line">      group by </span><br><span class="line">             player_id</span><br><span class="line">     ) b</span><br><span class="line">where </span><br><span class="line">      a.player_id&#x3D;b.player_id;</span><br></pre></td></tr></table></figure></div>

<p><strong>需求五</strong>：编写一个 SQL 查询，报告每个安装日期、当天安装游戏的玩家数量和第一天的保留时间。</p>
<table>
<thead>
<tr>
<th>install_dt</th>
<th>installs</th>
<th>Day1_retention</th>
</tr>
</thead>
<tbody><tr>
<td>2016-03-01</td>
<td>2</td>
<td>0.50</td>
</tr>
<tr>
<td>2017-06-25</td>
<td>1</td>
<td>0.00</td>
</tr>
</tbody></table>
<p>提示：玩家 1 和 3 在 2016-03-01 安装了游戏，但只有玩家 1 在 2016-03-02 重新登录，所以 2016-03-01 的第一天保留时间是 1/2=0.50<br>玩家 2 在 2017-06-25 安装了游戏，但在 2017-06-26 没有重新登录，因此 2017-06-25 的第一天保留为 0/1=0.00</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一</span><br><span class="line">SELECT</span><br><span class="line">      A.install_date,</span><br><span class="line">      COUNT(A.player_id) AS &#96;installs&#96;,</span><br><span class="line">      COUNT(AA.player_id) AS &#96;return_cnt&#96;</span><br><span class="line">FROM </span><br><span class="line">   (SELECT </span><br><span class="line">           player_id,</span><br><span class="line">           MIN(event_date) AS &#96;install_date&#96;</span><br><span class="line">	FROM </span><br><span class="line">           Activity</span><br><span class="line">	GROUP BY </span><br><span class="line">           player_id</span><br><span class="line">    ) AS A</span><br><span class="line">left JOIN </span><br><span class="line">    Activity AS AA </span><br><span class="line">ON </span><br><span class="line">    AA.event_date &#x3D; DATE_ADD(A.install_date,INTERVAL 1 DAY) AND AA.player_id &#x3D; A.player_id</span><br><span class="line">GROUP BY</span><br><span class="line">    A.install_date;</span><br><span class="line"></span><br><span class="line">#方法二</span><br><span class="line">SELECT </span><br><span class="line">      A.event_date AS &#96;install_dt&#96;,</span><br><span class="line">      COUNT(A.player_id) AS &#96;installs&#96;,</span><br><span class="line">      round(COUNT(C.player_id)&#x2F;COUNT(A.player_id),2) AS &#96;Day1_retention&#96;</span><br><span class="line">FROM</span><br><span class="line">      Activity AS A </span><br><span class="line">left JOIN </span><br><span class="line">      Activity AS B</span><br><span class="line">ON </span><br><span class="line">      A.player_id &#x3D; B.player_id AND A.event_date &gt; B.event_date</span><br><span class="line">left JOIN </span><br><span class="line">      Activity AS C</span><br><span class="line">ON    </span><br><span class="line">      A.player_id &#x3D; C.player_id AND C.event_date &#x3D; DATE_ADD(A.event_date,INTERVAL 1 DAY)</span><br><span class="line">WHERE </span><br><span class="line">      B.event_date IS NULL</span><br><span class="line">GROUP BY </span><br><span class="line">      A.event_date;</span><br></pre></td></tr></table></figure></div>

<h2 id="13-员工薪水中位数"><a href="#13-员工薪水中位数" class="headerlink" title="13. 员工薪水中位数"></a>13. 员工薪水中位数</h2><p>需求：请编写SQL查询来查找每个公司的薪水中位数。挑战点：你是否可以在不使用任何内置的SQL函数的情况下解决此问题。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Company</th>
<th>Salary</th>
</tr>
</thead>
<tbody><tr>
<td>5</td>
<td>A</td>
<td>451</td>
</tr>
<tr>
<td>6</td>
<td>A</td>
<td>513</td>
</tr>
<tr>
<td>12</td>
<td>B</td>
<td>234</td>
</tr>
<tr>
<td>9</td>
<td>B</td>
<td>1154</td>
</tr>
<tr>
<td>14</td>
<td>C</td>
<td>2645</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (Id int, Company varchar(255), Salary int);</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Company, Salary) values (1, &#39;A&#39;, 2341);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (2, &#39;A&#39;, 341);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (3, &#39;A&#39;, 15);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (4, &#39;A&#39;, 15314);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (5, &#39;A&#39;, 451);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (6, &#39;A&#39;, 513);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (7, &#39;B&#39;, 15);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (8, &#39;B&#39;, 13);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (9, &#39;B&#39;, 1154);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (10, &#39;B&#39;, 1345);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (11, &#39;B&#39;, 1221);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (12, &#39;B&#39;, 234);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (13, &#39;C&#39;, 2345);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (14, &#39;C&#39;, 2645);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (15, &#39;C&#39;, 2645);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (16, &#39;C&#39;, 2652);</span><br><span class="line">insert into Employee (Id, Company, Salary) values (17, &#39;C&#39;, 65);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">     b.id,</span><br><span class="line">     b.company,</span><br><span class="line">     b.salary</span><br><span class="line">from </span><br><span class="line">    (select</span><br><span class="line">           id,</span><br><span class="line">           company,</span><br><span class="line">           salary,</span><br><span class="line">           case @com when company then @rk:&#x3D;@rk+1 else @rk:&#x3D;1 end rk,</span><br><span class="line">           @com:&#x3D;company</span><br><span class="line">    from </span><br><span class="line">           employee,</span><br><span class="line">           (select @rk:&#x3D;0, @com:&#x3D;&#39;&#39;) a</span><br><span class="line">    order by</span><br><span class="line">           company,salary</span><br><span class="line">    ) b</span><br><span class="line">left join </span><br><span class="line">    (select</span><br><span class="line">           company,</span><br><span class="line">           count(1)&#x2F;2 cnt</span><br><span class="line">     from </span><br><span class="line">           employee</span><br><span class="line">     group by company</span><br><span class="line">    ) c</span><br><span class="line">on </span><br><span class="line">     b.company&#x3D;c.company</span><br><span class="line">where</span><br><span class="line">     b.rk in (cnt+0.5,cnt+1,cnt);</span><br></pre></td></tr></table></figure></div>

<h2 id="14-至少有5名直接下属的经理"><a href="#14-至少有5名直接下属的经理" class="headerlink" title="14. 至少有5名直接下属的经理"></a>14. 至少有5名直接下属的经理</h2><p>需求：Employee 表，请编写一个SQL查询来查找至少有5名直接下属的经理。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Name</th>
</tr>
</thead>
<tbody><tr>
<td>John</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (Id int, Name varchar(255), Department varchar(255), ManagerId int);</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (101, &#39;John&#39;, &#39;A&#39;, null);</span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (102, &#39;Dan&#39;, &#39;A&#39;, 101);</span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (103, &#39;James&#39;, &#39;A&#39;, 101);</span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (104, &#39;Amy&#39;, &#39;A&#39;, 101);</span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (105, &#39;Anne&#39;, &#39;A&#39;, 101);</span><br><span class="line">insert into Employee (Id, Name, Department, ManagerId) values (106, &#39;Ron&#39;, &#39;B&#39;, 101);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    Name</span><br><span class="line">FROM</span><br><span class="line">    Employee AS t1 </span><br><span class="line">JOIN </span><br><span class="line">   (SELECT</span><br><span class="line">        ManagerId</span><br><span class="line">    FROM</span><br><span class="line">        Employee</span><br><span class="line">    GROUP BY </span><br><span class="line">        ManagerId</span><br><span class="line">    HAVING</span><br><span class="line">        COUNT(ManagerId) &gt;&#x3D; 5</span><br><span class="line">    ) AS t2</span><br><span class="line">ON  </span><br><span class="line">    t1.Id &#x3D; t2.ManagerId;</span><br></pre></td></tr></table></figure></div>

<h2 id="15-给定数字的频率查询中位数"><a href="#15-给定数字的频率查询中位数" class="headerlink" title="15. 给定数字的频率查询中位数"></a>15. 给定数字的频率查询中位数</h2><p>需求：编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供 person 的以下信息：<br>FirstName, LastName, City, State</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>median</th>
</tr>
</thead>
<tbody><tr>
<td>0.0000</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Numbers (Number int, Frequency int);</span><br><span class="line"></span><br><span class="line">insert into Numbers (Number, Frequency) values (0, 7);</span><br><span class="line">insert into Numbers (Number, Frequency) values (1, 1);</span><br><span class="line">insert into Numbers (Number, Frequency) values (2, 3);</span><br><span class="line">insert into Numbers (Number, Frequency) values (3, 1);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      avg(t.number) as median</span><br><span class="line">from</span><br><span class="line">      (select</span><br><span class="line">             n1.number,</span><br><span class="line">             n1.frequency,</span><br><span class="line">             (select </span><br><span class="line">                   sum(frequency) </span><br><span class="line">              from </span><br><span class="line">                   numbers n2</span><br><span class="line">              where </span><br><span class="line">                   n2.number&lt;&#x3D;n1.number</span><br><span class="line">             ) as asc_frequency,</span><br><span class="line">             (select</span><br><span class="line">                   sum(frequency)</span><br><span class="line">              from </span><br><span class="line">                   numbers n3 </span><br><span class="line">              where </span><br><span class="line">                   n3.number&gt;&#x3D;n1.number</span><br><span class="line">             ) as desc_frequency</span><br><span class="line">      from </span><br><span class="line">             numbers n1</span><br><span class="line">      ) t</span><br><span class="line">where </span><br><span class="line">      t.asc_frequency&gt;&#x3D; (select sum(frequency) from numbers)&#x2F;2</span><br><span class="line">      and t.desc_frequency&gt;&#x3D; (select sum(frequency) from numbers)&#x2F;2;</span><br></pre></td></tr></table></figure></div>

<h2 id="16-当选者"><a href="#16-当选者" class="headerlink" title="16. 当选者"></a>16. 当选者</h2><p>需求：请编写 sql 语句来找到当选者（CandidateId）的名字</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Name</th>
</tr>
</thead>
<tbody><tr>
<td>B</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Candidate (id int, Name varchar(255));</span><br><span class="line">Create table If Not Exists Vote (id int, CandidateId int);</span><br><span class="line"></span><br><span class="line">insert into Candidate (id, Name) values (1, &#39;A&#39;);</span><br><span class="line">insert into Candidate (id, Name) values (2, &#39;B&#39;);</span><br><span class="line">insert into Candidate (id, Name) values (3, &#39;C&#39;);</span><br><span class="line">insert into Candidate (id, Name) values (4, &#39;D&#39;);</span><br><span class="line">insert into Candidate (id, Name) values (5, &#39;E&#39;);</span><br><span class="line"></span><br><span class="line">insert into Vote (id, CandidateId) values (1, 2);</span><br><span class="line">insert into Vote (id, CandidateId) values (2, 44);</span><br><span class="line">insert into Vote (id, CandidateId) values (3, 3);</span><br><span class="line">insert into Vote (id, CandidateId) values (4, 2);</span><br><span class="line">insert into Vote (id, CandidateId) values (5, 5);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    name AS &#39;Name&#39;</span><br><span class="line">FROM</span><br><span class="line">    Candidate</span><br><span class="line">JOIN</span><br><span class="line">    (SELECT</span><br><span class="line">        Candidateid</span><br><span class="line">    FROM</span><br><span class="line">        Vote</span><br><span class="line">    GROUP BY </span><br><span class="line">        Candidateid</span><br><span class="line">    ORDER BY </span><br><span class="line">        COUNT(*) DESC</span><br><span class="line">    LIMIT 1</span><br><span class="line">    ) AS winner</span><br><span class="line">WHERE</span><br><span class="line">    Candidate.id &#x3D; winner.Candidateid;</span><br></pre></td></tr></table></figure></div>

<h2 id="17-员工奖金"><a href="#17-员工奖金" class="headerlink" title="17. 员工奖金"></a>17. 员工奖金</h2><p>需求：选出所有 bonus &lt; 1000 的员工的 name 及其 bonus。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>name</th>
<th>bonus</th>
</tr>
</thead>
<tbody><tr>
<td>John</td>
<td>null</td>
</tr>
<tr>
<td>Dan</td>
<td>500</td>
</tr>
<tr>
<td>Brad</td>
<td>null</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (EmpId int, Name varchar(255), Supervisor int, Salary int);</span><br><span class="line">Create table If Not Exists Bonus (EmpId int, Bonus int);</span><br><span class="line"></span><br><span class="line">insert into Employee (EmpId, Name, Supervisor, Salary) values (3, &#39;Brad&#39;, null, 4000);</span><br><span class="line">insert into Employee (EmpId, Name, Supervisor, Salary) values (1, &#39;John&#39;, 3, 1000);</span><br><span class="line">insert into Employee (EmpId, Name, Supervisor, Salary) values (2, &#39;Dan&#39;, 3, 2000);</span><br><span class="line">insert into Employee (EmpId, Name, Supervisor, Salary) values (4, &#39;Thomas&#39;, 3, 4000);</span><br><span class="line"></span><br><span class="line">insert into Bonus (EmpId, Bonus) values (2, 500);</span><br><span class="line">insert into Bonus (EmpId, Bonus) values (4, 2000);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    Employee.name, </span><br><span class="line">    Bonus.bonus</span><br><span class="line">FROM</span><br><span class="line">    Employee</span><br><span class="line">LEFT JOIN</span><br><span class="line">    Bonus</span><br><span class="line">ON </span><br><span class="line">    Employee.empid &#x3D; Bonus.empid</span><br><span class="line">WHERE</span><br><span class="line">    bonus &lt; 1000 OR bonus IS NULL;</span><br></pre></td></tr></table></figure></div>

<h2 id="18-最高回答率"><a href="#18-最高回答率" class="headerlink" title="18. 最高回答率"></a>18. 最高回答率</h2><p>需求：请编写SQL查询来找到具有最高回答率的问题。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>survey_log</th>
</tr>
</thead>
<tbody><tr>
<td>285</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists survey_log (uid int, action varchar(255), question_id int, answer_id int, q_num int, timestamp int);</span><br><span class="line"></span><br><span class="line">insert into survey_log (uid, action, question_id, answer_id, q_num, timestamp) values (5, &#39;show&#39;, 285, null, 1, 123);</span><br><span class="line">insert into survey_log (uid, action, question_id, answer_id, q_num, timestamp) values (5, &#39;answer&#39;, 285, 124124, 1, &#39;124&#39;);</span><br><span class="line">insert into survey_log (uid, action, question_id, answer_id, q_num, timestamp) values (5, &#39;show&#39;, 369, null, 2, 125);</span><br><span class="line">insert into survey_log (uid, action, question_id, answer_id, q_num, timestamp) values (5, &#39;skip&#39;, 369, null, 2, 126);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一</span><br><span class="line">SELECT </span><br><span class="line">    question_id as survey_log</span><br><span class="line">FROM</span><br><span class="line">   (SELECT </span><br><span class="line">         question_id,</span><br><span class="line">         SUM(case when action&#x3D;&quot;answer&quot; THEN 1 ELSE 0 END) as num_answer,</span><br><span class="line">         SUM(case when action&#x3D;&quot;show&quot; THEN 1 ELSE 0 END) as num_show</span><br><span class="line">	FROM </span><br><span class="line">         survey_log</span><br><span class="line">	GROUP BY </span><br><span class="line">         question_id</span><br><span class="line">    ) as tbl</span><br><span class="line">ORDER BY</span><br><span class="line">    (num_answer &#x2F; num_show) DESC</span><br><span class="line">LIMIT 1;</span><br><span class="line"></span><br><span class="line">#方法二</span><br><span class="line">SELECT </span><br><span class="line">    question_id AS &#39;survey_log&#39;</span><br><span class="line">FROM</span><br><span class="line">    survey_log</span><br><span class="line">GROUP BY</span><br><span class="line">    question_id</span><br><span class="line">ORDER BY</span><br><span class="line">    COUNT(answer_id) &#x2F; COUNT(IF(action &#x3D; &#39;show&#39;, 1, 0)) DESC</span><br><span class="line">LIMIT 1;</span><br></pre></td></tr></table></figure></div>

<h2 id="19-员工累计薪水"><a href="#19-员工累计薪水" class="headerlink" title="19. 员工累计薪水"></a>19. 员工累计薪水</h2><p>需求：查询一个员工三个月内的累计薪水，但是不包括最近一个月的薪水。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Month</th>
<th>Salary</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>3</td>
<td>90</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>50</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>20</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>20</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>100</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>40</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employee (Id int, Month int, Salary int);</span><br><span class="line"></span><br><span class="line">insert into Employee (Id, Month, Salary) values (1, 1, 20);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (2, 1, 20);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (1, 2, 30);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (2, 2, 30);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (3, 2, 40);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (1, 3, 40);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (3, 3, 60);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (1, 4, 60);</span><br><span class="line">insert into Employee (Id, Month, Salary) values (3, 4, 70);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    E1.id,</span><br><span class="line">    E1.month,</span><br><span class="line">    (IFNULL(E1.salary, 0) + IFNULL(E2.salary, 0) + IFNULL(E3.salary, 0)) AS Salary</span><br><span class="line">FROM</span><br><span class="line">    (SELECT</span><br><span class="line">        id, MAX(month) AS month</span><br><span class="line">    FROM</span><br><span class="line">        Employee</span><br><span class="line">    GROUP BY </span><br><span class="line">        id</span><br><span class="line">    HAVING </span><br><span class="line">        COUNT(*) &gt; 1) AS maxmonth</span><br><span class="line">    LEFT JOIN</span><br><span class="line">        Employee E1 </span><br><span class="line">    ON </span><br><span class="line">        (maxmonth.id &#x3D; E1.id AND maxmonth.month &gt; E1.month)</span><br><span class="line">    LEFT JOIN</span><br><span class="line">        Employee E2 </span><br><span class="line">    ON </span><br><span class="line">        (E2.id &#x3D; E1.id AND E2.month &#x3D; E1.month - 1)</span><br><span class="line">    LEFT JOIN </span><br><span class="line">        Employee E3 </span><br><span class="line">    ON</span><br><span class="line">        (E3.id &#x3D; E1.id AND E3.month &#x3D; E1.month - 2)</span><br><span class="line">ORDER BY </span><br><span class="line">    id ASC , month DESC;</span><br></pre></td></tr></table></figure></div>

<h2 id="20-统计各专业人数"><a href="#20-统计各专业人数" class="headerlink" title="20. 统计各专业人数"></a>20. 统计各专业人数</h2><p>需求：查询 department 表中每个专业的学生人数 （即使没有学生的专业也需列出）。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>dept_name</th>
<th>student_number</th>
</tr>
</thead>
<tbody><tr>
<td>Engineering</td>
<td>2</td>
</tr>
<tr>
<td>Science</td>
<td>1</td>
</tr>
<tr>
<td>Law</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS student (student_id INT,student_name VARCHAR(45), gender VARCHAR(6), dept_id INT);</span><br><span class="line">CREATE TABLE IF NOT EXISTS department (dept_id INT, dept_name VARCHAR(255));</span><br><span class="line"></span><br><span class="line">insert into student (student_id, student_name, gender, dept_id) values (1, &#39;Jack&#39;, &#39;M&#39;, 1);</span><br><span class="line">insert into student (student_id, student_name, gender, dept_id) values (2, &#39;Jane&#39;, &#39;F&#39;, 1);</span><br><span class="line">insert into student (student_id, student_name, gender, dept_id) values (3, &#39;Mark&#39;, &#39;M&#39;, 2);</span><br><span class="line"></span><br><span class="line">insert into department (dept_id, dept_name) values (1, &#39;Engineering&#39;);</span><br><span class="line">insert into department (dept_id, dept_name) values (2, &#39;Science&#39;);</span><br><span class="line">insert into department (dept_id, dept_name) values (3, &#39;Law&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    dept_name,</span><br><span class="line">    COUNT(student_id) AS student_number</span><br><span class="line">FROM</span><br><span class="line">    department</span><br><span class="line">LEFT OUTER JOIN</span><br><span class="line">    student </span><br><span class="line">ON</span><br><span class="line">    department.dept_id &#x3D; student.dept_id</span><br><span class="line">GROUP BY </span><br><span class="line">    department.dept_name</span><br><span class="line">ORDER BY </span><br><span class="line">    student_number DESC, </span><br><span class="line">    department.dept_name;</span><br></pre></td></tr></table></figure></div>

<h2 id="21-寻找用户推荐人"><a href="#21-寻找用户推荐人" class="headerlink" title="21. 寻找用户推荐人"></a>21. 寻找用户推荐人</h2><p>需求：写一个查询语句，返回一个编号列表，列表中编号的推荐人的编号都 <strong>不是</strong> 2</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>name</th>
</tr>
</thead>
<tbody><tr>
<td>Will</td>
</tr>
<tr>
<td>Jane</td>
</tr>
<tr>
<td>Bill</td>
</tr>
<tr>
<td>Zack</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS customer (id INT,name VARCHAR(25),referee_id INT);</span><br><span class="line"></span><br><span class="line">insert into customer (id, name, referee_id) values (1, &#39;Will&#39;, null);</span><br><span class="line">insert into customer (id, name, referee_id) values (2, &#39;Jane&#39;, null);</span><br><span class="line">insert into customer (id, name, referee_id) values (3, &#39;Alex&#39;, 2);</span><br><span class="line">insert into customer (id, name, referee_id) values (4, &#39;Bill&#39;, null);</span><br><span class="line">insert into customer (id, name, referee_id) values (5, &#39;Zack&#39;, 1);</span><br><span class="line">insert into customer (id, name, referee_id) values (6, &#39;Mark&#39;, 2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      name</span><br><span class="line">FROM </span><br><span class="line">      customer</span><br><span class="line">WHERE </span><br><span class="line">      referee_id &lt;&gt; 2 OR referee_id IS NULL;</span><br></pre></td></tr></table></figure></div>

<h2 id="22-2016年的投资"><a href="#22-2016年的投资" class="headerlink" title="22. 2016年的投资"></a>22. 2016年的投资</h2><p>需求：写一个查询语句，将 2016 年 (TIV_2016) 所有成功投资的金额加起来，保留 2 位小数。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>TIV_2016</th>
</tr>
</thead>
<tbody><tr>
<td>45.00</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS insurance (PID INTEGER(11), TIV_2015 NUMERIC(15,2), TIV_2016 NUMERIC(15,2), LAT NUMERIC(5,2), LON NUMERIC(5,2) );</span><br><span class="line"></span><br><span class="line">insert into insurance (PID, TIV_2015, TIV_2016, LAT, LON) values (1, 10, 5, 10, 10);</span><br><span class="line">insert into insurance (PID, TIV_2015, TIV_2016, LAT, LON) values (2, 20, 20, 20, 20);</span><br><span class="line">insert into insurance (PID, TIV_2015, TIV_2016, LAT, LON) values (3, 10, 30, 20, 20);</span><br><span class="line">insert into insurance (PID, TIV_2015, TIV_2016, LAT, LON) values (4, 10, 40, 40, 40);</span><br></pre></td></tr></table></figure></div>

<p>提示：</p>
<p>对于一个投保人，他在 2016 年成功投资的条件是：</p>
<p>他在 2015 年的投保额 (TIV_2015) 至少跟一个其他投保人在 2015 年的投保额相同。<br>他所在的城市必须与其他投保人都不同（也就是说维度和经度不能跟其他任何一个投保人完全相同）。</p>
<p>就如最后一个投保人，第一个投保人同时满足两个条件：</p>
<ol>
<li>他在 2015 年的投保金额 TIV_2015 为 10 ，与第三个和第四个投保人在 2015 年的投保金额相同。</li>
<li>他所在城市的经纬度是独一无二的。</li>
</ol>
<p>第二个投保人两个条件都不满足。他在 2015 年的投资 TIV_2015 与其他任何投保人都不相同。<br>且他所在城市的经纬度与第三个投保人相同。基于同样的原因，第三个投保人投资失败。</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    SUM(insurance.TIV_2016) AS TIV_2016</span><br><span class="line">FROM</span><br><span class="line">    insurance</span><br><span class="line">WHERE</span><br><span class="line">    insurance.TIV_2015 IN(</span><br><span class="line">                          SELECT</span><br><span class="line">                                TIV_2015</span><br><span class="line">                          FROM</span><br><span class="line">                                insurance</span><br><span class="line">                          GROUP BY </span><br><span class="line">                                TIV_2015</span><br><span class="line">                          HAVING </span><br><span class="line">                                COUNT(*) &gt; 1</span><br><span class="line">                          )</span><br><span class="line">                      AND </span><br><span class="line">                          CONCAT(LAT, LON) IN(</span><br><span class="line">                                              SELECT</span><br><span class="line">                                                    CONCAT(LAT, LON)</span><br><span class="line">                                              FROM</span><br><span class="line">                                                    insurance</span><br><span class="line">                                              GROUP BY </span><br><span class="line">                                                    LAT , LON</span><br><span class="line">                                              HAVING COUNT(*) &#x3D; 1</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></div>

<h2 id="23-订单最多的客户"><a href="#23-订单最多的客户" class="headerlink" title="23. 订单最多的客户"></a>23. 订单最多的客户</h2><p>需求：在表 orders 中找到订单数最多客户对应的 customer_number 。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>customer_number</th>
</tr>
</thead>
<tbody><tr>
<td>3</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists orders (order_number int, customer_number int, order_date date, required_date date, shipped_date date, status char(15), comment char(200), key(order_number));</span><br><span class="line"></span><br><span class="line">insert into orders (order_number, customer_number) values (1, 1);</span><br><span class="line">insert into orders (order_number, customer_number) values (2, 2);</span><br><span class="line">insert into orders (order_number, customer_number) values (3, 3);</span><br><span class="line">insert into orders (order_number, customer_number) values (4, 3);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    customer_number</span><br><span class="line">FROM</span><br><span class="line">    orders</span><br><span class="line">GROUP BY </span><br><span class="line">    customer_number</span><br><span class="line">ORDER BY</span><br><span class="line">    COUNT(*) DESC</span><br><span class="line">LIMIT 1;</span><br></pre></td></tr></table></figure></div>

<p>进阶： 如果有多位顾客订单数并列最多，你能找到他们所有的 customer_number 吗？</p>
<h2 id="24-大的国家"><a href="#24-大的国家" class="headerlink" title="24. 大的国家"></a>24. 大的国家</h2><p>需求：编写一个SQL查询，输出表中所有大国家的名称、人口和面积。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>name</th>
<th>population</th>
<th>area</th>
</tr>
</thead>
<tbody><tr>
<td>Afghanistan</td>
<td>25500100</td>
<td>652230</td>
</tr>
<tr>
<td>Algeria</td>
<td>37100000</td>
<td>2381741</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists World (name varchar(255), continent varchar(255), area int, population int, gdp bigint);</span><br><span class="line"></span><br><span class="line">insert into World (name, continent, area, population, gdp) values (&#39;Afghanistan&#39;, &#39;Asia&#39;, 652230, 25500100, 20343000000);</span><br><span class="line">insert into World (name, continent, area, population, gdp) values (&#39;Albania&#39;, &#39;Europe&#39;, 28748, 2831741, 12960000000);</span><br><span class="line">insert into World (name, continent, area, population, gdp) values (&#39;Algeria&#39;, &#39;Africa&#39;, 2381741, 37100000, 188681000000);</span><br><span class="line">insert into World (name, continent, area, population, gdp) values (&#39;Andorra&#39;, &#39;Europe&#39;, 468, 78115, 3712000000);</span><br><span class="line">insert into World (name, continent, area, population, gdp) values (&#39;Angola&#39;, &#39;Africa&#39;, 1246700, 20609294, 100990000000);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一：or</span><br><span class="line">select </span><br><span class="line">      w.name,</span><br><span class="line">      w.population,</span><br><span class="line">      w.area</span><br><span class="line">from </span><br><span class="line">      world w</span><br><span class="line">where </span><br><span class="line">      w.area &gt;3000000 or w.population &gt;25000000</span><br><span class="line"></span><br><span class="line">#方法二：union</span><br><span class="line">select </span><br><span class="line">      w.name,</span><br><span class="line">      w.population,</span><br><span class="line">      w.area</span><br><span class="line">from </span><br><span class="line">      world w</span><br><span class="line">where </span><br><span class="line">      w.area&gt;3000000</span><br><span class="line">union</span><br><span class="line">select</span><br><span class="line">      w.name,</span><br><span class="line">      w.population,</span><br><span class="line">      w.area</span><br><span class="line">from </span><br><span class="line">      world w</span><br><span class="line">where </span><br><span class="line">      w.population&gt;25000000</span><br></pre></td></tr></table></figure></div>

<h2 id="25-超过五名学生的课"><a href="#25-超过五名学生的课" class="headerlink" title="25. 超过五名学生的课"></a>25. 超过五名学生的课</h2><p>需求：编写一个 SQL 查询，列出所有超过或等于5名学生的课。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>class</th>
</tr>
</thead>
<tbody><tr>
<td>Math</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists courses (student varchar(255), class varchar(255));</span><br><span class="line"></span><br><span class="line">insert into courses (student, class) values (&#39;A&#39;, &#39;Math&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;B&#39;, &#39;English&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;C&#39;, &#39;Math&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;D&#39;, &#39;Biology&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;E&#39;, &#39;Math&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;F&#39;, &#39;Computer&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;G&#39;, &#39;Math&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;H&#39;, &#39;Math&#39;);</span><br><span class="line">insert into courses (student, class) values (&#39;I&#39;, &#39;Math&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      class </span><br><span class="line">from </span><br><span class="line">      courses </span><br><span class="line">group by </span><br><span class="line">      class</span><br><span class="line">having </span><br><span class="line">      count(distinct student)&gt;&#x3D;5 ;</span><br></pre></td></tr></table></figure></div>

<h2 id="26-好友申请"><a href="#26-好友申请" class="headerlink" title="26. 好友申请"></a>26. 好友申请</h2><p>需求一：写一个查询语句，求出好友申请的通过率，用 2 位小数表示。通过率由接受好友申请的数目除以申请总数。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>accept_rate</th>
</tr>
</thead>
<tbody><tr>
<td>0.80</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists friend_request ( sender_id INT NOT NULL, send_to_id INT NULL, request_date DATE NULL);</span><br><span class="line">Create table If Not Exists request_accepted ( requester_id INT NOT NULL, accepter_id INT NULL, accept_date DATE NULL);</span><br><span class="line"></span><br><span class="line">insert into friend_request (sender_id, send_to_id, request_date) values (1, 2, &#39;2016&#x2F;06&#x2F;01&#39;);</span><br><span class="line">insert into friend_request (sender_id, send_to_id, request_date) values (1, 3, &#39;2016&#x2F;06&#x2F;01&#39;);</span><br><span class="line">insert into friend_request (sender_id, send_to_id, request_date) values (1, 4, &#39;2016&#x2F;06&#x2F;01&#39;);</span><br><span class="line">insert into friend_request (sender_id, send_to_id, request_date) values (2, 3, &#39;2016&#x2F;06&#x2F;02&#39;);</span><br><span class="line">insert into friend_request (sender_id, send_to_id, request_date) values (3, 4, &#39;2016&#x2F;06&#x2F;09&#39;);</span><br><span class="line"></span><br><span class="line">insert into request_accepted (requester_id, accepter_id, accept_date) values (1, 2, &#39;2016&#x2F;06&#x2F;03&#39;);</span><br><span class="line">insert into request_accepted (requester_id, accepter_id, accept_date) values (1, 3, &#39;2016&#x2F;06&#x2F;08&#39;);</span><br><span class="line">insert into request_accepted (requester_id, accepter_id, accept_date) values (2, 3, &#39;2016&#x2F;06&#x2F;08&#39;);</span><br><span class="line">insert into request_accepted (requester_id, accepter_id, accept_date) values (3, 4, &#39;2016&#x2F;06&#x2F;09&#39;);</span><br><span class="line">insert into request_accepted (requester_id, accepter_id, accept_date) values (3, 4, &#39;2016&#x2F;06&#x2F;10&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      round(</span><br><span class="line">            ifnull(</span><br><span class="line">                   (select count(*) from (select distinct requester_id, accepter_id from request_accepted) as A)</span><br><span class="line">                   &#x2F;</span><br><span class="line">                   (select count(*) from (select distinct sender_id, send_to_id from friend_request) as B)</span><br><span class="line">            , 0)</span><br><span class="line">      , 2) as accept_rate;</span><br></pre></td></tr></table></figure></div>



<p>需求二：写一个查询语句，求出谁拥有最多的好友和他拥有的好友数目。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>num</th>
</tr>
</thead>
<tbody><tr>
<td>3</td>
<td>3</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select ids as id, cnt as num</span><br><span class="line">from</span><br><span class="line">    (select</span><br><span class="line">           ids,</span><br><span class="line">           count(*) as cnt</span><br><span class="line">     from</span><br><span class="line">           (select </span><br><span class="line">                  requester_id as ids </span><br><span class="line">            from</span><br><span class="line">                  request_accepted</span><br><span class="line">            union all</span><br><span class="line">            select</span><br><span class="line">                  accepter_id </span><br><span class="line">            from</span><br><span class="line">                  request_accepted</span><br><span class="line">            ) as tbl1</span><br><span class="line">     group by ids</span><br><span class="line">     ) as tbl2</span><br><span class="line">order by </span><br><span class="line">     cnt desc</span><br><span class="line">limit 1;</span><br></pre></td></tr></table></figure></div>

<h2 id="27-体育馆人流量"><a href="#27-体育馆人流量" class="headerlink" title="27. 体育馆人流量"></a>27. 体育馆人流量</h2><p>需求：请编写一个查询语句，找出人流量的高峰期。高峰期时，至少连续三行记录中的人流量不少于100。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>visit_date</th>
<th>people</th>
</tr>
</thead>
<tbody><tr>
<td>5</td>
<td>2017-01-05</td>
<td>145</td>
</tr>
<tr>
<td>6</td>
<td>2017-01-06</td>
<td>1455</td>
</tr>
<tr>
<td>7</td>
<td>2017-01-07</td>
<td>199</td>
</tr>
<tr>
<td>8</td>
<td>2017-01-08</td>
<td>188</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists stadium (id int, visit_date DATE NULL, people int);</span><br><span class="line"></span><br><span class="line">insert into stadium (id, visit_date, people) values (1, &#39;2017-01-01&#39;, 10);</span><br><span class="line">insert into stadium (id, visit_date, people) values (2, &#39;2017-01-02&#39;, 109);</span><br><span class="line">insert into stadium (id, visit_date, people) values (3, &#39;2017-01-03&#39;, 150);</span><br><span class="line">insert into stadium (id, visit_date, people) values (4, &#39;2017-01-04&#39;, 99);</span><br><span class="line">insert into stadium (id, visit_date, people) values (5, &#39;2017-01-05&#39;, 145);</span><br><span class="line">insert into stadium (id, visit_date, people) values (6, &#39;2017-01-06&#39;, 1455);</span><br><span class="line">insert into stadium (id, visit_date, people) values (7, &#39;2017-01-07&#39;, 199);</span><br><span class="line">insert into stadium (id, visit_date, people) values (8, &#39;2017-01-08&#39;, 188);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">     distinct a.*</span><br><span class="line">FROM </span><br><span class="line">     stadium as a,</span><br><span class="line">     stadium as b,</span><br><span class="line">     stadium as c</span><br><span class="line">where</span><br><span class="line">     ((a.id &#x3D; b.id-1 and b.id+1 &#x3D; c.id) or(a.id-1 &#x3D; b.id and a.id+1 &#x3D; c.id) or(a.id-1 &#x3D; c.id and c.id-1 &#x3D; b.id))</span><br><span class="line">      and </span><br><span class="line">     (a.people&gt;&#x3D;100 and b.people&gt;&#x3D;100 and c.people&gt;&#x3D;100)</span><br><span class="line">order by </span><br><span class="line">     a.id;</span><br></pre></td></tr></table></figure></div>

<h2 id="28-连续空余座位"><a href="#28-连续空余座位" class="headerlink" title="28. 连续空余座位"></a>28. 连续空余座位</h2><p>需求：编写一个 SQL 查询，获取所有空余座位，并将它们按照 seat_id 排序</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>seat_id</th>
</tr>
</thead>
<tbody><tr>
<td>3</td>
</tr>
<tr>
<td>4</td>
</tr>
<tr>
<td>5</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists cinema (seat_id int primary key auto_increment, free bool);</span><br><span class="line"></span><br><span class="line">insert into cinema (seat_id, free) values (1, 1);</span><br><span class="line">insert into cinema (seat_id, free) values (2, 0);</span><br><span class="line">insert into cinema (seat_id, free) values (3, 1);</span><br><span class="line">insert into cinema (seat_id, free) values (4, 1);</span><br><span class="line">insert into cinema (seat_id, free) values (5, 1);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">     distinct a.seat_id</span><br><span class="line">from </span><br><span class="line">     cinema a </span><br><span class="line">join </span><br><span class="line">     cinema b</span><br><span class="line">on </span><br><span class="line">     abs(a.seat_id - b.seat_id) &#x3D; 1 and a.free &#x3D; true and b.free &#x3D; true</span><br><span class="line">order by </span><br><span class="line">     a.seat_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="29-销售员"><a href="#29-销售员" class="headerlink" title="29. 销售员"></a>29. 销售员</h2><p>需求：输出所有表 salesperson中，没有向公司 ‘RED’ 销售任何东西的销售员。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>name</th>
</tr>
</thead>
<tbody><tr>
<td>Amy</td>
</tr>
<tr>
<td>Mark</td>
</tr>
<tr>
<td>Alex</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists salesperson (sales_id int, name varchar(255), salary int,commission_rate int, hire_date varchar(255));</span><br><span class="line">Create table If Not Exists company (com_id int, name varchar(255), city varchar(255));</span><br><span class="line">Create table If Not Exists orders (order_id int, order_date varchar(255), com_id int, sales_id int, amount int);</span><br><span class="line"></span><br><span class="line">insert into salesperson (sales_id, name, salary, commission_rate, hire_date) values (1,&#39;John&#39;,100000, 6, &#39;4&#x2F;1&#x2F;2006&#39;);</span><br><span class="line">insert into salesperson (sales_id, name, salary, commission_rate, hire_date) values (2,&#39;Amy&#39;, 12000, 5, &#39;5&#x2F;1&#x2F;2010&#39;);</span><br><span class="line">insert into salesperson (sales_id, name, salary, commission_rate, hire_date) values (3,&#39;Mark&#39;,65000, 12, &#39;12&#x2F;25&#x2F;2008&#39;);</span><br><span class="line">insert into salesperson (sales_id, name, salary, commission_rate, hire_date) values (4,&#39;Pam&#39;, 25000, 25, &#39;1&#x2F;1&#x2F;2005&#39;);</span><br><span class="line">insert into salesperson (sales_id, name, salary, commission_rate, hire_date) values (5,&#39;Alex&#39;, 5000, 10, &#39;2&#x2F;3&#x2F;2007&#39;);</span><br><span class="line"></span><br><span class="line">insert into company (com_id, name, city) values (1, &#39;RED&#39;, &#39;Boston&#39;);</span><br><span class="line">insert into company (com_id, name, city) values (2, &#39;ORANGE&#39;, &#39;New York&#39;);</span><br><span class="line">insert into company (com_id, name, city) values (3, &#39;YELLOW&#39;, &#39;Boston&#39;);</span><br><span class="line">insert into company (com_id, name, city) values (4, &#39;GREEN&#39;, &#39;Austin&#39;);</span><br><span class="line"></span><br><span class="line">insert into orders (order_id, order_date, com_id, sales_id, amount) values (1, &#39;1&#x2F;1&#x2F;2014&#39;, 3, 4, 10000);</span><br><span class="line">insert into orders (order_id, order_date, com_id, sales_id, amount) values (2, &#39;2&#x2F;1&#x2F;2014&#39;, 4, 5, 5000);</span><br><span class="line">insert into orders (order_id, order_date, com_id, sales_id, amount) values (3, &#39;3&#x2F;1&#x2F;2014&#39;, 1, 1, 50000);</span><br><span class="line">insert into orders (order_id, order_date, com_id, sales_id, amount) values (4, &#39;4&#x2F;1&#x2F;2014&#39;, 1, 4, 25000);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    s.name</span><br><span class="line">FROM</span><br><span class="line">    salesperson s</span><br><span class="line">WHERE</span><br><span class="line">    s.sales_id NOT IN (</span><br><span class="line">                       SELECT</span><br><span class="line">                             o.sales_id</span><br><span class="line">                       FROM</span><br><span class="line">                             orders o</span><br><span class="line">                       LEFT JOIN</span><br><span class="line">                             company c </span><br><span class="line">                       ON</span><br><span class="line">                             o.com_id &#x3D; c.com_id</span><br><span class="line">                       WHERE</span><br><span class="line">                             c.name &#x3D; &#39;RED&#39;</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></div>

<h2 id="30-节点树"><a href="#30-节点树" class="headerlink" title="30. 节点树"></a>30. 节点树</h2><p>需求：写一个查询语句，输出所有节点的编号和节点的类型，并将结果按照节点编号排序。</p>
<p>表 tree，<strong>id</strong> 是树节点的编号， <strong>p_id</strong> 是它父节点的 <strong>id 。</strong></p>
<p>树中每个节点属于以下三种类型之一：</p>
<p>​        叶子：如果这个节点没有任何孩子节点。</p>
<p>​        根：如果这个节点是整棵树的根，即没有父节点。</p>
<p>​        内部节点：如果这个节点既不是叶子节点也不是根节点。</p>
<table>
<thead>
<tr>
<th>id</th>
<th>p_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>null</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
</tr>
</tbody></table>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>Type</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Root</td>
</tr>
<tr>
<td>2</td>
<td>Inner</td>
</tr>
<tr>
<td>3</td>
<td>Leaf</td>
</tr>
<tr>
<td>4</td>
<td>Leaf</td>
</tr>
<tr>
<td>5</td>
<td>Leaf</td>
</tr>
</tbody></table>
<p>解释:</p>
<p>节点 1 是根节点，因为它的父节点是 NULL ，同时它有孩子节点 2 和 3 。</p>
<p>节点 2 是内部节点，因为它有父节点 1 ，也有孩子节点 4 和 5 。</p>
<p>节点 3, 4 和 5 都是叶子节点，因为它们都有父节点同时没有孩子节点。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists tree (id int, p_id int);</span><br><span class="line"></span><br><span class="line">insert into tree (id, p_id) values (1, null);</span><br><span class="line">insert into tree (id, p_id) values (2, 1);</span><br><span class="line">insert into tree (id, p_id) values (3, 1);</span><br><span class="line">insert into tree (id, p_id) values (4, 2);</span><br><span class="line">insert into tree (id, p_id) values (5, 2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">方法一：</span><br><span class="line">SELECT</span><br><span class="line">    id, &#39;Root&#39; AS Type</span><br><span class="line">FROM</span><br><span class="line">    tree</span><br><span class="line">WHERE</span><br><span class="line">    p_id IS NULL</span><br><span class="line"></span><br><span class="line">UNION</span><br><span class="line"></span><br><span class="line">SELECT</span><br><span class="line">    id, &#39;Leaf&#39; AS Type</span><br><span class="line">FROM</span><br><span class="line">    tree</span><br><span class="line">WHERE</span><br><span class="line">    id NOT IN (SELECT DISTINCT</span><br><span class="line">            p_id</span><br><span class="line">        FROM</span><br><span class="line">            tree</span><br><span class="line">        WHERE</span><br><span class="line">            p_id IS NOT NULL)</span><br><span class="line">        AND p_id IS NOT NULL</span><br><span class="line"></span><br><span class="line">UNION</span><br><span class="line"></span><br><span class="line">SELECT</span><br><span class="line">    id, &#39;Inner&#39; AS Type</span><br><span class="line">FROM</span><br><span class="line">    tree</span><br><span class="line">WHERE</span><br><span class="line">    id IN (SELECT DISTINCT</span><br><span class="line">            p_id</span><br><span class="line">        FROM</span><br><span class="line">            tree</span><br><span class="line">        WHERE</span><br><span class="line">            p_id IS NOT NULL)</span><br><span class="line">        AND p_id IS NOT NULL</span><br><span class="line">ORDER BY id;</span><br><span class="line"></span><br><span class="line">方法二：</span><br><span class="line">SELECT</span><br><span class="line">      id AS &#96;Id&#96;,</span><br><span class="line">      CASE </span><br><span class="line">          WHEN tree.id &#x3D; (SELECT atree.id FROM tree atree WHERE atree.p_id IS NULL) THEN &#39;Root&#39;</span><br><span class="line">          WHEN tree.id IN (SELECT atree.p_id FROM tree atree) THEN &#39;Inner&#39;</span><br><span class="line">          ELSE &#39;Leaf&#39;</span><br><span class="line">      END AS Type</span><br><span class="line">FROM</span><br><span class="line">      tree</span><br><span class="line">ORDER BY &#96;Id&#96;;</span><br><span class="line"></span><br><span class="line">方法三：</span><br><span class="line">SELECT</span><br><span class="line">    atree.id,</span><br><span class="line">    IF(ISNULL(atree.p_id),&#39;Root&#39;, IF(atree.id IN (SELECT p_id FROM tree), &#39;Inner&#39;,&#39;Leaf&#39;)) Type</span><br><span class="line">FROM</span><br><span class="line">    tree atree</span><br><span class="line">ORDER BY atree.id;</span><br></pre></td></tr></table></figure></div>

<h2 id="31-判断是否是三角形"><a href="#31-判断是否是三角形" class="headerlink" title="31. 判断是否是三角形"></a>31. 判断是否是三角形</h2><p>需求：编写一个 SQL 查询，判断三条线段是否能形成一个三角形。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
<th>z</th>
<th>triangle</th>
</tr>
</thead>
<tbody><tr>
<td>13</td>
<td>15</td>
<td>15</td>
<td>No</td>
</tr>
<tr>
<td>10</td>
<td>20</td>
<td>15</td>
<td>Yes</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists triangle (x int, y int, z int);</span><br><span class="line"></span><br><span class="line">insert into triangle (x, y, z) values (13, 15, 30);</span><br><span class="line">insert into triangle (x, y, z) values (10, 20, 15);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      x,</span><br><span class="line">      y,</span><br><span class="line">      z,</span><br><span class="line">      if((x + y &lt;&#x3D; z or x + z &lt;&#x3D; y or y + z &lt;&#x3D; x), &quot;No&quot;, &quot;Yes&quot;) as triangle</span><br><span class="line">from triangle;</span><br></pre></td></tr></table></figure></div>

<h2 id="32-平面上的最近距离"><a href="#32-平面上的最近距离" class="headerlink" title="32. 平面上的最近距离"></a>32. 平面上的最近距离</h2><p>需求：写一个查询语句找到两点之间的最近距离，保留 2 位小数。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>shortest</th>
</tr>
</thead>
<tbody><tr>
<td>1.00</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE If Not Exists point_2d (x INT NOT NULL, y INT NOT NULL);</span><br><span class="line"></span><br><span class="line">insert into point_2d (x, y) values (-1, -1);</span><br><span class="line">insert into point_2d (x, y) values (0, 0);</span><br><span class="line">insert into point_2d (x, y) values (-1, -2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一：</span><br><span class="line">SELECT</span><br><span class="line">    ROUND(SQRT(MIN((POW(p1.x - p2.x, 2) + POW(p1.y - p2.y, 2)))), 2) AS shortest</span><br><span class="line">FROM</span><br><span class="line">    point_2d p1</span><br><span class="line">JOIN</span><br><span class="line">    point_2d p2 </span><br><span class="line">ON </span><br><span class="line">    p1.x !&#x3D; p2.x OR p1.y !&#x3D; p2.y;</span><br><span class="line"></span><br><span class="line">#方法二：</span><br><span class="line">SELECT</span><br><span class="line">    ROUND(SQRT(MIN((POW(p1.x - p2.x, 2) + POW(p1.y - p2.y, 2)))),2) AS shortest</span><br><span class="line">FROM</span><br><span class="line">    point_2d p1</span><br><span class="line">JOIN</span><br><span class="line">    point_2d p2 </span><br><span class="line">ON (p1.x &lt;&#x3D; p2.x AND p1.y &lt; p2.y) OR (p1.x &lt;&#x3D; p2.x AND p1.y &gt; p2.y) OR (p1.x &lt; p2.x AND p1.y &#x3D; p2.y);</span><br></pre></td></tr></table></figure></div>

<h2 id="33-直线上最近距离"><a href="#33-直线上最近距离" class="headerlink" title="33. 直线上最近距离"></a>33. 直线上最近距离</h2><p>需求：找到这些点中最近两个点之间的距离。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>shortest</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE If Not Exists point (x INT NOT NULL, UNIQUE INDEX x_UNIQUE (x ASC));</span><br><span class="line"></span><br><span class="line">insert into point (x) values (-1);</span><br><span class="line">insert into point (x) values (0);</span><br><span class="line">insert into point (x) values (2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    MIN(ABS(p1.x - p2.x)) AS shortest</span><br><span class="line">FROM</span><br><span class="line">    point p1</span><br><span class="line">JOIN</span><br><span class="line">    point p2 </span><br><span class="line">ON p1.x !&#x3D; p2.x;</span><br></pre></td></tr></table></figure></div>

<h2 id="34-二级关注者"><a href="#34-二级关注者" class="headerlink" title="34. 二级关注者"></a>34. 二级关注者</h2><p>需求：对每一个关注者(follower)，查询他的关注者数目。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>follower</th>
<th>num</th>
</tr>
</thead>
<tbody><tr>
<td>B</td>
<td>2</td>
</tr>
<tr>
<td>D</td>
<td>1</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists follow (followee varchar(255), follower varchar(255));</span><br><span class="line"></span><br><span class="line">insert into follow (followee, follower) values (&#39;A&#39;, &#39;B&#39;);</span><br><span class="line">insert into follow (followee, follower) values (&#39;B&#39;, &#39;C&#39;);</span><br><span class="line">insert into follow (followee, follower) values (&#39;B&#39;, &#39;D&#39;);</span><br><span class="line">insert into follow (followee, follower) values (&#39;D&#39;, &#39;E&#39;);</span><br></pre></td></tr></table></figure></div>

<p>解释：</p>
<p>以A为主体，A为被关注者，B为被关注者，求出关注B的关注者。这里需要注意，被关注者永远不会被他 / 她自己关注。<br>将结果按照字典序返回。</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      followee as &#39;follower&#39;,</span><br><span class="line">      count(distinct follower) as num</span><br><span class="line">from</span><br><span class="line">      follow</span><br><span class="line">where</span><br><span class="line">      followee in(select follower from follow)</span><br><span class="line">group by </span><br><span class="line">      1</span><br><span class="line">order by</span><br><span class="line">      1;</span><br></pre></td></tr></table></figure></div>

<h2 id="35-平均工资"><a href="#35-平均工资" class="headerlink" title="35. 平均工资"></a>35. 平均工资</h2><p>需求：写一个查询语句，求出在每一个工资发放日，每个部门的平均工资与公司的平均工资的比较结果 （高 / 低 / 相同）</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>pay_month</th>
<th>department_id</th>
<th>comparison</th>
</tr>
</thead>
<tbody><tr>
<td>2017-03</td>
<td>1</td>
<td>higher</td>
</tr>
<tr>
<td>2017-03</td>
<td>2</td>
<td>lower</td>
</tr>
<tr>
<td>2017-02</td>
<td>1</td>
<td>same</td>
</tr>
<tr>
<td>2017-02</td>
<td>2</td>
<td>same</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists salary (id int, employee_id int, amount int, pay_date date);</span><br><span class="line">Create table If Not Exists employee (employee_id int, department_id int);</span><br><span class="line"></span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (1, 1, 9000, &#39;2017&#x2F;03&#x2F;31&#39;);</span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (2, 2, 6000, &#39;2017&#x2F;03&#x2F;31&#39;);</span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (3, 3, 10000, &#39;2017&#x2F;03&#x2F;31&#39;);</span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (4, 1, 7000, &#39;2017&#x2F;02&#x2F;28&#39;);</span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (5, 2, 6000, &#39;2017&#x2F;02&#x2F;28&#39;);</span><br><span class="line">insert into salary (id, employee_id, amount, pay_date) values (6, 3, 8000, &#39;2017&#x2F;02&#x2F;28&#39;);</span><br><span class="line"></span><br><span class="line">insert into employee (employee_id, department_id) values (1, 1);</span><br><span class="line">insert into employee (employee_id, department_id) values (2, 2);</span><br><span class="line">insert into employee (employee_id, department_id) values (3, 2);</span><br></pre></td></tr></table></figure></div>

<p>解释:</p>
<p>在三月，公司的平均工资是 (9000+6000+10000)/3 = 8333.33…</p>
<p>由于部门 1 里只有一个 employee_id 为 1 的员工，所以部门 1 的平均工资就是此人的工资 9000 。因为 9000 &gt; 8333.33 ，所以比较结果是 ‘higher’。</p>
<p>第二个部门的平均工资为 employee_id 为 2 和 3 两个人的平均工资，为 (6000+10000)/2=8000 。因为 8000 &lt; 8333.33 ，所以比较结果是 ‘lower’ 。</p>
<p> 在二月用同样的公式求平均工资并比较，比较结果为 ‘same’ ，因为部门 1 和部门 2 的平均工资与公司的平均工资相同，都是 7000 。</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      department_salary.pay_month,</span><br><span class="line">      department_id,</span><br><span class="line">      case</span><br><span class="line">          when department_avg&gt;company_avg then &#39;higher&#39;</span><br><span class="line">          when department_avg&lt;company_avg then &#39;lower&#39;</span><br><span class="line">          else &#39;same&#39;</span><br><span class="line">      end as comparison</span><br><span class="line">from</span><br><span class="line">     (select</span><br><span class="line">            department_id,</span><br><span class="line">            avg(amount) as department_avg,</span><br><span class="line">            date_format(pay_date, &#39;%Y-%m&#39;) as pay_month</span><br><span class="line">      from </span><br><span class="line">            salary </span><br><span class="line">      join</span><br><span class="line">            employee</span><br><span class="line">      on  </span><br><span class="line">            salary.employee_id &#x3D; employee.employee_id</span><br><span class="line">     group by</span><br><span class="line">            department_id, pay_month</span><br><span class="line">     ) as department_salary</span><br><span class="line">join</span><br><span class="line">    (select</span><br><span class="line">           avg(amount) as company_avg,</span><br><span class="line">           date_format(pay_date, &#39;%Y-%m&#39;) as pay_month </span><br><span class="line">     from </span><br><span class="line">           salary</span><br><span class="line">     group by</span><br><span class="line">           date_format(pay_date, &#39;%Y-%m&#39;)</span><br><span class="line">     ) as company_salary</span><br><span class="line">on </span><br><span class="line">     department_salary.pay_month &#x3D; company_salary.pay_month;</span><br></pre></td></tr></table></figure></div>

<h2 id="36-学生地理信息报告"><a href="#36-学生地理信息报告" class="headerlink" title="36. 学生地理信息报告"></a>36. 学生地理信息报告</h2><p>需求：写一个查询语句实现对大洲（continent）列的 透视表 操作，使得每个学生按照姓名的字母顺序依次排列在对应的大洲下面。输出的标题应依次为美洲（America）、亚洲（Asia）和欧洲（Europe）。数据保证来自美洲的学生不少于来自亚洲或者欧洲的学生。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>America</th>
<th>Asia</th>
<th>Europe</th>
</tr>
</thead>
<tbody><tr>
<td>Jack</td>
<td>Xi</td>
<td>Pascal</td>
</tr>
<tr>
<td>Jane</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists student (name varchar(50), continent varchar(7));</span><br><span class="line"></span><br><span class="line">insert into student (name, continent) values (&#39;Jane&#39;, &#39;America&#39;);</span><br><span class="line">insert into student (name, continent) values (&#39;Pascal&#39;, &#39;Europe&#39;);</span><br><span class="line">insert into student (name, continent) values (&#39;Xi&#39;, &#39;Asia&#39;);</span><br><span class="line">insert into student (name, continent) values (&#39;Jack&#39;, &#39;America&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      MAX(if(A.continent &#x3D; &#39;America&#39;,A.NAME,NULL)) AS &#96;America&#96;,</span><br><span class="line">      MAX(if(A.continent &#x3D; &#39;Asia&#39;,A.NAME,NULL)) AS &#96;Asia&#96;,</span><br><span class="line">      MAX(if(A.continent &#x3D; &#39;Europe&#39;,A.NAME,NULL)) AS &#96;Europe&#96;</span><br><span class="line">FROM</span><br><span class="line">     (SELECT </span><br><span class="line">             S1.continent,</span><br><span class="line">             S1.NAME,</span><br><span class="line">             S1.row_id,</span><br><span class="line">             COUNT(*) AS &#96;trank&#96;</span><br><span class="line">	  FROM </span><br><span class="line">	        (SELECT</span><br><span class="line">                    S.*,</span><br><span class="line">                    @row_id:&#x3D;(@row_id + 1) AS &#96;row_id&#96;</span><br><span class="line">		     FROM</span><br><span class="line">                    student AS S,</span><br><span class="line">                    (SELECT @row_id:&#x3D;0) AS T</span><br><span class="line">             ) AS S1 </span><br><span class="line">	  JOIN </span><br><span class="line">	        (SELECT</span><br><span class="line">                    S.*,</span><br><span class="line">                    @n_row_id:&#x3D;(@n_row_id + 1) AS &#96;n_row_id&#96;</span><br><span class="line">		     FROM </span><br><span class="line">                    student AS S,</span><br><span class="line">                    (SELECT @n_row_id:&#x3D;0) AS T</span><br><span class="line">	         ) AS S2 </span><br><span class="line">	  ON </span><br><span class="line">            (S1.continent &#x3D; S2.continent AND</span><br><span class="line">            (S1.NAME &gt; S2.NAME OR (S1.NAME &#x3D; S2.NAME AND S1.row_id &gt;&#x3D; S2.n_row_id)))</span><br><span class="line">	  group BY</span><br><span class="line">             S1.continent,S1.NAME,S1.row_id</span><br><span class="line">	  order BY</span><br><span class="line">             S1.continent,S1.NAME</span><br><span class="line">      ) AS A</span><br><span class="line">GROUP BY </span><br><span class="line">      A.trank;</span><br></pre></td></tr></table></figure></div>

<h2 id="37-只出现一次的最大数字"><a href="#37-只出现一次的最大数字" class="headerlink" title="37. 只出现一次的最大数字"></a>37. 只出现一次的最大数字</h2><p>需求：编写一个 SQL 查询，找到只出现过一次的数字中，最大的一个数字。如果没有只出现一次的数字，输出 null 。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>num</th>
</tr>
</thead>
<tbody><tr>
<td>6</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists my_numbers (num int);</span><br><span class="line"></span><br><span class="line">insert into my_numbers (num) values (8);</span><br><span class="line">insert into my_numbers (num) values (8);</span><br><span class="line">insert into my_numbers (num) values (3);</span><br><span class="line">insert into my_numbers (num) values (3);</span><br><span class="line">insert into my_numbers (num) values (1);</span><br><span class="line">insert into my_numbers (num) values (4);</span><br><span class="line">insert into my_numbers (num) values (5);</span><br><span class="line">insert into my_numbers (num) values (6);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      ifnull((SELECT </span><br><span class="line">                    num</span><br><span class="line">              FROM </span><br><span class="line">                    my_numbers</span><br><span class="line">              group by </span><br><span class="line">                    num</span><br><span class="line">              having</span><br><span class="line">                    count(*) &#x3D; 1</span><br><span class="line">              order by </span><br><span class="line">                    num desc</span><br><span class="line">              limit 1), null) as num;</span><br></pre></td></tr></table></figure></div>

<h2 id="38-有趣的电影"><a href="#38-有趣的电影" class="headerlink" title="38. 有趣的电影"></a>38. 有趣的电影</h2><p>需求：编写一个 SQL 查询，找出所有影片描述为非 boring (不无聊) 的并且 id 为奇数 的影片，结果请按等级 rating 排列</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>movie</th>
<th>description</th>
<th>rating</th>
</tr>
</thead>
<tbody><tr>
<td>5</td>
<td>House card</td>
<td>Interesting</td>
<td>9.1</td>
</tr>
<tr>
<td>1</td>
<td>War</td>
<td>great 3D</td>
<td>8.9</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists cinema (id int, movie varchar(255), description varchar(255), rating float(2, 1));</span><br><span class="line"></span><br><span class="line">insert into cinema (id, movie, description, rating) values (1, &#39;War&#39;, &#39;great 3D&#39;, 8.9);</span><br><span class="line">insert into cinema (id, movie, description, rating) values (2, &#39;Science&#39;, &#39;fiction&#39;, 8.5);</span><br><span class="line">insert into cinema (id, movie, description, rating) values (3, &#39;irish&#39;, &#39;boring&#39;, 6.2);</span><br><span class="line">insert into cinema (id, movie, description, rating) values (4, &#39;Ice song&#39;, &#39;Fantacy&#39;, 8.6);</span><br><span class="line">insert into cinema (id, movie, description, rating) values (5, &#39;House card&#39;, &#39;Interesting&#39;, 9.1);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      id,</span><br><span class="line">      movie,</span><br><span class="line">      description,</span><br><span class="line">      rating</span><br><span class="line">from </span><br><span class="line">      cinema</span><br><span class="line">where </span><br><span class="line">      mod(id, 2) &#x3D; 1 and description !&#x3D; &#39;boring&#39;</span><br><span class="line">order by </span><br><span class="line">      rating DESC;</span><br></pre></td></tr></table></figure></div>

<h2 id="39-换座位"><a href="#39-换座位" class="headerlink" title="39. 换座位"></a>39. 换座位</h2><p>需求：编写一个 SQL 查询，小美是一所中学的信息科技老师，她有一张 seat 座位表，平时用来储存学生名字和与他们相对应的座位 id。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>student</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Doris</td>
</tr>
<tr>
<td>2</td>
<td>Abbot</td>
</tr>
<tr>
<td>3</td>
<td>Green</td>
</tr>
<tr>
<td>4</td>
<td>Emerson</td>
</tr>
<tr>
<td>5</td>
<td>Jeames</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists seat(id int, student varchar(255));</span><br><span class="line"></span><br><span class="line">insert into seat (id, student) values (1, &#39;Abbot&#39;);</span><br><span class="line">insert into seat (id, student) values (2, &#39;Doris&#39;);</span><br><span class="line">insert into seat (id, student) values (3, &#39;Emerson&#39;);</span><br><span class="line">insert into seat (id, student) values (4, &#39;Green&#39;);</span><br><span class="line">insert into seat (id, student) values (5, &#39;Jeames&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一</span><br><span class="line">select </span><br><span class="line">      a.id,</span><br><span class="line">      ifnull(b.student,a.student) as student </span><br><span class="line">from </span><br><span class="line">      seat as a </span><br><span class="line">left </span><br><span class="line">      join seat as b </span><br><span class="line">on </span><br><span class="line">      (a.id%2&#x3D;1 &amp;&amp; a.id&#x3D;b.id-1) || (a.id%2&#x3D;0 &amp;&amp; a.id&#x3D;b.id+1) </span><br><span class="line">order by </span><br><span class="line">      a.id;</span><br><span class="line"></span><br><span class="line">#方法二</span><br><span class="line">select </span><br><span class="line">      if(id%2&#x3D;0,id-1,if(id&#x3D;cnt,id,id+1)) as id,</span><br><span class="line">      student</span><br><span class="line">from </span><br><span class="line">      (select </span><br><span class="line">             count(*) as cnt</span><br><span class="line">       from </span><br><span class="line">             seat</span><br><span class="line">      )as a,</span><br><span class="line">      seat</span><br><span class="line">order by id;</span><br><span class="line"></span><br><span class="line">#方法三      </span><br><span class="line">select </span><br><span class="line">      b.id,</span><br><span class="line">      a.student</span><br><span class="line">from </span><br><span class="line">      seat as a,</span><br><span class="line">      seat as b,</span><br><span class="line">      (select</span><br><span class="line">             count(*) as cnt</span><br><span class="line">       from</span><br><span class="line">             seat</span><br><span class="line">      ) as c </span><br><span class="line">where </span><br><span class="line">      b.id&#x3D;1^(a.id-1)+1 || (c.cnt%2 &amp;&amp; b.id&#x3D;c.cnt &amp;&amp; a.id&#x3D;c.cnt);</span><br></pre></td></tr></table></figure></div>

<h2 id="40-交换工资"><a href="#40-交换工资" class="headerlink" title="40. 交换工资"></a>40. 交换工资</h2><p>需求：编写一个 SQL 查询，判断三条线段是否能形成一个三角形。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>sex</th>
<th>salary</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>A</td>
<td>f</td>
<td>2500</td>
</tr>
<tr>
<td>2</td>
<td>B</td>
<td>m</td>
<td>1500</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>f</td>
<td>5500</td>
</tr>
<tr>
<td>4</td>
<td>D</td>
<td>m</td>
<td>500</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table if not exists salary(id int, name varchar(100), sex char(1), salary int);</span><br><span class="line"></span><br><span class="line">insert into salary (id, name, sex, salary) values (1, &#39;A&#39;, &#39;m&#39;, 2500);</span><br><span class="line">insert into salary (id, name, sex, salary) values (2, &#39;B&#39;, &#39;f&#39;, 1500);</span><br><span class="line">insert into salary (id, name, sex, salary) values (3, &#39;C&#39;, &#39;m&#39;, 5500);</span><br><span class="line">insert into salary (id, name, sex, salary) values (4, &#39;D&#39;, &#39;f&#39;, 500);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UPDATE salary</span><br><span class="line">SET</span><br><span class="line">    sex &#x3D; CASE sex</span><br><span class="line">               WHEN &#39;m&#39; THEN &#39;f&#39;</span><br><span class="line">               ELSE &#39;m&#39;</span><br><span class="line">          END;</span><br></pre></td></tr></table></figure></div>

<h2 id="41-买下所有产品的用户"><a href="#41-买下所有产品的用户" class="headerlink" title="41. 买下所有产品的用户"></a>41. 买下所有产品的用户</h2><p>需求：编写一个 SQL 查询，从 Customer 表中查询购买了 Product 表中所有产品的客户的 id。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>customer_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
<tr>
<td>3</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Customer (customer_id int, product_key int)</span><br><span class="line">Create table Product (product_key int)</span><br><span class="line"></span><br><span class="line">insert into Customer (customer_id, product_key) values (1, 5)</span><br><span class="line">insert into Customer (customer_id, product_key) values (2, &#39;6&#39;)</span><br><span class="line">insert into Customer (customer_id, product_key) values (3, 5)</span><br><span class="line">insert into Customer (customer_id, product_key) values (3, &#39;6&#39;)</span><br><span class="line">insert into Customer (customer_id, product_key) values (1, &#39;6&#39;)</span><br><span class="line"></span><br><span class="line">insert into Product (product_key) values (5)</span><br><span class="line">insert into Product (product_key) values (&#39;6&#39;)</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select customer_id</span><br><span class="line">from </span><br><span class="line">(select customer_id,count(distinct product_key) as num </span><br><span class="line"> from Customer</span><br><span class="line"> group by customer_id</span><br><span class="line">) t</span><br><span class="line">join (</span><br><span class="line">    select count(product_key) as num</span><br><span class="line">    from Product</span><br><span class="line">) m </span><br><span class="line">on t.num &#x3D; m.num;</span><br></pre></td></tr></table></figure></div>

<h2 id="42-合作过至少三次的演员和导演"><a href="#42-合作过至少三次的演员和导演" class="headerlink" title="42. 合作过至少三次的演员和导演"></a>42. 合作过至少三次的演员和导演</h2><p>需求：编写一个 SQL 查询，查询语句获取合作过至少三次的演员和导演的 id 对 (actor_id, director_id)</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>actor_id</th>
<th>director_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>15</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists ActorDirector (actor_id int, director_id int, timestamp int);</span><br><span class="line"></span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (1, 1, 0);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (1, 1, 1);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (1, 1, 2);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (1, 2, 3);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (1, 2, 4);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (2, 1, 5);</span><br><span class="line">insert into ActorDirector (actor_id, director_id, timestamp) values (2, 1, 6);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      actor_id as ACTOR_ID ,</span><br><span class="line">      director_id as DIRECTOR_ID</span><br><span class="line">from </span><br><span class="line">      ActorDirector </span><br><span class="line">group by </span><br><span class="line">      actor_id,director_id </span><br><span class="line">having </span><br><span class="line">      count(*)&gt;&#x3D;3;</span><br></pre></td></tr></table></figure></div>

<h2 id="43-产品销售分析"><a href="#43-产品销售分析" class="headerlink" title="43. 产品销售分析"></a>43. 产品销售分析</h2><p>需求一：获取产品表 <code>Product</code> 中所有的 <strong>产品名称 product name</strong> 以及 该产品在 <code>Sales</code> 表中相对应的 <strong>上市年份 year</strong> 和 <strong>价格 price</strong>。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_name</th>
<th>year</th>
<th>price</th>
</tr>
</thead>
<tbody><tr>
<td>Nokia</td>
<td>2008</td>
<td>5000</td>
</tr>
<tr>
<td>Nokia</td>
<td>2009</td>
<td>5000</td>
</tr>
<tr>
<td>Apple</td>
<td>2011</td>
<td>9000</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table Sales (sale_id int, product_id int, year int, quantity int, price int);</span><br><span class="line">Create table Product (product_id int, product_name varchar(10));</span><br><span class="line"></span><br><span class="line">insert into Sales (sale_id, product_id, year, quantity, price) values (1, 100, 2008, 10, 5000);</span><br><span class="line">insert into Sales (sale_id, product_id, year, quantity, price) values (2, 100, 2009, 12, 5000);</span><br><span class="line">insert into Sales (sale_id, product_id, year, quantity, price) values (7, 200, 2011, 15, 9000);</span><br><span class="line"></span><br><span class="line">insert into Product (product_id, product_name) values (100, &#39;Nokia&#39;);</span><br><span class="line">insert into Product (product_id, product_name) values (200, &#39;Apple&#39;);</span><br><span class="line">insert into Product (product_id, product_name) values (300, &#39;Samsung&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      product_name,</span><br><span class="line">      year,</span><br><span class="line">      price</span><br><span class="line">from </span><br><span class="line">      Sales </span><br><span class="line">inner join </span><br><span class="line">      Product</span><br><span class="line">on</span><br><span class="line">      Sales.product_id &#x3D; Product.product_id;</span><br></pre></td></tr></table></figure></div>

<p>需求二：按产品 id product_id 来统计每个产品的销售总量。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_id</th>
<th>total_quantity</th>
</tr>
</thead>
<tbody><tr>
<td>100</td>
<td>22</td>
</tr>
<tr>
<td>200</td>
<td>15</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    product_id, </span><br><span class="line">    SUM(quantity) as total_quantity</span><br><span class="line">FROM</span><br><span class="line">    Sales</span><br><span class="line">GROUP BY</span><br><span class="line">    product_id;</span><br></pre></td></tr></table></figure></div>

<p>需求三：选出每个销售产品的 第一年 的 产品 id、年份、数量 和 价格。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_id</th>
<th>first_year</th>
<th>quantity</th>
<th>price</th>
</tr>
</thead>
<tbody><tr>
<td>100</td>
<td>2008</td>
<td>10</td>
<td>5000</td>
</tr>
<tr>
<td>200</td>
<td>2011</td>
<td>15</td>
<td>9000</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      product_id,</span><br><span class="line">      year as first_year, </span><br><span class="line">      quantity,</span><br><span class="line">      price</span><br><span class="line">from </span><br><span class="line">      Sales</span><br><span class="line">where </span><br><span class="line">     (product_id , year) in(</span><br><span class="line">                            select</span><br><span class="line">                                  product_id ,</span><br><span class="line">                                  min(year)</span><br><span class="line">                            from</span><br><span class="line">                                  Sales</span><br><span class="line">                            group by </span><br><span class="line">                                  product_id</span><br><span class="line">                            );</span><br></pre></td></tr></table></figure></div>

<h2 id="44-项目员工"><a href="#44-项目员工" class="headerlink" title="44. 项目员工"></a>44. 项目员工</h2><p>需求一：查询每一个项目中员工的平均工作年限，精确到小数点后两位。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>project_id</th>
<th>average_years</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2.00</td>
</tr>
<tr>
<td>2</td>
<td>2.50</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Project (project_id int, employee_id int);</span><br><span class="line">Create table If Not Exists Employee (employee_id int, name varchar(10), experience_years int);</span><br><span class="line"></span><br><span class="line">insert into Project (project_id, employee_id) values (1, 1);</span><br><span class="line">insert into Project (project_id, employee_id) values (1, 2);</span><br><span class="line">insert into Project (project_id, employee_id) values (1, 3);</span><br><span class="line">insert into Project (project_id, employee_id) values (2, 1);</span><br><span class="line">insert into Project (project_id, employee_id) values (2, 4);</span><br><span class="line"></span><br><span class="line">insert into Employee (employee_id, name, experience_years) values (1, &#39;Khaled&#39;, 3);</span><br><span class="line">insert into Employee (employee_id, name, experience_years) values (2, &#39;Ali&#39;, 2);</span><br><span class="line">insert into Employee (employee_id, name, experience_years) values (3, &#39;John&#39;, 1);</span><br><span class="line">insert into Employee (employee_id, name, experience_years) values (4, &#39;Doe&#39;, 2);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      project_id ,</span><br><span class="line">      round(avg(experience_years),2) as average_years</span><br><span class="line">from </span><br><span class="line">      Project</span><br><span class="line">left join </span><br><span class="line">      Employee</span><br><span class="line">on </span><br><span class="line">      Project.employee_id &#x3D; Employee.employee_id</span><br><span class="line">group by </span><br><span class="line">      project_id</span><br><span class="line">order by</span><br><span class="line">      project_id;</span><br></pre></td></tr></table></figure></div>

<p>需求二：报告所有雇员最多的项目。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>project_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      project_id</span><br><span class="line">FROM </span><br><span class="line">      Project</span><br><span class="line">GROUP BY </span><br><span class="line">      project_id</span><br><span class="line">HAVING </span><br><span class="line">      COUNT(employee_id) &#x3D; (SELECT</span><br><span class="line">                                  MAX(count_employee_id)</span><br><span class="line">                            FROM</span><br><span class="line">                                (SELECT </span><br><span class="line">                                       project_id,</span><br><span class="line">                                       COUNT(employee_id) AS count_employee_id</span><br><span class="line">                                 FROM</span><br><span class="line">                                       Project</span><br><span class="line">                                 GROUP BY </span><br><span class="line">                                       project_id</span><br><span class="line">                                ) As temp</span><br><span class="line">                           );</span><br></pre></td></tr></table></figure></div>

<p>需求三：报告在每一个项目中经验最丰富的雇员是谁。如果出现经验年数相同的情况，请报告所有具有最大经验年数的员工。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>project_id</th>
<th>employee_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      p.project_id,</span><br><span class="line">      p.employee_id</span><br><span class="line">from </span><br><span class="line">      Project p</span><br><span class="line">join </span><br><span class="line">      Employee e</span><br><span class="line">on </span><br><span class="line">      p.employee_id &#x3D; e.employee_id</span><br><span class="line">where </span><br><span class="line">     (p.project_id, e.experience_years) in (select</span><br><span class="line">                                                  p.project_id,</span><br><span class="line">                                                  max(e.experience_years)</span><br><span class="line">                                            from</span><br><span class="line">                                                  project p </span><br><span class="line">                                            join</span><br><span class="line">                                                  employee e</span><br><span class="line">                                            on </span><br><span class="line">                                                  p.employee_id &#x3D; e.employee_id</span><br><span class="line">                                            group by</span><br><span class="line">                                                  p.project_id</span><br><span class="line">                                           );</span><br></pre></td></tr></table></figure></div>

<h2 id="45-销售分析"><a href="#45-销售分析" class="headerlink" title="45. 销售分析"></a>45. 销售分析</h2><p>需求一：编写一个 SQL 查询，查询总销售额最高的销售者，如果有并列的，就都展示出来。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>seller_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
<tr>
<td>3</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Product (product_id int, product_name varchar(10), unit_price int);</span><br><span class="line">Create table If Not Exists Sales (seller_id int, product_id int,buyer_id int, sale_date date, quantity int, price int);</span><br><span class="line"></span><br><span class="line">insert into Product (product_id, product_name, unit_price) values (1, &#39;S8&#39;, 1000);</span><br><span class="line">insert into Product (product_id, product_name, unit_price) values (2, &#39;G4&#39;, 800);</span><br><span class="line">insert into Product (product_id, product_name, unit_price) values (3, &#39;iPhone&#39;, 1400);</span><br><span class="line"></span><br><span class="line">insert into Sales (seller_id, product_id, buyer_id, sale_date, quantity, price) values (1, 1, 1,&#39;2019-01-21&#39;, 2, 2000);</span><br><span class="line">insert into Sales (seller_id, product_id, buyer_id, sale_date, quantity, price) values (1, 2, 2,&#39;2019-02-17&#39;, 1, 800);</span><br><span class="line">insert into Sales (seller_id, product_id, buyer_id, sale_date, quantity, price) values (2, 1, 3,&#39;2019-06-02&#39;, 1, 800);</span><br><span class="line">insert into Sales (seller_id, product_id, buyer_id, sale_date, quantity, price) values (3, 3, 3,&#39;2019-05-13&#39;, 2, 2800);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      seller_id </span><br><span class="line">from </span><br><span class="line">      Sales</span><br><span class="line">group by </span><br><span class="line">      seller_id</span><br><span class="line">having </span><br><span class="line">      sum(price) &#x3D; (select</span><br><span class="line">                          sum(price) as ye_ji</span><br><span class="line">                    from  </span><br><span class="line">                          Sales</span><br><span class="line">                    group by</span><br><span class="line">                          seller_id</span><br><span class="line">                    order by </span><br><span class="line">                          ye_ji desc</span><br><span class="line">                    limit 1</span><br><span class="line">                   );</span><br></pre></td></tr></table></figure></div>

<p>需求二：编写一个 SQL 查询，查询购买了 S8 手机却没有购买 iPhone 的买家。注意这里 S8 和 iPhone 是 Product 表中的产品。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>buyer_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法一</span><br><span class="line">select </span><br><span class="line">      distinct buyer_id</span><br><span class="line">from </span><br><span class="line">      product p </span><br><span class="line">inner join </span><br><span class="line">      sales s</span><br><span class="line">on </span><br><span class="line">      p.product_id&#x3D;s.product_id</span><br><span class="line">where </span><br><span class="line">      product_name&#x3D;&#39;S8&#39; and buyer_id not in (select</span><br><span class="line">                                                    buyer_id</span><br><span class="line">                                              from</span><br><span class="line">                                                    product p</span><br><span class="line">                                              inner join</span><br><span class="line">                                                    sales s</span><br><span class="line">                                              on</span><br><span class="line">                                                    p.product_id&#x3D;s.product_id</span><br><span class="line">                                              where</span><br><span class="line">                                                    product_name&#x3D;&#39;iPhone&#39;</span><br><span class="line">                                              );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#方法二</span><br><span class="line">select </span><br><span class="line">      s8 as buyer_id</span><br><span class="line">from </span><br><span class="line">      (select </span><br><span class="line">             distinct buyer_id s8</span><br><span class="line">       from</span><br><span class="line">             product p </span><br><span class="line">       inner join </span><br><span class="line">             sales s</span><br><span class="line">       on</span><br><span class="line">             p.product_id&#x3D;s.product_id</span><br><span class="line">       where</span><br><span class="line">             product_name&#x3D;&#39;S8&#39;) t1</span><br><span class="line">left join</span><br><span class="line">      (select</span><br><span class="line">             distinct buyer_id ip</span><br><span class="line">       from</span><br><span class="line">             product p</span><br><span class="line">       inner join </span><br><span class="line">             sales s</span><br><span class="line">       on</span><br><span class="line">             p.product_id&#x3D;s.product_id</span><br><span class="line">       where</span><br><span class="line">             product_name&#x3D;&#39;iPhone&#39;</span><br><span class="line">      ) t2</span><br><span class="line">on </span><br><span class="line">       s8&#x3D;ip</span><br><span class="line">where </span><br><span class="line">       ip is null;</span><br></pre></td></tr></table></figure></div>

<p>需求三：编写一个 SQL 查询，报告2019年春季才售出的产品。即在2019-01-01至2019-03-31（含）之间。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_id</th>
<th>product_name</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>S8</td>
</tr>
<tr>
<td>2</td>
<td>G4</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      s.product_id,</span><br><span class="line">      product_name</span><br><span class="line">FROM </span><br><span class="line">      Sales s</span><br><span class="line">JOIN </span><br><span class="line">      Product p</span><br><span class="line">ON </span><br><span class="line">      s.product_id &#x3D; p.product_id</span><br><span class="line">GROUP BY </span><br><span class="line">      s.product_id</span><br><span class="line">HAVING </span><br><span class="line">      sale_date &gt;&#x3D; &#39;2019-01-01&#39; AND </span><br><span class="line">      sale_date &lt;&#x3D; &#39;2019-03-31&#39;;</span><br></pre></td></tr></table></figure></div>

<h2 id="46-小众书籍"><a href="#46-小众书籍" class="headerlink" title="46. 小众书籍"></a>46. 小众书籍</h2><p>需求：筛选出订单总量 少于10本 的 书籍 。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>book_id</th>
<th>name</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>“Kalila And Demna”</td>
</tr>
<tr>
<td>2</td>
<td>“28 Letters”</td>
</tr>
<tr>
<td>5</td>
<td>“The Hunger Games”</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Books (book_id int, name varchar(50), available_from date);</span><br><span class="line">Create table If Not Exists Orders (order_id int, book_id int, quantity int, dispatch_date date);</span><br><span class="line"></span><br><span class="line">insert into Books (book_id, name, available_from) values (1, &#39;Kalila And Demna&#39;, &#39;2010-01-01&#39;);</span><br><span class="line">insert into Books (book_id, name, available_from) values (2, &#39;28 Letters&#39;, &#39;2012-05-12&#39;);</span><br><span class="line">insert into Books (book_id, name, available_from) values (3, &#39;The Hobbit&#39;, &#39;2019-06-10&#39;);</span><br><span class="line">insert into Books (book_id, name, available_from) values (4, &#39;13 Reasons Why&#39;, &#39;2019-06-01&#39;);</span><br><span class="line">insert into Books (book_id, name, available_from) values (5, &#39;The Hunger Games&#39;, &#39;2008-09-21&#39;);</span><br><span class="line"></span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (1, 1, 2, &#39;2018-07-26&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (2, 1, 1, &#39;2018-11-05&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (3, 3, 8, &#39;2019-06-11&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (4, 4, 6, &#39;2019-06-05&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (5, 4, 5, &#39;2019-06-20&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (6, 5, 9, &#39;2009-02-02&#39;);</span><br><span class="line">insert into Orders (order_id, book_id, quantity, dispatch_date) values (7, 5, 8, &#39;2010-04-13&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      t1.book_id,</span><br><span class="line">      t1.name</span><br><span class="line">from </span><br><span class="line">      (select * from books where available_from &lt;date_sub(&#39;2019-06-23&#39;,interval 1 Month)) t1 </span><br><span class="line">left join </span><br><span class="line">      (select </span><br><span class="line">             *,</span><br><span class="line">             case</span><br><span class="line">                  when dispatch_date between &#39;2018-06-23&#39; and &#39;2019-06-23&#39; then quantity</span><br><span class="line">                  else 0 </span><br><span class="line">              end num </span><br><span class="line">       from orders</span><br><span class="line">      )  t2 </span><br><span class="line">on </span><br><span class="line">     t1.book_id&#x3D;t2.book_id </span><br><span class="line">group by </span><br><span class="line">     t1.book_id </span><br><span class="line">having </span><br><span class="line">     sum(if(t2.num is null,0,t2.num))&lt;10;</span><br></pre></td></tr></table></figure></div>

<h2 id="47-每日新用户统计"><a href="#47-每日新用户统计" class="headerlink" title="47. 每日新用户统计"></a>47. 每日新用户统计</h2><p>需求一：查询每一个项目中员工的平均工作年限，精确到小数点后两位。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>login_date</th>
<th>user_count</th>
</tr>
</thead>
<tbody><tr>
<td>2019-05-01</td>
<td>1</td>
</tr>
<tr>
<td>2019-06-21</td>
<td>2</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Traffic (user_id int, activity ENUM(&#39;login&#39;, &#39;logout&#39;, &#39;jobs&#39;, &#39;groups&#39;, &#39;homepage&#39;), activity_date date);</span><br><span class="line"></span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (1, &#39;login&#39;, &#39;2019-05-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (1, &#39;homepage&#39;, &#39;2019-05-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (1, &#39;logout&#39;, &#39;2019-05-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (2, &#39;login&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (2, &#39;logout&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (3, &#39;login&#39;, &#39;2019-01-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (3, &#39;jobs&#39;, &#39;2019-01-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (3, &#39;logout&#39;, &#39;2019-01-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (4, &#39;login&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (4, &#39;groups&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (4, &#39;logout&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (5, &#39;login&#39;, &#39;2019-03-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (5, &#39;logout&#39;, &#39;2019-03-01&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (5, &#39;login&#39;, &#39;2019-06-21&#39;);</span><br><span class="line">insert into Traffic (user_id, activity, activity_date) values (5, &#39;logout&#39;, &#39;2019-06-21&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">    minx as login_date,</span><br><span class="line">    count(user_id) as user_count</span><br><span class="line">from </span><br><span class="line">   (select </span><br><span class="line">          user_id,</span><br><span class="line">          min(activity_date) as minx</span><br><span class="line">    from </span><br><span class="line">          Traffic</span><br><span class="line">    where</span><br><span class="line">          activity&#x3D;&#39;login&#39;</span><br><span class="line">    group by </span><br><span class="line">          user_id</span><br><span class="line">    having </span><br><span class="line">          datediff(&#39;2019-06-30&#39;,minx)&lt;&#x3D;90</span><br><span class="line">    )s</span><br><span class="line">group by </span><br><span class="line">    minx;</span><br></pre></td></tr></table></figure></div>

<h2 id="48-每位学生的最高成绩"><a href="#48-每位学生的最高成绩" class="headerlink" title="48. 每位学生的最高成绩"></a>48. 每位学生的最高成绩</h2><p>需求一：查询每一个项目中员工的平均工作年限，精确到小数点后两位。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>student_id</th>
<th>average_years</th>
<th>grade</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2</td>
<td>99</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>95</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>82</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Enrollments (student_id int, course_id int, grade int);</span><br><span class="line"></span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (2, 2, 95);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (2, 3, 95);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (1, 1, 90);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (1, 2, 99);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (3, 1, 80);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (3, 2, 75);</span><br><span class="line">insert into Enrollments (student_id, course_id, grade) values (3, 3, 82);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      t.student_id,</span><br><span class="line">      if(count(e.grade) &gt; 1 ,min(e.course_id),course_id) as course_id,</span><br><span class="line">      t.max1 as grade</span><br><span class="line">from </span><br><span class="line">      Enrollments e </span><br><span class="line">right join</span><br><span class="line">     (select</span><br><span class="line">            student_id,</span><br><span class="line">            max(grade) as max1 </span><br><span class="line">      from </span><br><span class="line">            Enrollments</span><br><span class="line">      group by</span><br><span class="line">            student_id </span><br><span class="line">     )t</span><br><span class="line">on</span><br><span class="line">      t.student_id&#x3D;e.student_id and</span><br><span class="line">      t.max1 &#x3D; e.grade</span><br><span class="line">group by </span><br><span class="line">      e.student_id </span><br><span class="line">order by</span><br><span class="line">      t.student_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="49-Reported-Posts"><a href="#49-Reported-Posts" class="headerlink" title="49. Reported Posts"></a>49. Reported Posts</h2><p>需求一：Write an SQL query that reports the number of posts reported yesterday for each report reason. Assume today is 2019-07-05.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>report_reason</th>
<th>report_count</th>
</tr>
</thead>
<tbody><tr>
<td>spam</td>
<td>1</td>
</tr>
<tr>
<td>racism</td>
<td>2</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Actions (user_id int, post_id int, action_date date, action ENUM(&#39;view&#39;, &#39;like&#39;, &#39;reaction&#39;, &#39;comment&#39;, &#39;report&#39;, &#39;share&#39;), extra varchar(10));</span><br><span class="line"></span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (1, 1, &#39;2019-07-01&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (1, 1, &#39;2019-07-01&#39;, &#39;like&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (1, 1, &#39;2019-07-01&#39;, &#39;share&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (2, 4, &#39;2019-07-04&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (2, 4, &#39;2019-07-04&#39;, &#39;report&#39;, &#39;spam&#39;);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (3, 4, &#39;2019-07-04&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (3, 4, &#39;2019-07-04&#39;, &#39;report&#39;, &#39;spam&#39;);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (4, 3, &#39;2019-07-02&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (4, 3, &#39;2019-07-02&#39;, &#39;report&#39;, &#39;spam&#39;);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (5, 2, &#39;2019-07-04&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (5, 2, &#39;2019-07-04&#39;, &#39;report&#39;, &#39;racism&#39;);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (5, 5, &#39;2019-07-04&#39;, &#39;view&#39;, null);</span><br><span class="line">insert into Actions (user_id, post_id, action_date, action, extra) values (5, 5, &#39;2019-07-04&#39;, &#39;report&#39;, &#39;racism&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      extra report_reason,</span><br><span class="line">      count(distinct post_id) report_count </span><br><span class="line">from </span><br><span class="line">      Actions </span><br><span class="line">where </span><br><span class="line">      datediff(&#39;2019-07-05&#39;, action_date) &#x3D; 1 and</span><br><span class="line">      extra is not null and</span><br><span class="line">      action &#x3D; &#39;report&#39; </span><br><span class="line">group by</span><br><span class="line">      extra;</span><br></pre></td></tr></table></figure></div>

<p>需求二：Write an SQL query to find the average for daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>average_daily_percent</th>
</tr>
</thead>
<tbody><tr>
<td>50.00</td>
</tr>
</tbody></table>
<p>The percentage for 2019-07-04 is 50% because only one post of two spam reported posts was removed.<br>The percentage for 2019-07-02 is 100% because one post was reported as spam and it was removed.<br>The other days had no spam reports so the average is (50 + 100) / 2 = 75%<br>Note that the output is only one number and that we do not care about the remove dates.</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table if not exists Removals (post_id int, remove_date date);</span><br><span class="line"></span><br><span class="line">insert into Removals (post_id, remove_date) values (2, &#39;2019-07-20&#39;);</span><br><span class="line">insert into Removals (post_id, remove_date) values (3, &#39;2019-07-18&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      round(</span><br><span class="line">             SUM(delCount &#x2F; spamCount * 100) </span><br><span class="line">             &#x2F;</span><br><span class="line">             COUNT(DISTINCT action_date),</span><br><span class="line">          2) AS average_daily_percent</span><br><span class="line">FROM </span><br><span class="line">     (SELECT</span><br><span class="line">             action_date,</span><br><span class="line">             COUNT(distinct a.post_id) AS spamCount, </span><br><span class="line">             count(distinct b.post_id) AS delCount</span><br><span class="line">	  FROM</span><br><span class="line">             Actions a</span><br><span class="line">      LEFT JOIN</span><br><span class="line">             Removals b </span><br><span class="line">      ON </span><br><span class="line">             a.post_id &#x3D; b.post_id</span><br><span class="line">      where</span><br><span class="line">             a.extra &#x3D; &#39;spam&#39;</span><br><span class="line">	  GROUP BY </span><br><span class="line">             a.action_date</span><br><span class="line">     ) a;</span><br></pre></td></tr></table></figure></div>

<h2 id="50-Active-Businesses"><a href="#50-Active-Businesses" class="headerlink" title="50. Active Businesses"></a>50. Active Businesses</h2><p>需求：Write an SQL query to find all active businesses. An active business is a business that has more than one event type with occurences greater than the average occurences of that event type among all businesses.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>business_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
</tr>
</tbody></table>
<p>Average for ‘reviews’, ‘ads’ and ‘page views’ are (7+3)/2=5, (11+7+6)/3=8, (3+12)/2=7.5 respectively.<br>Business with id 1 has 7 ‘reviews’ events (more than 5) and 11 ‘ads’ events (more than 8) so it is an active business.</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Events (business_id int, event_type varchar(10), occurences int);</span><br><span class="line"></span><br><span class="line">insert into Events (business_id, event_type, occurences) values (1, &#39;reviews&#39;, 7);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (3, &#39;reviews&#39;, 3);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (1, &#39;ads&#39;, 11);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (2, &#39;ads&#39;, 7);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (3, &#39;ads&#39;, 6);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (1, &#39;page views&#39;, 3);</span><br><span class="line">insert into Events (business_id, event_type, occurences) values (2, &#39;page views&#39;, 12);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      DISTINCT(business_id) </span><br><span class="line">FROM </span><br><span class="line">      Events e </span><br><span class="line">LEFT JOIN</span><br><span class="line">      Events tmp</span><br><span class="line">ON    </span><br><span class="line">      e.event_type &#x3D; tmp.event_type </span><br><span class="line">WHERE</span><br><span class="line">      e.occurences &gt; tmp.avg_count</span><br><span class="line">GROUP BY </span><br><span class="line">      business_id</span><br><span class="line">HAVING </span><br><span class="line">      COUNT(1) &gt; 1</span><br></pre></td></tr></table></figure></div>

<h2 id="51-User-Purchase-Platform"><a href="#51-User-Purchase-Platform" class="headerlink" title="51. User Purchase Platform"></a>51. User Purchase Platform</h2><p>需求一：Write an SQL query to find the total number of users and the total amount spent using mobile only, desktop only and both mobile and desktop together for each date.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>spend_date</th>
<th>platform</th>
<th>total_amount</th>
<th>total_users</th>
</tr>
</thead>
<tbody><tr>
<td>2019-07-01</td>
<td>desktop</td>
<td>100</td>
<td>1</td>
</tr>
<tr>
<td>2019-07-01</td>
<td>mobile</td>
<td>100</td>
<td>1</td>
</tr>
<tr>
<td>2019-07-01</td>
<td>both</td>
<td>200</td>
<td>1</td>
</tr>
<tr>
<td>2019-07-02</td>
<td>desktop</td>
<td>100</td>
<td>1</td>
</tr>
<tr>
<td>2019-07-02</td>
<td>mobile</td>
<td>100</td>
<td>1</td>
</tr>
<tr>
<td>2019-07-02</td>
<td>both</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Spending (user_id int, spend_date date, platform ENUM(&#39;desktop&#39;, &#39;mobile&#39;), amount int);</span><br><span class="line"></span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (1, &#39;2019-07-01&#39;, &#39;mobile&#39;, 100);</span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (1, &#39;2019-07-01&#39;, &#39;desktop&#39;, 100);</span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (2, &#39;2019-07-01&#39;, &#39;mobile&#39;, 100);</span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (2, &#39;2019-07-02&#39;, &#39;mobile&#39;, 100);</span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (3, &#39;2019-07-01&#39;, &#39;desktop&#39;, 100);</span><br><span class="line">insert into Spending (user_id, spend_date, platform, amount) values (3, &#39;2019-07-02&#39;, &#39;desktop&#39;, 100);</span><br></pre></td></tr></table></figure></div>

<p>On 2019-07-01, user 1 purchased using both desktop and mobile, user 2 purchased using mobile only and user 3 purchased using desktop only.<br>On 2019-07-02, user 2 purchased using mobile only, user 3 purchased using desktop only and no one purchased using both platforms.</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      temp1.spend_date,</span><br><span class="line">      temp1.platform, </span><br><span class="line">      ifnull(temp3.total_amount, 0) total_amount, </span><br><span class="line">      ifnull(temp3.total_users,0) total_users</span><br><span class="line">from</span><br><span class="line">     (select</span><br><span class="line">            distinct(spend_date),</span><br><span class="line">            p.platform   </span><br><span class="line">      from </span><br><span class="line">            Spending,</span><br><span class="line">           (select</span><br><span class="line">                  &#39;desktop&#39; as platform union</span><br><span class="line">            select </span><br><span class="line">                  &#39;mobile&#39; as platform union</span><br><span class="line">            select</span><br><span class="line">                  &#39;both&#39; as platform</span><br><span class="line">           ) as p </span><br><span class="line">       ) as temp1</span><br><span class="line">left join </span><br><span class="line">      (select</span><br><span class="line">             spend_date,</span><br><span class="line">             platform,</span><br><span class="line">             sum(amount) as total_amount,</span><br><span class="line">             count(user_id) total_users</span><br><span class="line">       from</span><br><span class="line">            (select</span><br><span class="line">                   spend_date,</span><br><span class="line">                   user_id, </span><br><span class="line">                   case count(distinct platform)</span><br><span class="line">                        when 1 then platform</span><br><span class="line">                        when 2 then &#39;both&#39;</span><br><span class="line">                   end as  platform, </span><br><span class="line">                   sum(amount) as amount</span><br><span class="line">             from </span><br><span class="line">                   Spending</span><br><span class="line">             group by</span><br><span class="line">                   spend_date,</span><br><span class="line">                   user_id</span><br><span class="line">            ) as temp2</span><br><span class="line">      group by</span><br><span class="line">             spend_date,</span><br><span class="line">             platform</span><br><span class="line">      ) as  temp3</span><br><span class="line">on </span><br><span class="line">      temp1.platform &#x3D; temp3.platform and</span><br><span class="line">      temp1.spend_date &#x3D; temp3.spend_date;</span><br></pre></td></tr></table></figure></div>

<h2 id="52-User-Activity-for-the-Past-30-Days"><a href="#52-User-Activity-for-the-Past-30-Days" class="headerlink" title="52. User Activity for the Past 30 Days"></a>52. User Activity for the Past 30 Days</h2><p>需求一：Write an SQL query to find the average for daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>day</th>
<th>active_users</th>
</tr>
</thead>
<tbody><tr>
<td>2019-07-20</td>
<td>2</td>
</tr>
<tr>
<td>2019-07-21</td>
<td>2</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Activity (user_id int, session_id int, activity_date date, activity_type ENUM(&#39;open_session&#39;, &#39;end_session&#39;, &#39;scroll_down&#39;, &#39;send_message&#39;));</span><br><span class="line"></span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (1, 1, &#39;2019-07-20&#39;, &#39;open_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (1, 1, &#39;2019-07-20&#39;, &#39;scroll_down&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (1, 1, &#39;2019-07-20&#39;, &#39;end_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (2, 4, &#39;2019-07-20&#39;, &#39;open_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (2, 4, &#39;2019-07-21&#39;, &#39;send_message&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (2, 4, &#39;2019-07-21&#39;, &#39;end_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (3, 2, &#39;2019-07-21&#39;, &#39;open_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (3, 2, &#39;2019-07-21&#39;, &#39;send_message&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (3, 2, &#39;2019-07-21&#39;, &#39;end_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (4, 3, &#39;2019-06-25&#39;, &#39;open_session&#39;);</span><br><span class="line">insert into Activity (user_id, session_id, activity_date, activity_type) values (4, 3, &#39;2019-06-25&#39;, &#39;end_session&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      t.activity_date as day,</span><br><span class="line">      count(distinct t.user_id) as active_users</span><br><span class="line">from </span><br><span class="line">     (select </span><br><span class="line">            activity_date,</span><br><span class="line">            user_id</span><br><span class="line">      from</span><br><span class="line">            Activity</span><br><span class="line">      where </span><br><span class="line">            datediff(&#39;2019-07-27&#39;,activity_date) &lt;30 and</span><br><span class="line">            datediff( &#39;2019-07-27&#39;, activity_date) &gt;&#x3D;0</span><br><span class="line">      group by</span><br><span class="line">            user_id,</span><br><span class="line">            activity_date</span><br><span class="line">      having </span><br><span class="line">            count(activity_type)&gt;0</span><br><span class="line">     ) as t</span><br><span class="line">group by </span><br><span class="line">      t.activity_date;</span><br></pre></td></tr></table></figure></div>

<p>需求二：编写SQL查询以查找截至2019年7月27日（含）的30天内每个用户的平均会话数，四舍五入到小数点后两位。我们要为用户计算的会话是在该时间段内至少进行了一项活动的会话。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>average_sessions_per_user</th>
</tr>
</thead>
<tbody><tr>
<td>1.00</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      ROUND(IFNULL(AVG(count_session_id), 0), 2) AS average_sessions_per_user</span><br><span class="line">FROM</span><br><span class="line">     (SELECT</span><br><span class="line">            COUNT(DISTINCT session_id) AS count_session_id</span><br><span class="line">      FROM</span><br><span class="line">            Activity</span><br><span class="line">      WHERE </span><br><span class="line">            activity_date BETWEEN DATE_SUB(&quot;2019-07-27&quot;, INTERVAL 29 DAY) AND &quot;2019-07-27&quot;</span><br><span class="line">      GROUP BY</span><br><span class="line">            user_id</span><br><span class="line">      ) AS temp;</span><br></pre></td></tr></table></figure></div>

<h2 id="52-文章浏览"><a href="#52-文章浏览" class="headerlink" title="52. 文章浏览"></a>52. 文章浏览</h2><p>需求一：查询每一个项目中员工的平均工作年限，精确到小数点后两位。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
</tr>
</thead>
<tbody><tr>
<td>4</td>
</tr>
<tr>
<td>7</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Views (article_id int, author_id int, viewer_id int, view_date date);</span><br><span class="line">Truncate table Views;</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (1, 3, 5, &#39;2019-08-01&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (3, 4, 5, &#39;2019-08-01&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (1, 3, &#39;6&#39;, &#39;2019-08-02&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (2, &#39;7&#39;, &#39;7&#39;, &#39;2019-08-01&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (2, &#39;7&#39;, &#39;6&#39;, &#39;2019-08-02&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (4, &#39;7&#39;, 1, &#39;2019-07-22&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (3, 4, 4, &#39;2019-07-21&#39;);</span><br><span class="line">insert into Views (article_id, author_id, viewer_id, view_date) values (3, 4, 4, &#39;2019-07-21&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      distinct viewer_id as id</span><br><span class="line">from </span><br><span class="line">      Views </span><br><span class="line">where </span><br><span class="line">      viewer_id &#x3D; author_id</span><br><span class="line">order by </span><br><span class="line">      viewer_id;</span><br></pre></td></tr></table></figure></div>

<p>需求二：Write an SQL query to find all the people who viewed more than one article on the same date, sorted in ascending order by their id.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>project_id</th>
</tr>
</thead>
<tbody><tr>
<td>5</td>
</tr>
<tr>
<td>6</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      DISTINCT viewer_id as id </span><br><span class="line">FROM </span><br><span class="line">      views</span><br><span class="line">GROUP BY </span><br><span class="line">      viewer_id,view_date</span><br><span class="line">HAVING</span><br><span class="line">      COUNT(DISTINCT article_id)&gt;&#x3D;2</span><br><span class="line">ORDER BY </span><br><span class="line">      viewer_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="53-Market-Analysis"><a href="#53-Market-Analysis" class="headerlink" title="53. Market Analysis"></a>53. Market Analysis</h2><p>需求一：Write an SQL query to find for each user, the join date and the number of orders they made as a buyer in 2019.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>buyer_id</th>
<th>join_date</th>
<th>orders_in_2019</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2018-01-01</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2018-02-09</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>2018-01-19</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>2018-05-21</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Users (user_id int, join_date date, favorite_brand varchar(10));</span><br><span class="line">create table if not exists Orders (order_id int, order_date date, item_id int, buyer_id int, seller_id int);</span><br><span class="line">create table if not exists Items (item_id int, item_brand varchar(10));</span><br><span class="line"></span><br><span class="line">insert into Users (user_id, join_date, favorite_brand) values (1, &#39;2018-01-01&#39;, &#39;Lenovo&#39;);</span><br><span class="line">insert into Users (user_id, join_date, favorite_brand) values (2, &#39;2018-02-09&#39;, &#39;Samsung&#39;);</span><br><span class="line">insert into Users (user_id, join_date, favorite_brand) values (3, &#39;2018-01-19&#39;, &#39;LG&#39;);</span><br><span class="line">insert into Users (user_id, join_date, favorite_brand) values (4, &#39;2018-05-21&#39;, &#39;HP&#39;);</span><br><span class="line"></span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (1, &#39;2019-08-01&#39;, 4, 1, 2);</span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (2, &#39;2018-08-02&#39;, 2, 1, 3);</span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (3, &#39;2019-08-03&#39;, 3, 2, 3);</span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (4, &#39;2018-08-04&#39;, 1, 4, 2);</span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (5, &#39;2018-08-04&#39;, 1, 3, 4);</span><br><span class="line">insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (6, &#39;2019-08-05&#39;, 2, 2, 4);</span><br><span class="line"></span><br><span class="line">insert into Items (item_id, item_brand) values (1, &#39;Samsung&#39;);</span><br><span class="line">insert into Items (item_id, item_brand) values (2, &#39;Lenovo&#39;);</span><br><span class="line">insert into Items (item_id, item_brand) values (3, &#39;LG&#39;);</span><br><span class="line">insert into Items (item_id, item_brand) values (4, &#39;HP&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">       user_id AS buyer_id,</span><br><span class="line">       join_date,</span><br><span class="line">       IFNULL(COUNT(buyer_Id), 0) AS orders_in_2019</span><br><span class="line">FROM </span><br><span class="line">       Users u </span><br><span class="line">LEFT JOIN</span><br><span class="line">       Orders o</span><br><span class="line">ON  </span><br><span class="line">       U.user_id &#x3D; o.buyer_id AND</span><br><span class="line">       order_date &gt;&#x3D; &#39;2019-01-01&#39;</span><br><span class="line">GROUP BY</span><br><span class="line">       user_id</span><br><span class="line">ORDER BY</span><br><span class="line">       user_id;</span><br></pre></td></tr></table></figure></div>

<p>需求二：Write an SQL query to find for each user, whether the brand of the second item (by date) they sold is their favorite brand. If a user sold less than two items, report the answer for that user as no.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_id</th>
<th>2nd_item_fav_brand</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>no</td>
</tr>
<tr>
<td>2</td>
<td>no</td>
</tr>
<tr>
<td>3</td>
<td>yes</td>
</tr>
<tr>
<td>4</td>
<td>no</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      user_id as seller_id,</span><br><span class="line">      case</span><br><span class="line">         when t3.item_brand is null then &#39;no&#39;</span><br><span class="line">         when t3.item_brand &#x3D; u.favorite_brand then &#39;yes&#39;</span><br><span class="line">         else &#39;no&#39; </span><br><span class="line">      end as 2nd_item_fav_brand</span><br><span class="line">from </span><br><span class="line">      Users u</span><br><span class="line">left join </span><br><span class="line">     (select</span><br><span class="line">            order_id,</span><br><span class="line">            order_date,</span><br><span class="line">            t2.item_id,</span><br><span class="line">            buyer_id,</span><br><span class="line">            seller_id,</span><br><span class="line">            i.item_brand as item_brand</span><br><span class="line">      from </span><br><span class="line">           (select</span><br><span class="line">                  order_id,</span><br><span class="line">                  order_date,</span><br><span class="line">                  item_id,</span><br><span class="line">                  buyer_id,</span><br><span class="line">                  seller_id,</span><br><span class="line">                  cast(if(@prev &#x3D; seller_id,@rank :&#x3D; @rank + 1,@rank :&#x3D; 1) as unsigned) as rank,</span><br><span class="line">                  @prev :&#x3D; seller_id as prev</span><br><span class="line">            from </span><br><span class="line">                 (select</span><br><span class="line">                         order_id,</span><br><span class="line">                         order_date,</span><br><span class="line">                         item_id,</span><br><span class="line">                         buyer_id,</span><br><span class="line">                         seller_id</span><br><span class="line">                  from</span><br><span class="line">                         Orders</span><br><span class="line">                  group by</span><br><span class="line">                         seller_id,</span><br><span class="line">                         order_date</span><br><span class="line">                 ) as t1,</span><br><span class="line">                 (select </span><br><span class="line">                         @rank :&#x3D; 0,</span><br><span class="line">                         @prev :&#x3D; null</span><br><span class="line">                 ) as init) t2,</span><br><span class="line">                 Items i</span><br><span class="line">            where</span><br><span class="line">                  rank &#x3D; 2 and</span><br><span class="line">                  t2.item_id &#x3D; i.item_id</span><br><span class="line">     ) as t3</span><br><span class="line">on </span><br><span class="line">       u.user_id &#x3D; t3.seller_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="54-Product-Price-at-a-Given-Date"><a href="#54-Product-Price-at-a-Given-Date" class="headerlink" title="54. Product Price at a Given Date"></a>54. Product Price at a Given Date</h2><p>需求一：Write an SQL query to find the prices of all products on 2019-08-16. Assume the price of all products before any change is 10.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>project_id</th>
<th>price</th>
</tr>
</thead>
<tbody><tr>
<td>2</td>
<td>50</td>
</tr>
<tr>
<td>1</td>
<td>35</td>
</tr>
<tr>
<td>3</td>
<td>10</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Products (product_id int, new_price int, change_date date);</span><br><span class="line">Truncate table Products;</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (1, 20, &#39;2019-08-14&#39;);</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (2, 50, &#39;2019-08-14&#39;);</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (1, 30, &#39;2019-08-15&#39;);</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (1, 35, &#39;2019-08-16&#39;);</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (2, 65, &#39;2019-08-17&#39;);</span><br><span class="line">insert into Products (product_id, new_price, change_date) values (3, 20, &#39;2019-08-18&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    * </span><br><span class="line">FROM </span><br><span class="line">    (SELECT </span><br><span class="line">           product_id,</span><br><span class="line">           new_price AS price</span><br><span class="line">     FROM </span><br><span class="line">           Products</span><br><span class="line">     WHERE (product_id, change_date) IN (</span><br><span class="line">                                          SELECT</span><br><span class="line">                                                product_id,</span><br><span class="line">                                                MAX(change_date)</span><br><span class="line">                                          FROM </span><br><span class="line">                                                Products</span><br><span class="line">                                          WHERE </span><br><span class="line">                                                change_date &lt;&#x3D; &#39;2019-08-16&#39;</span><br><span class="line">                                          GROUP BY</span><br><span class="line">                                                product_id</span><br><span class="line">                                         )</span><br><span class="line">     UNION</span><br><span class="line">     SELECT</span><br><span class="line">            DISTINCT product_id, 10 AS price</span><br><span class="line">     FROM </span><br><span class="line">            Products</span><br><span class="line">     WHERE </span><br><span class="line">            product_id NOT IN (SELECT</span><br><span class="line">                                     product_id</span><br><span class="line">                               FROM  </span><br><span class="line">                                     Products</span><br><span class="line">                               WHERE change_date &lt;&#x3D; &#39;2019-08-16&#39;</span><br><span class="line">                              )</span><br><span class="line">     ) tmp</span><br><span class="line">ORDER BY </span><br><span class="line">     price DESC;</span><br></pre></td></tr></table></figure></div>

<h2 id="55-Immediate-Food-Delivery"><a href="#55-Immediate-Food-Delivery" class="headerlink" title="55. Immediate Food Delivery"></a>55. Immediate Food Delivery</h2><p>需求一：Write an SQL query to find the percentage of immediate orders in the table, rounded to 2 decimal places.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>immediate_percentage</th>
</tr>
</thead>
<tbody><tr>
<td>42.86</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Delivery (delivery_id int, customer_id int, order_date date, customer_pref_delivery_date date);</span><br><span class="line">Truncate table Delivery;</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (1, 1, &#39;2019-08-01&#39;, &#39;2019-08-02&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (2, 5, &#39;2019-08-02&#39;, &#39;2019-08-02&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (3, 1, &#39;2019-08-11&#39;, &#39;2019-08-11&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (4, 3, &#39;2019-08-24&#39;, &#39;2019-08-26&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (5, 4, &#39;2019-08-21&#39;, &#39;2019-08-22&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (6, 2, &#39;2019-08-11&#39;, &#39;2019-08-13&#39;);</span><br><span class="line">insert into Delivery (delivery_id, customer_id, order_date, customer_pref_delivery_date) values (7, 4, &#39;2019-08-09&#39;, &#39;2019-08-09&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT ROUND(</span><br><span class="line">    (SELECT COUNT(delivery_id)</span><br><span class="line">    FROM Delivery</span><br><span class="line">    WHERE order_date &#x3D; customer_pref_delivery_date)</span><br><span class="line">    * 100 &#x2F; COUNT(delivery_id)</span><br><span class="line">        , 2) </span><br><span class="line">AS immediate_percentage</span><br><span class="line">FROM Delivery;</span><br></pre></td></tr></table></figure></div>

<p>需求二：Write an SQL query to find the percentage of immediate orders in the first orders of all customers, rounded to 2 decimal places.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>immediate_percentage</th>
</tr>
</thead>
<tbody><tr>
<td>40.00</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      round(</span><br><span class="line">               count(case when d.order_date &#x3D; d.customer_pref_delivery_date then 1 end)</span><br><span class="line">               * </span><br><span class="line">               100&#x2F;count(*),</span><br><span class="line">            2) as immediate_percentage</span><br><span class="line">from </span><br><span class="line">     Delivery d,</span><br><span class="line">    (select</span><br><span class="line">           delivery_id,</span><br><span class="line">           customer_id,</span><br><span class="line">           min(order_date) as order_date</span><br><span class="line">     from</span><br><span class="line">           Delivery</span><br><span class="line">     group by</span><br><span class="line">           customer_id</span><br><span class="line">    ) as t</span><br><span class="line">where</span><br><span class="line">     d.customer_id &#x3D; t.customer_id</span><br><span class="line">     and d.order_date &#x3D; t.order_date;</span><br></pre></td></tr></table></figure></div>

<h2 id="56-重新格式化部门表"><a href="#56-重新格式化部门表" class="headerlink" title="56. 重新格式化部门表"></a>56. 重新格式化部门表</h2><p>需求一：编写一个 SQL 查询来重新格式化表，使得新的表中有一个部门 id 列和一些对应 每个月 的收入（revenue）列。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>Jan_Revenue</th>
<th>Feb_Revenue</th>
<th>Mar_Revenue</th>
<th>…</th>
<th>Dec_Revenue</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>8000</td>
<td>7000</td>
<td>6000</td>
<td>…</td>
<td>null</td>
</tr>
<tr>
<td>2</td>
<td>9000</td>
<td>null</td>
<td>null</td>
<td>…</td>
<td>null</td>
</tr>
<tr>
<td>3</td>
<td>null</td>
<td>10000</td>
<td>null</td>
<td>…</td>
<td>null</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Department (id int, revenue int, month varchar(5));</span><br><span class="line">Truncate table Department;</span><br><span class="line">insert into Department (id, revenue, month) values (1, 8000, &#39;Jan&#39;);</span><br><span class="line">insert into Department (id, revenue, month) values (2, 9000, &#39;Jan&#39;);</span><br><span class="line">insert into Department (id, revenue, month) values (3, 10000, &#39;Feb&#39;);</span><br><span class="line">insert into Department (id, revenue, month) values (1, 7000, &#39;Feb&#39;);</span><br><span class="line">insert into Department (id, revenue, month) values (1, 6000, &#39;Mar&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">      DISTINCT id AS &quot;id&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Jan&quot;, revenue, null)) AS &quot;Jan_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Feb&quot;, revenue, null)) AS &quot;Feb_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Mar&quot;, revenue, null)) AS &quot;Mar_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Apr&quot;, revenue, null)) AS &quot;Apr_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;May&quot;, revenue, null)) AS &quot;May_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Jun&quot;, revenue, null)) AS &quot;Jun_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Jul&quot;, revenue, null)) AS &quot;Jul_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Aug&quot;, revenue, null)) AS &quot;Aug_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Sep&quot;, revenue, null)) AS &quot;Sep_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Oct&quot;, revenue, null)) AS &quot;Oct_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Nov&quot;, revenue, null)) AS &quot;Nov_Revenue&quot;,</span><br><span class="line">      SUM(IF (month &#x3D; &quot;Dec&quot;, revenue, null)) AS &quot;Dec_Revenue&quot; </span><br><span class="line">FROM </span><br><span class="line">      Department</span><br><span class="line">GROUP BY id;</span><br></pre></td></tr></table></figure></div>

<h2 id="57-每月交易"><a href="#57-每月交易" class="headerlink" title="57. 每月交易"></a>57. 每月交易</h2><p>需求一：查询每一个项目中员工的平均工作年限，精确到小数点后两位。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>month</th>
<th>country</th>
<th>trans_count</th>
<th>approved_count</th>
<th>trans_total_amount</th>
<th>approved_total_amount</th>
</tr>
</thead>
<tbody><tr>
<td>2018-12</td>
<td>US</td>
<td>2</td>
<td>1</td>
<td>3000</td>
<td>1000</td>
</tr>
<tr>
<td>2019-01</td>
<td>US</td>
<td>1</td>
<td>1</td>
<td>2000</td>
<td>2000</td>
</tr>
<tr>
<td>2019-01</td>
<td>DE</td>
<td>1</td>
<td>1</td>
<td>2000</td>
<td>2000</td>
</tr>
<tr>
<td>2019-05</td>
<td>US</td>
<td>2</td>
<td>1</td>
<td>3000</td>
<td>1000</td>
</tr>
<tr>
<td>2019-06</td>
<td>US</td>
<td>3</td>
<td>2</td>
<td>12000</td>
<td>8000</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table if not exists Transactions (id int, country varchar(4), state enum(&#39;approved&#39;, &#39;declined&#39;), amount int, trans_date date);</span><br><span class="line">create table if not exists Chargebacks (trans_id int, trans_date date);</span><br><span class="line"></span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (101, &#39;US&#39;, &#39;approved&#39;, 1000, &#39;2018-12-18&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (102, &#39;US&#39;, &#39;declined&#39;, 2000, &#39;2018-12-19&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (103, &#39;US&#39;, &#39;approved&#39;, 2000, &#39;2019-01-01&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (104, &#39;DE&#39;, &#39;approved&#39;, 2000, &#39;2019-01-07&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (105, &#39;US&#39;, &#39;approved&#39;, 1000, &#39;2019-05-18&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (106, &#39;US&#39;, &#39;declined&#39;, 2000, &#39;2019-05-19&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (107, &#39;US&#39;, &#39;approved&#39;, 3000, &#39;2019-06-10&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (108, &#39;US&#39;, &#39;declined&#39;, 4000, &#39;2019-06-13&#39;);</span><br><span class="line">insert into Transactions (id, country, state, amount, trans_date) values (109, &#39;US&#39;, &#39;approved&#39;, 5000, &#39;2019-06-15&#39;);</span><br><span class="line"></span><br><span class="line">insert into Chargebacks (trans_id, trans_date) values (102, &#39;2019-05-29&#39;);</span><br><span class="line">insert into Chargebacks (trans_id, trans_date) values (101, &#39;2019-06-30&#39;);</span><br><span class="line">insert into Chargebacks (trans_id, trans_date) values (105, &#39;2019-09-18&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      date_format(trans_date,&#39;%Y-%m&#39;) as month,</span><br><span class="line">      country,</span><br><span class="line">      count(*) as trans_count,</span><br><span class="line">      sum(if(state&#x3D;&#39;approved&#39;,1,0)) as approved_count,</span><br><span class="line">      sum(amount) as trans_total_amount,</span><br><span class="line">      sum(if(state&#x3D;&#39;approved&#39;,amount,0)) as approved_total_amount</span><br><span class="line">from </span><br><span class="line">      Transactions t</span><br><span class="line">group by</span><br><span class="line">      date_format(trans_date,&#39;%Y-%m&#39;),</span><br><span class="line">      country;</span><br></pre></td></tr></table></figure></div>

<p>需求二：编写一个 SQL 查询，以查找每个月和每个国家/地区的已批准交易的数量及其总金额、退单的数量及其总金额。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>month</th>
<th>country</th>
<th>approved_count</th>
<th>approved_amount</th>
<th>chargeback_count</th>
<th>chargeback_amount</th>
</tr>
</thead>
<tbody><tr>
<td>2018-12</td>
<td>US</td>
<td>1</td>
<td>1000</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2019-01</td>
<td>DE</td>
<td>1</td>
<td>2000</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2019-01</td>
<td>US</td>
<td>1</td>
<td>2000</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2019-05</td>
<td>US</td>
<td>1</td>
<td>1000</td>
<td>1</td>
<td>2000</td>
</tr>
<tr>
<td>2019-06</td>
<td>US</td>
<td>2</td>
<td>8000</td>
<td>1</td>
<td>1000</td>
</tr>
<tr>
<td>2019-09</td>
<td>US</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1000</td>
</tr>
</tbody></table>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">       month as MONTH,</span><br><span class="line">       country as COUNTRY,</span><br><span class="line">       SUM(IF(type &#x3D; &#39;approved&#39;, 1, 0)) AS APPROVED_COUNT,</span><br><span class="line">       SUM(IF(type &#x3D; &#39;approved&#39;, amount, 0)) AS APPROVED_AMOUNT,</span><br><span class="line">       SUM(IF(type &#x3D; &#39;chargeback&#39;, 1, 0)) AS CHARGEBACK_COUNT,</span><br><span class="line">       SUM(IF(type &#x3D; &#39;chargeback&#39;, amount, 0)) AS CHARGEBACK_AMOUNT</span><br><span class="line">FROM </span><br><span class="line">      (SELECT </span><br><span class="line">              date_format(t.trans_date,&#39;%Y-%m&#39;) AS month,</span><br><span class="line">              t.country,</span><br><span class="line">              amount,</span><br><span class="line">              &#39;approved&#39; AS type</span><br><span class="line">        FROM</span><br><span class="line">              Transactions AS t</span><br><span class="line">        WHERE </span><br><span class="line">              state &#x3D; &#39;approved&#39;</span><br><span class="line">        UNION ALL</span><br><span class="line">        SELECT</span><br><span class="line">              date_format(c.trans_date,&#39;%Y-%m&#39;) AS month,</span><br><span class="line">              t.country,</span><br><span class="line">              amount,</span><br><span class="line">              &#39;chargeback&#39; AS type</span><br><span class="line">         FROM </span><br><span class="line">              Transactions AS t</span><br><span class="line">         INNER JOIN</span><br><span class="line">              Chargebacks AS c </span><br><span class="line">         ON t.id &#x3D; c.trans_id</span><br><span class="line">         ) AS tt</span><br><span class="line">GROUP BY </span><br><span class="line">         tt.month,</span><br><span class="line">         tt.country;</span><br></pre></td></tr></table></figure></div>

<h2 id="58-锦标赛优胜者"><a href="#58-锦标赛优胜者" class="headerlink" title="58. 锦标赛优胜者"></a>58. 锦标赛优胜者</h2><p>需求一：编写一个 SQL 查询来查找每组中的获胜者。每组的获胜者是在组内得分最高的选手。如果平局，得分最低的选手获胜。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>group_id</th>
<th>player_id</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>15</td>
</tr>
<tr>
<td>2</td>
<td>35</td>
</tr>
<tr>
<td>3</td>
<td>40</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Players (player_id int, group_id int);</span><br><span class="line">Create table If Not Exists Matches (match_id int, first_player int, second_player int, first_score int, second_score int);</span><br><span class="line">Truncate table Players;</span><br><span class="line">insert into Players (player_id, group_id) values (10, 2);</span><br><span class="line">insert into Players (player_id, group_id) values (15, 1);</span><br><span class="line">insert into Players (player_id, group_id) values (20, 3);</span><br><span class="line">insert into Players (player_id, group_id) values (25, 1);</span><br><span class="line">insert into Players (player_id, group_id) values (30, 1);</span><br><span class="line">insert into Players (player_id, group_id) values (35, 2);</span><br><span class="line">insert into Players (player_id, group_id) values (40, 3);</span><br><span class="line">insert into Players (player_id, group_id) values (45, 1);</span><br><span class="line">insert into Players (player_id, group_id) values (50, 2);</span><br><span class="line">Truncate table Matches;</span><br><span class="line">insert into Matches (match_id, first_player, second_player, first_score, second_score) values (1, 15, 45, 3, 0);</span><br><span class="line">insert into Matches (match_id, first_player, second_player, first_score, second_score) values (2, 30, 25, 1, 2);</span><br><span class="line">insert into Matches (match_id, first_player, second_player, first_score, second_score) values (3, 30, 15, 2, 0);</span><br><span class="line">insert into Matches (match_id, first_player, second_player, first_score, second_score) values (4, 40, 20, 5, 2);</span><br><span class="line">insert into Matches (match_id, first_player, second_player, first_score, second_score) values (5, 35, 50, 1, 1);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      group_id,</span><br><span class="line">      player_id</span><br><span class="line">from </span><br><span class="line">    (select </span><br><span class="line">           group_id,</span><br><span class="line">           player_id,</span><br><span class="line">           sum(</span><br><span class="line">               case</span><br><span class="line">                   when player_id &#x3D; first_player then first_score</span><br><span class="line">                   when player_id &#x3D; second_player then second_score</span><br><span class="line">               end</span><br><span class="line">               ) as totalScores</span><br><span class="line">     from </span><br><span class="line">          Players p,</span><br><span class="line">          Matches m</span><br><span class="line">     where</span><br><span class="line">          p.player_id &#x3D; m.first_player or</span><br><span class="line">          p.player_id &#x3D; m.second_player</span><br><span class="line">     group by</span><br><span class="line">          group_id,</span><br><span class="line">          player_id</span><br><span class="line">     order by</span><br><span class="line">          group_id,</span><br><span class="line">          totalScores desc,</span><br><span class="line">          player_id</span><br><span class="line">    ) as temp</span><br><span class="line">group by </span><br><span class="line">     group_id</span><br><span class="line">order by </span><br><span class="line">     group_id,</span><br><span class="line">     totalScores desc,</span><br><span class="line">     player_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="59-Last-Person-to-Fit-in-the-Elevator"><a href="#59-Last-Person-to-Fit-in-the-Elevator" class="headerlink" title="59. Last Person to Fit in the Elevator"></a>59. Last Person to Fit in the Elevator</h2><p>需求：Queue table is ordered by turn in the example for simplicity.<br>In the example George Washington(id 5), John Adams(id 3) and Thomas Jefferson(id 6) will enter the elevator as their weight sum is 250 + 350 + 400 = 1000.<br>Thomas Jefferson(id 6) is the last person to fit in the elevator because he has the last turn in these three people.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>person_name</th>
</tr>
</thead>
<tbody><tr>
<td>Thomas Jefferson</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Queue (person_id int, person_name varchar(30), weight int, turn int);</span><br><span class="line">Truncate table Queue;</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (5, &#39;George Washington&#39;, 250, 1);</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (4, &#39;Thomas Jefferson&#39;, 175, 5);</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (3, &#39;John Adams&#39;, 350, 2);</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (6, &#39;Thomas Jefferson&#39;, 400, 3);</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (1, &#39;James Elephant&#39;, 500, 6);</span><br><span class="line">insert into Queue (person_id, person_name, weight, turn) values (2, &#39;Will Johnliams&#39;, 200, 4);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      person_name</span><br><span class="line">from </span><br><span class="line">      Queue q1</span><br><span class="line">where </span><br><span class="line">     (select</span><br><span class="line">           sum(weight)</span><br><span class="line">      from</span><br><span class="line">           Queue</span><br><span class="line">      where turn &lt;&#x3D; q1.turn) &lt;&#x3D; 1000</span><br><span class="line">order by </span><br><span class="line">      turn desc </span><br><span class="line">limit 1;</span><br></pre></td></tr></table></figure></div>

<h2 id="60-Queries-Quality-and-Percentage"><a href="#60-Queries-Quality-and-Percentage" class="headerlink" title="60. Queries Quality and Percentage"></a>60. Queries Quality and Percentage</h2><p>需求：Write an SQL query to find each query_name, the quality and poor_query_percentage.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>query_name</th>
<th>quality</th>
<th>poor_query_percentage</th>
</tr>
</thead>
<tbody><tr>
<td>Dog</td>
<td>2.50</td>
<td>33.33</td>
</tr>
<tr>
<td>Cat</td>
<td>0.66</td>
<td>33.33</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Queries (query_name varchar(30), result varchar(50), position int, rating int);</span><br><span class="line">Truncate table Queries;</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Dog&#39;, &#39;Golden Retriever&#39;, 1, 5);</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Dog&#39;, &#39;German Shepherd&#39;, 2, 5);</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Dog&#39;, &#39;Mule&#39;, &#39;200&#39;, 1);</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Cat&#39;, &#39;Shirazi&#39;, 5, 2);</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Cat&#39;, &#39;Siamese&#39;, 3, 3);</span><br><span class="line">insert into Queries (query_name, result, position, rating) values (&#39;Cat&#39;, &#39;Sphynx&#39;, 7, 4);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      query_name,</span><br><span class="line">      round(avg(rating&#x2F;position), 2) as quality ,</span><br><span class="line">      round((count(if(rating&lt;3, True, null)) &#x2F; count(query_name)) *100 , 2) as poor_query_percentage</span><br><span class="line">from</span><br><span class="line">      Queries</span><br><span class="line">group by </span><br><span class="line">      query_name;</span><br></pre></td></tr></table></figure></div>

<h2 id="61-Team-Scores-in-Football-Tournament"><a href="#61-Team-Scores-in-Football-Tournament" class="headerlink" title="61. Team Scores in Football Tournament"></a>61. Team Scores in Football Tournament</h2><p>需求一：You would like to compute the scores of all teams after all matches. Points are awarded as follows:<br>A team receives three points if they win a match (Score strictly more goals than the opponent team).<br>A team receives one point if they draw a match (Same number of goals as the opponent team).<br>A team receives no points if they lose a match (Score less goals than the opponent team).<br>Write an SQL query that selects the team_id, team_name and num_points of each team in the tournament after all described matches. Result table should be ordered by num_points (decreasing order). In case of a tie, order the records by team_id (increasing order).</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>team_id</th>
<th>team_name</th>
<th>num_points</th>
</tr>
</thead>
<tbody><tr>
<td>10</td>
<td>Leetcode FC</td>
<td>7</td>
</tr>
<tr>
<td>20</td>
<td>NewYork FC</td>
<td>3</td>
</tr>
<tr>
<td>50</td>
<td>Toronto FC</td>
<td>3</td>
</tr>
<tr>
<td>30</td>
<td>Atlanta FC</td>
<td>1</td>
</tr>
<tr>
<td>40</td>
<td>Chicago FC</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Teams (team_id int, team_name varchar(30));</span><br><span class="line">Create table If Not Exists Matches (match_id int, host_team int, guest_team int, host_goals int, guest_goals int);</span><br><span class="line">Truncate table Teams;</span><br><span class="line">insert into Teams (team_id, team_name) values (10, &#39;Leetcode FC&#39;);</span><br><span class="line">insert into Teams (team_id, team_name) values (20, &#39;NewYork FC&#39;);</span><br><span class="line">insert into Teams (team_id, team_name) values (30, &#39;Atlanta FC&#39;);</span><br><span class="line">insert into Teams (team_id, team_name) values (40, &#39;Chicago FC&#39;);</span><br><span class="line">insert into Teams (team_id, team_name) values (50, &#39;Toronto FC&#39;);</span><br><span class="line">Truncate table Matches;</span><br><span class="line">insert into Matches (match_id, host_team, guest_team, host_goals, guest_goals) values (1, 10, 20, 30, 0);</span><br><span class="line">insert into Matches (match_id, host_team, guest_team, host_goals, guest_goals) values (2, 30, 10, 2, 2);</span><br><span class="line">insert into Matches (match_id, host_team, guest_team, host_goals, guest_goals) values (3, 10, 50, 5, 1);</span><br><span class="line">insert into Matches (match_id, host_team, guest_team, host_goals, guest_goals) values (4, 20, 30, 1, 0);</span><br><span class="line">insert into Matches (match_id, host_team, guest_team, host_goals, guest_goals) values (5, 50, 30, 1, 0);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">     *</span><br><span class="line">FROM</span><br><span class="line">    (SELECT </span><br><span class="line">           a.team_id,</span><br><span class="line">           MAX(team_name) AS team_name,</span><br><span class="line">           SUM(</span><br><span class="line">                CASE </span><br><span class="line">			        WHEN a.team_id &#x3D; b.host_team THEN </span><br><span class="line">				    CASE </span><br><span class="line">					    WHEN b.host_goals &gt; b.guest_goals THEN 3</span><br><span class="line">					    WHEN b.host_goals &#x3D; b.guest_goals THEN 1</span><br><span class="line">			            ELSE 0</span><br><span class="line">				    END</span><br><span class="line">			        WHEN a.team_id &#x3D; b.guest_team THEN </span><br><span class="line">				    CASE </span><br><span class="line">					    WHEN b.host_goals &lt; b.guest_goals THEN 3</span><br><span class="line">					    WHEN b.host_goals &#x3D; b.guest_goals THEN 1</span><br><span class="line">					    ELSE 0</span><br><span class="line">				    END</span><br><span class="line">			        ELSE 0</span><br><span class="line">		       END</span><br><span class="line">           ) AS num_points</span><br><span class="line">	FROM </span><br><span class="line">         Teams a</span><br><span class="line">    LEFT JOIN</span><br><span class="line">         Matches b</span><br><span class="line">    ON </span><br><span class="line">         a.team_id &#x3D; b.host_team OR </span><br><span class="line">         a.team_id &#x3D; b.guest_team</span><br><span class="line">	GROUP BY a.team_id</span><br><span class="line">    ) a </span><br><span class="line">ORDER BY</span><br><span class="line">    a.num_points DESC,</span><br><span class="line">    a.team_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="62-报告系统状态的连续日期"><a href="#62-报告系统状态的连续日期" class="headerlink" title="62. 报告系统状态的连续日期"></a>62. 报告系统状态的连续日期</h2><p>需求：系统 每天 运行一个任务。每个任务都独立于先前的任务。任务的状态可以是失败或是成功。编写一个 SQL 查询 2019-01-01 到 2019-12-31 期间任务连续同状态 period_state 的起止日期（start_date 和 end_date）。即如果任务失败了，就是失败状态的起止日期，如果任务成功了，就是成功状态的起止日期。最后结果按照起始日期 start_date 排序</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>period_state</th>
<th>start date</th>
<th>end date</th>
</tr>
</thead>
<tbody><tr>
<td>present</td>
<td>2019-01-01</td>
<td>2019-01-03</td>
</tr>
<tr>
<td>missing</td>
<td>2019-01-04</td>
<td>2019-01-05</td>
</tr>
<tr>
<td>present</td>
<td>2019-01-06</td>
<td>2019-01-06</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Failed (fail_date date);</span><br><span class="line">Create table If Not Exists Succeeded (success_date date);</span><br><span class="line">Truncate table Failed;</span><br><span class="line">insert into Failed (fail_date) values (&#39;2018-12-28&#39;);</span><br><span class="line">insert into Failed (fail_date) values (&#39;2018-12-29&#39;);</span><br><span class="line">insert into Failed (fail_date) values (&#39;2019-01-04&#39;);</span><br><span class="line">insert into Failed (fail_date) values (&#39;2019-01-05&#39;);</span><br><span class="line">Truncate table Succeeded;</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2018-12-30&#39;);</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2018-12-31&#39;);</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2019-01-01&#39;);</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2019-01-02&#39;);</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2019-01-03&#39;);</span><br><span class="line">insert into Succeeded (success_date) values (&#39;2019-01-06&#39;);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      if(str&#x3D;1,&#39;succeeded&#39;,&#39;failed&#39;) as period_state ,</span><br><span class="line">      min(date) as start_date,</span><br><span class="line">      max(date) as end_date</span><br><span class="line">from </span><br><span class="line">     (select </span><br><span class="line">            @diff :&#x3D; @diff+ if(num &#x3D; 1 , 1,0) as diff,</span><br><span class="line">            date,</span><br><span class="line">            str</span><br><span class="line">      from</span><br><span class="line">           (select </span><br><span class="line">                  case </span><br><span class="line">                      when @str &#x3D; str and  date_add(@pre,interval 1 day) &#x3D; date  then @num :&#x3D; @num +1</span><br><span class="line">                      when @str:&#x3D;str then  @num :&#x3D; 1</span><br><span class="line">                      else @num :&#x3D; 1</span><br><span class="line">                  end as num,</span><br><span class="line">                  @pre :&#x3D; date,</span><br><span class="line">                  date,</span><br><span class="line">                  str</span><br><span class="line">            from </span><br><span class="line">                 (select </span><br><span class="line">                        fail_date as date ,</span><br><span class="line">                        0 as &#39;str&#39;</span><br><span class="line">                  from </span><br><span class="line">                        Failed </span><br><span class="line">                  union  </span><br><span class="line">                  select</span><br><span class="line">                        success_date,</span><br><span class="line">                        1</span><br><span class="line">                  from </span><br><span class="line">                        Succeeded </span><br><span class="line">                 ) s,</span><br><span class="line">                 (select @pre:&#x3D;null,@num:&#x3D;0,@str :&#x3D; null) s1</span><br><span class="line">            where </span><br><span class="line">                  date between &#39;2019-01-01&#39; and &#39;2019-12-31&#39;</span><br><span class="line">            order by</span><br><span class="line">                  date </span><br><span class="line">           ) s,</span><br><span class="line">           (select @diff:&#x3D;0)  s1</span><br><span class="line">     ) ys</span><br><span class="line">group by </span><br><span class="line">      diff,</span><br><span class="line">      str;</span><br></pre></td></tr></table></figure></div>

<h2 id="62-每个帖子的评论数"><a href="#62-每个帖子的评论数" class="headerlink" title="62. 每个帖子的评论数"></a>62. 每个帖子的评论数</h2><p>需求一：编写 SQL 语句以查找每个帖子的评论数。结果表应包含帖子的 post_id 和对应的评论数 number_of_comments 并且按 post_id 升序排列。Submissions 可能包含重复的评论。您应该计算每个帖子的唯一评论数。Submissions 可能包含重复的帖子。您应该将它们视为一个帖子。</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>post_id</th>
<th>number_of_comments</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>12</td>
<td>0</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Submissions (sub_id int, parent_id int);</span><br><span class="line">Truncate table Submissions;</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (1, null);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (2, null);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (1, null);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (12, null);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (3, 1);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (5, 2);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (3, 1);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (4, 1);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (9, 1);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (10, 2);</span><br><span class="line">insert into Submissions (sub_id, parent_id) values (6, 7);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">	  post_id,</span><br><span class="line">	  COUNT( DISTINCT S2.sub_id ) AS number_of_comments </span><br><span class="line">FROM</span><br><span class="line">	(SELECT</span><br><span class="line">           DISTINCT sub_id AS post_id </span><br><span class="line">     FROM </span><br><span class="line">           Submissions</span><br><span class="line">     WHERE </span><br><span class="line">           parent_id IS NULL</span><br><span class="line">    ) S1</span><br><span class="line">LEFT JOIN</span><br><span class="line">     Submissions S2</span><br><span class="line">ON</span><br><span class="line">     S1.post_id &#x3D; S2.parent_id </span><br><span class="line">GROUP BY</span><br><span class="line">     S1.post_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="63-Average-Selling-Price"><a href="#63-Average-Selling-Price" class="headerlink" title="63. Average Selling Price"></a>63. Average Selling Price</h2><p>需求一：Write an SQL query to find the average selling price for each product.  average_price should be rounded to 2 decimal places.</p>
<p>The query result format is in the following example:</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>product_id</th>
<th>average_price</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>6.96</td>
</tr>
<tr>
<td>2</td>
<td>16.96</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Prices (product_id int, start_date date, end_date date, price int);</span><br><span class="line">Create table If Not Exists UnitsSold (product_id int, purchase_date date, units int);</span><br><span class="line">Truncate table Prices;</span><br><span class="line">insert into Prices (product_id, start_date, end_date, price) values (1, &#39;2019-02-17&#39;, &#39;2019-02-28&#39;, 5);</span><br><span class="line">insert into Prices (product_id, start_date, end_date, price) values (1, &#39;2019-03-01&#39;, &#39;2019-03-22&#39;, 20);</span><br><span class="line">insert into Prices (product_id, start_date, end_date, price) values (2, &#39;2019-02-01&#39;, &#39;2019-02-20&#39;, 15);</span><br><span class="line">insert into Prices (product_id, start_date, end_date, price) values (2, &#39;2019-02-21&#39;, &#39;2019-03-31&#39;, 30);</span><br><span class="line">Truncate table UnitsSold;</span><br><span class="line">insert into UnitsSold (product_id, purchase_date, units) values (1, &#39;2019-02-25&#39;, 100);</span><br><span class="line">insert into UnitsSold (product_id, purchase_date, units) values (1, &#39;2019-03-01&#39;, 15);</span><br><span class="line">insert into UnitsSold (product_id, purchase_date, units) values (2, &#39;2019-02-10&#39;, 200);</span><br><span class="line">insert into UnitsSold (product_id, purchase_date, units) values (2, &#39;2019-03-22&#39;, 30);</span><br></pre></td></tr></table></figure></div>

<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      product_id,</span><br><span class="line">      round(sum(a)&#x2F;sum(units),2) as average_price</span><br><span class="line">from</span><br><span class="line">   (select </span><br><span class="line">          p.product_id as product_id,</span><br><span class="line">          price,units,</span><br><span class="line">          price * units as a</span><br><span class="line">    from </span><br><span class="line">          Prices p </span><br><span class="line">    left join</span><br><span class="line">          UnitsSold u</span><br><span class="line">    on </span><br><span class="line">          p.product_id&#x3D;u.product_id and </span><br><span class="line">          purchase_date&lt;&#x3D;end_date and </span><br><span class="line">          purchase_date&gt;&#x3D;start_date</span><br><span class="line">   )t</span><br><span class="line">group by </span><br><span class="line">    product_id;</span><br></pre></td></tr></table></figure></div>

<h2 id="64-Page-Recommendations"><a href="#64-Page-Recommendations" class="headerlink" title="64. Page Recommendations"></a>64. Page Recommendations</h2><p>需求一：Write an SQL query to recommend pages to the user with user_id = 1 using the pages that your friends liked. It should not recommend pages you already liked. Return result table in any order without duplicates.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>recommended_page</th>
</tr>
</thead>
<tbody><tr>
<td>23</td>
</tr>
<tr>
<td>24</td>
</tr>
<tr>
<td>56</td>
</tr>
<tr>
<td>33</td>
</tr>
<tr>
<td>77</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Friendship (user1_id int, user2_id int);</span><br><span class="line">Create table If Not Exists Likes (user_id int, page_id int);</span><br><span class="line">Truncate table Friendship;</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (1, 2);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (1, 3);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (1, 4);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (2, 3);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (2, 4);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (2, 5);</span><br><span class="line">insert into Friendship (user1_id, user2_id) values (6, 1);</span><br><span class="line">Truncate table Likes;</span><br><span class="line">insert into Likes (user_id, page_id) values (1, 88);</span><br><span class="line">insert into Likes (user_id, page_id) values (2, 23);</span><br><span class="line">insert into Likes (user_id, page_id) values (3, 24);</span><br><span class="line">insert into Likes (user_id, page_id) values (4, 56);</span><br><span class="line">insert into Likes (user_id, page_id) values (5, 11);</span><br><span class="line">insert into Likes (user_id, page_id) values (6, 33);</span><br><span class="line">insert into Likes (user_id, page_id) values (2, 77);</span><br><span class="line">insert into Likes (user_id, page_id) values (3, 77);</span><br><span class="line">insert into Likes (user_id, page_id) values (6, 88);</span><br></pre></td></tr></table></figure></div>

<p>解释：</p>
<p>User one is friend with users 2, 3, 4 and 6.</p>
<p>Suggested pages are 23 from user 2, 24 from user 3, 56 from user 3 and 33 from user 6.</p>
<p>Page 77 is suggested from both user 2 and user 3.<br>Page 88 is not suggested because user 1 already likes it.</p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">      distinct page_id as recommended_page</span><br><span class="line">from </span><br><span class="line">      Likes,</span><br><span class="line">      friendship</span><br><span class="line">where </span><br><span class="line">      page_id not in(select </span><br><span class="line">                            page_id </span><br><span class="line">                     from </span><br><span class="line">                            likes</span><br><span class="line">                     where </span><br><span class="line">                            user_id&#x3D;1</span><br><span class="line">                    ) and</span><br><span class="line">      user_id in (select</span><br><span class="line">                        user1_id</span><br><span class="line">                  from</span><br><span class="line">                        friendship</span><br><span class="line">                  where user2_id&#x3D;1</span><br><span class="line">                 ) or</span><br><span class="line">      user_id in (select</span><br><span class="line">                        user2_id </span><br><span class="line">                  from </span><br><span class="line">                        friendship </span><br><span class="line">                  where</span><br><span class="line">                        user1_id&#x3D;1);</span><br></pre></td></tr></table></figure></div>

<h2 id="65-All-People-Report-to-the-Given-Manager"><a href="#65-All-People-Report-to-the-Given-Manager" class="headerlink" title="65. All People Report to the Given Manager"></a>65. All People Report to the Given Manager</h2><p>需求一：Write an SQL query to find employee_id of all employees that directly or indirectly report their work to the head of the company.</p>
<p>The indirect relation between managers will not exceed 3 managers as the company is small. Return result table in any order without duplicates.</p>
<p>展示效果：</p>
<table>
<thead>
<tr>
<th>employee_id</th>
</tr>
</thead>
<tbody><tr>
<td>2</td>
</tr>
<tr>
<td>77</td>
</tr>
<tr>
<td>4</td>
</tr>
<tr>
<td>7</td>
</tr>
</tbody></table>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Create table If Not Exists Employees (employee_id int, employee_name varchar(30), manager_id int);</span><br><span class="line">Truncate table Employees;</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (1, &#39;Boss&#39;, 1);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (3, &#39;Alice&#39;, 3);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (2, &#39;Bob&#39;, 1);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (4, &#39;Daniel&#39;, 2);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (7, &#39;Luis&#39;, 4);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (8, &#39;John&#39;, 3);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (9, &#39;Angela&#39;, 8);</span><br><span class="line">insert into Employees (employee_id, employee_name, manager_id) values (77, &#39;Robert&#39;, 1);</span><br></pre></td></tr></table></figure></div>

<p>提示：</p>
<p>The head of the company is the employee with employee_id 1.</p>
<p>The employees with employee_id 2 and 77 report their work directly to the head of the company.</p>
<p>The employee with employee_id 4 report his work indirectly to the head of the company 4 –&gt; 2 –&gt; 1. </p>
<p>The employee with employee_id 7 report his work indirectly to the head of the company 7 –&gt; 4 –&gt; 2 –&gt; 1.</p>
<p>The employees with employee_id 3, 8 and 9 don’t report their work to head of company directly or indirectly. </p>
<p>最终SQL:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">      employee_id EMPLOYEE_ID</span><br><span class="line">from </span><br><span class="line">      employees</span><br><span class="line">where </span><br><span class="line">      manager_id&#x3D;1 and </span><br><span class="line">      employee_id!&#x3D;1</span><br><span class="line">union</span><br><span class="line">select</span><br><span class="line">      a1.employee_id</span><br><span class="line">from </span><br><span class="line">      employees a1,</span><br><span class="line">     (select </span><br><span class="line">            employee_id</span><br><span class="line">      from</span><br><span class="line">            employees</span><br><span class="line">      where</span><br><span class="line">            manager_id&#x3D;1 and</span><br><span class="line">            employee_id!&#x3D;1</span><br><span class="line">     ) a</span><br><span class="line">where</span><br><span class="line">     manager_id&#x3D;a.employee_id</span><br><span class="line">union</span><br><span class="line">select </span><br><span class="line">     a2.employee_id</span><br><span class="line">from </span><br><span class="line">     employees a2,</span><br><span class="line">    (select</span><br><span class="line">           a1.employee_id employee_id</span><br><span class="line">    from </span><br><span class="line">           employees a1,</span><br><span class="line">           (select </span><br><span class="line">                  employee_id</span><br><span class="line">            from</span><br><span class="line">                  employees</span><br><span class="line">            where</span><br><span class="line">                  manager_id&#x3D;1 and</span><br><span class="line">                  employee_id!&#x3D;1</span><br><span class="line">           ) a</span><br><span class="line">    where </span><br><span class="line">           manager_id&#x3D;a.employee_id</span><br><span class="line">    ) a3</span><br><span class="line">where </span><br><span class="line">    manager_id&#x3D;a3.employee_id</span><br><span class="line">order by </span><br><span class="line">    employee_id;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka知识整理</title>
    <url>/2020/06/18/kafka%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><blockquote>
<p>本文转载自： <a href="https://chenhefei.github.io/2020/04/01/Kafka/Kafka-learning/" target="_blank" rel="noopener">https://chenhefei.github.io/2020/04/01/Kafka/Kafka-learning/</a> </p>
</blockquote>
<h3 id="kafka的定义"><a href="#kafka的定义" class="headerlink" title="kafka的定义"></a>kafka的定义</h3><p>Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p>
<h3 id="消息队列有什么好处"><a href="#消息队列有什么好处" class="headerlink" title="消息队列有什么好处"></a>消息队列有什么好处</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）解耦</span><br><span class="line">允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</span><br><span class="line">2）可恢复性</span><br><span class="line">系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</span><br><span class="line">3）缓冲</span><br><span class="line">有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</span><br><span class="line">4）灵活性 &amp; 峰值处理能力</span><br><span class="line">在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</span><br><span class="line">5）异步通信</span><br><span class="line">很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</span><br></pre></td></tr></table></figure></div>

<h3 id="消费队列的两种模式"><a href="#消费队列的两种模式" class="headerlink" title="消费队列的两种模式"></a>消费队列的两种模式</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</span><br><span class="line">消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。</span><br><span class="line">消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。</span><br><span class="line">（2）发布&#x2F;订阅模式（一对多，消费者消费数据之后不会清除消息）</span><br><span class="line">消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中的相关概念"><a href="#kafka中的相关概念" class="headerlink" title="kafka中的相关概念"></a>kafka中的相关概念</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）Producer ：消息生产者，就是向kafka broker发消息的客户端；</span><br><span class="line">2）Consumer ：消息消费者，向kafka broker取消息的客户端；</span><br><span class="line">3）Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</span><br><span class="line">4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</span><br><span class="line">5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</span><br><span class="line">6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</span><br><span class="line">7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</span><br><span class="line">8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</span><br><span class="line">9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka配置文件"><a href="#kafka配置文件" class="headerlink" title="kafka配置文件"></a>kafka配置文件</h3><p>位置</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 kafka]$ cd config&#x2F;</span><br><span class="line">[ys@hadoop102 config]$ vi server.properties</span><br></pre></td></tr></table></figure></div>

<p>内容</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">0</span></span><br><span class="line"><span class="comment">#删除topic功能使能</span></span><br><span class="line"><span class="meta">delete.topic.enable</span>=<span class="string">true</span></span><br><span class="line"><span class="comment">#处理网络请求的线程数量</span></span><br><span class="line"><span class="meta">num.network.threads</span>=<span class="string">3</span></span><br><span class="line"><span class="comment">#用来处理磁盘IO的线程数量</span></span><br><span class="line"><span class="meta">num.io.threads</span>=<span class="string">8</span></span><br><span class="line"><span class="comment">#发送套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.send.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#接收套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.receive.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#请求套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.request.max.bytes</span>=<span class="string">104857600</span></span><br><span class="line"><span class="comment">#kafka运行日志存放的路径</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka/logs</span></span><br><span class="line"><span class="comment">#topic在当前broker上的分区个数</span></span><br><span class="line"><span class="meta">num.partitions</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#用来恢复和清理data下数据的线程数量</span></span><br><span class="line"><span class="meta">num.recovery.threads.per.data.dir</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#segment文件保留的最长时间，超时将被删除</span></span><br><span class="line"><span class="meta">log.retention.hours</span>=<span class="string">168</span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址</span></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">hadoop102:2181,hadoop103:2181,hadoop104:2181</span></span><br></pre></td></tr></table></figure></div>

<h3 id="kafka分布式的broker-id配置"><a href="#kafka分布式的broker-id配置" class="headerlink" title="kafka分布式的broker.id配置"></a>kafka分布式的broker.id配置</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plain修改配置文件&#x2F;opt&#x2F;module&#x2F;kafka&#x2F;config&#x2F;server.properties中的broker.id&#x3D;1、broker.id&#x3D;2注：broker.id不得重复</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka的群起脚本"><a href="#kafka的群起脚本" class="headerlink" title="kafka的群起脚本"></a>kafka的群起脚本</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">echo "========== $i ==========" </span><br><span class="line">ssh $i '/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties'</span><br><span class="line">done</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka的命令行操作命令"><a href="#kafka的命令行操作命令" class="headerlink" title="kafka的命令行操作命令"></a>kafka的命令行操作命令</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">启动</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server.properties</span><br><span class="line"></span><br><span class="line">查看当前服务器中的所有topic</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --list</span><br><span class="line"></span><br><span class="line">创建topic</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first</span><br><span class="line">选项说明：</span><br><span class="line">--topic 定义topic名</span><br><span class="line">--replication-factor  定义副本数</span><br><span class="line">--partitions  定义分区数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">删除topic</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first</span><br><span class="line">需要server.properties中设置delete.topic.enable&#x3D;true否则只是标记删除。</span><br><span class="line"></span><br><span class="line">发送消息</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-console-producer.sh --broker-list hadoop102:9092 --topic first</span><br><span class="line">&gt;hello world</span><br><span class="line">&gt;atguigu  atguigu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">消费消息</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line">--zookeeper hadoop102:2181 --topic first</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line">--zookeeper hadoop102:2181 --topic first --consumer.config config&#x2F;consumer.properties 指定消费者的配置文件(可将多个消费者放置在一个组内)</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line">--bootstrap-server hadoop102:9092 --topic first</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-console-consumer.sh \</span><br><span class="line">--bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br><span class="line">注 : --from-beginning：会把主题中以往所有的数据都读取出来。</span><br><span class="line"></span><br><span class="line">查看某个Topic的详情</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first</span><br><span class="line"></span><br><span class="line">修改分区数</span><br><span class="line">[atguigu@hadoop102 kafka]$ bin&#x2F;kafka-topics.sh --zookeeper hadoop102:2181 --alter --topic first --partitions 6</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka工作流程"><a href="#kafka工作流程" class="headerlink" title="kafka工作流程"></a>kafka工作流程</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</span><br><span class="line"></span><br><span class="line">topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。</span><br><span class="line"></span><br><span class="line">由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</span><br><span class="line">如下</span><br><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br><span class="line"></span><br><span class="line">index和log文件以当前segment的第一条消息的offset命名。</span><br><span class="line"></span><br><span class="line">“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka生产者的分区分配策略"><a href="#kafka生产者的分区分配策略" class="headerlink" title="kafka生产者的分区分配策略"></a>kafka生产者的分区分配策略</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）分区的原因</span><br><span class="line">（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</span><br><span class="line">（2）可以提高并发，因为可以以Partition为单位读写了。</span><br><span class="line"></span><br><span class="line">2）分区的原则</span><br><span class="line">我们需要将producer发送的数据封装成一个ProducerRecord对象。</span><br><span class="line">（1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</span><br><span class="line">（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</span><br><span class="line">（3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka如何保证数据可靠性"><a href="#kafka如何保证数据可靠性" class="headerlink" title="kafka如何保证数据可靠性"></a>kafka如何保证数据可靠性</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">为保证producer发送的数据能可靠的发送到指定的topic，</span><br><span class="line">topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），</span><br><span class="line">如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</span><br></pre></td></tr></table></figure></div>

<h3 id="都有哪些副本数据同步策略-优缺点是什么"><a href="#都有哪些副本数据同步策略-优缺点是什么" class="headerlink" title="都有哪些副本数据同步策略 优缺点是什么"></a>都有哪些副本数据同步策略 优缺点是什么</h3><table>
<thead>
<tr>
<th><strong>方案</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>半数以上完成同步，就发送ack</strong></td>
<td>延迟低</td>
<td>选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td>
</tr>
<tr>
<td><strong>全部完成同步，才发送ack</strong></td>
<td>选举新的leader时，容忍n台节点的故障，需要n+1个副本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<h3 id="kafka的副本同步策略是什么-这个策略会出现什么问题"><a href="#kafka的副本同步策略是什么-这个策略会出现什么问题" class="headerlink" title="kafka的副本同步策略是什么 这个策略会出现什么问题"></a>kafka的副本同步策略是什么 这个策略会出现什么问题</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka选择了第二种方案，原因如下：</span><br><span class="line">1.同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</span><br><span class="line">2.虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</span><br><span class="line"></span><br><span class="line">采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中的ISR是什么"><a href="#kafka中的ISR是什么" class="headerlink" title="kafka中的ISR是什么"></a>kafka中的ISR是什么</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。</span><br><span class="line"></span><br><span class="line">当ISR中的follower完成数据的同步之后，leader就会给producer发送ack。</span><br><span class="line"></span><br><span class="line">如果follower长时间未向leader同步数据，则该follower将被踢出ISR，</span><br><span class="line"></span><br><span class="line">该时间阈值由replica.lag.time.max.ms参数设定。</span><br><span class="line"></span><br><span class="line">Leader发生故障之后，就会从ISR中选举新的leader。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中的ack应答机制是什么"><a href="#kafka中的ack应答机制是什么" class="headerlink" title="kafka中的ack应答机制是什么"></a>kafka中的ack应答机制是什么</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。</span><br><span class="line">所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">acks参数配置：</span><br><span class="line">acks：</span><br><span class="line">0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</span><br><span class="line">1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；</span><br><span class="line">-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka如何进行故障处理"><a href="#kafka如何进行故障处理" class="headerlink" title="kafka如何进行故障处理"></a>kafka如何进行故障处理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LEO：指的是每个副本最大的offset；</span><br><span class="line">HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">（1）follower故障follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</span><br><span class="line">（2）leader故障</span><br><span class="line">leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</span><br><span class="line">注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka消费者的消费方式"><a href="#kafka消费者的消费方式" class="headerlink" title="kafka消费者的消费方式"></a>kafka消费者的消费方式</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">consumer采用pull（拉）模式从broker中读取数据。</span><br><span class="line">push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</span><br><span class="line">pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka消费者的分区分配策略"><a href="#kafka消费者的分区分配策略" class="headerlink" title="kafka消费者的分区分配策略"></a>kafka消费者的分区分配策略</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。</span><br><span class="line">Kafka有两种分配策略，一是RoundRobin，一是Range。</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka消费者如何维护offset"><a href="#kafka消费者如何维护offset" class="headerlink" title="kafka消费者如何维护offset"></a>kafka消费者如何维护offset</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</span><br><span class="line"></span><br><span class="line">Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</span><br><span class="line"></span><br><span class="line">1）修改配置文件consumer.properties</span><br><span class="line">exclude.internal.topics&#x3D;false</span><br><span class="line">2）读取offset</span><br><span class="line">0.11.0.0之前版本:</span><br><span class="line">bin&#x2F;kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config&#x2F;consumer.properties --from-beginning</span><br><span class="line">0.11.0.0之后版本(含):</span><br><span class="line">bin&#x2F;kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config&#x2F;consumer.properties --from-beginning</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中的消费者组是什么"><a href="#kafka中的消费者组是什么" class="headerlink" title="kafka中的消费者组是什么"></a>kafka中的消费者组是什么</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">配置config&#x2F;consumer.properties文件中的group.id</span><br><span class="line">然后在启动消费者时候使用同一个配置文件 就可以让消费者在一个组内</span><br><span class="line"></span><br><span class="line">同一个消费者组中的消费者，同一时刻只能有一个消费者消费。</span><br><span class="line"></span><br><span class="line">如果消费者组中的消费者多于当前的分区数 会有警告提醒</span><br><span class="line">No broker partitions consumed by consumer thread ...</span><br><span class="line"></span><br><span class="line">如果停止了所有的消费者 那么offset会维护在我们选择的地方(zk中或者是本地) </span><br><span class="line">再次启动消费者会根据选择的GTP(group topic partition所维护的offset位置进行继续消费)</span><br><span class="line"></span><br><span class="line">下图为zk中维护的信息</span><br></pre></td></tr></table></figure></div>

<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522214846.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522214846.png" class="lazyload"></a></p>
<h3 id="kafka为什么能够高效读写数据"><a href="#kafka为什么能够高效读写数据" class="headerlink" title="kafka为什么能够高效读写数据"></a>kafka为什么能够高效读写数据</h3><ul>
<li>分布式框架</li>
<li>分区</li>
<li>顺序写磁盘<ul>
<li>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</li>
</ul>
</li>
<li>零复制技术<ul>
<li><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522214804.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522214804.png" class="lazyload"></a></li>
</ul>
</li>
</ul>
<h3 id="kafka的零拷贝技术如何实现"><a href="#kafka的零拷贝技术如何实现" class="headerlink" title="kafka的零拷贝技术如何实现"></a>kafka的零拷贝技术如何实现</h3><p>kafka中的消费者在读取服务端的数据时，需要将服务端的磁盘文件通过网络发送到消费者进程，网络发送需要经过几种网络节点。如下图所示：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522215536.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522215536.png" class="lazyload"></a></p>
<p>传统的读取文件数据并发送到网络的步骤如下：<br>（1）操作系统将数据从磁盘文件中读取到内核空间的页面缓存；<br>（2）应用程序将数据从内核空间读入用户空间缓冲区；<br>（3）应用程序将读到数据写回内核空间并放入socket缓冲区；<br>（4）操作系统将数据从socket缓冲区复制到网卡接口，此时数据才能通过网络发送。</p>
<p>通常情况下，Kafka的消息会有多个订阅者，生产者发布的消息会被不同的消费者多次消费，为了优化这个流程，Kafka使用了“零拷贝技术”，如下图所示：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522215604.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522215604.png" class="lazyload"></a></p>
<p>“零拷贝技术”只用将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。</p>
<p>如果有10个消费者，传统方式下，数据复制次数为4*10=40次，而使用“零拷贝技术”只需要1+10=11次，一次为从磁盘复制到页面缓存，10次表示10个消费者各自读取一次页面缓存。</p>
<hr>
<p>传统的文件拷贝通常需要从用户态去转到核心态，经过read buffer，然后再返回到用户态的应用层buffer，然后再从用户态把数据拷贝到核心态的socket buffer，然后发送到网卡。</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220145.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220145.png" class="lazyload"></a></p>
<p>传统的数据传输需要多次的用户态和核心态之间的切换，而且还要把数据复制多次，最终才打到网卡。</p>
<p>如果减少了用户态与核心态之间的切换，是不是就会更快了呢？</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220205.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220205.png" class="lazyload"></a></p>
<p>此时我们会发现用户态“空空如也”。数据没有来到用户态，而是直接在核心态就进行了传输，但这样依然还是有多次复制。首先数据被读取到read buffer中，然后发到socket buffer，最后才发到网卡。虽然减少了用户态和核心态的切换，但依然存在多次数据复制。</p>
<p>如果可以进一步减少数据复制的次数，甚至没有数据复制是不是就会做到最快呢？</p>
<p><strong>DMA</strong></p>
<p>别急，这里我们先介绍一个新的武器:DMA。</p>
<p>DMA，全称叫Direct Memory Access，一种可让某些硬件子系统去直接访问系统主内存，而不用依赖CPU的计算机系统的功能。听着是不是很厉害，跳过CPU，直接访问主内存。传统的内存访问都需要通过CPU的调度来完成。如下图：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220517.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220517.png" class="lazyload"></a></p>
<p>而DMA，则可以绕过CPU，硬件自己去直接访问系统主内存。如下图：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220536.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220536.png" class="lazyload"></a></p>
<p>很多硬件都支持DMA，这其中就包括网卡。</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220558.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220558.png" class="lazyload"></a></p>
<p><strong>零拷贝</strong></p>
<p>回到本文中的文件传输，有了DMA后，就可以实现绝对的零拷贝了，因为网卡是直接去访问系统主内存的。如下图：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220616.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220616.png" class="lazyload"></a></p>
<p><strong>Java的零拷贝实现</strong></p>
<p>在Java中的零拷贝实现是在FileChannel中，其中有个方法transferTo(position,fsize,src)。</p>
<p>传统的文件传输是通过java.io.DataOutputStream，java.io.FileInputStream来实现的，然后通过while循环来读取input，然后写入到output中。</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220646.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220646.png" class="lazyload"></a></p>
<p>零拷贝则是通过java.nio.channels.FileChannel中的transferTo方法来实现的。transferTo方法底层是基于操作系统的sendfile这个system call来实现的（不再需要拷贝到用户态了），sendfile负责把数据从某个fd（file descriptor）传输到另一个fd。</p>
<p>sendfile：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220717.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220717.png" class="lazyload"></a></p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220822.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220822.png" class="lazyload"></a></p>
<p>Java的transferTo：</p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220850.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220850.png" class="lazyload"></a></p>
<p><strong>传统方式与零拷贝性能对比</strong></p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522220906.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522220906.png" class="lazyload"></a></p>
<p>可以看出速度快出至少三倍多。Kafka在文件传输的过程中正是使用了零拷贝技术对文件进行拷贝。建议以后多用FileChannel的transferTo吧。</p>
<p><strong>总结</strong></p>
<ul>
<li>传统的文件传输有多次用户态和内核态之间的切换，而且文件在多个buffer之间要复制多次最终才被发送到网卡。</li>
<li>DMA是一种硬件直接访问系统主内存的技术。</li>
<li>多种硬件都已使用了DMA技术，其中就包括网卡（NIC）。</li>
<li>DMA技术让CPU得到解放，让CPU可以不用一直守着来完成文件传输。</li>
<li>零拷贝技术减少了用户态与内核态之间的切换，让拷贝次数降到最低，从而实现高性能。</li>
<li>Kafka使用零拷贝技术来进行文件的传输。</li>
</ul>
<h3 id="zk在kafka中的作用"><a href="#zk在kafka中的作用" class="headerlink" title="zk在kafka中的作用"></a>zk在kafka中的作用</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</span><br><span class="line">Controller的管理工作都是依赖于Zookeeper的。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">每个broker都会在zk进行注册</span><br><span class="line">然后KafkaController会实时监听zk中的&#x2F;brokers&#x2F;ids下的节点情况[0,1,2]</span><br><span class="line">如果broker0宕机 ids中的节点会实时变化为[1,2]</span><br><span class="line">KafkaController会更新topic中的leader和isr队列</span><br><span class="line">KafkaController会获取当前可用的isr并从中选出新的leader</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka的消息发送流程是什么样的"><a href="#kafka的消息发送流程是什么样的" class="headerlink" title="kafka的消息发送流程是什么样的"></a>kafka的消息发送流程是什么样的</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka的Producer发送消息采用的是异步发送的方式。</span><br><span class="line">在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，</span><br><span class="line">以及一个线程共享变量——RecordAccumulator(这个里面有分区)</span><br><span class="line"></span><br><span class="line">main线程将消息发送给RecordAccumulator，</span><br><span class="line">Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。</span><br><span class="line"></span><br><span class="line">注意这里面 先走拦截器 再走序列化器 再走分区器</span><br><span class="line">达到batch.size大小或者是linger.ms时间就发到RecordAccumulator中</span><br><span class="line">sender线程去拉取</span><br></pre></td></tr></table></figure></div>

<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522223103.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522223103.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">相关参数：</span><br><span class="line">batch.size：只有数据积累到batch.size之后，sender才会发送数据。(默认16kb)</span><br><span class="line">linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</span><br></pre></td></tr></table></figure></div>

<h3 id="如何使用kafka-API-实现异步消息发送"><a href="#如何使用kafka-API-实现异步消息发送" class="headerlink" title="如何使用kafka API 实现异步消息发送"></a>如何使用kafka API 实现异步消息发送</h3><h4 id="准备知识"><a href="#准备知识" class="headerlink" title="准备知识"></a>准备知识</h4><p>需要用到的类：</p>
<p><strong>KafkaProducer</strong>：需要创建一个生产者对象，用来发送数据</p>
<p><strong>ProducerConfig</strong>：获取所需的一系列配置参数</p>
<p><strong>ProducerRecord</strong>：每条数据都要封装成一个ProducerRecord对象</p>
<p>几个比较重要的配置项</p>
<p>//kafka集群，broker-list<br>props.put(“bootstrap.servers”, “hadoop102:9092”);</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>); <span class="comment">//重试次数 props.put("retries", 1); //批次大小 props.put("batch.size", 16384); //等待时间 props.put("linger.ms", 1); //RecordAccumulator缓冲区大小 props.put("buffer.memory", 33554432); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>kafka集群位置</li>
<li>批次大小</li>
<li>批次等待时间</li>
<li>重试次数</li>
<li>缓冲区大小</li>
<li>序列化器(<code>org\apache\kafka\common\serialization\Serializer.java</code>)</li>
</ul>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523030013.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523030013.png" class="lazyload"></a></p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522224718.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522224718.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">org\apache\kafka\clients\producer\ProducerConfig.java</span></span><br><span class="line"></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String BOOTSTRAP_SERVERS_CONFIG = "bootstrap.servers";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METADATA_MAX_AGE_CONFIG = "metadata.max.age.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String BATCH_SIZE_CONFIG = "batch.size";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String ACKS_CONFIG = "acks";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String LINGER_MS_CONFIG = "linger.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CLIENT_ID_CONFIG = "client.id";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String SEND_BUFFER_CONFIG = "send.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECEIVE_BUFFER_CONFIG = "receive.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_REQUEST_SIZE_CONFIG = "max.request.size";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MS_CONFIG = "reconnect.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MAX_MS_CONFIG = "reconnect.backoff.max.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_BLOCK_MS_CONFIG = "max.block.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String BUFFER_MEMORY_CONFIG = "buffer.memory";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RETRY_BACKOFF_MS_CONFIG = "retry.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String COMPRESSION_TYPE_CONFIG = "compression.type";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_SAMPLE_WINDOW_MS_CONFIG = "metrics.sample.window.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_NUM_SAMPLES_CONFIG = "metrics.num.samples";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_RECORDING_LEVEL_CONFIG = "metrics.recording.level";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRIC_REPORTER_CLASSES_CONFIG = "metric.reporters";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = "max.in.flight.requests.per.connection";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RETRIES_CONFIG = "retries";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String KEY_SERIALIZER_CLASS_CONFIG = "key.serializer";</span></span><br><span class="line"></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String VALUE_SERIALIZER_CLASS_CONFIG = "value.serializer";</span></span><br><span class="line"></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CONNECTIONS_MAX_IDLE_MS_CONFIG = "connections.max.idle.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String PARTITIONER_CLASS_CONFIG = "partitioner.class";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String REQUEST_TIMEOUT_MS_CONFIG = "request.timeout.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String INTERCEPTOR_CLASSES_CONFIG = "interceptor.classes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String ENABLE_IDEMPOTENCE_CONFIG = "enable.idempotence";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String TRANSACTION_TIMEOUT_CONFIG = "transaction.timeout.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String TRANSACTIONAL_ID_CONFIG = "transactional.id";</span></span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">org\apache\kafka\clients\consumer\ConsumerConfig.java</span></span><br><span class="line"></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String GROUP_ID_CONFIG = "group.id";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_POLL_RECORDS_CONFIG = "max.poll.records";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_POLL_INTERVAL_MS_CONFIG = "max.poll.interval.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String SESSION_TIMEOUT_MS_CONFIG = "session.timeout.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String HEARTBEAT_INTERVAL_MS_CONFIG = "heartbeat.interval.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String BOOTSTRAP_SERVERS_CONFIG = "bootstrap.servers";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String ENABLE_AUTO_COMMIT_CONFIG = "enable.auto.commit";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String AUTO_COMMIT_INTERVAL_MS_CONFIG = "auto.commit.interval.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String PARTITION_ASSIGNMENT_STRATEGY_CONFIG = "partition.assignment.strategy";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String AUTO_OFFSET_RESET_CONFIG = "auto.offset.reset";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String FETCH_MIN_BYTES_CONFIG = "fetch.min.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String FETCH_MAX_BYTES_CONFIG = "fetch.max.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final int DEFAULT_FETCH_MAX_BYTES = 52428800;</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String FETCH_MAX_WAIT_MS_CONFIG = "fetch.max.wait.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METADATA_MAX_AGE_CONFIG = "metadata.max.age.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String MAX_PARTITION_FETCH_BYTES_CONFIG = "max.partition.fetch.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final int DEFAULT_MAX_PARTITION_FETCH_BYTES = 1048576;</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String SEND_BUFFER_CONFIG = "send.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECEIVE_BUFFER_CONFIG = "receive.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CLIENT_ID_CONFIG = "client.id";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MS_CONFIG = "reconnect.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MAX_MS_CONFIG = "reconnect.backoff.max.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RETRY_BACKOFF_MS_CONFIG = "retry.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_SAMPLE_WINDOW_MS_CONFIG = "metrics.sample.window.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_NUM_SAMPLES_CONFIG = "metrics.num.samples";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_RECORDING_LEVEL_CONFIG = "metrics.recording.level";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRIC_REPORTER_CLASSES_CONFIG = "metric.reporters";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CHECK_CRCS_CONFIG = "check.crcs";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String KEY_DESERIALIZER_CLASS_CONFIG = "key.deserializer";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String VALUE_DESERIALIZER_CLASS_CONFIG = "value.deserializer";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CONNECTIONS_MAX_IDLE_MS_CONFIG = "connections.max.idle.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String REQUEST_TIMEOUT_MS_CONFIG = "request.timeout.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String INTERCEPTOR_CLASSES_CONFIG = "interceptor.classes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String EXCLUDE_INTERNAL_TOPICS_CONFIG = "exclude.internal.topics";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final boolean DEFAULT_EXCLUDE_INTERNAL_TOPICS = true;</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String ISOLATION_LEVEL_CONFIG = "isolation.level";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String DEFAULT_ISOLATION_LEVEL;</span></span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">org\apache\kafka\clients\CommonClientConfigs.java</span></span><br><span class="line"></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String BOOTSTRAP_SERVERS_CONFIG = "bootstrap.servers";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METADATA_MAX_AGE_CONFIG = "metadata.max.age.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String SEND_BUFFER_CONFIG = "send.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECEIVE_BUFFER_CONFIG = "receive.buffer.bytes";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CLIENT_ID_CONFIG = "client.id";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MS_CONFIG = "reconnect.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RECONNECT_BACKOFF_MAX_MS_CONFIG = "reconnect.backoff.max.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String RETRY_BACKOFF_MS_CONFIG = "retry.backoff.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_SAMPLE_WINDOW_MS_CONFIG = "metrics.sample.window.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_NUM_SAMPLES_CONFIG = "metrics.num.samples";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRICS_RECORDING_LEVEL_CONFIG = "metrics.recording.level";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String METRIC_REPORTER_CLASSES_CONFIG = "metric.reporters";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String SECURITY_PROTOCOL_CONFIG = "security.protocol";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String DEFAULT_SECURITY_PROTOCOL = "PLAINTEXT";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String CONNECTIONS_MAX_IDLE_MS_CONFIG = "connections.max.idle.ms";</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static final String REQUEST_TIMEOUT_MS_CONFIG = "request.timeout.ms";</span></span><br></pre></td></tr></table></figure></div>

<h4 id="不带回调的API"><a href="#不带回调的API" class="headerlink" title="不带回调的API"></a>不带回调的API</h4><p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523005738.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523005738.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 整个配置中的key可以使用ProducerConfig中定义的常量</span></span><br><span class="line">        <span class="comment">//kafka集群，broker-list</span></span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//重试次数</span></span><br><span class="line">        props.put(<span class="string">"retries"</span>, <span class="number">1</span>); </span><br><span class="line"></span><br><span class="line">        <span class="comment">//批次大小</span></span><br><span class="line">        props.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>); </span><br><span class="line"></span><br><span class="line">        <span class="comment">//等待时间</span></span><br><span class="line">        props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>); </span><br><span class="line"></span><br><span class="line">        <span class="comment">//RecordAccumulator缓冲区大小</span></span><br><span class="line">        props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first"</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            <span class="comment">// 轮循 这个会用到分区器 </span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"second"</span>,<span class="string">"value++&gt;"</span>+i));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据给的key进行hash 然后放在不同的分区 这个会使用到分区器</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"second"</span>,<span class="string">"key"</span>+i,<span class="string">"value==&gt;"</span>+i));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 具体指定了分区号 就不再使用到key 这个不会用到分区器</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;<span class="number">5</span>)&#123;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"second"</span>,<span class="string">"key"</span>+i,<span class="string">"value**&gt;"</span>+i));</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"second"</span>,<span class="string">"key"</span>+i,<span class="string">"value^^&gt;"</span>+i));</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">               </span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 分区器源码解读</span></span><br><span class="line">org\apache\kafka\clients\producer\Partitioner.java</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Partitioner</span> <span class="keyword">extends</span> <span class="title">Configurable</span>, <span class="title">Closeable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//唯一实现类</span></span><br><span class="line">org\apache\kafka\clients\producer\internals\DefaultPartitioner.java</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 传进来的是topic key 还有序列化后的key value 序列化后的value</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">        <span class="comment">//如果key是空的 后面的逻辑用了自增然后对分区取余 其实就是轮循</span></span><br><span class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">            <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">                <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">                <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 如果key不是空的 将keyBytes传进去然后做hash murmur2是一种哈希算法</span></span><br><span class="line">            <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="带回调的API"><a href="#带回调的API" class="headerlink" title="带回调的API"></a>带回调的API</h4><p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523005738.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523005738.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">跟上面不同的就是在使用send方法时候 带上一个回调函数</span><br><span class="line">    <span class="comment">// 回调方法:当前消息发出后 不管是消息成功发送还是发送失败 都会执行该回调方法</span></span><br><span class="line">    <span class="comment">// metadata 当前消息的元数据</span></span><br><span class="line">    <span class="comment">// metadata能拿到当前分区的各种数据 如下图所示</span></span><br><span class="line">    <span class="comment">// 偏移量 分区 主题 时间戳 等等</span></span><br><span class="line">    <span class="comment">// exception 当消息发送失败 会返回该异常</span></span><br></pre></td></tr></table></figure></div>

<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523010150.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523010150.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// org\apache\kafka\clients\producer\Callback.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Callback</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这是一个接口 里面有一个方法</span></span><br><span class="line"></span><br><span class="line">它有两个实现类</span><br></pre></td></tr></table></figure></div>

<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523010746.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523010746.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 示例 带回调的API</span></span><br><span class="line"><span class="keyword">package</span> com.atguigu.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyCallBackProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props  = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//kafka集群的位置</span></span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">//ack级别</span></span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG,<span class="string">"all"</span>);</span><br><span class="line">        <span class="comment">//重试次数</span></span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG,<span class="number">3</span>);</span><br><span class="line">        <span class="comment">//批次大小</span></span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG,<span class="number">16384</span>);</span><br><span class="line">        <span class="comment">//等待时间</span></span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG,<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//缓冲区大小</span></span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG,<span class="number">33554432</span>);</span><br><span class="line">        <span class="comment">//k v 序列化器</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.生产数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span> ; i++) &#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"second"</span>, <span class="string">"atguigu@@@@@"</span> + i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 回调方法: 当前的消息发送出去以后，会执行回调方法。</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> metadata  当前消息的元数据信息。</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> exception 当发送失败，会返回异常。</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        <span class="comment">//发送成功</span></span><br><span class="line">                        System.out.println(metadata.topic() + <span class="string">" -- "</span> + metadata.partition() + <span class="string">" -- "</span> + metadata.offset());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment">// TimeUnit.MILLISECONDS.sleep(100);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="kafka-API中没有写producer-close-为什么读不到数据-也没有回调方法"><a href="#kafka-API中没有写producer-close-为什么读不到数据-也没有回调方法" class="headerlink" title="kafka API中没有写producer.close()为什么读不到数据 也没有回调方法"></a>kafka API中没有写producer.close()为什么读不到数据 也没有回调方法</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是因为异步发送消息的原因</span><br><span class="line"></span><br><span class="line">main线程在发送完数据之后就结束了 这个时间小于了批次拉取设置的时间1ms </span><br><span class="line"></span><br><span class="line">sender线程去拉取数据的同时需要执行main线程中的回调方法 </span><br><span class="line">但是现在main线程已经关闭 所以无法执行回调方法</span><br><span class="line"></span><br><span class="line">如果我们不写close方法 而是让main线程休眠100ms 这时sender就能在这个时间内拉取到数据并执行回调方法</span><br><span class="line"></span><br><span class="line">所以close方法肯定会等待sender线程拉取数据完成后再进行关闭</span><br><span class="line">具体实现可以看close()方法的源码 如下</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// org\apache\kafka\clients\producer\KafkaProducer.java</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Close this producer. This method blocks until all previously sent requests complete.</span></span><br><span class="line"><span class="comment">     * This method is equivalent to &lt;code&gt;close(Long.MAX_VALUE, TimeUnit.MILLISECONDS)&lt;/code&gt;.</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * &lt;strong&gt;If close() is called from &#123;<span class="doctag">@link</span> Callback&#125;, a warning message will be logged and close(0, TimeUnit.MILLISECONDS)</span></span><br><span class="line"><span class="comment">     * will be called instead. We do this because the sender thread would otherwise try to join itself and</span></span><br><span class="line"><span class="comment">     * block forever.&lt;/strong&gt;</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptException If the thread is interrupted while blocked</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="comment">//关闭此生产者。 此方法一直阻塞所有以前发送的请求完成。 此方法等效于close(Long.MAX_VALUE, TimeUnit.MILLISECONDS) 如果关闭（）被从调用Callback ，警告消息将被记录并关闭（0，TimeUnit.MILLISECONDS）将被代替调用。 我们这样做是因为发件人线程否则将尝试加入自己和永远阻塞。</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        close(Long.MAX_VALUE, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * This method waits up to &lt;code&gt;timeout&lt;/code&gt; for the producer to complete the sending of all incomplete requests.</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * If the producer is unable to complete all requests before the timeout expires, this method will fail</span></span><br><span class="line"><span class="comment">     * any unsent and unacknowledged records immediately.</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * If invoked from within a &#123;<span class="doctag">@link</span> Callback&#125; this method will not block and will be equivalent to</span></span><br><span class="line"><span class="comment">     * &lt;code&gt;close(0, TimeUnit.MILLISECONDS)&lt;/code&gt;. This is done since no further sending will happen while</span></span><br><span class="line"><span class="comment">     * blocking the I/O thread of the producer.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> timeout The maximum time to wait for producer to complete any pending requests. The value should be</span></span><br><span class="line"><span class="comment">     *                non-negative. Specifying a timeout of zero means do not wait for pending send requests to complete.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> timeUnit The time unit for the &lt;code&gt;timeout&lt;/code&gt;</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptException If the thread is interrupted while blocked</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IllegalArgumentException If the &lt;code&gt;timeout&lt;/code&gt; is negative.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="comment">// 这种方法最多等待timeout的生产者完成所有未完成的请求的发送。</span></span><br><span class="line"><span class="comment">// 如果生产者是无法完成所有请求超时到期之前，此方法将立即失败任何未发送和未确认的记录。</span></span><br><span class="line"><span class="comment">// 如果从内调用Callback此方法不会阻止和将等效于close(0, TimeUnit.MILLISECONDS) 这样做是因为同时阻断生产者的I/O线程没有进一步的发送会发生</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit timeUnit)</span> </span>&#123;</span><br><span class="line">        close(timeout, timeUnit, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit timeUnit, <span class="keyword">boolean</span> swallowException)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"The timeout cannot be negative."</span>);</span><br><span class="line"></span><br><span class="line">        log.info(<span class="string">"Closing the Kafka producer with timeoutMillis = &#123;&#125; ms."</span>, timeUnit.toMillis(timeout));</span><br><span class="line">        <span class="comment">// this will keep track of the first encountered exception</span></span><br><span class="line">        AtomicReference&lt;Throwable&gt; firstException = <span class="keyword">new</span> AtomicReference&lt;&gt;();</span><br><span class="line">        <span class="keyword">boolean</span> invokedFromCallback = Thread.currentThread() == <span class="keyword">this</span>.ioThread;</span><br><span class="line">        <span class="keyword">if</span> (timeout &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (invokedFromCallback) &#123;</span><br><span class="line">                log.warn(<span class="string">"Overriding close timeout &#123;&#125; ms to 0 ms in order to prevent useless blocking due to self-join. "</span> +</span><br><span class="line">                        <span class="string">"This means you have incorrectly invoked close with a non-zero timeout from the producer call-back."</span>, timeout);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// Try to close gracefully.</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.sender != <span class="keyword">null</span>)</span><br><span class="line">                    <span class="keyword">this</span>.sender.initiateClose();</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.ioThread != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">this</span>.ioThread.join(timeUnit.toMillis(timeout));</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException t) &#123;</span><br><span class="line">                        firstException.compareAndSet(<span class="keyword">null</span>, t);</span><br><span class="line">                        log.error(<span class="string">"Interrupted while joining ioThread"</span>, t);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.sender != <span class="keyword">null</span> &amp;&amp; <span class="keyword">this</span>.ioThread != <span class="keyword">null</span> &amp;&amp; <span class="keyword">this</span>.ioThread.isAlive()) &#123;</span><br><span class="line">            log.info(<span class="string">"Proceeding to force close the producer since pending requests could not be completed "</span> +</span><br><span class="line">                    <span class="string">"within timeout &#123;&#125; ms."</span>, timeout);</span><br><span class="line">            <span class="keyword">this</span>.sender.forceClose();</span><br><span class="line">            <span class="comment">// Only join the sender thread when not calling from callback.</span></span><br><span class="line">            <span class="comment">// 仅当不从回调调用时才加入发送者线程。</span></span><br><span class="line">            <span class="keyword">if</span> (!invokedFromCallback) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">this</span>.ioThread.join();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    firstException.compareAndSet(<span class="keyword">null</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ClientUtils.closeQuietly(interceptors, <span class="string">"producer interceptors"</span>, firstException);</span><br><span class="line">        ClientUtils.closeQuietly(metrics, <span class="string">"producer metrics"</span>, firstException);</span><br><span class="line">        ClientUtils.closeQuietly(keySerializer, <span class="string">"producer keySerializer"</span>, firstException);</span><br><span class="line">        ClientUtils.closeQuietly(valueSerializer, <span class="string">"producer valueSerializer"</span>, firstException);</span><br><span class="line">        ClientUtils.closeQuietly(partitioner, <span class="string">"producer partitioner"</span>, firstException);</span><br><span class="line">        AppInfoParser.unregisterAppInfo(JMX_PREFIX, clientId);</span><br><span class="line">        log.debug(<span class="string">"The Kafka producer has closed."</span>);</span><br><span class="line">        <span class="keyword">if</span> (firstException.get() != <span class="keyword">null</span> &amp;&amp; !swallowException)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Failed to close kafka producer"</span>, firstException.get());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="如何使用kafka-API-实现同步消息发送"><a href="#如何使用kafka-API-实现同步消息发送" class="headerlink" title="如何使用kafka API 实现同步消息发送"></a>如何使用kafka API 实现同步消息发送</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</span><br><span class="line">由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方法即可。</span><br><span class="line"></span><br><span class="line">区别就在于在send方法处拿到返回值future</span><br><span class="line">然后调用future中的get方法</span><br><span class="line">调用此方法就会阻塞当前线程 一直等到结果返回</span><br><span class="line"></span><br><span class="line">java\util\concurrent\Future.java</span><br></pre></td></tr></table></figure></div>

<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523014826.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523014826.png" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyCallBackProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props  = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//kafka集群的位置</span></span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">//ack级别</span></span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG,<span class="string">"all"</span>);</span><br><span class="line">        <span class="comment">//重试次数</span></span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG,<span class="number">3</span>);</span><br><span class="line">        <span class="comment">//批次大小</span></span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG,<span class="number">16384</span>);</span><br><span class="line">        <span class="comment">//等待时间</span></span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG,<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//缓冲区大小</span></span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG,<span class="number">33554432</span>);</span><br><span class="line">        <span class="comment">//k v 序列化器</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.生产数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span> ; i++) &#123;</span><br><span class="line">            Future&lt;RecordMetadata&gt; future = producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"second"</span>, <span class="string">"atguigu@@@@@"</span> + i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 回调方法: 当前的消息发送出去以后，会执行回调方法。</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> metadata  当前消息的元数据信息。</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> exception 当发送失败，会返回异常。</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        <span class="comment">//发送成功</span></span><br><span class="line">                        System.out.println(metadata.topic() + <span class="string">" -- "</span> + metadata.partition() + <span class="string">" -- "</span> + metadata.offset());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            <span class="comment">// 发送一个之后阻塞线程等待返回结果才继续发送下一个</span></span><br><span class="line">            <span class="comment">// 阻塞等待 ， 同步发送</span></span><br><span class="line">            <span class="comment">// 此时会发现结果严格按照发送的顺序</span></span><br><span class="line">            RecordMetadata recordMetadata = future.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka的分区器怎么写-如何自定义分区器"><a href="#kafka的分区器怎么写-如何自定义分区器" class="headerlink" title="kafka的分区器怎么写 如何自定义分区器"></a>kafka的分区器怎么写 如何自定义分区器</h3><ul>
<li>继承<code>Partitioner</code></li>
<li>重写三个方法<code>configure() partition() close()</code></li>
</ul>
<blockquote>
<p>可以根据传进的key分区 也可根据value分区</p>
<p>在定义好自己的分区器之后 还要再配置中添加分区器的全类名 否则会走默认的分区器</p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">系统默认分区器</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Compute the partition for the given record.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic The topic name</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key The key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyBytes serialized key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value The value to partition on or null</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> valueBytes serialized value to partition on or null</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cluster The current cluster metadata</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">            <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">                <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">                <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">        AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123;</span><br><span class="line">            counter = <span class="keyword">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());</span><br><span class="line">            AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">            <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">                counter = currentCounter;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单实现一个分区器</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123; <span class="comment">// key为空 到0号分区</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// key不为空 到1号分区</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 如果要使用自己定义的分区器 要在配置中指定分区器并传入分区器的全类名</span></span><br><span class="line">props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,<span class="string">"com.atguigu.kafka.partitioner.MyPartitioner"</span>);</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka的消费者需要注意的主要问题是什么"><a href="#kafka的消费者需要注意的主要问题是什么" class="headerlink" title="kafka的消费者需要注意的主要问题是什么"></a>kafka的消费者需要注意的主要问题是什么</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</span><br><span class="line"></span><br><span class="line">由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</span><br><span class="line"></span><br><span class="line">所以offset的维护是Consumer消费数据是必须考虑的问题。</span><br></pre></td></tr></table></figure></div>

<h3 id="如何使用kafka-API-实现消息接收-消费者"><a href="#如何使用kafka-API-实现消息接收-消费者" class="headerlink" title="如何使用kafka API 实现消息接收(消费者)"></a>如何使用kafka API 实现消息接收(消费者)</h3><h4 id="准备知识-1"><a href="#准备知识-1" class="headerlink" title="准备知识"></a>准备知识</h4><p>需要用到的类：</p>
<p><strong>KafkaConsumer</strong>：需要创建一个消费者对象，用来消费数据</p>
<p><strong>ConsumerConfig</strong>：获取所需的一系列配置参数</p>
<p><strong>ConsuemrRecord</strong>：每条数据都要封装成一个ConsumerRecord对象</p>
<p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。</p>
<p>自动提交offset的相关参数：</p>
<p><strong>enable.auto.commit</strong>：是否开启自动提交offset功能</p>
<p><strong>auto.commit.interval.ms</strong>：自动提交offset的时间间隔</p>
<hr>
<p>几个比较重要的配置项</p>
<ul>
<li>自动提交offset功能</li>
<li>自动提交时间间隔</li>
<li>消费者组</li>
<li>反序列化器(对应生产者端的序列化<code>org\apache\kafka\common\serialization\Deserializer.java</code>)</li>
</ul>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523025729.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523025729.png" class="lazyload"></a></p>
<h4 id="自动提交offset"><a href="#自动提交offset" class="headerlink" title="自动提交offset"></a>自动提交offset</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> fun.hoffee.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//指定kafka集群的位置</span></span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//开启自动提交offset</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true);</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//自动提交offset的间隔</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定消费者组</span></span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"atguigu"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定kv的反序列化器</span></span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 订阅主题</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>, <span class="string">"second"</span>, <span class="string">"third"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.topic() + <span class="string">" -- "</span> + record.partition() + <span class="string">" -- "</span> + record.offset() + <span class="string">" -- "</span> + record.key() + <span class="string">" -- "</span> + record.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 此时创建的是新组 不能消费到之前的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果想要消费之前的数据 需要重置offset</span></span><br><span class="line"><span class="comment">// 由auto.offset.rest参数(ConsumerConfig中的AUTO_OFFSET_RESET_CONFIG = "auto.offset.reset";)控制  默认值为latest</span></span><br><span class="line"><span class="comment">// 可以配置为 earliest | latest | none</span></span><br><span class="line">---</span><br><span class="line"><span class="comment">// 文档说明如下 :</span></span><br><span class="line"><span class="comment">// What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted): </span></span><br><span class="line"><span class="comment">// earliest: automatically reset the offset to the earliest offset </span></span><br><span class="line"><span class="comment">// latest: automatically reset the offset to the latest offset </span></span><br><span class="line"><span class="comment">// none: throw exception to the consumer if no previous offset is found for the consumer's group </span></span><br><span class="line"><span class="comment">// anything else: throw exception to the consumer.</span></span><br><span class="line"><span class="comment">// 当Kafka中没有初始偏移量或服务器上不再存在当前偏移量时（例如，因为该数据已被删除），该怎么办：</span></span><br><span class="line"><span class="comment">// 最早：自动将偏移量重置为最早的偏移量 </span></span><br><span class="line"><span class="comment">// 最新：自动将偏移量重置为最新偏移量 </span></span><br><span class="line"><span class="comment">// 无：如果未找到消费者组的先前偏移量，则向消费者抛出异常 </span></span><br><span class="line"><span class="comment">// 其他：向消费者抛出异常</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 人话: 如果这个是一个新的组 或者是 这个组拿了一个kafka中不存在的偏移量去消费数据时候 kafka就会自动帮忙重置offset 如果配置过这个参数 就按这个参数配置的来 如果没有配置过 默认重置为latest</span></span><br></pre></td></tr></table></figure></div>

<h4 id="重置offset"><a href="#重置offset" class="headerlink" title="重置offset"></a>重置offset</h4><blockquote>
<p>具体说明见上一节代码末尾</p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//指定kafka集群的位置</span></span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//开启自动提交offset</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true);</span></span><br><span class="line">        <span class="comment">//关闭自动提交offset</span></span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//自动提交offset的间隔</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//重置offset :   earliest(最早)   latest(最后)</span></span><br><span class="line">        <span class="comment">//满足两个条件: </span></span><br><span class="line">        <span class="comment">// 1. 当前的消费者组在kafka没有消费过所订阅的主题   </span></span><br><span class="line">        <span class="comment">// 2.当前消费者组使用的offset在kafka集群中已经被删除</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">"earliest"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定消费者组</span></span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">"atguigu111"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定kv的反序列化器</span></span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String,String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 订阅主题</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>,<span class="string">"second"</span>,<span class="string">"third"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="comment">// 此处是拉取数据方法 poll中传递的参数是超时时间 当主题中没有数据时候 等待超时时间之后再进行拉取数据</span></span><br><span class="line">            <span class="comment">// 假如某一次没有消费到数据 会等待响应的时间之后再进行拉取 单位是ms</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records  = consumer.poll(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.topic() + <span class="string">" -- "</span> + record.partition() + <span class="string">" -- "</span> + record.offset() +<span class="string">" -- "</span> +</span><br><span class="line">                    record.key() +<span class="string">" -- "</span> + record.value());</span><br><span class="line">       		&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="手动提交offset的两种方式"><a href="#手动提交offset的两种方式" class="headerlink" title="手动提交offset的两种方式"></a>手动提交offset的两种方式</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">虽然自动提交offset十分简介便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</span><br><span class="line"></span><br><span class="line">手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。</span><br><span class="line"></span><br><span class="line">两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；</span><br><span class="line"></span><br><span class="line">不同点是，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">由于同步提交offset有失败重试机制，故更加可靠</span><br><span class="line"></span><br><span class="line">虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果关闭了提交offset 在一直没有关闭consumer的情况下 consumer能正常消费数据 </span><br><span class="line">因为consumer从kafka中拿到offset后会一直将offset维护在内存中</span><br><span class="line"></span><br><span class="line">但是一旦关闭 因为没有向kafka提交过offset 则offset还是之前的</span><br><span class="line">那么这段时间生产的数据将被重复消费</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//指定kafka集群的位置</span></span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"hadoop102:9092"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//开启自动提交offset</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true);</span></span><br><span class="line">        <span class="comment">//关闭自动提交offset</span></span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//自动提交offset的间隔</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//重置offset :   earliest(最早)   latest(最后)</span></span><br><span class="line">        <span class="comment">//满足两个条件: 1. 当前的消费者组在kafka没有消费过所订阅的主题   2.当前消费者组使用的offset在kafka集群中已经被删除</span></span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">"earliest"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定消费者组</span></span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">"atguigu111"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定kv的反序列化器</span></span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String,String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 订阅主题</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>,<span class="string">"second"</span>,<span class="string">"third"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="comment">// 此处是拉取数据方法 poll中传递的参数是超时时间 当主题中没有数据时候 等待超时时间之后再进行拉取数据</span></span><br><span class="line">            <span class="comment">// 假如某一次没有消费到数据 会等待响应的时间之后再进行拉取 单位是ms</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records  = consumer.poll(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.topic() + <span class="string">" -- "</span> + record.partition() + <span class="string">" -- "</span> + record.offset() +<span class="string">" -- "</span> +</span><br><span class="line">                    record.key() +<span class="string">" -- "</span> + record.value());</span><br><span class="line">        &#125;</span><br><span class="line">            <span class="comment">//手动提交offset</span></span><br><span class="line">            <span class="comment">//同步提交 代码会阻塞 直到提交offset成功 才开始消费下一条数据</span></span><br><span class="line">            consumer.commitSync();  <span class="comment">//阻塞</span></span><br><span class="line">            <span class="comment">//异步提交 会触发提交offset的操作 但是会继续消费数据 不管offset是否提交成功</span></span><br><span class="line">            <span class="comment">//consumer.commitAsync();</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中重复消费数据和漏消费数据的情况"><a href="#kafka中重复消费数据和漏消费数据的情况" class="headerlink" title="kafka中重复消费数据和漏消费数据的情况"></a>kafka中重复消费数据和漏消费数据的情况</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。</span><br><span class="line"></span><br><span class="line">先提交offset后消费，有可能造成数据的漏消费；</span><br><span class="line"></span><br><span class="line">而先消费后提交offset，有可能会造成数据的重复消费。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是offset的提交  和 消费数据 这两件事之间的先后顺序问题</span><br><span class="line"></span><br><span class="line">例1 : </span><br><span class="line">消费者poll进100条数据 但是在消费到第60条时候宕机 但是offset已经提交 这时候 offset超前</span><br><span class="line">则后40条出现漏消费</span><br><span class="line"></span><br><span class="line">例2 :</span><br><span class="line">消费者poll进100条数据 但是offset在提交时候失败 但此时是先消费后提交offset的情况 这时候 offset滞后</span><br><span class="line">则这100条数据在下次启动时候会被重复消费</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如何解决这个问题?</span><br><span class="line"></span><br><span class="line">将两件事情绑定在一起 如果失败则同时失败 如果成功则同时成功</span><br><span class="line">不允许出现一个失败一个成功的情况</span><br><span class="line"></span><br><span class="line">将两件事绑定为事务</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka-API-如何实现自定义存储offset"><a href="#kafka-API-如何实现自定义存储offset" class="headerlink" title="kafka API 如何实现自定义存储offset"></a>kafka API 如何实现自定义存储offset</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kafka 0.9版本之前，offset存储在zookeeper，0.9版本及之后，默认将offset存储在Kafka的一个内置的topic中。除此之外，Kafka还可以选择自定义存储offset。</span><br><span class="line"></span><br><span class="line">offset的维护是相当繁琐的，因为需要考虑到消费者的Rebalace。</span><br><span class="line"></span><br><span class="line">当有新的消费者加入消费者组、已有的消费者推出消费者组或者所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫做Rebalance。</span><br><span class="line"></span><br><span class="line">消费者发生Rebalance之后，每个消费者消费的分区就会发生变化。因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的offset位置继续消费。</span><br><span class="line"></span><br><span class="line">要实现自定义存储offset，需要借助ConsumerRebalanceListener，以下为示例代码，其中提交和获取offset的方法，需要根据所选的offset存储系统自行实现。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;TopicPartition, Long&gt; currentOffset = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 创建配置信息</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Kafka集群</span></span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop102:9092"</span>); </span><br><span class="line"></span><br><span class="line">		<span class="comment">// 消费者组，只要group.id相同，就属于同一个消费者组</span></span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>); </span><br><span class="line"></span><br><span class="line">		<span class="comment">// 关闭自动提交offset</span></span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Key和Value的反序列化类</span></span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 消费者订阅主题 在订阅时候创建一个ConsumerRebalanceListener的对象实时监听</span></span><br><span class="line">    	<span class="comment">// 并重写两个方法onPartitionsRevoked 和 onPartitionsAssigned</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>), <span class="keyword">new</span> ConsumerRebalanceListener() &#123;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//该方法会在Rebalance之前调用</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">                commitOffset(currentOffset);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//该方法会在Rebalance之后调用</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">                currentOffset.clear();</span><br><span class="line">                <span class="keyword">for</span> (TopicPartition partition : partitions) &#123;</span><br><span class="line">                    consumer.seek(partition, getOffset(partition));</span><br><span class="line">                    <span class="comment">//定位到最近提交的offset位置继续消费</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="comment">//消费者拉取数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(<span class="string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line">                currentOffset.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), record.offset());</span><br><span class="line">            &#125;</span><br><span class="line">            commitOffset(currentOffset);<span class="comment">//异步提交</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取某分区的最新offset</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getOffset</span><span class="params">(TopicPartition partition)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;<span class="comment">// 这里是伪代码 需要根据具体存储的系统来实现</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//提交该消费者所有分区的offset</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">commitOffset</span><span class="params">(Map&lt;TopicPartition, Long&gt; currentOffset)</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 这里是伪代码 需要根据具体存储的系统来实现</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="kafka中的拦截器是如何实现的-原理是什么"><a href="#kafka中的拦截器是如何实现的-原理是什么" class="headerlink" title="kafka中的拦截器是如何实现的 原理是什么"></a>kafka中的拦截器是如何实现的 原理是什么</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</span><br><span class="line">对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</span><br><span class="line">（1）configure(configs)</span><br><span class="line">获取配置信息和初始化数据时调用。</span><br><span class="line"></span><br><span class="line">（2）onSend(ProducerRecord)：</span><br><span class="line">该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</span><br><span class="line"></span><br><span class="line">（3）onAcknowledgement(RecordMetadata, Exception)：</span><br><span class="line">该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</span><br><span class="line"></span><br><span class="line">（4）close：</span><br><span class="line">关闭interceptor，主要用于执行一些资源清理工作</span><br><span class="line">如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</span><br></pre></td></tr></table></figure></div>

<h3 id="请实现一个kafka的拦截器"><a href="#请实现一个kafka的拦截器" class="headerlink" title="请实现一个kafka的拦截器"></a>请实现一个kafka的拦截器</h3><p><strong>需求：</strong></p>
<p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p>
<p><strong>分析:</strong></p>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523043416.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523043416.png" class="lazyload"></a></p>
<p><strong>时间拦截器</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> fun.hoffee.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在所有的消息内容前面加上时间戳</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取当前消息的value</span></span><br><span class="line">        String value = record.value();</span><br><span class="line">        value = System.currentTimeMillis() + <span class="string">" -- "</span> + value;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//构造一个producerRecord</span></span><br><span class="line">        ProducerRecord&lt;String, String&gt; resultRecord =</span><br><span class="line">                <span class="keyword">new</span> ProducerRecord&lt;&gt;(record.topic(), record.partition(), record.key(), value);</span><br><span class="line">        <span class="keyword">return</span> resultRecord;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><strong>计数拦截器</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> fun.hoffee.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 统计发送成功或失败的消息个数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer success = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer fail = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 相当于原路返回没有做处理</span></span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">            success++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            fail++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 整个拦截器走完之后 调用该方法</span></span><br><span class="line">        System.out.println(<span class="string">"Success : "</span> + success);</span><br><span class="line">        System.out.println(<span class="string">"Fail :"</span> + fail);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><strong>在生产者的配置文件中配置拦截器(可设置多个 设置为一个list)</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> fun.hoffee.kafka.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterceptorProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建配置对象</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//指定kafka集群的位置，broker-list</span></span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">//指定ack的应答级别  0  1  -1(all)</span></span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</span><br><span class="line">        <span class="comment">//重试次数</span></span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG, <span class="number">5</span>);</span><br><span class="line">        <span class="comment">//批次大小</span></span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);  <span class="comment">// 16kb</span></span><br><span class="line">        <span class="comment">//等待时间</span></span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//RecordAccumulator缓冲区大小</span></span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);  <span class="comment">// 32M</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定kv的序列化器</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定拦截器</span></span><br><span class="line">        <span class="comment">// "A list of classes to use as interceptors. Implementing the &lt;code&gt;ProducerInterceptor&lt;/code&gt; interface allows you to intercept (and possibly mutate) the records received by the producer before they are published to the Kafka cluster. By default, there are no interceptors.";</span></span><br><span class="line">        List&lt;String&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        interceptors.add(<span class="string">"com.atguigu.kafka.interceptor.TimeInterceptor"</span>);</span><br><span class="line">        interceptors.add(<span class="string">"com.atguigu.kafka.interceptor.CountInterceptor"</span>);</span><br><span class="line">        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 创建生产者对象</span></span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 生产数据</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"second"</span>, <span class="string">"shangguigu==&gt;"</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 关闭</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="flume如何对接kafka"><a href="#flume如何对接kafka" class="headerlink" title="flume如何对接kafka"></a>flume如何对接kafka</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">使用kafkasink</span><br><span class="line"></span><br><span class="line">此时kafkasink相当于kafka的生产者 它可以根据消息的标记发送给kafka中不同的topic</span><br></pre></td></tr></table></figure></div>

<p>flume官网关于kafka sink的介绍如下</p>
<p>这是一个Flume Sink实现，可以将数据发布到 <a href="http://kafka.apache.org/" target="_blank" rel="noopener">Kafka</a>主题。目标之一是将Flume与Kafka集成在一起，以便基于拉式的处理系统可以处理来自各种Flume来源的数据。目前，该版本支持Kafka 0.9.x系列发行版。</p>
<p>此版本的Flume不再支持Kafka的旧版本（0.8.x）。</p>
<p>必需的属性以粗体标记。</p>
<table>
<thead>
<tr>
<th>Property Name</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><strong>type</strong></td>
<td>–</td>
<td>Must be set to <code>org.apache.flume.sink.kafka.KafkaSink</code></td>
</tr>
<tr>
<td><strong>kafka.bootstrap.servers</strong></td>
<td>–</td>
<td>List of brokers Kafka-Sink will connect to, to get the list of topic partitions This can be a partial list of brokers, but we recommend at least two for HA. The format is comma separated list of hostname:port Kafka-Sink将连接到的代理列表，以获取主题分区列表。这可以是部分代理列表，但是对于HA，我们建议至少两个。格式是用逗号分隔的主机名：端口列表</td>
</tr>
<tr>
<td>kafka.topic</td>
<td>default-flume-topic</td>
<td>The topic in Kafka to which the messages will be published. If this parameter is configured, messages will be published to this topic. If the event header contains a “topic” field, the event will be published to that topic overriding the topic configured here. Kafka中将发布消息的主题。如果配置了此参数，则消息将发布到该主题。如果事件标题包含“主题”字段，则事件将发布到该主题，并覆盖此处配置的主题。</td>
</tr>
<tr>
<td>flumeBatchSize</td>
<td>100</td>
<td>How many messages to process in one batch. Larger batches improve throughput while adding latency. 一批中要处理多少条消息。较大的批次可提高吞吐量，同时增加延迟。</td>
</tr>
<tr>
<td>kafka.producer.acks</td>
<td>1</td>
<td>How many replicas must acknowledge a message before its considered successfully written. Accepted values are 0 (Never wait for acknowledgement), 1 (wait for leader only), -1 (wait for all replicas) Set this to -1 to avoid data loss in some cases of leader failure. 在成功考虑一条消息之前，有多少个副本必须确认一条消息。接受的值为0（永远不等待确认），1（仅等待领导者），-1（等待所有副本）将其设置为-1，以避免在某些领导者失败的情况下丢失数据。</td>
</tr>
<tr>
<td>useFlumeEventFormat</td>
<td>false</td>
<td>By default events are put as bytes onto the Kafka topic directly from the event body. Set to true to store events as the Flume Avro binary format. Used in conjunction with the same property on the KafkaSource or with the parseAsFlumeEvent property on the Kafka Channel this will preserve any Flume headers for the producing side. 默认情况下，事件直接从事件主体作为字节放入Kafka主题。设置为true可将事件存储为Flume Avro二进制格式。与KafkaSource上的相同属性或Kafka Channel上的parseAsFlumeEvent属性结合使用，将为生产方保留任何Flume标头。</td>
</tr>
<tr>
<td>defaultPartitionId</td>
<td>–</td>
<td>Specifies a Kafka partition ID (integer) for all events in this channel to be sent to, unless overriden by <code>partitionIdHeader</code>. By default, if this property is not set, events will be distributed by the Kafka Producer’s partitioner - including by <code>key</code> if specified (or by a partitioner specified by <code>kafka.partitioner.class</code>).</td>
</tr>
<tr>
<td>partitionIdHeader</td>
<td>–</td>
<td>When set, the sink will take the value of the field named using the value of this property from the event header and send the message to the specified partition of the topic. If the value represents an invalid partition, an EventDeliveryException will be thrown. If the header value is present then this setting overrides <code>defaultPartitionId</code>.</td>
</tr>
<tr>
<td>kafka.producer.security.protocol</td>
<td>PLAINTEXT</td>
<td>Set to SASL_PLAINTEXT, SASL_SSL or SSL if writing to Kafka using some level of security. See below for additional info on secure setup.</td>
</tr>
<tr>
<td><em>more producer security props</em></td>
<td></td>
<td>If using SASL_PLAINTEXT, SASL_SSL or SSL refer to <a href="http://kafka.apache.org/documentation.html#security" target="_blank" rel="noopener">Kafka security</a> for additional properties that need to be set on producer.</td>
</tr>
<tr>
<td>Other Kafka Producer Properties</td>
<td>–</td>
<td>These properties are used to configure the Kafka Producer. Any producer property supported by Kafka can be used. The only requirement is to prepend the property name with the prefix <code>kafka.producer</code>. For example: kafka.producer.linger.ms</td>
</tr>
</tbody></table>
<p>The Kafka sink also provides defaults for the key.serializer(org.apache.kafka.common.serialization.StringSerializer) and value.serializer(org.apache.kafka.common.serialization.ByteArraySerializer). Modification of these parameters is not recommended.</p>
<p>An example configuration of a Kafka sink is given below. Properties starting with the prefix <code>kafka.producer</code> the Kafka producer. The properties that are passed when creating the Kafka producer are not limited to the properties given in this example. Also it is possible to include your custom properties here and access them inside the preprocessor through the Flume Context object passed in as a method argument.</p>
<p>示例配置如下:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k1.type &#x3D; org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.kafka.topic &#x3D; mytopic &#x2F;&#x2F; 指定写入topic</span><br><span class="line">a1.sinks.k1.kafka.bootstrap.servers &#x3D; localhost:9092 &#x2F;&#x2F; kafka位置</span><br><span class="line">a1.sinks.k1.kafka.flumeBatchSize &#x3D; 20</span><br><span class="line">a1.sinks.k1.kafka.producer.acks &#x3D; 1</span><br><span class="line">a1.sinks.k1.kafka.producer.linger.ms &#x3D; 1</span><br><span class="line">a1.sinks.ki.kafka.producer.compression.type &#x3D; snappy</span><br></pre></td></tr></table></figure></div>

<h3 id="实现flume中不同的event发往kafka中不同的topic"><a href="#实现flume中不同的event发往kafka中不同的topic" class="headerlink" title="实现flume中不同的event发往kafka中不同的topic"></a>实现flume中不同的event发往kafka中不同的topic</h3><p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523053711.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523053711.png" class="lazyload"></a></p>
<h3 id="如何监控kafka"><a href="#如何监控kafka" class="headerlink" title="如何监控kafka"></a>如何监控kafka</h3><h3 id="kafka面试题总结"><a href="#kafka面试题总结" class="headerlink" title="kafka面试题总结"></a>kafka面试题总结</h3><h4 id="1-Kafka中的ISR、OSR、AR又代表什么？"><a href="#1-Kafka中的ISR、OSR、AR又代表什么？" class="headerlink" title="1.Kafka中的ISR、OSR、AR又代表什么？"></a>1.Kafka中的ISR、OSR、AR又代表什么？</h4><blockquote>
<p>ISR：与leader保持同步的follower集合<br>AR：分区的所有副本</p>
</blockquote>
<h4 id="2-Kafka中的HW、LEO等分别代表什么？"><a href="#2-Kafka中的HW、LEO等分别代表什么？" class="headerlink" title="2.Kafka中的HW、LEO等分别代表什么？"></a>2.Kafka中的HW、LEO等分别代表什么？</h4><blockquote>
<p>LEO：没个副本的最后条消息的offset<br>HW：一个分区中所有副本最小的offset 控制整个分区中哪些数据能够暴露给消费者</p>
</blockquote>
<h4 id="3-Kafka中是怎么体现消息顺序性的？"><a href="#3-Kafka中是怎么体现消息顺序性的？" class="headerlink" title="3.Kafka中是怎么体现消息顺序性的？"></a>3.Kafka中是怎么体现消息顺序性的？</h4><blockquote>
<p>每个分区内，每条消息都有一个offset，故只能保证分区内有序。</p>
</blockquote>
<h4 id="4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="4.Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>4.Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h4><blockquote>
<p>拦截器 -&gt; 序列化器 -&gt; 分区器</p>
</blockquote>
<h4 id="5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"><a href="#5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？" class="headerlink" title="5.Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"></a>5.Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</h4><p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200522223103.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200522223103.png" class="lazyload"></a></p>
<h4 id="6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"><a href="#6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？" class="headerlink" title="6.“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"></a>6.“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？</h4><blockquote>
<p>正确</p>
</blockquote>
<h4 id="7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？"><a href="#7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？" class="headerlink" title="7.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？"></a>7.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？</h4><blockquote>
<p>offset+1 记录下次消费的数据的offset</p>
</blockquote>
<h4 id="8-有哪些情形会造成重复消费？"><a href="#8-有哪些情形会造成重复消费？" class="headerlink" title="8.有哪些情形会造成重复消费？"></a>8.有哪些情形会造成重复消费？</h4><p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523163301.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523163301.png" class="lazyload"></a></p>
<h4 id="9-有哪些情景会造成消息漏消费？"><a href="#9-有哪些情景会造成消息漏消费？" class="headerlink" title="9.有哪些情景会造成消息漏消费？"></a>9.有哪些情景会造成消息漏消费？</h4><blockquote>
<p>先提交offset，后消费，有可能造成数据的重复</p>
</blockquote>
<h4 id="10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="10.当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>10.当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h4><blockquote>
<p>1）会在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/first</p>
<p>2）触发Controller的监听程序</p>
<p>3）kafka Controller 负责topic的创建工作，并更新metadata cache</p>
</blockquote>
<h4 id="11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="11.topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>11.topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h4><blockquote>
<p>可以增加</p>
<p>bin/kafka-topics.sh –zookeeper localhost:2181/kafka –alter –topic topic-config –partitions 3</p>
</blockquote>
<h4 id="12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="12.topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>12.topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h4><blockquote>
<p>不可以减少，现有的分区数据难以处理。</p>
</blockquote>
<h4 id="13-Kafka有内部的topic吗？如果有是什么？有什么所用？"><a href="#13-Kafka有内部的topic吗？如果有是什么？有什么所用？" class="headerlink" title="13.Kafka有内部的topic吗？如果有是什么？有什么所用？"></a>13.Kafka有内部的topic吗？如果有是什么？有什么所用？</h4><blockquote>
<p>__consumer_offsets, 共有50个分区 保存消费者offset</p>
</blockquote>
<h4 id="14-Kafka分区分配的概念？"><a href="#14-Kafka分区分配的概念？" class="headerlink" title="14.Kafka分区分配的概念？"></a>14.Kafka分区分配的概念？</h4><blockquote>
<p>一个topic多个分区，一个消费者组多个消费者，故需要将分区分配个消费者(roundrobin、range)</p>
</blockquote>
<h4 id="15-简述Kafka的日志目录结构？"><a href="#15-简述Kafka的日志目录结构？" class="headerlink" title="15.简述Kafka的日志目录结构？"></a>15.简述Kafka的日志目录结构？</h4><blockquote>
<p>每个分区对应一个文件夹，文件夹的命名为topic-0，topic-1，内部为.log和.index文件</p>
</blockquote>
<h4 id="16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？"><a href="#16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？" class="headerlink" title="16.如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？"></a>16.如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？</h4><blockquote>
<p>先通过offset比对log文件的名字 确定好后 再找到对应的index文件中offset对应的消息索引位置</p>
<p>最后在log文件中找到相应的消息</p>
</blockquote>
<p><a href="https://gitee.com/hoffeechen/image/raw/master/img/20200523163707.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://gitee.com/hoffeechen/image/raw/master/img/20200523163707.png" class="lazyload"></a></p>
<h4 id="17-聊一聊Kafka-Controller的作用？"><a href="#17-聊一聊Kafka-Controller的作用？" class="headerlink" title="17.聊一聊Kafka Controller的作用？"></a>17.聊一聊Kafka Controller的作用？</h4><blockquote>
<p>负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p>
</blockquote>
<h4 id="18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="18.Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>18.Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h4><blockquote>
<p>partition leader（ISR），由Controller负责</p>
<p>Controller（先到先得）</p>
</blockquote>
<h4 id="19-失效副本是指什么？有那些应对措施？"><a href="#19-失效副本是指什么？有那些应对措施？" class="headerlink" title="19.失效副本是指什么？有那些应对措施？"></a>19.失效副本是指什么？有那些应对措施？</h4><blockquote>
<p>不能及时与leader同步，暂时踢出ISR，等其追上leader之后再重新加入</p>
</blockquote>
<h4 id="20-Kafka的那些设计让它有如此高的性能？"><a href="#20-Kafka的那些设计让它有如此高的性能？" class="headerlink" title="20.Kafka的那些设计让它有如此高的性能？"></a>20.Kafka的那些设计让它有如此高的性能？</h4><blockquote>
<p>分区，顺序写磁盘，0-copy</p>
</blockquote>
<h3 id="其他kafka相关面试题搜集-一"><a href="#其他kafka相关面试题搜集-一" class="headerlink" title="其他kafka相关面试题搜集(一)"></a>其他kafka相关面试题搜集(一)</h3><h4 id="1、请说明什么是Apache-Kafka"><a href="#1、请说明什么是Apache-Kafka" class="headerlink" title="1、请说明什么是Apache Kafka?"></a>1、请说明什么是Apache Kafka?</h4><blockquote>
<p>Apache Kafka是由Apache开发的一种发布订阅消息系统，它是一个分布式的、分区的和可复制的提交日志服务。</p>
</blockquote>
<h4 id="2、说说Kafka的使用场景？"><a href="#2、说说Kafka的使用场景？" class="headerlink" title="2、说说Kafka的使用场景？"></a>2、说说Kafka的使用场景？</h4><blockquote>
<p>①异步处理<br>②应用解耦<br>③流量削峰<br>④日志处理<br>⑤消息通讯等。</p>
</blockquote>
<h4 id="3、使用Kafka有什么优点和缺点？"><a href="#3、使用Kafka有什么优点和缺点？" class="headerlink" title="3、使用Kafka有什么优点和缺点？"></a>3、使用Kafka有什么优点和缺点？</h4><blockquote>
<p>优点：<br>①支持跨数据中心的消息复制；<br>②单机吞吐量：十万级，最大的优点，就是吞吐量高;<br>③topic数量都吞吐量的影响：topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源;<br>④时效性：ms级;<br>⑤可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用;<br>⑥消息可靠性：经过参数优化配置，消息可以做到0丢失;<br>⑦功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用。</p>
</blockquote>
<blockquote>
<p>缺点：<br>①由于是批量发送，数据并非真正的实时； 仅支持统一分区内消息有序，无法实现全局消息有序；<br>②有可能消息重复消费；<br>③依赖zookeeper进行元数据管理，等等。</p>
</blockquote>
<h4 id="4、为什么说Kafka性能很好，体现在哪里？"><a href="#4、为什么说Kafka性能很好，体现在哪里？" class="headerlink" title="4、为什么说Kafka性能很好，体现在哪里？"></a>4、为什么说Kafka性能很好，体现在哪里？</h4><blockquote>
<p>①顺序读写<br>②零拷贝<br>③分区<br>④批量发送<br>⑤数据压缩</p>
</blockquote>
<h4 id="5、请说明什么是传统的消息传递方法"><a href="#5、请说明什么是传统的消息传递方法" class="headerlink" title="5、请说明什么是传统的消息传递方法?"></a>5、请说明什么是传统的消息传递方法?</h4><blockquote>
<p>传统的消息传递方法包括两种：<br>排队：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人。<br>发布-订阅：在这个模型中，消息被广播给所有的用户。</p>
</blockquote>
<h4 id="6、请说明Kafka相对传统技术有什么优势"><a href="#6、请说明Kafka相对传统技术有什么优势" class="headerlink" title="6、请说明Kafka相对传统技术有什么优势?"></a>6、请说明Kafka相对传统技术有什么优势?</h4><blockquote>
<p>①快速:单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作。<br>②可伸缩:在一组机器上对数据进行分区<br>③和简化，以支持更大的数据<br>④持久:消息是持久性的，并在集群中进<br>⑤行复制，以防止数据丢失。<br>⑥设计:它提供了容错保证和持久性</p>
</blockquote>
<h4 id="7、解释Kafka的Zookeeper是什么-我们可以在没有Zookeeper的情况下使用Kafka吗"><a href="#7、解释Kafka的Zookeeper是什么-我们可以在没有Zookeeper的情况下使用Kafka吗" class="headerlink" title="7、解释Kafka的Zookeeper是什么?我们可以在没有Zookeeper的情况下使用Kafka吗?"></a>7、解释Kafka的Zookeeper是什么?我们可以在没有Zookeeper的情况下使用Kafka吗?</h4><blockquote>
<p>Zookeeper是一个开放源码的、高性能的协调服务，它用于Kafka的分布式应用。<br>不，不可能越过Zookeeper，直接联系Kafka broker。一旦Zookeeper停止工作，它就不能服务客户端请求。<br>Zookeeper主要用于在集群中不同节点之间进行通信<br>在Kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取<br>除此之外，它还执行其他活动，如: leader检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。</p>
</blockquote>
<h4 id="8、解释Kafka的用户如何消费信息"><a href="#8、解释Kafka的用户如何消费信息" class="headerlink" title="8、解释Kafka的用户如何消费信息?"></a>8、解释Kafka的用户如何消费信息?</h4><blockquote>
<p>在Kafka中传递消息是通过使用sendfile API完成的。它支持将字节从套接口转移到磁盘，通过内核空间保存副本，并在内核用户之间调用内核。</p>
</blockquote>
<h4 id="9、解释如何提高远程用户的吞吐量"><a href="#9、解释如何提高远程用户的吞吐量" class="headerlink" title="9、解释如何提高远程用户的吞吐量?"></a>9、解释如何提高远程用户的吞吐量?</h4><blockquote>
<p>如果用户位于与broker不同的数据中心，则可能需要调优套接口缓冲区大小，以对长网络延迟进行摊销。</p>
</blockquote>
<h4 id="10、解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息"><a href="#10、解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息" class="headerlink" title="10、解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息?"></a>10、解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息?</h4><blockquote>
<p>在数据中，为了精确地获得Kafka的消息，你必须遵循两件事:</p>
<p>在数据消耗期间避免重复，在数据生产过程中避免重复。</p>
<p>这里有两种方法，可以在数据生成时准确地获得一个语义:</p>
<p>每个分区使用一个单独的写入器，每当你发现一个网络错误，检查该分区中的最后一条消息，以查看您的最后一次写入是否成功</p>
<p>在消息中包含一个主键(UUID或其他)，并在用户中进行反复制</p>
</blockquote>
<h4 id="11、解释如何减少ISR中的扰动-broker什么时候离开ISR"><a href="#11、解释如何减少ISR中的扰动-broker什么时候离开ISR" class="headerlink" title="11、解释如何减少ISR中的扰动?broker什么时候离开ISR?"></a>11、解释如何减少ISR中的扰动?broker什么时候离开ISR?</h4><blockquote>
<p>ISR是一组与leaders完全同步的消息副本，也就是说ISR中包含了所有提交的消息。ISR应该总是包含所有的副本，直到出现真正的故障。如果一个副本从leader中脱离出来，将会从ISR中删除。</p>
</blockquote>
<h4 id="12、Kafka为什么需要复制"><a href="#12、Kafka为什么需要复制" class="headerlink" title="12、Kafka为什么需要复制?"></a>12、Kafka为什么需要复制?</h4><blockquote>
<p>Kafka的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用。</p>
</blockquote>
<h4 id="13、如果副本在ISR中停留了很长时间表明什么"><a href="#13、如果副本在ISR中停留了很长时间表明什么" class="headerlink" title="13、如果副本在ISR中停留了很长时间表明什么?"></a>13、如果副本在ISR中停留了很长时间表明什么?</h4><blockquote>
<p>如果一个副本在ISR中保留了很长一段时间，那么它就表明，跟踪器无法像在leader收集数据那样快速地获取数据。</p>
</blockquote>
<h4 id="14、请说明如果首选的副本不在ISR中会发生什么"><a href="#14、请说明如果首选的副本不在ISR中会发生什么" class="headerlink" title="14、请说明如果首选的副本不在ISR中会发生什么?"></a>14、请说明如果首选的副本不在ISR中会发生什么?</h4><blockquote>
<p>如果首选的副本不在ISR中，控制器将无法将leadership转移到首选的副本。</p>
</blockquote>
<h4 id="15、有可能在生产后发生消息偏移吗"><a href="#15、有可能在生产后发生消息偏移吗" class="headerlink" title="15、有可能在生产后发生消息偏移吗?"></a>15、有可能在生产后发生消息偏移吗?</h4><blockquote>
<p>在大多数队列系统中，作为生产者的类无法做到这一点，它的作用是触发并忘记消息。broker将完成剩下的工作，比如使用id进行适当的元数据处理、偏移量等。</p>
<p>作为消息的用户，你可以从Kafka broker中获得补偿。如果你注视SimpleConsumer类，你会注意到它会获取包括偏移量作为列表的MultiFetchResponse对象。此外，当你对Kafka消息进行迭代时，你会拥有包括偏移量和消息发送的MessageAndOffset对象。</p>
</blockquote>
<h4 id="16、Kafka的设计时什么样的呢？"><a href="#16、Kafka的设计时什么样的呢？" class="headerlink" title="16、Kafka的设计时什么样的呢？"></a>16、Kafka的设计时什么样的呢？</h4><blockquote>
<p>Kafka将消息以topic为单位进行归纳</p>
<p>将向Kafka topic发布消息的程序成为producers. 将订阅了topics并消费消息的程序成为consumer.</p>
<p>Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个broker.</p>
<p>producers通过网络将消息发送到Kafka集群，集群向消费者提供消息</p>
</blockquote>
<h4 id="17、数据传输的事务定义有哪三种？"><a href="#17、数据传输的事务定义有哪三种？" class="headerlink" title="17、数据传输的事务定义有哪三种？"></a>17、数据传输的事务定义有哪三种？</h4><blockquote>
<p>（1）最多一次:<br>消息不会被重复发送，最多被传输一次，但也有可能一次不传输<br>（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.<br>（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的</p>
</blockquote>
<h4 id="18、Kafka判断一个节点是否还活着有那两个条件？"><a href="#18、Kafka判断一个节点是否还活着有那两个条件？" class="headerlink" title="18、Kafka判断一个节点是否还活着有那两个条件？"></a>18、Kafka判断一个节点是否还活着有那两个条件？</h4><blockquote>
<p>（1）节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接<br>（2）如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久</p>
</blockquote>
<h4 id="19、producer是否直接将数据发送到broker的leader-主节点-？"><a href="#19、producer是否直接将数据发送到broker的leader-主节点-？" class="headerlink" title="19、producer是否直接将数据发送到broker的leader(主节点)？"></a>19、producer是否直接将数据发送到broker的leader(主节点)？</h4><blockquote>
<p>producer直接将数据发送到broker的leader(主节点)，不需要在多个节点进行分发，为了帮助producer做到这点，所有的Kafka节点都可以及时的告知:哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了。</p>
</blockquote>
<h4 id="20、Kafa-consumer是否可以消费指定分区消息？"><a href="#20、Kafa-consumer是否可以消费指定分区消息？" class="headerlink" title="20、Kafa consumer是否可以消费指定分区消息？"></a>20、Kafa consumer是否可以消费指定分区消息？</h4><blockquote>
<p>Kafa consumer消费消息时，向broker发出”fetch”请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的</p>
</blockquote>
<h4 id="21、Kafka消息是采用Pull模式，还是Push模式？"><a href="#21、Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="21、Kafka消息是采用Pull模式，还是Push模式？"></a>21、Kafka消息是采用Pull模式，还是Push模式？</h4><blockquote>
<p>Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。这样做有好处也有坏处：由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。消息系统都致力于让consumer以最大的速率最快速的消费消息，但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。最终Kafka还是选取了传统的pull模式</p>
<p>Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull模式下，consumer就可以根据自己的消费能力去决定这些策略</p>
<p>Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发</p>
</blockquote>
<h4 id="22、Kafka存储在硬盘上的消息格式是什么？"><a href="#22、Kafka存储在硬盘上的消息格式是什么？" class="headerlink" title="22、Kafka存储在硬盘上的消息格式是什么？"></a>22、Kafka存储在硬盘上的消息格式是什么？</h4><blockquote>
<p>消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和CRC32校验码。<br>消息长度: 4 bytes (value: 1+4+n)<br>版本号: 1 byte<br>CRC校验码: 4 bytes<br>具体的消息: n bytes</p>
</blockquote>
<h4 id="23、Kafka高效文件存储设计特点："><a href="#23、Kafka高效文件存储设计特点：" class="headerlink" title="23、Kafka高效文件存储设计特点："></a>23、Kafka高效文件存储设计特点：</h4><blockquote>
<p>(1).Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。<br>(2).通过索引信息可以快速定位message和确定response的最大大小。<br>(3).通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。<br>(4).通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</p>
</blockquote>
<h4 id="24、Kafka-与传统消息系统之间有三个关键区别"><a href="#24、Kafka-与传统消息系统之间有三个关键区别" class="headerlink" title="24、Kafka 与传统消息系统之间有三个关键区别"></a>24、Kafka 与传统消息系统之间有三个关键区别</h4><blockquote>
<p>(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留<br>(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性<br>(3).Kafka 支持实时的流式处理</p>
</blockquote>
<h4 id="25、Kafka创建Topic时如何将分区放置到不同的Broker中"><a href="#25、Kafka创建Topic时如何将分区放置到不同的Broker中" class="headerlink" title="25、Kafka创建Topic时如何将分区放置到不同的Broker中"></a>25、Kafka创建Topic时如何将分区放置到不同的Broker中</h4><blockquote>
<p>副本因子不能大于 Broker 的个数；<br>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；<br>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；<br>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的</p>
</blockquote>
<h4 id="26、Kafka新建的分区会在哪个目录下创建"><a href="#26、Kafka新建的分区会在哪个目录下创建" class="headerlink" title="26、Kafka新建的分区会在哪个目录下创建"></a>26、Kafka新建的分区会在哪个目录下创建</h4><blockquote>
<p>在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上用于提高读写性能。 当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。 如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据。 但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic名+分区ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。</p>
</blockquote>
<h4 id="27、partition的数据如何保存到硬盘"><a href="#27、partition的数据如何保存到硬盘" class="headerlink" title="27、partition的数据如何保存到硬盘"></a>27、partition的数据如何保存到硬盘</h4><blockquote>
<p>topic中的多个partition以文件夹的形式保存到broker，每个分区序号从0递增， 且消息有序 Partition文件下有多个segment（xxx.index，xxx.log） segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为1g 如果大小大于1g时，会滚动一个新的segment并且以上一个segment最后一条消息的偏移量命名</p>
</blockquote>
<h4 id="28、kafka的ack机制"><a href="#28、kafka的ack机制" class="headerlink" title="28、kafka的ack机制"></a>28、kafka的ack机制</h4><blockquote>
<p>request.required.acks有三个值 0 1 -1<br>0:生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢数据<br>1：服务端会等待ack值 leader副本确认接收到消息后发送ack但是如果leader挂掉后他不确保是否复制完成新leader也会导致数据丢失<br>-1：同样在1的基础上 服务端会等所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失</p>
</blockquote>
<h4 id="29、Kafka的消费者如何消费数据"><a href="#29、Kafka的消费者如何消费数据" class="headerlink" title="29、Kafka的消费者如何消费数据"></a>29、Kafka的消费者如何消费数据</h4><blockquote>
<p>消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置 等到下次消费时，他会接着上次位置继续消费。同时也可以按照指定的offset进行重新消费。</p>
</blockquote>
<h4 id="30、消费者负载均衡策略"><a href="#30、消费者负载均衡策略" class="headerlink" title="30、消费者负载均衡策略"></a>30、消费者负载均衡策略</h4><blockquote>
<p>结合consumer的加入和退出进行再平衡策略。</p>
</blockquote>
<h4 id="31、kafka消息数据是否有序？"><a href="#31、kafka消息数据是否有序？" class="headerlink" title="31、kafka消息数据是否有序？"></a>31、kafka消息数据是否有序？</h4><blockquote>
<p>消费者组里某具体分区是有序的，所以要保证有序只能建一个分区，但是实际这样会存在性能问题，具体业务具体分析后确认。</p>
</blockquote>
<h4 id="32、kafaka生产数据时数据的分组策略-生产者决定数据产生到集群的哪个partition中"><a href="#32、kafaka生产数据时数据的分组策略-生产者决定数据产生到集群的哪个partition中" class="headerlink" title="32、kafaka生产数据时数据的分组策略,生产者决定数据产生到集群的哪个partition中"></a>32、kafaka生产数据时数据的分组策略,生产者决定数据产生到集群的哪个partition中</h4><blockquote>
<p>每一条消息都是以（key，value）格式 Key是由生产者发送数据传入 所以生产者（key）决定了数据产生到集群的哪个partition</p>
</blockquote>
<h4 id="33、kafka-consumer-什么情况会触发再平衡reblance"><a href="#33、kafka-consumer-什么情况会触发再平衡reblance" class="headerlink" title="33、kafka consumer 什么情况会触发再平衡reblance?"></a>33、kafka consumer 什么情况会触发再平衡reblance?</h4><blockquote>
<p>①一旦消费者加入或退出消费组，导致消费组成员列表发生变化，消费组中的所有消费者都要执行再平衡。<br>②订阅主题分区发生变化，所有消费者也都要再平衡。</p>
</blockquote>
<h4 id="34、描述下kafka-consumer-再平衡步骤"><a href="#34、描述下kafka-consumer-再平衡步骤" class="headerlink" title="34、描述下kafka consumer 再平衡步骤?"></a>34、描述下kafka consumer 再平衡步骤?</h4><blockquote>
<p>①关闭数据拉取线程，清空队列和消息流，提交偏移量；<br>②释放分区所有权，删除zk中分区和消费者的所有者关系；<br>③将所有分区重新分配给每个消费者，每个消费者都会分到不同分区；<br>④将分区对应的消费者所有关系写入ZK，记录分区的所有权信息；<br>⑤重启消费者拉取线程管理器，管理每个分区的拉取线程。</p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>spark系列之spark-sql</title>
    <url>/2020/06/18/spark%E7%B3%BB%E5%88%97%E4%B9%8Bspark-sql/</url>
    <content><![CDATA[<h1 id="SparkSQL概述"><a href="#SparkSQL概述" class="headerlink" title="SparkSQL概述"></a>SparkSQL概述</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Spark SQL是Spark用于结构化数据(structured data)处理的Spark模块</p>
<h2 id="Hive与SparkSQL"><a href="#Hive与SparkSQL" class="headerlink" title="Hive与SparkSQL"></a>Hive与SparkSQL</h2><p>其中SparkSQL作为Spark生态的一员继续发展，而不再受限于Hive，只是兼容Hive；</p>
<p>而Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎。</p>
<p>Spark SQL为了简化RDD的开发，提高开发效率，提供了2个编程抽象，类似Spark Core中的RDD</p>
<ul>
<li><p>DataFrame</p>
</li>
<li><p>DataSet</p>
</li>
</ul>
<h2 id="DataFrame简介"><a href="#DataFrame简介" class="headerlink" title="DataFrame简介"></a>DataFrame简介</h2><p>在Spark中，DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库中的二维表格。DataFrame与RDD的主要区别在于，前者带有schema元信息，即DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得Spark SQL得以洞察更多的结构信息，从而对藏于DataFrame背后的数据源以及作用于DataFrame之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观RDD，由于无从得知所存数据元素的具体内部结构，Spark Core只能在stage层面进行简单、通用的流水线优化。</p>
<p>同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从 API 易用性的角度上看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API 要更加友好，门槛更低。</p>
<p><a href="https://pic.downk.cc/item/5eead8dd14195aa594f363b6.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eead8dd14195aa594f363b6.png" class="lazyload"></a></p>
<p>上图直观地体现了DataFrame和RDD的区别。</p>
<p>左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得 Spark SQL 可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。</p>
<p>DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待</p>
<p>DataFrame也是懒执行的，但性能上比RDD要高，主要原因：<strong>优化的执行计划</strong>，即查询计划通过Spark catalyst optimiser进行优化</p>
<h2 id="DataSet简介"><a href="#DataSet简介" class="headerlink" title="DataSet简介"></a>DataSet简介</h2><p>DataSet是分布式数据集合。DataSet是<strong>Spark 1.6</strong>中添加的一个新抽象，是DataFrame的一个扩展。它提供了RDD的优势（强类型，使用强大的lambda函数的能力）以及Spark SQL优化执行引擎的优点。DataSet也可以使用功能性的转换（操作map，flatMap，filter等等）。</p>
<ul>
<li><p>DataSet是DataFrame API的一个扩展，是SparkSQL最新的数据抽象</p>
</li>
<li><p>用户友好的API风格，既具有类型安全检查也具有DataFrame的查询优化特性；</p>
</li>
<li><p>用样例类来对DataSet中定义数据的结构信息，样例类中每个属性的名称直接映射到DataSet中的字段名称；</p>
</li>
<li><p>DataSet是强类型的。比如可以有DataSet[Car]，DataSet[Person]。</p>
</li>
<li><p>DataFrame是DataSet的特列，DataFrame=DataSet[Row] ，所以可以通过as方法将DataFrame转换为DataSet。Row是一个类型，跟Car、Person这些的类型一样，所有的表结构信息都用Row来表示。获取数据时需要指定顺序</p>
</li>
</ul>
<h1 id="SparkSQL核心编程"><a href="#SparkSQL核心编程" class="headerlink" title="SparkSQL核心编程"></a>SparkSQL核心编程</h1><p>Spark Core中，如果想要执行应用程序，需要首先构建上下文环境对象SparkContext，Spark SQL其实可以理解为对Spark Core的一种封装，不仅仅在模型上进行了封装，上下文环境对象也进行了封装。</p>
<p>SparkSession是Spark最新的SQL查询起始点，SparkSession内部封装了SparkContext，所以计算实际上是由sparkContext完成的。</p>
<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><p>Spark SQL的DataFrame API 允许我们使用 DataFrame 而不用必须去注册临时表或者生成 SQL 表达式。DataFrame API 既有 transformation操作也有action操作。</p>
<h3 id="创建df"><a href="#创建df" class="headerlink" title="创建df"></a>创建df</h3><p>在Spark SQL中SparkSession是创建DataFrame和执行SQL的入口，创建DataFrame有三种方式：通过Spark的数据源进行创建；从一个存在的RDD进行转换；还可以从Hive Table进行查询返回。</p>
<p>1、 从Spark数据源进行创建</p>
<ul>
<li>读取json文件创建DataFrame</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"data/user.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br></pre></td></tr></table></figure></div>

<p>2、从RDD进行转换</p>
<p>3、从Hive Table进行查询返回</p>
<h3 id="SQL语法"><a href="#SQL语法" class="headerlink" title="SQL语法"></a>SQL语法</h3><p>SQL语法风格是指我们查询数据的时候使用SQL语句来查询，这种风格的查询必须要有临时视图或者全局视图来辅助</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"data/user.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br><span class="line">scala&gt; df.createOrReplaceTempView(<span class="string">"people"</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> sqlDF = spark.sql(<span class="string">"SELECT * FROM people"</span>)</span><br><span class="line">sqlDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， name: string]</span><br><span class="line">scala&gt; sqlDF.show</span><br><span class="line">+---+--------+</span><br><span class="line">|age|username|</span><br><span class="line">+---+--------+</span><br><span class="line">| <span class="number">20</span>|zhangsan|</span><br><span class="line">| <span class="number">30</span>|     lisi|</span><br><span class="line">| <span class="number">40</span>|   wangwu|</span><br><span class="line">+---+--------+</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意：普通临时表是Session范围内的，如果想应用范围内有效，可以使用全局临时表。</p>
<p>使用全局临时表时需要全路径访问，如：global_temp.people</p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; df.createGlobalTempView(<span class="string">"people"</span>)</span><br><span class="line">scala&gt; spark.sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show()</span><br><span class="line">+---+--------+</span><br><span class="line">|age|username|</span><br><span class="line">+---+--------+</span><br><span class="line">| <span class="number">20</span>|zhangsan|</span><br><span class="line">| <span class="number">30</span>|     lisi|</span><br><span class="line">| <span class="number">40</span>|   wangwu|</span><br><span class="line">+---+--------+</span><br><span class="line"></span><br><span class="line">scala&gt; spark.newSession().sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show()</span><br><span class="line">+---+--------+</span><br><span class="line">|age|username|</span><br><span class="line">+---+--------+</span><br><span class="line">| <span class="number">20</span>|zhangsan|</span><br><span class="line">| <span class="number">30</span>|     lisi|</span><br><span class="line">| <span class="number">40</span>|   wangwu|</span><br><span class="line">+---+--------+</span><br></pre></td></tr></table></figure></div>

<h3 id="DSL语法"><a href="#DSL语法" class="headerlink" title="DSL语法"></a>DSL语法</h3><p>DataFrame提供一个特定领域语言(domain-specific language, DSL)去管理结构化的数据。可以在 Scala, Java, Python 和 R 中使用 DSL，使用 DSL 语法风格不必去创建临时视图了</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"data/user.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， name: string]</span><br><span class="line"></span><br><span class="line">scala&gt; df.printSchema</span><br><span class="line">root</span><br><span class="line"> |-- age: <span class="type">Long</span> (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- username: string (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; df.select(<span class="string">"username"</span>).show()</span><br><span class="line">+--------+</span><br><span class="line">|username|</span><br><span class="line">+--------+</span><br><span class="line">|zhangsan|</span><br><span class="line">|     lisi|</span><br><span class="line">|   wangwu|</span><br><span class="line">+--------+</span><br><span class="line"></span><br><span class="line">scala&gt; df.select($<span class="string">"username"</span>,$<span class="string">"age"</span> + <span class="number">1</span>).show</span><br><span class="line">scala&gt; df.select(<span class="symbol">'username</span>, <span class="symbol">'age</span> + <span class="number">1</span>).show()</span><br><span class="line">scala&gt; df.select(<span class="symbol">'username</span>, <span class="symbol">'age</span> + <span class="number">1</span> as <span class="string">"newage"</span>).show()</span><br><span class="line"></span><br><span class="line">+--------+---------+</span><br><span class="line">|username|(age + <span class="number">1</span>)|</span><br><span class="line">+--------+---------+</span><br><span class="line">|zhangsan|        <span class="number">21</span>|</span><br><span class="line">|    lisi|        <span class="number">31</span>|</span><br><span class="line">| wangwu|         <span class="number">41</span>|</span><br><span class="line">+--------+---------+</span><br><span class="line"></span><br><span class="line">scala&gt; df.filter($<span class="string">"age"</span>&gt;<span class="number">30</span>).show</span><br><span class="line">+---+---------+</span><br><span class="line">|age| username|</span><br><span class="line">+---+---------+</span><br><span class="line">| <span class="number">40</span>|    wangwu|</span><br><span class="line">+---+---------+</span><br><span class="line"></span><br><span class="line">scala&gt; df.groupBy(<span class="string">"age"</span>).count.show</span><br><span class="line">+---+-----+</span><br><span class="line">|age|count|</span><br><span class="line">+---+-----+</span><br><span class="line">| <span class="number">20</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="number">30</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="number">40</span>|    <span class="number">1</span>|</span><br><span class="line">+---+-----+</span><br></pre></td></tr></table></figure></div>

<h3 id="RDD转换为DataFrame"><a href="#RDD转换为DataFrame" class="headerlink" title="RDD转换为DataFrame"></a>RDD转换为DataFrame</h3><p>在IDEA中开发程序时，如果需要RDD与DF或者DS之间互相操作，那么需要引入 import spark.implicits._</p>
<p>这里的spark不是Scala中的包名，而是创建的sparkSession对象的变量名称，所以必须先创建SparkSession对象再导入。这里的spark对象不能使用var声明，因为Scala只支持val修饰的对象的引入。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> idRDD = sc.textFile(<span class="string">"data/id.txt"</span>)</span><br><span class="line">scala&gt; idRDD.toDF(<span class="string">"id"</span>).show</span><br><span class="line">+---+</span><br><span class="line">| id|</span><br><span class="line">+---+</span><br><span class="line">|  <span class="number">1</span>|</span><br><span class="line">|  <span class="number">2</span>|</span><br><span class="line">|  <span class="number">3</span>|</span><br><span class="line">|  <span class="number">4</span>|</span><br><span class="line">+---+</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>实际开发中，一般通过样例类将RDD转换为DataFrame</p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">User</span></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">sc</span>.<span class="title">makeRDD</span>(<span class="params"><span class="type">List</span>(("zhangsan",30</span>), (<span class="params">"lisi",40</span>))).<span class="title">map</span>(<span class="params">t=&gt;<span class="type">User</span>(t._1, t._2</span>)).<span class="title">toDF</span>.<span class="title">show</span></span></span><br><span class="line"><span class="class"><span class="title">+--------+---+</span></span></span><br><span class="line"><span class="class"><span class="title">|</span>     <span class="title">name|age|</span></span></span><br><span class="line"><span class="class"><span class="title">+--------+---+</span></span></span><br><span class="line"><span class="class"><span class="title">|zhangsan|</span> 30<span class="title">|</span></span></span><br><span class="line"><span class="class"><span class="title">|</span>    <span class="title">lisi|</span> 40<span class="title">|</span></span></span><br><span class="line"><span class="class"><span class="title">+--------+---+</span></span></span><br></pre></td></tr></table></figure></div>

<h3 id="DataFrame转换为RDD"><a href="#DataFrame转换为RDD" class="headerlink" title="DataFrame转换为RDD"></a>DataFrame转换为RDD</h3><p>DataFrame其实就是对RDD的封装，所以可以直接获取内部的RDD</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = sc.makeRDD(<span class="type">List</span>((<span class="string">"zhangsan"</span>,<span class="number">30</span>), (<span class="string">"lisi"</span>,<span class="number">40</span>))).map(t=&gt;<span class="type">User</span>(t._1, t._2)).toDF</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = df.rdd</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">46</span>] at rdd at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> array = rdd.collect</span><br><span class="line">array: <span class="type">Array</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">Array</span>([zhangsan,<span class="number">30</span>], [lisi,<span class="number">40</span>])</span><br></pre></td></tr></table></figure></div>

<p>注意：此时得到的RDD存储类型为Row</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; array(<span class="number">0</span>)</span><br><span class="line">res28: org.apache.spark.sql.<span class="type">Row</span> = [zhangsan,<span class="number">30</span>]</span><br><span class="line">scala&gt; array(<span class="number">0</span>)(<span class="number">0</span>)</span><br><span class="line">res29: <span class="type">Any</span> = zhangsan</span><br><span class="line">scala&gt; array(<span class="number">0</span>).getAs[<span class="type">String</span>](<span class="string">"name"</span>)</span><br><span class="line">res30: <span class="type">String</span> = zhangsan</span><br></pre></td></tr></table></figure></div>

<h2 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h2><p>DataSet是具有强类型的数据集合，需要提供对应的类型信息。</p>
<h3 id="创建DataSet"><a href="#创建DataSet" class="headerlink" title="创建DataSet"></a>创建DataSet</h3><p>1、使用样例类序列创建DataSet</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Person</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">val</span> <span class="title">caseClassDS</span> </span>= <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">"zhangsan"</span>,<span class="number">2</span>)).toDS()</span><br><span class="line"></span><br><span class="line">caseClassDS: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [name: string, age: <span class="type">Long</span>]</span><br><span class="line"></span><br><span class="line">scala&gt; caseClassDS.show</span><br><span class="line">+---------+---+</span><br><span class="line">|     name|age|</span><br><span class="line">+---------+---+</span><br><span class="line">| zhangsan|  <span class="number">2</span>|</span><br><span class="line">+---------+---+</span><br></pre></td></tr></table></figure></div>

<p>2、使用基本类型的序列创建DataSet</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ds = <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>).toDS</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Int</span>] = [value: int]</span><br><span class="line"></span><br><span class="line">scala&gt; ds.show</span><br><span class="line">+-----+</span><br><span class="line">|value|</span><br><span class="line">+-----+</span><br><span class="line">|    <span class="number">1</span>|</span><br><span class="line">|    <span class="number">2</span>|</span><br><span class="line">|    <span class="number">3</span>|</span><br><span class="line">|    <span class="number">4</span>|</span><br><span class="line">|    <span class="number">5</span>|</span><br><span class="line">+-----+</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意：在实际使用的时候，很少用到把序列转换成DataSet，更多的是通过RDD来得到DataSet</p>
</blockquote>
<h3 id="RDD转换为DataSet"><a href="#RDD转换为DataSet" class="headerlink" title="RDD转换为DataSet"></a>RDD转换为DataSet</h3><p>SparkSQL能够自动将包含有case类的RDD转换成DataSet，case类定义了table的结构，case类属性通过反射变成了表的列名。Case类可以包含诸如Seq或者Array等复杂的结构。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">User</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">sc</span>.<span class="title">makeRDD</span>(<span class="params"><span class="type">List</span>(("zhangsan",30</span>), (<span class="params">"lisi",49</span>))).<span class="title">map</span>(<span class="params">t=&gt;<span class="type">User</span>(t._1, t._2</span>)).<span class="title">toDS</span></span></span><br><span class="line"><span class="class"><span class="title">res11</span></span>: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br></pre></td></tr></table></figure></div>

<h3 id="DataSet转换为RDD"><a href="#DataSet转换为RDD" class="headerlink" title="DataSet转换为RDD"></a>DataSet转换为RDD</h3><p>DataSet其实也是对RDD的封装，所以可以直接获取内部的RDD</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">User</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">sc</span>.<span class="title">makeRDD</span>(<span class="params"><span class="type">List</span>(("zhangsan",30</span>), (<span class="params">"lisi",49</span>))).<span class="title">map</span>(<span class="params">t=&gt;<span class="type">User</span>(t._1, t._2</span>)).<span class="title">toDS</span></span></span><br><span class="line"><span class="class"><span class="title">res11</span></span>: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = res11.rdd</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">User</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">51</span>] at rdd at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collect</span><br><span class="line">res12: <span class="type">Array</span>[<span class="type">User</span>] = <span class="type">Array</span>(<span class="type">User</span>(zhangsan,<span class="number">30</span>), <span class="type">User</span>(lisi,<span class="number">49</span>))</span><br></pre></td></tr></table></figure></div>

<h2 id="DataFrame和DataSet转换"><a href="#DataFrame和DataSet转换" class="headerlink" title="DataFrame和DataSet转换"></a>DataFrame和DataSet转换</h2><p>DataFrame其实是DataSet的特例，所以它们之间是可以互相转换的。</p>
<ul>
<li>DataFrame转换为DataSet</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">User</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">val</span> <span class="title">df</span> </span>= sc.makeRDD(<span class="type">List</span>((<span class="string">"zhangsan"</span>,<span class="number">30</span>), (<span class="string">"lisi"</span>,<span class="number">49</span>))).toDF(<span class="string">"name"</span>,<span class="string">"age"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> ds = df.as[<span class="type">User</span>]</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br></pre></td></tr></table></figure></div>

<ul>
<li>DataSet转换为DataFrame</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ds = df.as[<span class="type">User</span>]</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> df = ds.toDF</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br></pre></td></tr></table></figure></div>

<h2 id="RDD、DataFrame、DataSet三者关系"><a href="#RDD、DataFrame、DataSet三者关系" class="headerlink" title="RDD、DataFrame、DataSet三者关系"></a>RDD、DataFrame、DataSet三者关系</h2><p>在SparkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。他们和RDD有什么区别呢？首先从版本的产生上来看：</p>
<ul>
<li><p>Spark1.0 =&gt; RDD </p>
</li>
<li><p>Spark1.3 =&gt; DataFrame</p>
</li>
<li><p>Spark1.6 =&gt; Dataset</p>
</li>
</ul>
<p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。在后期的Spark版本中，DataSet有可能会逐步取代RDD和DataFrame成为唯一的API接口。</p>
<h3 id="三者共性"><a href="#三者共性" class="headerlink" title="三者共性"></a>三者共性</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RDD、DataFrame、DataSet全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利;</span><br><span class="line">三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到Action如foreach时，三者才会开始遍历运算;</span><br><span class="line">三者有许多共同的函数，如filter，排序等;</span><br><span class="line">在对DataFrame和Dataset进行操作许多操作都需要这个包:import spark.implicits._（在创建好SparkSession对象后尽量直接导入）</span><br><span class="line">三者都会根据 Spark 的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出</span><br><span class="line">三者都有partition的概念</span><br><span class="line">DataFrame和DataSet均可使用模式匹配获取各个字段的值和类型</span><br></pre></td></tr></table></figure></div>

<h3 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1)RDD</span><br><span class="line">    RDD一般和spark mlib同时使用</span><br><span class="line">    RDD不支持sparksql操作</span><br><span class="line">2)DataFrame</span><br><span class="line">    与RDD和Dataset不同，DataFrame每一行的类型固定为Row，每一列的值没法直接访问，只有通过解析才能获取各个字段的值</span><br><span class="line">    DataFrame与DataSet一般不与 spark mlib 同时使用</span><br><span class="line">    DataFrame与DataSet均支持 SparkSQL 的操作，比如select，groupby之类，还能注册临时表&#x2F;视窗，进行 sql 语句操作</span><br><span class="line">    DataFrame与DataSet支持一些特别方便的保存方式，比如保存成csv，可以带上表头，这样每一列的字段名一目了然(后面专门讲解)</span><br><span class="line">3)DataSet</span><br><span class="line">    Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同。 DataFrame其实就是DataSet的一个特例  type DataFrame &#x3D; Dataset[Row]</span><br><span class="line">    DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的getAS方法或者共性中的第七条提到的模式匹配拿出特定字段。而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息</span><br></pre></td></tr></table></figure></div>

<h3 id="三者的互相转换"><a href="#三者的互相转换" class="headerlink" title="三者的互相转换"></a>三者的互相转换</h3><p><a href="https://pic.downk.cc/item/5eeae20e14195aa594fe779a.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5eeae20e14195aa594fe779a.png" class="lazyload"></a></p>
<h2 id="IDEA开发SparkSQL"><a href="#IDEA开发SparkSQL" class="headerlink" title="IDEA开发SparkSQL"></a>IDEA开发SparkSQL</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQL01_Demo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建上下文环境配置对象</span></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"SparkSQL01_Demo"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(conf).getOrCreate()</span><br><span class="line">    <span class="comment">//RDD=&gt;DataFrame=&gt;DataSet转换需要引入隐式转换规则，否则无法转换</span></span><br><span class="line">    <span class="comment">//spark不是包名，是上下文环境对象名</span></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取json文件 创建DataFrame  &#123;"username": "lisi","age": 18&#125;</span></span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.json(<span class="string">"D:\\dev\\workspace\\spark-bak\\spark-bak-00\\input\\test.json"</span>)</span><br><span class="line">    <span class="comment">//df.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//SQL风格语法</span></span><br><span class="line">    df.createOrReplaceTempView(<span class="string">"user"</span>)</span><br><span class="line">    <span class="comment">//spark.sql("select avg(age) from user").show</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//DSL风格语法</span></span><br><span class="line">    <span class="comment">//df.select("username","age").show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****RDD=&gt;DataFrame=&gt;DataSet*****</span></span><br><span class="line">    <span class="comment">//RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd1: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Int</span>)] = spark.sparkContext.makeRDD(<span class="type">List</span>((<span class="number">1</span>,<span class="string">"qiaofeng"</span>,<span class="number">30</span>),(<span class="number">2</span>,<span class="string">"xuzhu"</span>,<span class="number">28</span>),(<span class="number">3</span>,<span class="string">"duanyu"</span>,<span class="number">20</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df1: <span class="type">DataFrame</span> = rdd1.toDF(<span class="string">"id"</span>,<span class="string">"name"</span>,<span class="string">"age"</span>)</span><br><span class="line">    <span class="comment">//df1.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//DateSet</span></span><br><span class="line">    <span class="keyword">val</span> ds1: <span class="type">Dataset</span>[<span class="type">User</span>] = df1.as[<span class="type">User</span>]</span><br><span class="line">    <span class="comment">//ds1.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****DataSet=&gt;DataFrame=&gt;RDD*****</span></span><br><span class="line">    <span class="comment">//DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df2: <span class="type">DataFrame</span> = ds1.toDF()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//RDD  返回的RDD类型为Row，里面提供的getXXX方法可以获取字段值，类似jdbc处理结果集，但是索引从0开始</span></span><br><span class="line">    <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[<span class="type">Row</span>] = df2.rdd</span><br><span class="line">    <span class="comment">//rdd2.foreach(a=&gt;println(a.getString(1)))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****RDD=&gt;DataSet*****</span></span><br><span class="line">    rdd1.map&#123;</span><br><span class="line">      <span class="keyword">case</span> (id,name,age)=&gt;<span class="type">User</span>(id,name,age)</span><br><span class="line">    &#125;.toDS()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****DataSet=&gt;=&gt;RDD*****</span></span><br><span class="line">    ds1.rdd</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放资源</span></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id:<span class="type">Int</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br></pre></td></tr></table></figure></div>

<h2 id="用户自定义函数"><a href="#用户自定义函数" class="headerlink" title="用户自定义函数"></a>用户自定义函数</h2><p>用户可以通过spark.udf功能添加自定义函数，实现自定义功能。</p>
<h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>创建DataFrame</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"data/user.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br></pre></td></tr></table></figure></div>

<p>注册UDF</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.udf.register(<span class="string">"addName"</span>,(x:<span class="type">String</span>)=&gt; <span class="string">"Name:"</span>+x)</span><br><span class="line">res9: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function1&gt;,<span class="type">StringType</span>,<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>)))</span><br></pre></td></tr></table></figure></div>

<p>创建临时表</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; df.createOrReplaceTempView(<span class="string">"people"</span>)</span><br></pre></td></tr></table></figure></div>

<p>应用UDF</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"Select addName(name),age from people"</span>).show()</span><br></pre></td></tr></table></figure></div>

<h3 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h3><p>强类型的Dataset和弱类型的DataFrame都提供了相关的聚合函数， 如 count()，countDistinct()，avg()，max()，min()。除此之外，用户可以设定自己的自定义聚合函数。通过继承UserDefinedAggregateFunction来实现用户自定义聚合函数。</p>
<p><strong>需求：实现求平均工资</strong></p>
<p>1、RDD实现</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"app"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"><span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="keyword">val</span> res: (<span class="type">Int</span>, <span class="type">Int</span>) = sc.makeRDD(<span class="type">List</span>((<span class="string">"zhangsan"</span>, <span class="number">20</span>), (<span class="string">"lisi"</span>, <span class="number">30</span>), (<span class="string">"wangw"</span>, <span class="number">40</span>))).map &#123;</span><br><span class="line">  <span class="keyword">case</span> (name, age) =&gt; &#123;</span><br><span class="line">    (age, <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;.reduce &#123;</span><br><span class="line">  (t1, t2) =&gt; &#123;</span><br><span class="line">    (t1._1 + t2._1, t1._2 + t2._2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">println(res._1/res._2)</span><br><span class="line"><span class="comment">// 关闭连接</span></span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></div>

<p>2、累加器实现</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAC</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">Int</span>,<span class="type">Int</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> sum:<span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> count:<span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">return</span> sum ==<span class="number">0</span> &amp;&amp; count == <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[<span class="type">Int</span>, <span class="type">Int</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> newMyAc = <span class="keyword">new</span> <span class="type">MyAC</span></span><br><span class="line">    newMyAc.sum = <span class="keyword">this</span>.sum</span><br><span class="line">    newMyAc.count = <span class="keyword">this</span>.count</span><br><span class="line">    newMyAc</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    sum =<span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(v: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    sum += v</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[<span class="type">Int</span>, <span class="type">Int</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    other <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> o:<span class="type">MyAC</span>=&gt;&#123;</span><br><span class="line">        sum += o.sum</span><br><span class="line">        count += o.count</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> _=&gt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: <span class="type">Int</span> = sum/count</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>3、实现方式 - UDAF - 弱类型</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">定义类继承UserDefinedAggregateFunction，并重写其中方法</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAveragUDAF</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 聚合函数输入参数的数据类型</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">"age"</span>,<span class="type">IntegerType</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 聚合函数缓冲区中值的数据类型(age,count)</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">    <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">"sum"</span>,<span class="type">LongType</span>),<span class="type">StructField</span>(<span class="string">"count"</span>,<span class="type">LongType</span>)))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 函数返回值的数据类型</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">DoubleType</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 稳定性：对于相同的输入是否一直返回相同的输出。</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 函数缓冲区初始化</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 存年龄的总和</span></span><br><span class="line">    buffer(<span class="number">0</span>) = <span class="number">0</span>L</span><br><span class="line">    <span class="comment">// 存年龄的个数</span></span><br><span class="line">    buffer(<span class="number">1</span>) = <span class="number">0</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 更新缓冲区中的数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>,input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!input.isNullAt(<span class="number">0</span>)) &#123;</span><br><span class="line">      buffer(<span class="number">0</span>) = buffer.getLong(<span class="number">0</span>) + input.getInt(<span class="number">0</span>)</span><br><span class="line">      buffer(<span class="number">1</span>) = buffer.getLong(<span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 合并缓冲区</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>,buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getLong(<span class="number">0</span>) + buffer2.getLong(<span class="number">0</span>)</span><br><span class="line">    buffer1(<span class="number">1</span>) = buffer1.getLong(<span class="number">1</span>) + buffer2.getLong(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算最终结果</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Double</span> = buffer.getLong(<span class="number">0</span>).toDouble / buffer.getLong(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建聚合函数</span></span><br><span class="line"><span class="keyword">var</span> myAverage = <span class="keyword">new</span> <span class="type">MyAveragUDAF</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//在spark中注册聚合函数</span></span><br><span class="line">spark.udf.register(<span class="string">"avgAge"</span>,myAverage)</span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">"select avgAge(age) from user"</span>).show()</span><br></pre></td></tr></table></figure></div>

<p>4、实现方式 - UDAF - 强类型</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//输入数据类型</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User01</span>(<span class="params">username:<span class="type">String</span>,age:<span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">//缓存类型</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">AgeBuffer</span>(<span class="params">var sum:<span class="type">Long</span>,var count:<span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">/**</span></span></span><br><span class="line"><span class="class">  <span class="title">*</span> <span class="title">定义类继承org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">sql</span>.<span class="title">expressions</span>.<span class="title">Aggregator</span></span></span><br><span class="line"><span class="class">  <span class="title">*</span> <span class="title">重写类中的方法</span></span></span><br><span class="line"><span class="class">  <span class="title">*/</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">MyAveragUDAF1</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">User01</span>,<span class="type">AgeBuffer</span>,<span class="type">Double</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    <span class="type">AgeBuffer</span>(<span class="number">0</span>L,<span class="number">0</span>L)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(b: <span class="type">AgeBuffer</span>, a: <span class="type">User01</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    b.sum = b.sum + a.age</span><br><span class="line">    b.count = b.count + <span class="number">1</span></span><br><span class="line">    b</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">AgeBuffer</span>, b2: <span class="type">AgeBuffer</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    b1.sum = b1.sum + b2.sum</span><br><span class="line">    b1.count = b1.count + b2.count</span><br><span class="line">    b1</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(buff: <span class="type">AgeBuffer</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">    buff.sum.toDouble/buff.count</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//DataSet默认额编解码器，用于序列化，固定写法</span></span><br><span class="line">  <span class="comment">//自定义类型就是produce   自带类型根据类型选择</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">AgeBuffer</span>] = &#123;</span><br><span class="line">    <span class="type">Encoders</span>.product</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Double</span>] = &#123;</span><br><span class="line">    <span class="type">Encoders</span>.scalaDouble</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"><span class="comment">//封装为DataSet</span></span><br><span class="line"><span class="keyword">val</span> ds: <span class="type">Dataset</span>[<span class="type">User01</span>] = df.as[<span class="type">User01</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建聚合函数</span></span><br><span class="line"><span class="keyword">var</span> myAgeUdaf1 = <span class="keyword">new</span> <span class="type">MyAveragUDAF1</span></span><br><span class="line"><span class="comment">//将聚合函数转换为查询的列</span></span><br><span class="line"><span class="keyword">val</span> col: <span class="type">TypedColumn</span>[<span class="type">User01</span>, <span class="type">Double</span>] = myAgeUdaf1.toColumn</span><br><span class="line"></span><br><span class="line"><span class="comment">//查询</span></span><br><span class="line">ds.select(col).show()</span><br></pre></td></tr></table></figure></div>

<h2 id="数据的加载和保存"><a href="#数据的加载和保存" class="headerlink" title="数据的加载和保存"></a>数据的加载和保存</h2><h3 id="通用的加载和保存方式"><a href="#通用的加载和保存方式" class="headerlink" title="通用的加载和保存方式"></a>通用的加载和保存方式</h3><p>SparkSQL提供了通用的保存数据和数据加载的方式。这里的通用指的是使用相同的API，根据不同的参数读取和保存不同格式的数据，<strong>SparkSQL默认读取和保存的文件格式为parquet</strong></p>
<p>1) 加载数据</p>
<p><code>spark.read.load</code>是加载数据的通用方法</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.read.format(<span class="string">"…"</span>)[.option(<span class="string">"…"</span>)].load(<span class="string">"…"</span>)</span><br></pre></td></tr></table></figure></div>

<p>1)保存数据</p>
<p><code>df.write.save</code> 是保存数据的通用方法</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt;df.write.format(<span class="string">"…"</span>)[.option(<span class="string">"…"</span>)].save(<span class="string">"…"</span>)</span><br></pre></td></tr></table></figure></div>

<h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><p><strong>Spark SQL的默认数据源为Parquet格式。</strong></p>
<p><strong>Parquet是一种能够有效存储嵌套数据的列式存储格式。</strong></p>
<p>数据源为Parquet文件时，Spark SQL可以方便的执行所有的操作，不需要使用format。修改配置项spark.sql.sources.default，可修改默认数据源格式。</p>
<p>加载数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.load(<span class="string">"/opt/module/spark-local/examples/src/main/resources/users.parquet"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; df.show</span><br></pre></td></tr></table></figure></div>

<p>保存数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> df = spark.read.json(<span class="string">"/opt/module/data/input/people.json"</span>)</span><br><span class="line"><span class="comment">//保存为parquet格式</span></span><br><span class="line">scala&gt; df.write.mode(<span class="string">"append"</span>).save(<span class="string">"/opt/module/data/output"</span>)</span><br></pre></td></tr></table></figure></div>

<h3 id="JSON-CSV-MySQL"><a href="#JSON-CSV-MySQL" class="headerlink" title="JSON/CSV/MySQL"></a>JSON/CSV/MySQL</h3><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><p>Apache Hive 是 Hadoop 上的 SQL 引擎，Spark SQL编译时可以包含 Hive 支持，也可以不包含。包含 Hive 支持的 Spark SQL 可以支持 Hive 表访问、UDF (用户自定义函数)以及 Hive 查询语言(HiveQL/HQL)等。需要强调的一点是，如果要在 Spark SQL 中包含Hive 的库，并不需要事先安装 Hive。一般来说，最好还是在编译Spark SQL时引入Hive支持，这样就可以使用这些特性了。如果你下载的是二进制版本的 Spark，它应该已经在编译时添加了 Hive 支持。</p>
<p>若要把 Spark SQL 连接到一个部署好的 Hive 上，你必须把 hive-site.xml 复制到 Spark的配置文件目录中($SPARK_HOME/conf)。即使没有部署好 Hive，Spark SQL 也可以运行。 需要注意的是，如果你没有部署好Hive，Spark SQL 会在当前的工作目录中创建出自己的 Hive 元数据仓库，叫作 metastore_db。此外，如果你尝试使用 HiveQL 中的 CREATE TABLE (并非 CREATE EXTERNAL TABLE)语句来创建表，这些表会被放在你默认的文件系统中的 /user/hive/warehouse 目录中(如果你的 classpath 中有配好的 hdfs-site.xml，默认的文件系统就是 HDFS，否则就是本地文件系统)。</p>
<p>spark-shell默认是Hive支持的；代码中是默认不支持的，需要手动指定（加一个参数即可）。</p>
<p>1、内嵌的Hive</p>
<p>如果使用 Spark 内嵌的 Hive, 则什么都不用做, 直接使用即可.</p>
<p>Hive 的元数据存储在 derby 中, 仓库地址:$SPARK_HOME/spark-warehouse</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"show tables"</span>).show</span><br><span class="line">。。。</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">|database|tableName|isTemporary|</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">"create table aa(id int)"</span>)</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">"show tables"</span>).show</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">|database|tableName|isTemporary|</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|       aa|      <span class="literal">false</span>|</span><br><span class="line">+--------+---------+-----------+</span><br></pre></td></tr></table></figure></div>

<p>向表加载本地数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"load data local inpath 'input/ids.txt' into table aa"</span>)</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">"select * from aa"</span>).show</span><br><span class="line">+---+</span><br><span class="line">| id|</span><br><span class="line">+---+</span><br><span class="line">|  <span class="number">1</span>|</span><br><span class="line">|  <span class="number">2</span>|</span><br><span class="line">|  <span class="number">3</span>|</span><br><span class="line">|  <span class="number">4</span>|</span><br><span class="line">+---+</span><br></pre></td></tr></table></figure></div>

<p>在实际使用中, 几乎没有任何人会使用内置的 Hive</p>
<p>2、外部的Hive</p>
<p>如果想连接外部已经部署好的Hive，需要通过以下几个步骤：</p>
<ul>
<li><p>Spark要接管Hive需要把hive-site.xml拷贝到conf/目录下</p>
</li>
<li><p>把Mysql的驱动copy到jars/目录下</p>
</li>
<li><p>如果访问不到hdfs，则需要把core-site.xml和hdfs-site.xml拷贝到conf/目录下</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"show tables"</span>).show</span><br><span class="line"><span class="number">20</span>/<span class="number">04</span>/<span class="number">25</span> <span class="number">22</span>:<span class="number">05</span>:<span class="number">14</span> <span class="type">WARN</span> <span class="type">ObjectStore</span>: <span class="type">Failed</span> to get database global_temp, returning <span class="type">NoSuchObjectException</span></span><br><span class="line">+--------+--------------------+-----------+</span><br><span class="line">|database|           tableName|isTemporary|</span><br><span class="line">+--------+--------------------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|                 emp|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|hive_hbase_emp_table|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>| relevance_hbase_emp|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|          staff_hive|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|                 ttt|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|   user_visit_action|      <span class="literal">false</span>|</span><br><span class="line">+--------+--------------------+-----------+</span><br></pre></td></tr></table></figure></div>

<p>3、运行 Spark SQL CLI</p>
<p>Spark SQL CLI可以很方便的在本地运行Hive元数据服务以及从命令行执行查询任务。在Spark目录下执行如下命令启动Spark SQL CLI，直接执行SQL语句，类似一Hive窗口</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/spark-sql</span><br></pre></td></tr></table></figure></div>

<p>4、代码操作Hive</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>将hive-site.xml文件拷贝到项目的resources目录中，代码实现</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建SparkSession</span></span><br><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">  .builder()</span><br><span class="line">  .enableHiveSupport()</span><br><span class="line">  .master(<span class="string">"local[*]"</span>)</span><br><span class="line">  .appName(<span class="string">"sql"</span>)</span><br><span class="line">  .getOrCreate()</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>注意：在开发工具中创建数据库默认是在本地仓库，通过参数修改数据库仓库的地址: config(“spark.sql.warehouse.dir”, “hdfs://linux1:9000/user/hive/warehouse”)</p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>spark</tag>
        <tag>spark-sql</tag>
      </tags>
  </entry>
  <entry>
    <title>spark系列之spark基础</title>
    <url>/2020/06/17/spark%E7%B3%BB%E5%88%97%E4%B9%8Bspark%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul>
<li>Spark Core</li>
</ul>
<p>Spark Core中提供了Spark最基础与最核心的功能，Spark其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib都是在Spark Core的基础上进行扩展的</p>
<ul>
<li>Spark SQL</li>
</ul>
<p>Spark SQL是Spark用来操作结构化数据的组件。通过Spark SQL，用户可以使用SQL或者Apache Hive版本的SQL方言（HQL）来查询数据。</p>
<ul>
<li>Spark Streaming</li>
</ul>
<p>Spark Streaming是Spark平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</p>
<ul>
<li>Spark MLlib</li>
</ul>
<p>MLlib是Spark提供的一个机器学习算法库。MLlib不仅提供了模型评估、数据导入等额外的功能，还提供了一些更底层的机器学习原语。</p>
<ul>
<li>Spark GraphX</li>
</ul>
<p>GraphX是Spark面向图计算提供的框架与算法库。</p>
<h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 该插件用于将Scala代码编译成class文件 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!-- 声明绑定到maven的compile阶段 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>WordCount</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建Spark运行配置对象</span></span><br><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"WordCount"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建Spark上下文环境对象（连接对象）</span></span><br><span class="line"><span class="keyword">val</span> sc : <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取文件数据</span></span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">"input/word.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将文件中的数据进行分词</span></span><br><span class="line"><span class="keyword">val</span> wordRDD: <span class="type">RDD</span>[<span class="type">String</span>] = fileRDD.flatMap( _.split(<span class="string">" "</span>) )</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换数据结构 word =&gt; (word, 1)</span></span><br><span class="line"><span class="keyword">val</span> word2OneRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordRDD.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将转换结构后的数据按照相同的单词进行分组聚合</span></span><br><span class="line"><span class="keyword">val</span> word2CountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = word2OneRDD.reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将数据聚合结果采集到内存中</span></span><br><span class="line"><span class="keyword">val</span> word2Count: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = word2CountRDD.collect()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印结果</span></span><br><span class="line">word2Count.foreach(println)</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭Spark连接</span></span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></div>

<h1 id="spark运行环境"><a href="#spark运行环境" class="headerlink" title="spark运行环境"></a>spark运行环境</h1><h2 id="local"><a href="#local" class="headerlink" title="local"></a>local</h2><p>所谓的Local模式，就是不需要其他任何节点资源就可以在本地执行Spark代码的环境，一般用于教学，调试，演示等，</p>
<h2 id="standalone"><a href="#standalone" class="headerlink" title="standalone"></a>standalone</h2><p>local本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的集群中去执行，这里我们来看看只使用Spark自身节点运行的集群模式，也就是我们所谓的独立部署（Standalone）模式。Spark的Standalone模式体现了经典的master-slave模式。</p>
<p>集群规划:</p>
<table>
<thead>
<tr>
<th></th>
<th>Linux1</th>
<th>Linux2</th>
<th>Linux3</th>
</tr>
</thead>
<tbody><tr>
<td>Spark</td>
<td>Worker  <strong>Master</strong></td>
<td>Worker</td>
<td>Worker</td>
</tr>
</tbody></table>
<h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><p><strong>独立部署（Standalone）模式由Spark自身提供计算资源，无需其他框架提供资源。</strong>这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的Yarn环境下Spark是如何工作的（其实是因为在国内工作中，Yarn使用的非常多）。</p>
<h2 id="k8s-amp-Mesos"><a href="#k8s-amp-Mesos" class="headerlink" title="k8s &amp; Mesos"></a>k8s &amp; Mesos</h2><p>Mesos是Apache下的开源分布式资源管理框架，它被称为是分布式系统的内核,在Twitter得到广泛使用,管理着Twitter超过30,0000台服务器上的应用部署，但是在国内，依然使用着传统的Hadoop大数据框架，所以国内使用Mesos框架的并不多，但是原理其实都差不多。</p>
<h2 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h2><p>一般教学演示使用。</p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><table>
<thead>
<tr>
<th>模式</th>
<th>Spark安装机器数</th>
<th>需启动的进程</th>
<th>所属者</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Local</td>
<td>1</td>
<td>无</td>
<td>Spark</td>
<td>测试</td>
</tr>
<tr>
<td>Standalone</td>
<td>3</td>
<td>Master及Worker</td>
<td>Spark</td>
<td>单独部署</td>
</tr>
<tr>
<td>Yarn</td>
<td>1</td>
<td>Yarn及HDFS</td>
<td>Hadoop</td>
<td>混合部署</td>
</tr>
</tbody></table>
<p>端口号</p>
<ul>
<li><p>Spark查看当前Spark-shell运行任务情况端口号：4040（计算）</p>
</li>
<li><p>Spark Master内部通信服务端口号：7077</p>
</li>
<li><p>Standalone模式下，Spark Master Web端口号：8080（资源）</p>
</li>
<li><p>Spark历史服务器端口号：18080</p>
</li>
<li><p>Hadoop YARN任务运行情况查看端口号：8088</p>
</li>
</ul>
<h1 id="spark运行架构"><a href="#spark运行架构" class="headerlink" title="spark运行架构"></a>spark运行架构</h1><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><p>Spark框架有两个核心组件：</p>
<p><strong>1、Driver</strong></p>
<p>Spark驱动器节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。Driver在Spark作业执行时主要负责：</p>
<ul>
<li><p>将用户程序转化为作业（job）</p>
</li>
<li><p>在Executor之间调度任务(task)</p>
</li>
<li><p>跟踪Executor的执行情况</p>
</li>
<li><p>通过UI展示查询运行情况</p>
</li>
</ul>
<p>实际上，我们无法准确地描述Driver的定义，因为在整个的编程过程中没有看到任何有关Driver的字眼。所以简单理解，所谓的Driver就是驱使整个应用运行起来的程序，也称之为Driver类。</p>
<p><strong>2、Executor</strong></p>
<p>Spark Executor是集群中工作节点（Worker）中的一个JVM进程，负责在 Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。</p>
<p>Executor有两个核心功能：</p>
<ul>
<li><p>负责运行组成Spark应用的任务，并将结果返回给驱动器进程</p>
</li>
<li><p>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p>
</li>
</ul>
<p>3、ApplicationMaster</p>
<p>Hadoop用户向YARN集群提交应用程序时,提交程序中应该包含ApplicationMaster，用于向资源调度器申请执行任务的资源容器Container，运行用户自己的程序任务job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。</p>
<p>说的简单点就是，RM（资源）和Driver（计算）之间的解耦合靠的就是ApplicationMaster。</p>
<h3 id="提交流程"><a href="#提交流程" class="headerlink" title="提交流程"></a>提交流程</h3><p>Spark应用程序提交到Yarn环境中执行的时候，一般会有两种部署执行的方式：Client和Cluster。</p>
<p><strong>两种模式，主要区别在于：Driver程序的运行节点。</strong></p>
<p><strong>Yarn Client模式</strong></p>
<p>Client模式将用于监控和调度的Driver模块在客户端执行，而不是Yarn中，所以一般用于测试。</p>
<ul>
<li><p><strong>Driver在任务提交的本地机器上运行</strong></p>
</li>
<li><p>Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</p>
</li>
<li><p>ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，负责向ResourceManager申请Executor内存</p>
</li>
<li><p>ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程</p>
</li>
<li><p>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数</p>
</li>
<li><p>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</p>
</li>
</ul>
<p><strong>Yarn Cluster模式</strong></p>
<p><strong>Cluster模式将用于监控和调度的Driver模块启动在Yarn集群资源中执行。</strong>一般应用于实际生产环境。</p>
<ul>
<li><p>在YARN Cluster模式下，任务提交后会和ResourceManager通讯申请启动ApplicationMaster，</p>
</li>
<li><p>随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver。</p>
</li>
<li><p>Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配container，然后在合适的NodeManager上启动Executor进程</p>
</li>
<li><p>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，</p>
</li>
<li><p>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</p>
</li>
</ul>
<h1 id="spark核心编程"><a href="#spark核心编程" class="headerlink" title="spark核心编程"></a>spark核心编程</h1><p>Spark计算框架为了能够对数据进行高并发和高吞吐的处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：</p>
<ul>
<li><p>RDD : 弹性分布式数据集</p>
</li>
<li><p>累加器：分布式共享只写变量</p>
</li>
<li><p>广播变量：分布式共享只读变量</p>
</li>
</ul>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p>
<blockquote>
<p>数据集：RDD封装了计算逻辑，并不保存数据</p>
</blockquote>
<h3 id="RDD并行度与分区"><a href="#RDD并行度与分区" class="headerlink" title="RDD并行度与分区"></a>RDD并行度与分区</h3><p>默认情况下，Spark可以切分任务，并将任务发送给Executor节点并行计算，而这个并行计算的任务数量我们称之为并行度。这个数量可以在构建RDD时指定。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"spark"</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> dataRDD: <span class="type">RDD</span>[<span class="type">Int</span>] =</span><br><span class="line">    sparkContext.makeRDD(</span><br><span class="line">        <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),</span><br><span class="line">        <span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] =</span><br><span class="line">    sparkContext.textFile(</span><br><span class="line">        <span class="string">"input"</span>,</span><br><span class="line">        <span class="number">2</span>)</span><br><span class="line">fileRDD.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br></pre></td></tr></table></figure></div>

<p>读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，数据分区规则的Spark源码如下</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">positions</span></span>(length: <span class="type">Long</span>, numSlices: <span class="type">Int</span>): <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">  (<span class="number">0</span> until numSlices).iterator.map &#123; i =&gt;</span><br><span class="line">    <span class="keyword">val</span> start = ((i * length) / numSlices).toInt</span><br><span class="line">    <span class="keyword">val</span> end = (((i + <span class="number">1</span>) * length) / numSlices).toInt</span><br><span class="line">    (start, end)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异，具体Spark源码如下</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">public <span class="type">InputSplit</span>[] getSplits(<span class="type">JobConf</span> job, int numSplits)</span><br><span class="line">    <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line"></span><br><span class="line">    long totalSize = <span class="number">0</span>;                           <span class="comment">// compute total size</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">FileStatus</span> file: files) &#123;                <span class="comment">// check we have valid files</span></span><br><span class="line">      <span class="keyword">if</span> (file.isDirectory()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IOException</span>(<span class="string">"Not a file: "</span>+ file.getPath());</span><br><span class="line">      &#125;</span><br><span class="line">      totalSize += file.getLen();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    long goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</span><br><span class="line">    long minSize = <span class="type">Math</span>.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</span><br><span class="line">      <span class="type">FileInputFormat</span>.<span class="type">SPLIT_MINSIZE</span>, <span class="number">1</span>), minSplitSize);</span><br><span class="line">      </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">FileStatus</span> file: files) &#123;</span><br><span class="line">    </span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (isSplitable(fs, path)) &#123;</span><br><span class="line">          long blockSize = file.getBlockSize();</span><br><span class="line">          long splitSize = computeSplitSize(goalSize, minSize, blockSize);</span><br><span class="line"></span><br><span class="line">          ...</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">protected</span> long computeSplitSize(long goalSize, long minSize,</span><br><span class="line">                                       long blockSize) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="type">Math</span>.max(minSize, <span class="type">Math</span>.min(goalSize, blockSize));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="RDD创建"><a href="#RDD创建" class="headerlink" title="RDD创建"></a>RDD创建</h3><p>1、从集合（内存）中创建RDD</p>
<p>parallelize和makeRDD</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"spark"</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> rdd1 = sparkContext.parallelize(</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> rdd2 = sparkContext.makeRDD(</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">)</span><br><span class="line">rdd1.collect().foreach(println)</span><br><span class="line">rdd2.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br></pre></td></tr></table></figure></div>

<p>makeRDD方法其实就是parallelize方法</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeRDD</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    seq: <span class="type">Seq</span>[<span class="type">T</span>],</span><br><span class="line">    numSlices: <span class="type">Int</span> = defaultParallelism): <span class="type">RDD</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  parallelize(seq, numSlices)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>2、从外部存储（文件）创建RDD</p>
<p>由外部存储系统的数据集创建RDD包括：本地的文件系统，所有Hadoop支持的数据集，比如HDFS、HBase等。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"spark"</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">"input"</span>)</span><br><span class="line">fileRDD.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br></pre></td></tr></table></figure></div>

<p>3、从其他RDD创建</p>
<p>主要是通过一个RDD运算完后，再产生新的RDD。</p>
<p>4、直接创建RDD（new）</p>
<p>使用new的方式直接构造RDD</p>
<h3 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a>转换算子</h3><p>RDD整体上分为Value类型、双Value类型和Key-Value类型</p>
<h4 id="value类型"><a href="#value类型" class="headerlink" title="value类型"></a>value类型</h4><p>map</p>
<p>mapPartitions</p>
<p>mapPartitionsWithIndex</p>
<p>flatMap</p>
<p>glom</p>
<ul>
<li>将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变</li>
</ul>
<p>groupBy</p>
<p>filter</p>
<ul>
<li>将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃</li>
</ul>
<p>sample</p>
<ul>
<li>根据指定的规则从数据集中抽取数据</li>
</ul>
<p>distinct</p>
<p>coalesce</p>
<ul>
<li>根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率</li>
</ul>
<p>repartition</p>
<blockquote>
<p>小问题：coalesce和repartition区别？</p>
<p>repartition算子其实底层调用的就是coalesce算子，只不过固定使用了shuffle的操作,可以让数据更均衡一下，可以有效防止数据倾斜问题。</p>
<p>如果缩减分区，一般就采用coalesce，如果想扩大分区，就采用repartition</p>
</blockquote>
<p>sortBy</p>
<p>pipe</p>
<ul>
<li>管道，针对每个分区，都调用一次shell脚本，返回输出的RDD。</li>
</ul>
<h4 id="双Value类型"><a href="#双Value类型" class="headerlink" title="双Value类型"></a>双Value类型</h4><p>intersection</p>
<ul>
<li>对源RDD和参数RDD求交集后返回一个新的RDD</li>
</ul>
<p>union</p>
<ul>
<li>对源RDD和参数RDD求并集后返回一个新的RDD</li>
</ul>
<p>subtract</p>
<ul>
<li>以一个RDD元素为主，去除两个RDD中重复元素，将其他元素保留下来。求差集</li>
</ul>
<p>zip</p>
<ul>
<li>将两个RDD中的元素，以键值对的形式进行合并。其中，键值对中的Key为第1个RDD中的元素，Value为第2个RDD中的元素。</li>
</ul>
<h4 id="Key-Value类型"><a href="#Key-Value类型" class="headerlink" title="Key - Value类型"></a>Key - Value类型</h4><p>partitionBy</p>
<ul>
<li>将数据按照指定Partitioner重新进行分区。Spark默认的分区器是HashPartitioner</li>
</ul>
<p>reduceByKey</p>
<p>groupByKey</p>
<blockquote>
<p>reduceByKey和groupByKey的区别？</p>
<p>两个算子没有使用上的区别。所以使用的时候需要根据应用场景来选择。</p>
<p>从性能上考虑，reduceByKey存在预聚合功能，这样，在shuffle的过程中，落盘的数据量会变少，所以读写磁盘的速度会变快。性能更高</p>
</blockquote>
<p>aggregateByKey</p>
<ul>
<li>将数据根据不同的规则进行分区内计算和分区间计算</li>
<li><code>dataRDD1.aggregateByKey(0)(_+_,_+_)</code></li>
</ul>
<p>foldByKey</p>
<ul>
<li>当分区内计算规则和分区间计算规则相同时，aggregateByKey就可以简化为foldByKey</li>
<li><code>dataRDD1.foldByKey(0)(_+_)</code></li>
</ul>
<p>combineByKey</p>
<ul>
<li>最通用的对key-value型rdd进行聚集操作的聚集函数（aggregation function）。类似于aggregate()，combineByKey()允许用户返回值的类型与输入不一致。</li>
</ul>
<blockquote>
<p>reduceByKey、foldByKey、aggregateByKey、combineByKey的区别？</p>
<p>从源码的角度来讲，四个算子的底层逻辑是相同的。</p>
<p>aggregateByKey的算子会将初始值和第一个value使用分区内的计算规则进行计算</p>
<p>foldByKey的算子的分区内和分区间的计算规则相同，并且初始值和第一个value使用的规则相同</p>
<p>combineByKey第一个参数就是对第一个value进行处理，所以无需初始值。</p>
<p>reduceByKey不会对第一个value进行处理，分区内和分区间计算规则相同</p>
<p>上面的四个算子都支持预聚合功能。所以shuffle性能比较高</p>
<p>上面的四个算子都可以实现WordCount</p>
</blockquote>
<p>sortByKey</p>
<p>join</p>
<p>leftOuterJoin</p>
<p>cogroup</p>
<ul>
<li>在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<v>,Iterable<w>))类型的RDD</w></v></li>
</ul>
<h3 id="行动算子"><a href="#行动算子" class="headerlink" title="行动算子"></a>行动算子</h3><p>reduce</p>
<ul>
<li>聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据</li>
</ul>
<p>collect</p>
<ul>
<li>在驱动程序中，以数组Array的形式返回数据集的所有元素</li>
</ul>
<p>count</p>
<p>first</p>
<p>take</p>
<p>takeOrdered</p>
<p>aggregate</p>
<ul>
<li>分区的数据通过初始值和分区内的数据进行聚合，<strong>然后再和初始值进行分区间的数据聚合</strong></li>
</ul>
<p>fold</p>
<ul>
<li>折叠操作，aggregate的简化版操作</li>
</ul>
<p>countByKey</p>
<p>save相关算子</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 保存成Text文件</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">"output"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列化成对象保存到文件</span></span><br><span class="line">rdd.saveAsObjectFile(<span class="string">"output1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 保存成Sequencefile文件</span></span><br><span class="line">rdd.map((_,<span class="number">1</span>)).saveAsSequenceFile(<span class="string">"output2"</span>)</span><br></pre></td></tr></table></figure></div>

<p>foreach</p>
<ul>
<li>分布式遍历RDD中的每一个元素，调用指定函数</li>
</ul>
<h3 id="RDD序列化"><a href="#RDD序列化" class="headerlink" title="RDD序列化"></a>RDD序列化</h3><p>1) 闭包检查</p>
<p><strong>从计算的角度, 算子以外的代码都是在Driver端执行, 算子里面的代码都是在Executor端执行。</strong>那么在scala的函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给Executor端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化，这个操作我们称之为闭包检测。</p>
<p>2) Kryo序列化框架</p>
<blockquote>
<p>参考地址: <a href="https://github.com/EsotericSoftware/kryo" target="_blank" rel="noopener">https://github.com/EsotericSoftware/kryo</a></p>
</blockquote>
<p>Java的序列化能够序列化任何的类。但是比较重，序列化后，对象的提交也比较大。</p>
<p>Spark出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制。Kryo速度是Serializable的10倍。当RDD在Shuffle数据的时候，简单数据类型、数组和字符串类型已经在Spark内部使用Kryo来序列化。</p>
<h3 id="RDD依赖关系"><a href="#RDD依赖关系" class="headerlink" title="RDD依赖关系"></a>RDD依赖关系</h3><p>1、RDD血缘关系</p>
<p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">"input/1.txt"</span>)</span><br><span class="line">println(fileRDD.toDebugString)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordRDD: <span class="type">RDD</span>[<span class="type">String</span>] = fileRDD.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">println(wordRDD.toDebugString)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordRDD.map((_,<span class="number">1</span>))</span><br><span class="line">println(mapRDD.toDebugString)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = mapRDD.reduceByKey(_+_)</span><br><span class="line">println(resultRDD.toDebugString)</span><br><span class="line"></span><br><span class="line">resultRDD.collect()</span><br></pre></td></tr></table></figure></div>

<p>2、RDD依赖关系</p>
<p>这里所谓的依赖关系，其实就是RDD之间的关系</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">"input/1.txt"</span>)</span><br><span class="line">println(fileRDD.dependencies)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordRDD: <span class="type">RDD</span>[<span class="type">String</span>] = fileRDD.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">println(wordRDD.dependencies)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordRDD.map((_,<span class="number">1</span>))</span><br><span class="line">println(mapRDD.dependencies)</span><br><span class="line">println(<span class="string">"----------------------"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = mapRDD.reduceByKey(_+_)</span><br><span class="line">println(resultRDD.dependencies)</span><br><span class="line"></span><br><span class="line">resultRDD.collect()</span><br></pre></td></tr></table></figure></div>

<p>3、RDD窄依赖</p>
<p>窄依赖表示每一个父RDD的Partition最多被子RDD的一个Partition使用，窄依赖我们形象的比喻为独生子女。</p>
<p>4、RDD宽依赖</p>
<p>宽依赖表示同一个父RDD的Partition被多个子RDD的Partition依赖，会引起Shuffle，总结：宽依赖我们形象的比喻为超生。</p>
<p><strong>5、RDD任务划分</strong></p>
<p>RDD任务切分中间分为：Application、Job、Stage和Task</p>
<ul>
<li><p>Application：初始化一个SparkContext即生成一个Application；</p>
</li>
<li><p>Job：一个Action算子就会生成一个Job；</p>
</li>
<li><p><strong>Stage：Stage等于宽依赖(ShuffleDependency)的个数加1；</strong></p>
</li>
<li><p><strong>Task：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数。</strong></p>
</li>
</ul>
<p>注意：Application-&gt;Job-&gt;Stage-&gt;Task每一层都是1对n的关系。 </p>
<h3 id="RDD持久化"><a href="#RDD持久化" class="headerlink" title="RDD持久化"></a>RDD持久化</h3><p>1、RDD Cache缓存</p>
<p>RDD通过Cache或者Persist方法将前面的计算结果缓存，默认情况下会把数据以序列化的形式缓存在JVM的堆内存中。但是并不是这两个方法被调用时立即缓存，<strong>而是触发后面的action算子时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cache操作会增加血缘关系，不改变原有的血缘关系</span></span><br><span class="line">println(wordToOneRdd.toDebugString)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据缓存。</span></span><br><span class="line">wordToOneRdd.cache()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以更改存储级别</span></span><br><span class="line"><span class="comment">//mapRdd.persist(StorageLevel.MEMORY_AND_DISK_2)</span></span><br></pre></td></tr></table></figure></div>

<p>存储级别</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StorageLevel</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></div>

<p>缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p>
<p>Spark会自动对一些Shuffle操作的中间数据做持久化操作(比如：reduceByKey)。这样做的目的是为了当一个节点Shuffle失败了避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用persist或cache。</p>
<p>2、RDD CheckPoint检查点</p>
<p>所谓的检查点其实就是通过将RDD中间结果写入磁盘</p>
<p>由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。</p>
<p>对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 设置检查点路径</span></span><br><span class="line">sc.setCheckpointDir(<span class="string">"./checkpoint1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个RDD，读取指定位置文件:hello ys ys</span></span><br><span class="line"><span class="keyword">val</span> lineRdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">"input/1.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 业务逻辑</span></span><br><span class="line"><span class="keyword">val</span> wordRdd: <span class="type">RDD</span>[<span class="type">String</span>] = lineRdd.flatMap(line =&gt; line.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordToOneRdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = wordRdd.map &#123;</span><br><span class="line">    word =&gt; &#123;</span><br><span class="line">        (word, <span class="type">System</span>.currentTimeMillis())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 增加缓存,避免再重新跑一个job做checkpoint</span></span><br><span class="line">wordToOneRdd.cache()</span><br><span class="line"><span class="comment">// 数据检查点：针对wordToOneRdd做检查点计算</span></span><br><span class="line">wordToOneRdd.checkpoint()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 触发执行逻辑</span></span><br><span class="line">wordToOneRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure></div>

<p><strong>缓存和检查点区别</strong></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）Cache缓存只是将数据保存起来，不切断血缘依赖。Checkpoint检查点切断血缘依赖。</span><br><span class="line"></span><br><span class="line">2）Cache缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint的数据通常存储在HDFS等容错、高可用的文件系统，可靠性高。</span><br><span class="line"></span><br><span class="line">3）建议对checkpoint()的RDD使用Cache缓存，这样checkpoint的job只需从Cache缓存中读取数据即可，否则需要再从头计算一次RDD。</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.bigdata.spark.core.cache</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Spark02_Checkpoint</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"SparkCoreTest"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line">        <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">// 设置检查点路径， 一般路径应该为分布式存储路径，HDFS</span></span><br><span class="line">        sc.setCheckpointDir(<span class="string">"cp"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 检查点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// RDD的持久化可能会导致数据丢失，如果数据丢失，那么需要重新再次计算，性能不高</span></span><br><span class="line">        <span class="comment">// 所以如果能够保证数据不丢，那么是一个好的选择</span></span><br><span class="line">        <span class="comment">// 可以将数据保存到检查点中，这样是分布式存储，所以比较安全。</span></span><br><span class="line">        <span class="comment">// 所以将数据保存到检查点前，需要设定检查点路径</span></span><br><span class="line">        <span class="keyword">val</span> rdd1 = rdd.map(</span><br><span class="line">            num =&gt; &#123;</span><br><span class="line">                <span class="comment">//println("num.....")</span></span><br><span class="line">                num</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查点</span></span><br><span class="line">        <span class="comment">// 检查点为了准确，需要重头再执行一遍，就等同于开启一个新的作业</span></span><br><span class="line">        <span class="comment">// 为了提高效率，一般情况下，是先使用cache后在使用检查点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查点会切断RDD的血缘关系。将当前检查点当成数据计算的起点。</span></span><br><span class="line">        <span class="comment">// 持久化操作是不能切断血缘关系，因为一旦内存中数据丢失，无法恢复数据</span></span><br><span class="line">        <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[<span class="type">Int</span>] = rdd1.cache()</span><br><span class="line">        rdd2.checkpoint()</span><br><span class="line">        println(rdd2.toDebugString)</span><br><span class="line">        println(rdd2.collect().mkString(<span class="string">","</span>))</span><br><span class="line">        println(rdd2.toDebugString)</span><br><span class="line">        println(<span class="string">"**********************"</span>)</span><br><span class="line">        println(rdd2.collect().mkString(<span class="string">","</span>))</span><br><span class="line"></span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="RDD分区器"><a href="#RDD分区器" class="headerlink" title="RDD分区器"></a>RDD分区器</h3><p>Spark目前支持Hash分区和Range分区，和用户自定义分区。</p>
<p><strong>Hash分区为当前的默认分区。</strong></p>
<p>分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区，进而决定了Reduce的个数。</p>
<ul>
<li><p>只有Key-Value类型的RDD才有分区器，非Key-Value类型的RDD分区的值是None</p>
</li>
<li><p>每个RDD的分区ID范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的。</p>
</li>
</ul>
<p><strong>1)</strong> <strong>Hash分区</strong>：对于给定的key，计算其hashCode,并除以分区个数取余</p>
<p><strong>2)</strong> <strong>Range分区</strong>：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序</p>
<h3 id="文件读取与保存"><a href="#文件读取与保存" class="headerlink" title="文件读取与保存"></a>文件读取与保存</h3><p>Spark的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。</p>
<p>文件格式分为：text文件、json文件、csv文件、sequence文件以及Object文件；</p>
<p>文件系统分为：本地文件系统、HDFS、HBASE以及数据库。</p>
<h2 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h2><p>累加器用来把Executor端变量信息聚合到Driver端。</p>
<p>在Driver程序中定义的变量，在Executor端的每个Task都会得到这个变量的一份新的副本，每个task更新这些副本的值后，传回Driver端进行merge。</p>
<p>系统累加器</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">// 声明累加器</span></span><br><span class="line"><span class="keyword">var</span> sum = sc.longAccumulator(<span class="string">"sum"</span>);</span><br><span class="line">rdd.foreach(</span><br><span class="line">  num =&gt; &#123;</span><br><span class="line">    <span class="comment">// 使用累加器</span></span><br><span class="line">    sum.add(num)</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"><span class="comment">// 获取累加器的值</span></span><br><span class="line">println(<span class="string">"sum = "</span> + sum.value)</span><br></pre></td></tr></table></figure></div>

<p>自定义累加器</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 自定义累加器</span></span><br><span class="line"><span class="comment">// 1. 继承AccumulatorV2，并设定泛型</span></span><br><span class="line"><span class="comment">// 2. 重写累加器的抽象方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordCountAccumulator</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]]</span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> map : mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>] = mutable.<span class="type">Map</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 累加器是否为初始状态</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">  map.isEmpty</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 复制累加器</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]] = &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">WordCountAccumulator</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重置累加器</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  map.clear()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向累加器中增加数据 (In)</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(word: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 查询map中是否存在相同的单词</span></span><br><span class="line">    <span class="comment">// 如果有相同的单词，那么单词的数量加1</span></span><br><span class="line">    <span class="comment">// 如果没有相同的单词，那么在map中增加这个单词</span></span><br><span class="line">    map(word) = map.getOrElse(word, <span class="number">0</span>L) + <span class="number">1</span>L</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 合并累加器</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> map1 = map</span><br><span class="line">  <span class="keyword">val</span> map2 = other.value</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 两个Map的合并</span></span><br><span class="line">  map = map1.foldLeft(map2)(</span><br><span class="line">    ( innerMap, kv ) =&gt; &#123;</span><br><span class="line">      innerMap(kv._1) = innerMap.getOrElse(kv._1, <span class="number">0</span>L) + kv._2</span><br><span class="line">      innerMap</span><br><span class="line">    &#125;</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回累加器的结果 （Out）</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>] = map</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2><p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的<strong>只读</strong>值，以供一个或多个Spark操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，广播变量用起来都很顺手。在多个并行操作中使用同一个变量，但是 Spark会为每个任务分别发送。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">List</span>( (<span class="string">"a"</span>,<span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"c"</span>, <span class="number">3</span>), (<span class="string">"d"</span>, <span class="number">4</span>) ),<span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> list = <span class="type">List</span>( (<span class="string">"a"</span>,<span class="number">4</span>), (<span class="string">"b"</span>, <span class="number">5</span>), (<span class="string">"c"</span>, <span class="number">6</span>), (<span class="string">"d"</span>, <span class="number">7</span>) )</span><br><span class="line"><span class="comment">// 声明广播变量</span></span><br><span class="line"><span class="keyword">val</span> broadcast: <span class="type">Broadcast</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = sc.broadcast(list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = rdd1.map &#123;</span><br><span class="line">  <span class="keyword">case</span> (key, num) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> num2 = <span class="number">0</span></span><br><span class="line">    <span class="comment">// 使用广播变量</span></span><br><span class="line">    <span class="keyword">for</span> ((k, v) &lt;- broadcast.value) &#123;</span><br><span class="line">      <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">        num2 = v</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    (key, (num, num2))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>sqoop常见问题汇总</title>
    <url>/2020/06/17/sqoop%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Sqoop是连接关系型数据库和Hadoop的桥梁，主要有两个方面(导入和导出)。</p>
<p>目前在我的工程实践中，一般是将MySQL数据进行导入导出</p>
<h1 id="Sqoop参数"><a href="#Sqoop参数" class="headerlink" title="Sqoop参数"></a>Sqoop参数</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/module/sqoop/bin/sqoop import \</span><br><span class="line">--connect \</span><br><span class="line">--username \</span><br><span class="line">--password \</span><br><span class="line">--target-dir \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers \</span><br><span class="line">--fields-terminated-by   \</span><br><span class="line">--query   "$2" ' and $CONDITIONS;'</span><br></pre></td></tr></table></figure></div>

<h1 id="Sqoop导入导出Null存储一致性问题"><a href="#Sqoop导入导出Null存储一致性问题" class="headerlink" title="Sqoop导入导出Null存储一致性问题"></a>Sqoop导入导出Null存储一致性问题</h1><p>Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null。为了保证数据两端的一致性。</p>
<p>往hive导入数据时采用<code>--null-string</code>和<code>--null-non-string</code>。</p>
<p>在从hive导出数据时采用<code>--input-null-string</code>和<code>--input-null-non-string</code>两个参数。</p>
<h1 id="Sqoop数据导出一致性问题"><a href="#Sqoop数据导出一致性问题" class="headerlink" title="Sqoop数据导出一致性问题"></a>Sqoop数据导出一致性问题</h1><p>场景：如Sqoop在导出到Mysql时，使用4个Map任务，过程中有2个任务失败，那此时MySQL中存储了另外两个Map任务导入的数据，此时老板正好看到了这个报表数据。而开发工程师发现任务失败后，会调试问题并最终将全部数据正确的导入MySQL，那后面老板再次看报表数据，发现本次看到的数据与之前的不一致，这在生产环境是不允许的。</p>
<blockquote>
<p>官网：<a href="http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html" target="_blank" rel="noopener">http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html</a></p>
<p>Since Sqoop breaks down export process into multiple transactions, it is possible that a failed export job may result in partial data being committed to the database. This can further lead to subsequent jobs failing due to insert collisions in some cases, or lead to duplicated data in others. You can overcome this problem by specifying a staging table via the –staging-table option which acts as an auxiliary table that is used to stage exported data. The staged data is finally moved to the destination table in a single transaction.</p>
</blockquote>
<p>–staging-table方式</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop export --connect jdbc:mysql://192.168.137.10:3306/user_behavior --username root --password 123456 --table app_cource_study_report --columns watch_video_cnt,complete_video_cnt,dt --fields-terminated-by "\t" --export-dir "/user/hive/warehouse/tmp.db/app_cource_study_analysis_$&#123;day&#125;" --staging-table app_cource_study_report_tmp --clear-staging-table --input-null-string '\N'</span><br></pre></td></tr></table></figure></div>

<h1 id="Sqoop底层运行的任务是什么"><a href="#Sqoop底层运行的任务是什么" class="headerlink" title="Sqoop底层运行的任务是什么"></a>Sqoop底层运行的任务是什么</h1><p>只有Map阶段，没有Reduce阶段的任务。</p>
<p>默认是4个MapTask。</p>
<h1 id="Sqoop一天导入多少数据"><a href="#Sqoop一天导入多少数据" class="headerlink" title="Sqoop一天导入多少数据"></a>Sqoop一天导入多少数据</h1><p>100万日活=》10万订单，1人10条，每天1g左右业务数据</p>
<p>Sqoop每天将1G的数据量导入到数仓。</p>
<h1 id="Sqoop数据导出的时候一次执行多长时间"><a href="#Sqoop数据导出的时候一次执行多长时间" class="headerlink" title="Sqoop数据导出的时候一次执行多长时间"></a>Sqoop数据导出的时候一次执行多长时间</h1><p>每天晚上00:30开始执行，Sqoop任务一般情况40 -50分钟的都有。取决于数据量（11:11，6:18等活动在1个小时左右）。</p>
<h1 id="Sqoop在导入数据的时候数据倾斜"><a href="#Sqoop在导入数据的时候数据倾斜" class="headerlink" title="Sqoop在导入数据的时候数据倾斜"></a>Sqoop在导入数据的时候数据倾斜</h1><blockquote>
<p><a href="https://blog.csdn.net/lizhiguo18/article/details/103969906" target="_blank" rel="noopener">https://blog.csdn.net/lizhiguo18/article/details/103969906</a></p>
</blockquote>
<p>Sqoop 抽数的并行化主要涉及到两个参数：num-mappers：启动N个map来并行导入数据，默认4个；split-by：按照某一列来切分表的工作单元。</p>
<p>通过ROWNUM() 生成一个严格均匀分布的字段，然后指定为分割字段.</p>
<h1 id="Sqoop数据导出Parquet"><a href="#Sqoop数据导出Parquet" class="headerlink" title="Sqoop数据导出Parquet"></a>Sqoop数据导出Parquet</h1><p><strong>我在工程项目中经常遇到的问题</strong></p>
<p>Ads层数据用Sqoop往MySql中导入数据的时候，如果用了orc（Parquet）不能导入，需转化成text格式</p>
<p>（1）创建临时表，把Parquet中表数据导入到临时表，把临时表导出到目标表用于可视化</p>
<p>（2）Sqoop里面有参数，可以直接把Parquet转换为text</p>
<p>（3）ads层建表的时候就不要建Parquet表</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>sqoop</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>sqoop</tag>
        <tag>离线大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>redis为什么那么快</title>
    <url>/2020/06/16/redis%E4%B8%BA%E4%BB%80%E4%B9%88%E9%82%A3%E4%B9%88%E5%BF%AB/</url>
    <content><![CDATA[<h1 id="redis是单线程的，为什么那么快"><a href="#redis是单线程的，为什么那么快" class="headerlink" title="redis是单线程的，为什么那么快"></a>redis是单线程的，为什么那么快</h1><ul>
<li><p>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。</p>
</li>
<li><p>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的</p>
</li>
<li><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗</p>
</li>
<li><p>使用多路I/O复用模型，非阻塞IO</p>
</li>
<li><p>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>数据库</tag>
        <tag>缓存</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark的WordCount到底有几个RDD</title>
    <url>/2020/06/16/Spark%E7%9A%84WordCount%E5%88%B0%E5%BA%95%E6%9C%89%E5%87%A0%E4%B8%AARDD/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote>
<p>本文转载自  <a href="https://blog.csdn.net/zhongqi2513/article/details/81513587" target="_blank" rel="noopener">https://blog.csdn.net/zhongqi2513/article/details/81513587</a> </p>
</blockquote>
<p>这样的一句标准的sparkcore的wordcount的代码到底能要产生几个RDD呢。相信大家对于一个标准的WordCount的代码一定不陌生：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">sc.textFile(<span class="string">"hdfs://myha01/wc/input/words.txt"</span>)</span><br><span class="line">  .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">  .map((_,<span class="number">1</span>))</span><br><span class="line">  .reduceByKey(_+_)</span><br><span class="line">  .saveAsTextFile(<span class="string">"hdfs://myha01/wc/output/"</span>)</span><br></pre></td></tr></table></figure></div>


<p>这局代码：</p>
<p>1、开始使用了一个textFile用来读取数据的方法</p>
<p>2、中间使用了三个标准的RDD的操作算子：</p>
<p><code>flatMap(_.split(&quot; &quot;))</code> 负责把由每一行组成的RDD按照空格切开压平成标准的由单词组成的RDD</p>
<p><code>map((_,1))</code>负责把每个单词word变成（word,1）每个单词出现一次</p>
<p><code>reduceByKey(_+_)</code>负责把按照key相同也就是单词相同的key-value划分成一组，然后每一组做count聚合，最终就得出了输入文件中，每个单词出现了多少次。</p>
<p>3、最后，使用了一个<code>saveAsTextFile</code>的方法来存储数据</p>
<p>那到底这句代码中执行过程中，是不是刚好每个算子生成一个RDD呢？ 很不幸，不是的。如果需要知晓答案，最好的方式，就是翻阅参与运算的每个算子到底做了什么事情。</p>
<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><p>接下来是详细分析：</p>
<p>1、首先看sc.textFile(“hdfs://myha01/wc/input/words.txt”)：textFile方法在SparkContext类中</p>
<p><a href="https://img-blog.csdn.net/2018080818524234?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/2018080818524234?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>接着看textFile中的hadoopFile方法的实现：</p>
<p><a href="https://img-blog.csdn.net/20180808185447476?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808185447476?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>通过这个代码可以得知，在hadoopFile的内部产生了<strong>第一个RDD：HadoopRDD</strong></p>
<p>接着回到textFile方法：</p>
<p><a href="https://img-blog.csdn.net/20180808185553702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808185553702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>发现，其实返回的HadoopRDD又调用了map算子，看map算子的实现：</p>
<p><a href="https://img-blog.csdn.net/20180808185644932?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808185644932?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>map算子的内部实现中，又创建了一个RDD，这就是<strong>第二个RDD： MapPartitionsRDD</strong></p>
<p>那也就是说，textFile算子的最终返回值就是第二个RDD：MapPartitionsRDD</p>
<p>接着看：flatMap(_.split(“ “))算子的操作实现：flatMap算子在RDD中</p>
<p><a href="https://img-blog.csdn.net/20180808190412683?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808190412683?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>所以flatMap(_.split(“ “))算子操作产生了<strong>第三个RDD：MapPartitionsRDD</strong></p>
<p>接着看map((_,1))算子操作：map算子在RDD类中</p>
<p><a href="https://img-blog.csdn.net/20180808190610353?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808190610353?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>map((_,1))算子的具体实现依然是简单的new MapPartitionRDD的方式生成<strong>第四个RDD：MapPartitionsRDD</strong></p>
<p>接着看：reduceByKey(<em>+</em>)算子的具体实现：reduceByKey在PairRDDFunctions类中</p>
<p><a href="https://img-blog.csdn.net/20180808191032475?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808191032475?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>跳到：</p>
<p><a href="https://img-blog.csdn.net/20180808191055291?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808191055291?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>跳到：</p>
<p><a href="https://img-blog.csdn.net/20180808191139772?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808191139772?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>到这个地方说明：reduceByKey算子的返回值其实是创建了<strong>第五个RDD：ShuffledRDD</strong></p>
<p>接着看：saveAsTextFile(“hdfs://myha01/wc/output/“)算子的具体实现：saveAsTextFile算子在RDD类中</p>
<p><a href="https://img-blog.csdn.net/20180808191410601?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808191410601?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>this.mapPartitions这句代码在调用的时候，在mapPartitions的内部，其实又创建了<strong>第六个RDD：MapPartitionRDD</strong></p>
<p><a href="https://img-blog.csdn.net/20180808191542404?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808191542404?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>接着回到：saveAsTextFile方法的实现，其实返现，最后一句话在调用中，也会生成一个RDD</p>
<p>这就是<strong>第七个RDD：MapPartitionRDD</strong></p>
<p><a href="https://img-blog.csdn.net/20180808192008596?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/20180808192008596?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>到底为止，其他的地方，是没有再产生RDD的。</p>
<p>所以按照刚才的分析得出的最终结论是：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一个RDD：HadoopRDD</span><br><span class="line">第二个RDD：MapPartitionsRDD</span><br><span class="line">第三个RDD：MapPartitionsRDD</span><br><span class="line">第四个RDD：MapPartitionsRDD</span><br><span class="line">第五个RDD：ShuffledRDD</span><br><span class="line">第六个RDD：MapPartitionRDD</span><br><span class="line">第七个RDD：MapPartitionRDD</span><br></pre></td></tr></table></figure></div>

<p>其实，在执行saveAsTextFile之前，我们可以通过RDD提供的toDebugString看到这些个算子在调用的时候到底产生了多少个RDD:</p>
<p><a href="https://img-blog.csdn.net/2018080819285544?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://img-blog.csdn.net/2018080819285544?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob25ncWkyNTEz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" class="lazyload"></a></p>
<p>望各位仁兄牢记。如果不记得，请翻阅源码。本篇文章是基于最新的Spark-2.3.1的版本</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>7个RDD，2+1+1+1+2</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">sc.textFile(<span class="string">"hdfs://myha01/wc/input/words.txt"</span>)</span><br><span class="line">  .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">  .map((_,<span class="number">1</span>))</span><br><span class="line">  .reduceByKey(_+_)</span><br><span class="line">  .saveAsTextFile(<span class="string">"hdfs://myha01/wc/output/"</span>)</span><br></pre></td></tr></table></figure></div>

<table>
<thead>
<tr>
<th>算子</th>
<th>产生的RDD</th>
</tr>
</thead>
<tbody><tr>
<td><code>sc.textFile(&quot;hdfs://myha01/wc/input/words.txt&quot;)</code></td>
<td>第一个RDD：HadoopRDD<br>第二个RDD：MapPartitionsRDD</td>
</tr>
<tr>
<td><code>.flatMap(_.split(&quot; &quot;))</code></td>
<td>第三个RDD：MapPartitionsRDD</td>
</tr>
<tr>
<td><code>.map((_,1))</code></td>
<td>第四个RDD：MapPartitionsRDD</td>
</tr>
<tr>
<td><code>.reduceByKey(_+_)</code></td>
<td>第五个RDD：ShuffledRDD</td>
</tr>
<tr>
<td><code>.saveAsTextFile(&quot;hdfs://myha01/wc/output/&quot;)</code></td>
<td>第六个RDD：MapPartitionRDD<br>第七个RDD：MapPartitionRDD</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>spark</tag>
        <tag>spark-core</tag>
      </tags>
  </entry>
  <entry>
    <title>常用排序算法总结</title>
    <url>/2020/06/15/%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 冒泡排序 时间复杂度 O(n^2) 空间复杂度O(1)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BubbleSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bubbleSort</span><span class="params">(<span class="keyword">int</span>[] data)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      System.out.println(<span class="string">"开始排序"</span>);</span><br><span class="line">      <span class="keyword">int</span> arrayLength = data.length;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; arrayLength - <span class="number">1</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">         <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; arrayLength - <span class="number">1</span> - i; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(data[j] &gt; data[j + <span class="number">1</span>])&#123;</span><br><span class="line">               <span class="keyword">int</span> temp = data[j + <span class="number">1</span>];</span><br><span class="line">               data[j + <span class="number">1</span>] = data[j];</span><br><span class="line">               data[j] = temp;</span><br><span class="line">               flag = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         System.out.println(java.util.Arrays.toString(data));</span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (!flag)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">int</span>[] data = &#123; <span class="number">9</span>, -<span class="number">16</span>, <span class="number">21</span>, <span class="number">23</span>, -<span class="number">30</span>, -<span class="number">49</span>, <span class="number">21</span>, <span class="number">30</span>, <span class="number">30</span> &#125;;</span><br><span class="line"></span><br><span class="line">      System.out.println(<span class="string">"排序之前：\n"</span> + java.util.Arrays.toString(data));</span><br><span class="line"></span><br><span class="line">      bubbleSort(data);</span><br><span class="line"></span><br><span class="line">      System.out.println(<span class="string">"排序之后：\n"</span> + java.util.Arrays.toString(data));</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.shuzu;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 标准快排</span></span><br><span class="line"><span class="comment"> * 【注意】</span></span><br><span class="line"><span class="comment"> * 最左边为基准数（flag）的时候，从右开始往前遍历。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Kuaisupaixu</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">quicksort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (left &gt; right) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> flag = arr[left];</span><br><span class="line">        <span class="keyword">int</span> l = left;</span><br><span class="line">        <span class="keyword">int</span> r = right;</span><br><span class="line">        <span class="keyword">int</span> temp;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (l != r) &#123;</span><br><span class="line">            <span class="keyword">while</span> (arr[r] &gt;= flag &amp;&amp; l &lt; r) &#123; <span class="comment">//【重点】</span></span><br><span class="line">                r -= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span> (arr[l] &lt;= flag &amp;&amp; l &lt; r) &#123;</span><br><span class="line">                l += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            temp = arr[r];</span><br><span class="line">            arr[r] = arr[l];</span><br><span class="line">            arr[l] = temp;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        arr[left] = arr[l];</span><br><span class="line">        arr[l] = flag;</span><br><span class="line"></span><br><span class="line">        quicksort(arr, left, l - <span class="number">1</span>);</span><br><span class="line">        quicksort(arr, l + <span class="number">1</span>, right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] a = &#123;<span class="number">9</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">0</span>&#125;;</span><br><span class="line">        quicksort(a, <span class="number">0</span>, a.length - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : a) &#123;</span><br><span class="line">            System.out.print(i + <span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 快排</span></span><br><span class="line"><span class="comment"> * 时间复杂度:平均时间复杂度为O(nlogn)</span></span><br><span class="line"><span class="comment"> * 空间复杂度:O(logn)，因为递归栈空间的使用问题</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span></span>(list: <span class="type">List</span>[<span class="type">Int</span>]): <span class="type">List</span>[<span class="type">Int</span>] = list <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Nil</span> =&gt; <span class="type">Nil</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">List</span>() =&gt; <span class="type">List</span>()</span><br><span class="line">    <span class="keyword">case</span> head :: tail =&gt;</span><br><span class="line">      <span class="keyword">val</span> (left, right) = tail.partition(_ &lt; head)</span><br><span class="line">      quickSort(left) ::: head :: quickSort(right)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>核心思想：不断的将大的数组分成两个小数组，直到不能拆分为止，即形成了单个值。此时使用合并的排序思想对已经有序的数组进行合并，合并为一个大的数据，不断重复此过程，直到最终所有数据合并到一个数组为止。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.shuzu;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 【归并排序】</span></span><br><span class="line"><span class="comment"> * 时间复杂度nlogn（平均，最好，最坏都是这个值）</span></span><br><span class="line"><span class="comment"> * 空间复杂度n（用空间换时间，时间上和快排差不多）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MergeSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> arr[] = &#123;<span class="number">8</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">2</span>&#125;; <span class="comment">//</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> temp[] = <span class="keyword">new</span> <span class="keyword">int</span>[arr.length]; <span class="comment">//归并排序需要一个额外空间</span></span><br><span class="line">        mergeSort(arr, <span class="number">0</span>, arr.length - <span class="number">1</span>, temp);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"归并排序后="</span> + Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分+合方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mergeSort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (left &lt; right) &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (left + right) / <span class="number">2</span>; <span class="comment">//中间索引</span></span><br><span class="line">            <span class="comment">//向左递归进行分解</span></span><br><span class="line">            mergeSort(arr, left, mid, temp);</span><br><span class="line">            <span class="comment">//向右递归进行分解</span></span><br><span class="line">            mergeSort(arr, mid + <span class="number">1</span>, right, temp);</span><br><span class="line">            <span class="comment">//合并</span></span><br><span class="line">            merge(arr, left, mid, right, temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//合并的方法</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> arr   排序的原始数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> left  左边有序序列的初始索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> mid   中间索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> right 右边索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> temp  做中转的数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> left, <span class="keyword">int</span> mid, <span class="keyword">int</span> right, <span class="keyword">int</span>[] temp)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> i = left; <span class="comment">// 初始化i, 左边有序序列的初始索引</span></span><br><span class="line">        <span class="keyword">int</span> j = mid + <span class="number">1</span>; <span class="comment">//初始化j, 右边有序序列的初始索引</span></span><br><span class="line">        <span class="keyword">int</span> t = <span class="number">0</span>; <span class="comment">// 指向temp数组的当前索引</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//(一)</span></span><br><span class="line">        <span class="comment">//先把左右两边(有序)的数据按照规则填充到temp数组</span></span><br><span class="line">        <span class="comment">//直到左右两边的有序序列，有一边处理完毕为止</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= right) &#123;<span class="comment">//继续</span></span><br><span class="line">            <span class="comment">//如果左边的有序序列的当前元素，小于等于右边有序序列的当前元素</span></span><br><span class="line">            <span class="comment">//即将左边的当前元素，填充到 temp数组</span></span><br><span class="line">            <span class="comment">//然后 t++, i++</span></span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt;= arr[j]) &#123;</span><br><span class="line">                temp[t] = arr[i];</span><br><span class="line">                t += <span class="number">1</span>;</span><br><span class="line">                i += <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//反之,将右边有序序列的当前元素，填充到temp数组</span></span><br><span class="line">                temp[t] = arr[j];</span><br><span class="line">                t += <span class="number">1</span>;</span><br><span class="line">                j += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//(二)</span></span><br><span class="line">        <span class="comment">//把有剩余数据的一边的数据依次全部填充到temp</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid) &#123; <span class="comment">//左边的有序序列还有剩余的元素，就全部填充到temp</span></span><br><span class="line">            temp[t] = arr[i];</span><br><span class="line">            t += <span class="number">1</span>;</span><br><span class="line">            i += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (j &lt;= right) &#123; <span class="comment">//右边的有序序列还有剩余的元素，就全部填充到temp</span></span><br><span class="line">            temp[t] = arr[j];</span><br><span class="line">            t += <span class="number">1</span>;</span><br><span class="line">            j += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//(三)</span></span><br><span class="line">        <span class="comment">//将temp数组的元素拷贝到arr</span></span><br><span class="line">        <span class="comment">//注意，并不是每次都拷贝所有</span></span><br><span class="line">        t = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> tempLeft = left; <span class="comment">//</span></span><br><span class="line">        <span class="comment">//第一次合并 tempLeft = 0 , right = 1 //  tempLeft = 2  right = 3 // tL=0 ri=3</span></span><br><span class="line">        <span class="comment">//最后一次 tempLeft = 0  right = 7</span></span><br><span class="line">        <span class="keyword">while</span> (tempLeft &lt;= right) &#123;</span><br><span class="line">            arr[tempLeft] = temp[t];</span><br><span class="line">            t += <span class="number">1</span>;</span><br><span class="line">            tempLeft += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 快排 </span></span><br><span class="line"><span class="comment"> * 时间复杂度:O(nlogn)</span></span><br><span class="line"><span class="comment"> * 空间复杂度:O(n)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(left: <span class="type">List</span>[<span class="type">Int</span>], right: <span class="type">List</span>[<span class="type">Int</span>]): <span class="type">List</span>[<span class="type">Int</span>] = (left, right) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Nil</span>, _) =&gt; right</span><br><span class="line">    <span class="keyword">case</span> (_, <span class="type">Nil</span>) =&gt; left</span><br><span class="line">    <span class="keyword">case</span> (x :: xTail, y :: yTail) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (x &lt;= y) x :: merge(xTail, right)</span><br><span class="line">      <span class="keyword">else</span> y :: merge(left, yTail)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 二分查找 时间复杂度O(log2n);空间复杂度O(1)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binarySearch</span></span>(arr:<span class="type">Array</span>[<span class="type">Int</span>],left:<span class="type">Int</span>,right:<span class="type">Int</span>,findVal:<span class="type">Int</span>): <span class="type">Int</span>=&#123;</span><br><span class="line">  <span class="keyword">if</span>(left&gt;right)&#123;<span class="comment">//递归退出条件，找不到，返回-1</span></span><br><span class="line">    <span class="number">-1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> midIndex = (left+right)/<span class="number">2</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (findVal &lt; arr(midIndex))&#123;<span class="comment">//向左递归查找</span></span><br><span class="line">    binarySearch(arr,left,midIndex<span class="number">-1</span>,findVal)</span><br><span class="line">  &#125;<span class="keyword">else</span> <span class="keyword">if</span>(findVal &gt; arr(midIndex))&#123;<span class="comment">//向右递归查找</span></span><br><span class="line">    binarySearch(arr,midIndex+<span class="number">1</span>,right,findVal)</span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;<span class="comment">//查找到，返回下标</span></span><br><span class="line">    midIndex</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.chazhao;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 查找数目超过半数的值并打印，如果没有就打印0</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 方法二：快速排序，中间的值就是数量为半数的值。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//&#123;1,2,3,2,2,2,5,4,2&#125;</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Banshuchazhao</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">MoreThanHalfNum_Solution</span><span class="params">(<span class="keyword">int</span>[] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = array[<span class="number">0</span>], count = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; array.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (array[i] == res)</span><br><span class="line">                count++;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                count--;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (count == <span class="number">0</span>) &#123;</span><br><span class="line">                res = array[i];</span><br><span class="line">                count = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 验证</span></span><br><span class="line">        count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; array.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (array[i] == res)</span><br><span class="line">                count++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count &gt; array.length / <span class="number">2</span> ? res : <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = MoreThanHalfNum_Solution(<span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>&#125;);</span><br><span class="line">        System.out.println(i);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>拓展需求：当一个有序数组中，有多个相同的数值时，如何将所有的数值都查找到。</p>
<p>代码实现如下：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  &#123;1,8, 10, 89, 1000, 1000，1234&#125; 当一个有序数组中，有多个相同的数值时，如何将所有的数值都查找到，比如这里的 1000.</span></span><br><span class="line"><span class="comment">  //分析</span></span><br><span class="line"><span class="comment">  1. 返回的结果是一个可变数组 ArrayBuffer</span></span><br><span class="line"><span class="comment">  2. 在找到结果时，向左边扫描，向右边扫描 [条件]</span></span><br><span class="line"><span class="comment">  3. 找到结果后，就加入到ArrayBuffer</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">binarySearch2</span></span>(arr: <span class="type">Array</span>[<span class="type">Int</span>], l: <span class="type">Int</span>, r: <span class="type">Int</span>,</span><br><span class="line">                    findVal: <span class="type">Int</span>): <span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//找不到条件?</span></span><br><span class="line">    <span class="keyword">if</span> (l &gt; r) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="type">ArrayBuffer</span>()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> midIndex = (l + r) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">val</span> midVal = arr(midIndex)</span><br><span class="line">    <span class="keyword">if</span> (midVal &gt; findVal) &#123;</span><br><span class="line">      <span class="comment">//向左进行递归查找</span></span><br><span class="line">      binarySearch2(arr, l, midIndex - <span class="number">1</span>, findVal)</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (midVal &lt; findVal) &#123; <span class="comment">//向右进行递归查找</span></span><br><span class="line">      binarySearch2(arr, midIndex + <span class="number">1</span>, r, findVal)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      println(<span class="string">"midIndex="</span> + midIndex)</span><br><span class="line">      <span class="comment">//定义一个可变数组</span></span><br><span class="line">      <span class="keyword">val</span> resArr = <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line">      <span class="comment">//向左边扫描</span></span><br><span class="line">      <span class="keyword">var</span> temp = midIndex - <span class="number">1</span></span><br><span class="line">      breakable &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (temp &lt; <span class="number">0</span> || arr(temp) != findVal) &#123;</span><br><span class="line">            <span class="keyword">break</span>()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (arr(temp) == findVal) &#123;</span><br><span class="line">            resArr.append(temp)</span><br><span class="line">          &#125;</span><br><span class="line">          temp -= <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//将中间这个索引加入</span></span><br><span class="line">      resArr.append(midIndex)</span><br><span class="line">      <span class="comment">//向右边扫描</span></span><br><span class="line">      temp = midIndex + <span class="number">1</span></span><br><span class="line">      breakable &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (temp &gt; arr.length - <span class="number">1</span> || arr(temp) != findVal) &#123;</span><br><span class="line">            <span class="keyword">break</span>()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (arr(temp) == findVal) &#123;</span><br><span class="line">            resArr.append(temp)</span><br><span class="line">          &#125;</span><br><span class="line">          temp += <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> resArr</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="二叉树相关"><a href="#二叉树相关" class="headerlink" title="二叉树相关"></a>二叉树相关</h1><p>二叉树的特点</p>
<p>（1）树执行查找、删除、插入的时间复杂度都是O(logN)</p>
<p>（2）遍历二叉树的方法包括前序、中序、后序</p>
<p>（3）非平衡树指的是根的左右两边的子节点的数量不一致</p>
<p>（4）在非空二叉树中，第i层的结点总数不超过 , i&gt;=1；</p>
<p>（5）深度为h的二叉树最多有个结点(h&gt;=1)，最少有h个结点；</p>
<p>（6）对于任意一棵二叉树，如果其叶结点数为N0，而度数为2的结点总数为N2，则N0=N2+1；</p>
<p>定义节点以及前序、中序、后序遍历</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>(<span class="params">treeNo:<span class="type">Int</span></span>)</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> no = treeNo</span><br><span class="line">  <span class="keyword">var</span> left:<span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> right:<span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//后序遍历</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">postOrder</span></span>():<span class="type">Unit</span>=&#123;</span><br><span class="line">    <span class="comment">//向左递归输出左子树</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>.left != <span class="literal">null</span>)&#123;</span><br><span class="line">      <span class="keyword">this</span>.left.postOrder</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向右递归输出右子树</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.right.postOrder</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//输出当前节点值</span></span><br><span class="line">    printf(<span class="string">"节点信息 no=%d \n"</span>,no)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//中序遍历</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">infixOrder</span></span>():<span class="type">Unit</span>=&#123;</span><br><span class="line">    <span class="comment">//向左递归输出左子树</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>.left != <span class="literal">null</span>)&#123;</span><br><span class="line">      <span class="keyword">this</span>.left.infixOrder()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//输出当前节点值</span></span><br><span class="line">    printf(<span class="string">"节点信息 no=%d \n"</span>,no)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向右递归输出右子树</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.right.infixOrder()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//前序遍历</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preOrder</span></span>():<span class="type">Unit</span>=&#123;</span><br><span class="line">    <span class="comment">//输出当前节点值</span></span><br><span class="line">    printf(<span class="string">"节点信息 no=%d \n"</span>,no)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向左递归输出左子树</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>.left != <span class="literal">null</span>)&#123;</span><br><span class="line">      <span class="keyword">this</span>.left.postOrder()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向右递归输出右子树</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.right.preOrder()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//后序遍历查找</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">postOrderSearch</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line">    <span class="comment">//向左递归输出左子树</span></span><br><span class="line">    <span class="keyword">var</span> resNode:<span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.left != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.left.postOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (resNode != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> resNode</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.right.postOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (resNode != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> resNode</span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">"ttt~~"</span>)</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.no == no) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span></span><br><span class="line">    &#125;</span><br><span class="line">    resNode</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//中序遍历查找</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">infixOrderSearch</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> resNode : <span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line">    <span class="comment">//先向左递归查找</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.left != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.left.infixOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (resNode != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> resNode</span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">"yyy~~"</span>)</span><br><span class="line">    <span class="keyword">if</span> (no == <span class="keyword">this</span>.no) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向右递归查找</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.right.infixOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> resNode</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//前序查找</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preOrderSearch</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (no == <span class="keyword">this</span>.no) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向左递归查找</span></span><br><span class="line">    <span class="keyword">var</span> resNode : <span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.left != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.left.preOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (resNode != <span class="literal">null</span>)&#123;</span><br><span class="line">      <span class="keyword">return</span>  resNode</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向右边递归查找</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      resNode = <span class="keyword">this</span>.right.preOrderSearch(no)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> resNode</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//删除节点</span></span><br><span class="line">  <span class="comment">//删除节点规则</span></span><br><span class="line">  <span class="comment">//1如果删除的节点是叶子节点，则删除该节点</span></span><br><span class="line">  <span class="comment">//2如果删除的节点是非叶子节点，则删除该子树</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">delNode</span></span>(no:<span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//首先比较当前节点的左子节点是否为要删除的节点</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.left != <span class="literal">null</span> &amp;&amp; <span class="keyword">this</span>.left.no == no) &#123;</span><br><span class="line">      <span class="keyword">this</span>.left = <span class="literal">null</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//比较当前节点的右子节点是否为要删除的节点</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span> &amp;&amp; <span class="keyword">this</span>.right.no == no) &#123;</span><br><span class="line">      <span class="keyword">this</span>.right = <span class="literal">null</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向左递归删除</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.left != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.left.delNode(no)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//向右递归删除</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.right != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.right.delNode(no)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>定义二叉树，前序、中序、后序遍历，前序、中序、后序查找，删除节点</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span></span>&#123;</span><br><span class="line">  <span class="keyword">var</span> root:<span class="type">TreeNode</span> = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//后序遍历</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">postOrder</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (root != <span class="literal">null</span>)&#123;</span><br><span class="line">      root.postOrder()</span><br><span class="line">    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">      println(<span class="string">"当前二叉树为空，不能遍历"</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">//中序遍历</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">infixOrder</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>)&#123;</span><br><span class="line">        root.infixOrder()</span><br><span class="line">      &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        println(<span class="string">"当前二叉树为空，不能遍历"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//前序遍历</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preOrder</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>)&#123;</span><br><span class="line">        root.preOrder()</span><br><span class="line">      &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        println(<span class="string">"当前二叉树为空，不能遍历"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//后序遍历查找</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postOrderSearch</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>) &#123;</span><br><span class="line">        root.postOrderSearch(no)</span><br><span class="line">      &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//中序遍历查找</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">infixOrderSeacher</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> root.infixOrderSearch(no)</span><br><span class="line">      &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//前序查找</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preOrderSearch</span></span>(no:<span class="type">Int</span>): <span class="type">TreeNode</span> = &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> root.preOrderSearch(no)</span><br><span class="line">      &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//println("当前二叉树为空，不能查找")</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//删除节点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delNode</span></span>(no:<span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (root != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">//先处理一下root是不是要删除的</span></span><br><span class="line">        <span class="keyword">if</span> (root.no == no)&#123;</span><br><span class="line">          root = <span class="literal">null</span></span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">          root.delNode(no)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法与数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot精简教程</title>
    <url>/2020/06/14/springboot%E7%B2%BE%E7%AE%80%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="SpringBoot"><a href="#SpringBoot" class="headerlink" title="SpringBoot"></a>SpringBoot</h1><h2 id="2-1-Spring分布式架构"><a href="#2-1-Spring分布式架构" class="headerlink" title="2.1 Spring分布式架构"></a>2.1 Spring分布式架构</h2><p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image3.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image3.png" class="lazyload"></a></p>
<h2 id="2-2-SpringBoot-概述"><a href="#2-2-SpringBoot-概述" class="headerlink" title="2.2 SpringBoot 概述"></a>2.2 SpringBoot 概述</h2><p>Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。</p>
<p>该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。</p>
<p>通过这种方式，Spring Boot致力于在蓬勃发展的快速应用开发领域(rapid application development)成为领导者。</p>
<h2 id="2-3-为什么要使用SpringBoot"><a href="#2-3-为什么要使用SpringBoot" class="headerlink" title="2.3 为什么要使用SpringBoot"></a>2.3 为什么要使用SpringBoot</h2><p>说到为什么使用Spring Boot, 就不得不提到Spring框架的前世今生</p>
<p>Spring框架由于其繁琐的配置，一度被人认为“配置地狱”，各种XML、Annotation配置混合使用，让人眼花缭乱，而且如果出错了也很难找出原因。</p>
<p>通过SpringMVC框架部署和发布web程序，需要和系统外服务器进行关联，操作繁琐不方便。</p>
<p>Spring Boot是由Spring官方推出的一个新框架，对Spring进行了高度封装，是Spring未来的发展方向。使用Spring<br>Boot框架后，可以帮助开发者快速搭建Spring框架，也可以帮助开发者快速启动一个Web服务，无须依赖外部Servlet容器，使编码变得简单，使配置变得简单，使部署变得简单，使监控变得简单。</p>
<h2 id="2-4-Spring-前世今生"><a href="#2-4-Spring-前世今生" class="headerlink" title="2.4 Spring 前世今生"></a>2.4 Spring 前世今生</h2><p>1) Spring1.x 时代</p>
<p>在Spring1.x时代，都是通过xml文件配置bean</p>
<p>随着项目的不断扩大，需要将xml配置分放到不同的配置文件中</p>
<p>需要频繁的在java类和xml配置文件中切换。</p>
<p>2) Spring2.x时代</p>
<p>随着JDK 1.5带来的注解支持，Spring2.x可以使用注解对Bean进行申明和注入，大大的<br>减少了xml配置文件，同时也大大简化了项目的开发。</p>
<p>那么，问题来了，究竟是应该使用xml还是注解呢？</p>
<blockquote>
<p>最佳实践：</p>
<p>应用的基本配置用xml，比如：数据源、资源文件等； </p>
<p>业务开发用注解，比如：Service中注入bean等； </p>
</blockquote>
<p>3) Spring3.x到Spring4.x</p>
<p>从Spring3.x开始提供了Java配置方式，使用Java配置方式可以更好的理解你配置的<br>Bean，现在我们就处于这个时代，并且Spring4.x和Spring<br>boot都推荐使用java配置的式。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Spring 1.X</span></span><br><span class="line"><span class="comment">//使用基本的框架类及配置文件（.xml）实现对象的声明及对象关系的整合。</span></span><br><span class="line">org.springframework.core.io.ClassPathResource</span><br><span class="line">org.springframework.beans.factory.xml.XmlBeanFactory</span><br><span class="line">org.springframework.context.support.ClassPathXmlApplicationContext </span><br><span class="line"><span class="comment">//Spring 2.X</span></span><br><span class="line"><span class="comment">//使用注解代替配置文件中对象的声明。简化配置。</span></span><br><span class="line">org.springframework.stereotype.<span class="meta">@Component</span></span><br><span class="line">org.springframework.stereotype.<span class="meta">@Controller</span></span><br><span class="line">org.springframework.stereotype.<span class="meta">@Service</span></span><br><span class="line">org.springframework.stereotype.<span class="meta">@Repository</span></span><br><span class="line">org.springframework.stereotype.<span class="meta">@Scope</span></span><br><span class="line">org.springframework.beans.factory.annotation.<span class="meta">@Autowired</span> </span><br><span class="line"><span class="comment">//Spring 3.X</span></span><br><span class="line"><span class="comment">//使用更强大的注解完全代替配置文件。</span></span><br><span class="line">org.springframework.context.annotation.AnnotationConfigApplicationContext</span><br><span class="line">org.springframework.context.annotation.<span class="meta">@Configuration</span></span><br><span class="line">org.springframework.context.annotation.<span class="meta">@Bean</span></span><br><span class="line">org.springframework.context.annotation.<span class="meta">@Value</span></span><br><span class="line">org.springframework.context.annotation.<span class="meta">@Import</span> </span><br><span class="line"><span class="comment">//Spring 4.X</span></span><br><span class="line"><span class="comment">//使用条件注解强化之前版本的注解。</span></span><br><span class="line">org.springframework.context.annotation.<span class="meta">@Conditional</span></span><br></pre></td></tr></table></figure></div>



<h2 id="2-5-自动创建一个SpringBoot项目"><a href="#2-5-自动创建一个SpringBoot项目" class="headerlink" title="2.5 自动创建一个SpringBoot项目"></a>2.5 自动创建一个SpringBoot项目</h2><p>1) 在Idea中new→Module→Spring Initializr</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image4.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image4.png" class="lazyload"></a></p>
<p>2) 给工程命名、设置包名等，其他默认即可</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image5.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image5.png" class="lazyload"></a></p>
<p>3) 选择工程的版本</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image6.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image6.png" class="lazyload"></a></p>
<p>4) 点击Next ，给工程命名，然后点击Finish</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image7.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image7.png" class="lazyload"></a></p>
<h2 id="2-6-手动创建一个SpringBoot-项目"><a href="#2-6-手动创建一个SpringBoot-项目" class="headerlink" title="2.6 手动创建一个SpringBoot 项目"></a>2.6 手动创建一个SpringBoot 项目</h2><h3 id="2-6-1-创建Maven项目"><a href="#2-6-1-创建Maven项目" class="headerlink" title="2.6.1 创建Maven项目"></a>2.6.1 创建Maven项目</h3><h3 id="2-6-2-集成Spring-Boot框架"><a href="#2-6-2-集成Spring-Boot框架" class="headerlink" title="2.6.2 集成Spring Boot框架"></a>2.6.2 集成Spring Boot框架</h3><ul>
<li>修改pom.xml文件，增加Spring Boot框架的依赖关系及对Web环境的支持。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.5.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>Spring Boot版本为官方最新正式版2.2.2.RELEASE</li>
<li>以往的项目中，所有类库的依赖关系都需要我们自己导入到pom.xml文件中，但是Spring<br>Boot项目增加spring-boot-starter-web依赖后，会自动加载web环境配置相关依赖(SpringMVC,<br>Tomcat)，简化了我们的操作。</li>
<li>spring-boot-starter-parent：继承Spring Boot的相关参数</li>
<li>spring-boot-starter-xxx：代表一个Spring Boot模块</li>
<li>spring-boot-starter-web：代表Web模块，在这个模块中包含了许多依赖的JAR包</li>
</ul>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image8.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image8.png" class="lazyload"></a></p>
<p>扩展:修改一下Maven编译插件的版本</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">  	<span class="comment">&lt;!-- 设置Maven编译插件的版本  SpringBoot高版本用的Maven插件版本比较</span></span><br><span class="line"><span class="comment">          高，STS没支持到，需手动指定 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">maven-jar-plugin.version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">maven-jar-plugin.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure></div>



<h3 id="2-6-3-增加程序代码"><a href="#2-6-3-增加程序代码" class="headerlink" title="2.6.3 增加程序代码"></a>2.6.3 增加程序代码</h3><ul>
<li>在src/main/java目录中增加类com.atguigu.springboot.SpringBootSelfApplication，并增加相应代码。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootSelfApplication</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		SpringApplication.run(SpringBootSelfApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>Spring<br>Boot项目中都会有一个以Application结尾的应用类，然后有一个标准的Java入口方法main方法。通过这个方法启动SpringBoot项目，方法中无需放入任何业务逻辑。</li>
<li>@SpringBootApplication注解是Spring Boot核心注解</li>
<li>右键点击项目或项目中的SpringBootSelfApplication类, 选择菜单Run as Spring Boot<br>App，启动SpringBoot项目.</li>
</ul>
<h3 id="2-6-4-集成Tomcat服务器"><a href="#2-6-4-集成Tomcat服务器" class="headerlink" title="2.6.4 集成Tomcat服务器"></a>2.6.4 集成Tomcat服务器</h3><ul>
<li>SpringBoot内置了Tomcat，当增加Web依赖后执行main方法，等同于启动Tomcat服务器,<br>默认端口号为8080。如果想具体指定,通过server.port来指定</li>
<li>默认情况下SpringBoot启动后，默认的context-path的值为/，从浏览器端访问项目时，,不需要加项目名，直接通过<br><a href="http://localhost:8080/请求名" target="_blank" rel="noopener">http://localhost:8080/请求名</a> 来访问，<br>如果想具体指定，通过server.servlet.context-path来指定</li>
<li>例如:在src/main/resources/目录中增加application.properties文件。</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">server.servlet.context-path</span>=<span class="string">/</span></span><br><span class="line"><span class="meta">server.port</span>=<span class="string">80</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>SpringBoot会自动读取src/main/resources/路径或着src/main/resources/config路径中的application.properties文件或application.yml文件。</li>
</ul>
<h3 id="2-6-5-为什么还会有配置文件"><a href="#2-6-5-为什么还会有配置文件" class="headerlink" title="2.6.5 为什么还会有配置文件"></a>2.6.5 为什么还会有配置文件</h3><p>Spring Boot我们称之为微框架，这里的“微”不是小和少的意思，而是“简”的意思，简单，简洁。</p>
<p>项目中大部分的基础配置由Spring Boot框架帮我们自动集成，简化了我们的配置，但是框架自身为了扩展性，依然需要提供配置文件。</p>
<p>上面的代码中只是简单的应用了Spring Boot框架，但是我们真正要做的是将Spring<br>Boot应用到项目中，所以接下来我们增加对SpringMVC框架，Mybatis框架的集成。</p>
<h2 id="2-7-SpringBoot-集成-Spring-amp-Spring-Web-MVC"><a href="#2-7-SpringBoot-集成-Spring-amp-Spring-Web-MVC" class="headerlink" title="2.7 SpringBoot 集成 Spring &amp; Spring Web MVC"></a>2.7 SpringBoot 集成 Spring &amp; Spring Web MVC</h2><ul>
<li>基本的Spring Boot环境已经构建好了，现在需要配置Spring框架及SpringMVC框架的业务环境</li>
</ul>
<h3 id="2-7-1-ComponentScan注解"><a href="#2-7-1-ComponentScan注解" class="headerlink" title="2.7.1 @ComponentScan注解"></a>2.7.1 @ComponentScan注解</h3><ul>
<li>通过@ComponentScan注解指定扫描的包</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.ComponentScan;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ComponentScan</span>(basePackages=<span class="string">"com.atguigu"</span>)</span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootSelfApplication</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		SpringApplication.run(SpringBootSelfApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>默认扫描</li>
</ul>
<p>默认扫描当前包com.atguigu.springboot和子包com.atguigu.springboot.*</p>
<p>如果还需要扫描其他的包，那么需要增加@ComponentScan注解,指定包名进行扫描。</p>
<h3 id="2-7-2-增加控制器代码"><a href="#2-7-2-增加控制器代码" class="headerlink" title="2.7.2 增加控制器代码"></a>2.7.2 增加控制器代码</h3><p>在src/main/java目录中增加类com.atguigu.springboot.controller.UserController，并增加相应代码。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Controller;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseBody;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@ResponseBody</span>	  <span class="comment">//返回Json数据</span></span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/getAllUser"</span>)  <span class="comment">//指定请求URL</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Object <span class="title">getAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		Map&lt;String,String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">		map.put(<span class="string">"username"</span>, <span class="string">"张三"</span>);</span><br><span class="line">		<span class="keyword">return</span> map;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-7-3-执行main方法启动应用"><a href="#2-7-3-执行main方法启动应用" class="headerlink" title="2.7.3 执行main方法启动应用"></a>2.7.3 执行main方法启动应用</h3><p>访问路径<code>http://localhost:8080[/应用路径名称]/ getAllUser</code>页面打印JSON字符串即可<a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image9.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image9.png" class="lazyload"></a></p>
<h3 id="2-7-4-Controller和-RestController区别"><a href="#2-7-4-Controller和-RestController区别" class="headerlink" title="2.7.4 @Controller和@RestController区别"></a>2.7.4 @Controller和@RestController区别</h3><p>@RestController等同于@Controller + @ResponseBody，所以上面的代码可以变为：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/getAllUser"</span>)  <span class="comment">//指定请求URL</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Object <span class="title">getAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		Map&lt;String,String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">		map.put(<span class="string">"username"</span>, <span class="string">"张三"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> map;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-7-5-页面跳转-了解"><a href="#2-7-5-页面跳转-了解" class="headerlink" title="2.7.5 页面跳转[了解]"></a>2.7.5 页面跳转[了解]</h3><p>1) 如果需要转发跳转Jsp页面,可参考如下步骤</p>
<ul>
<li>在pom.xml中加入如下依赖</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.tomcat.embed<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tomcat-embed-jasper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.servlet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jstl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>将jsp页面存放在src/main/webapp目录下,Springboot默认从该目录下查找jsp页面</li>
<li>在application.properties文件中配置：</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">properties</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.mvc.view.prefix</span>=<span class="string">/   </span></span><br><span class="line"><span class="meta">spring.mvc.view.suffix</span>=<span class="string">.jsp</span></span><br></pre></td></tr></table></figure></div>

<p>2) 如需要进行重定向，可参考如下步骤</p>
<ul>
<li>在请求处理方法中的返回值前面加上”redirect:”</li>
<li>重定向的页面同样存放在src/main/webapp下</li>
</ul>
<h2 id="2-8-SpringBoot集成通用Mapper"><a href="#2-8-SpringBoot集成通用Mapper" class="headerlink" title="2.8 SpringBoot集成通用Mapper"></a>2.8 SpringBoot集成通用Mapper</h2><h3 id="2-8-1-通用Mapper简介"><a href="#2-8-1-通用Mapper简介" class="headerlink" title="2.8.1 通用Mapper简介"></a>2.8.1 通用Mapper简介</h3><p>通用mapper可以极大的方便开发人员进行CRUD操作，提供极其方便的单表增删改查。</p>
<p>一句话简单说，它就是个辅助mybatis极简单表开发的组件。它不是为了替代mybatis，而是让mybatis的开发更方便。</p>
<h3 id="2-8-2-集成通用Mapper"><a href="#2-8-2-集成通用Mapper" class="headerlink" title="2.8.2 集成通用Mapper"></a>2.8.2 集成通用Mapper</h3><p>1) 在pom.xml中加入通用Mapper的starter</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>tk.mybatis<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mapper-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">	   </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>2) 添加持久层代码</p>
<ul>
<li>通用Mapper提供了Mapper接口，该接口中提供了常用的CRUD方法.</li>
<li>用户可以自己定义自己的Mapper接口，继承通用Mapper提供的Mapper接口，</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.mapper;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.springboot.beans.User;</span><br><span class="line"><span class="keyword">import</span> tk.mybatis.mapper.common.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">User</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>3) 在src/main/resources下创建application.yml文件,配置数据源</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># jdbc配置</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost:3306/bigdata?serverTimezone=UTC</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="number">1234</span></span><br></pre></td></tr></table></figure></div>

<h2 id="2-9-整合测试"><a href="#2-9-整合测试" class="headerlink" title="2.9 整合测试"></a>2.9 整合测试</h2><h3 id="2-9-1-增加业务层代码"><a href="#2-9-1-增加业务层代码" class="headerlink" title="2.9.1 增加业务层代码"></a>2.9.1 增加业务层代码</h3><p>1) 增加业务层接口</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.springboot.beans.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 查询所有的用户</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> List&lt;User&gt; <span class="title">selectAllUser</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>2) 增加业务层实现类</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.springboot.beans.User;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.springboot.mapper.UserMapper;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> UserMapper userMapper;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> List&lt;User&gt; <span class="title">selectAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> userMapper.selectAll();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-9-2-增加控制层方法"><a href="#2-9-2-增加控制层方法" class="headerlink" title="2.9.2 增加控制层方法"></a>2.9.2 增加控制层方法</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.springboot.controller;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.springboot.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> UserService userService;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/getAllUser"</span>)  <span class="comment">//指定请求URL</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Object <span class="title">getAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> userService.selectAllUser();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-9-3-扫描Mapper"><a href="#2-9-3-扫描Mapper" class="headerlink" title="2.9.3 扫描Mapper"></a>2.9.3 扫描Mapper</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@MapperScan</span>(basePackages = <span class="string">"com.atguigu.springboot.mapper"</span>)</span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootSelfApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringBootSelfApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-9-4-测试"><a href="#2-9-4-测试" class="headerlink" title="2.9.4 测试"></a>2.9.4 测试</h3><p>访问路径<code>http://localhost:8080[/应用路径名称]/ getAllUser</code>页面打印JSON字符串即可</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image10.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image10.png" class="lazyload"></a></p>
<h2 id="2-10-Restful风格URL"><a href="#2-10-Restful风格URL" class="headerlink" title="2.10 Restful风格URL"></a>2.10 Restful风格URL</h2><h3 id="2-10-1-REST-简介"><a href="#2-10-1-REST-简介" class="headerlink" title="2.10.1 REST 简介"></a>2.10.1 REST 简介</h3><p>REST（Representational State Transfer）又被称作表现层状态转换。它涉及到三个重要名词：</p>
<ul>
<li><p>资源</p>
<p>所谓资源简单讲就是服务所能提供的数据，可以是实体数据也可是媒体类型，图片、PDF、文本等</p>
</li>
<li><p>表现层</p>
<p>何为变现层？简单说就是将数据以某种方式展现给用户，或者给客户返回一张图片等等动作称之为表现，通常是已JSON或XML形式展现数据</p>
</li>
<li><p>状态转换</p>
<p>状态转换就是对数据进行一系列的操作，因为资源本身并非一尘不变，随着需求的变化而变化。一个资源可能会随着需求的变化而经历一个资源创建、修改、查询、删除等过程，REST风格正是基于HTTP协议运行的，HTTP协议又被称为无状态协议，所以资源的变化需要在服务端完成，</p>
</li>
</ul>
<p>简单用一句话概括就是：REST风格使用URL定位资源，用HTTP动词（GET,POST,DELETE,PUT）描述操作。</p>
<h3 id="2-10-1-REST-规定"><a href="#2-10-1-REST-规定" class="headerlink" title="2.10.1 REST 规定"></a>2.10.1 REST 规定</h3><ul>
<li><p>GET请求</p>
<ul>
<li>获取资源</li>
</ul>
</li>
</ul>
<blockquote>
<p>例如：/emp/1</p>
<p>获取id=1的员工信息</p>
</blockquote>
<ul>
<li>POST请求</li>
<li>添加资源</li>
</ul>
<blockquote>
<p>例如：/emp</p>
<p>添加员工信息</p>
</blockquote>
<ul>
<li>PUT请求</li>
<li>更新资源</li>
</ul>
<blockquote>
<p>例如：/emp/1</p>
<p>更新id=1的员工信息</p>
</blockquote>
<ul>
<li>DELETE请求</li>
<li>删除资源</li>
</ul>
<blockquote>
<p>例如：/emp/1</p>
<p>删除id=1的员工信息</p>
</blockquote>
<h3 id="2-10-2-Resulful风格URL-和普通URL对比"><a href="#2-10-2-Resulful风格URL-和普通URL对比" class="headerlink" title="2.10.2 Resulful风格URL 和普通URL对比"></a>2.10.2 Resulful风格URL 和普通URL对比</h3><p>普通URL:<code>localhost:8888/SpringBootSelf/selectUser?id=1001&amp;username=zhangsan</code></p>
<p>Restful:  <code>localhost:8888/SpringBootSelf/selectUser/1001/zhangsan</code></p>
<h3 id="2-10-3-如何在后台处理Restful风格URL中的参数"><a href="#2-10-3-如何在后台处理Restful风格URL中的参数" class="headerlink" title="2.10.3 如何在后台处理Restful风格URL中的参数"></a>2.10.3 如何在后台处理Restful风格URL中的参数</h3><ul>
<li><p>客户端的URL:<code>localhost:8888/SpringBootSelf/selectUser/1001</code></p>
</li>
<li><p>在@RequestMapping注解中使用 {} 占位符对应实际URL中的参数</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/selectUser/&#123;ids&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User  <span class="title">selectUser</span><span class="params">(@PathVariable(<span class="string">"ids"</span>)</span> Integer id ) </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> userService.doSelectUser(id);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在方法中使用@PathVariable注解指定将占位符对应的URL中的参数值赋值给方法的形参.</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/selectUser/&#123;ids&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User  <span class="title">selectUser</span><span class="params">(@PathVariable(<span class="string">"ids"</span>)</span> Integer id ) </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> userService.doSelectUser(id);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-10-4-转换PUT请求和DELETE请求-了解"><a href="#2-10-4-转换PUT请求和DELETE请求-了解" class="headerlink" title="2.10.4 转换PUT请求和DELETE请求[了解]"></a>2.10.4 转换PUT请求和DELETE请求[了解]</h3><ul>
<li><p>PUT请求和DELETE请求需要通过POST请求来转换</p>
</li>
<li><p>发送POST请求我们需要在form表单中发送，所以我们需要使用SpringBoot的模板</p>
</li>
<li><p>转换的步骤：</p>
<p>1、添加Thymeleaf模块</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-thymeleaf<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>添加该模块后在main/resources目录下创建templates目录</p>
</blockquote>
<p>2、在templates目录下创建index.html页面，添加form表单，请求方式设置为post，表单中设置一个隐藏域，name属性值为_method,value值为put（转换为PUT请求时的值）或delete（转换为DELETE请求时的值）</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">html</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/getEmp/1"</span>&gt;</span>获取员工<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/emp/4"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"hidden"</span> <span class="attr">name</span>=<span class="string">"_method"</span> <span class="attr">value</span>=<span class="string">"delete"</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"删除员工"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>3、配置过滤器</p>
<ul>
<li>创建一个类继承HiddenHttpMethodFilter</li>
<li>在类上添加@WebFilter</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.web.filter.HiddenHttpMethodFilter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebFilter;</span><br><span class="line"></span><br><span class="line"><span class="meta">@WebFilter</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilter</span> <span class="keyword">extends</span> <span class="title">HiddenHttpMethodFilter</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>4、在启动类上添加@ServletComponentScan注解</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ServletComponentScan</span></span><br><span class="line"><span class="meta">@MapperScan</span>(basePackages = <span class="string">"com.atguigu.springboot.mapper"</span>)</span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootSelfApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SpringBootSelfApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>JavaWeb</category>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>JavaWeb</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>spring精简教程</title>
    <url>/2020/06/14/spring%E7%B2%BE%E7%AE%80%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="简单了解框架"><a href="#简单了解框架" class="headerlink" title="简单了解框架"></a>简单了解框架</h1><p>框架，即framework。其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。</p>
<p>框架是对特定应用领域中的应用系统的部分设计和实现的整体结构。</p>
<p>因为软件系统发展到今天已经很复杂了，特别是服务器端软件，涉及到的知识，内容，问题太多。在某些方面使用别人成熟的框架，就相当于让别人帮你完成一些基础工作，你只需要集中精力完成系统的业务逻辑设计。而且框架一般是成熟，稳健的，他可以处理系统很多细节问题，比如，事务处理，安全性，数据流控制等问题。还有框架一般都经过很多人使用，所以结构很好，所以扩展性也很好，而且它是不断升级的，你可以直接享受别人升级代码带来的好处。</p>
<h1 id="第1章-Spring"><a href="#第1章-Spring" class="headerlink" title="第1章 Spring"></a>第1章 Spring</h1><h2 id="1-1-Spring-概述"><a href="#1-1-Spring-概述" class="headerlink" title="1.1 Spring 概述"></a>1.1 Spring 概述</h2><p>1) Spring是一个开源框架</p>
<p>2) Spring为简化企业级开发而生，使用Spring，JavaBean就可以实现很多以前要靠EJB才能实现的功能。同样的功能，在EJB中要通过繁琐的配置和复杂的代码才能够实现，而在Spring中却非常的优雅和简洁。</p>
<p>3) Spring是一个<strong>IOC</strong>(DI)和<strong>AOP</strong>容器框架。</p>
<p>4) Spring的优良特性</p>
<blockquote>
<p>① <strong>非侵入式</strong>：基于Spring开发的应用中的对象可以不依赖于Spring的API</p>
<p>② <strong>依赖注入</strong>：DI——Dependency Injection，反转控制(IOC)最经典的实现。</p>
<p>③ <strong>面向切面编程</strong>：Aspect Oriented Programming——AOP</p>
<p>④ <strong>容器</strong>：Spring是一个容器，因为它包含并且管理应用对象的生命周期</p>
<p><strong>⑤ 组件化</strong>：Spring实现了使用简单的组件配置组合成一个复杂的应用。在 Spring 中可以使用XML和Java注解组合这些对象。</p>
</blockquote>
<p><strong>⑥ 一站式</strong>：在IOC和AOP的基础上可以整合各种企业应用的开源框架和优秀的第三方类库（实际上Spring<br>自身也提供了表述层的SpringMVC和持久层的Spring JDBC）。</p>
<p>5) Spring模块</p>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image1.png" data-fancybox="group" data-caption="Image" class="fancybox"><img alt="Image" title="Image" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image1.png" class="lazyload"></a></p>
<h2 id="1-2-Spring-HelloWorld"><a href="#1-2-Spring-HelloWorld" class="headerlink" title="1.2 Spring HelloWorld"></a>1.2 Spring HelloWorld</h2><p>1) 创建一个Maven版的Java工程</p>
<p>2) 在pom.xml中加入对Spring的依赖</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  	  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-context<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.0.0.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>3) 创建Spring的核心配置文件</p>
<ul>
<li>File-&gt;New-&gt;Spring Bean Configuration File</li>
<li>为文件取名字 例如：applicationContext.xml</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>4) 编写组件</p>
<ul>
<li>创建控制层组件</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.controller;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 控制层组件  处理客户端的请求，给客户端响应</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title">listAllUsers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建业务层组件接口</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.service;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 业务层组件   处理业务逻辑</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title">doGetAllUser</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建业务层组件实现类</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span>  <span class="keyword">implements</span> <span class="title">UserService</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doGetAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建持久层组件接口</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.dao;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 持久层组件  负责数据库的CRUD操作</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserDao</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">selectAllUsers</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建持久层组件实现类</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDaoJdbcImpl</span> <span class="keyword">implements</span> <span class="title">UserDao</span>  </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">selectAllUsers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		System.out.println(<span class="string">"UserDaoJdbcImpl  selectAllUsers  Success ....."</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在spring的核心配置文件中管理Bean</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">&lt;!-- 管理组件 --&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- </span></span><br><span class="line"><span class="comment">		bean: 对应一个被Spring管理的组件对象</span></span><br><span class="line"><span class="comment">		 	id: bean的唯一标识</span></span><br><span class="line"><span class="comment">		 	class: 组件对象对应的类的全类名</span></span><br><span class="line"><span class="comment">	 --&gt;</span>	</span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"userController"</span> <span class="attr">class</span>=<span class="string">"com.ys.spring.controller.UserController"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"userServiceImpl"</span> <span class="attr">class</span>=<span class="string">"com.ys.spring.service.UserServiceImpl"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"userDaoJdbcImpl"</span> <span class="attr">class</span>=<span class="string">"com.ys.spring.dao.UserDaoJdbcImpl"</span>&gt;</span><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>编写测试类</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.controller.UserController;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestSpring</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSpringXML</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">//1. 先创建Spring的容器对象</span></span><br><span class="line">		ApplicationContext ctx = </span><br><span class="line">				<span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"applicationContext.xml"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//2. 从Spring的容器中获取Bean对象</span></span><br><span class="line">		UserController uc = ctx.getBean(<span class="string">"userController"</span>, UserController<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"uc:"</span> + uc);</span><br><span class="line">		UserService us = ctx.getBean(<span class="string">"userServiceImpl"</span>,UserService<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"us:"</span> + us );</span><br><span class="line">		UserDao ud = ctx.getBean(<span class="string">"userDaoJdbcImpl"</span>,UserDao<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"ud:"</span> + ud );		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>5) 组件装配</p>
<ul>
<li>在控制层组件中定义业务层组件类型的属性</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.controller;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 控制层组件  处理客户端的请求，给客户端响应</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> UserService userService ;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserService</span><span class="params">(UserService userService)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.userService = userService;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title">listAllUsers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		userService.doGetAllUser();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在业务层组件中定义持久层组件类型的属性</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span>  <span class="keyword">implements</span> <span class="title">UserService</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">private</span> UserDao userDao ;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDao userDao)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.userDao = userDao;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doGetAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		userDao.selectAllUsers();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在Spring的核心配置文件中完成组件装配</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang"></div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;beans xmlns=<span class="string">"http://www.springframework.org/schema/beans"</span></span><br><span class="line">	xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">	xsi:schemaLocation=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"</span>&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;!-- 管理组件 --&gt;</span><br><span class="line">	&lt;!-- </span><br><span class="line">		bean: 对应一个被Spring管理的组件对象</span><br><span class="line">		 	id: bean的唯一标识</span><br><span class="line">		 	class: 组件对象对应的类的全类名</span><br><span class="line">	 --&gt;	</span><br><span class="line">	&lt;bean id=<span class="string">"userController"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.ys.spring.controller.UserController"</span>&gt;</span><br><span class="line">		&lt;!-- 给属性注入值 --&gt;</span><br><span class="line">		&lt;property name="userService" ref="userServiceImpl"&gt;&lt;/property&gt;</span><br><span class="line">	&lt;/bean&gt;</span><br><span class="line">	</span><br><span class="line">	&lt;bean id=<span class="string">"userServiceImpl"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.ys.spring.service.UserServiceImpl"</span>&gt;</span><br><span class="line">		&lt;property name="userDao" ref="userDaoJdbcImpl"&gt;&lt;/property&gt;</span><br><span class="line">	&lt;/bean&gt;</span><br><span class="line">	&lt;bean id="userDaoJdbcImpl" class="com.ys.spring.dao.UserDaoJdbcImpl"&gt;&lt;/bean&gt;</span><br><span class="line"></span><br><span class="line">&lt;/beans&gt;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>测试控制层 业务层 持久层的调用</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.controller.UserController;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestSpring</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSpringXML</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">//1. 先创建Spring的容器对象</span></span><br><span class="line">		ApplicationContext ctx = </span><br><span class="line">				<span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"applicationContext.xml"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//2. 从Spring的容器中获取Bean对象</span></span><br><span class="line">		UserController uc = ctx.getBean(<span class="string">"userController"</span>, UserController<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"uc:"</span> + uc);</span><br><span class="line">		UserService us = ctx.getBean(<span class="string">"userServiceImpl"</span>,UserService<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"us:"</span> + us );</span><br><span class="line">		UserDao ud = ctx.getBean(<span class="string">"userDaoJdbcImpl"</span>,UserDao<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"ud:"</span> + ud );</span><br><span class="line">		</span><br><span class="line">		uc.listAllUsers();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>



<h2 id="1-3-基于注解开发Spring应用"><a href="#1-3-基于注解开发Spring应用" class="headerlink" title="1.3 基于注解开发Spring应用"></a>1.3 基于注解开发Spring应用</h2><h3 id="1-3-1-常用注解标识组件"><a href="#1-3-1-常用注解标识组件" class="headerlink" title="1.3.1 常用注解标识组件"></a>1.3.1 常用注解标识组件</h3><p>1) 普通组件：</p>
<blockquote>
<p>@Component 标识一个受Spring IOC容器管理的组件</p>
</blockquote>
<p>2) 持久化层组件：</p>
<blockquote>
<p>@Repository 标识一个受Spring IOC容器管理的持久化层组件</p>
</blockquote>
<p>3) 业务逻辑层组件：</p>
<blockquote>
<p>@Service 标识一个受Spring IOC容器管理的业务逻辑层组件</p>
</blockquote>
<p>4) 表述层控制器组件：</p>
<blockquote>
<p>@Controller 标识一个受Spring IOC容器管理的表述层控制器组件</p>
</blockquote>
<h3 id="1-3-2-组件命名规则"><a href="#1-3-2-组件命名规则" class="headerlink" title="1.3.2 组件命名规则"></a>1.3.2 组件命名规则</h3><p>1) 默认情况：使用组件的简单类名首字母小写后得到的字符串作为bean的id</p>
<p>2) 使用组件注解的value属性指定bean的id</p>
<p>3) 注意：事实上Spring并没有能力识别一个组件到底是不是它所标记的类型，即使将<br>@Respository注解用在一个表述层控制器组件上面也不会产生任何错误，所以<br>@Respository、@Service、@Controller这几个注解仅仅是为了让开发人员自己 明确当前的组件扮演的角色。</p>
<h3 id="1-3-3-Spring-HelloWorld-注解版"><a href="#1-3-3-Spring-HelloWorld-注解版" class="headerlink" title="1.3.3 Spring HelloWorld 注解版"></a>1.3.3 Spring HelloWorld 注解版</h3><p>1) 在控制层 业务层 持久层组件标注对应的注解</p>
<ul>
<li>在控制层组件标注注解</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在业务层组件标注注解</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span>  <span class="keyword">implements</span> <span class="title">UserService</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在持久层组件标注注解</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDaoJdbcImpl</span> <span class="keyword">implements</span> <span class="title">UserDao</span>  </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>2) 在Spring的核心配置文件中开启组件扫描</p>
<ul>
<li>首先在xml文件中的namespace视图下勾选context名称空间</li>
</ul>
<p><a href="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image2.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="http://www.zh0122.com/2017/04/15/04_%E5%B0%9A%E7%A1%85%E8%B0%B7JavaEE%E6%8A%80%E6%9C%AF%E4%B9%8BSpring&SpringBoot/media/image2.png" class="lazyload"></a></p>
<ul>
<li>在Spring的核心配置文件中开启组件扫描</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xmlns:context</span>=<span class="string">"http://www.springframework.org/schema/context"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">		http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 组件扫描 </span></span><br><span class="line"><span class="comment">		 base-package: 基本包</span></span><br><span class="line"><span class="comment">		 Spring会扫描通过base-package指定的包下以及子包下的组件，将带有Spring相关</span></span><br><span class="line"><span class="comment">         注解的类管理到IOC容器中。</span></span><br><span class="line"><span class="comment">	 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.ys.spring"</span>&gt;</span><span class="tag">&lt;/<span class="name">context:component-scan</span>&gt;</span>	</span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>3) 编写测试类</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.controller.UserController;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestSpring</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSpringXML</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">//1. 先创建Spring的容器对象</span></span><br><span class="line">		ApplicationContext ctx = </span><br><span class="line">				<span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"applicationContext.xml"</span>);	</span><br><span class="line">		<span class="comment">//2. 从Spring的容器中获取Bean对象</span></span><br><span class="line">		UserController uc = ctx.getBean(<span class="string">"userController"</span>, UserController<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"uc:"</span> + uc);</span><br><span class="line">		UserService us = ctx.getBean(<span class="string">"userServiceImpl"</span>,UserService<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"us:"</span> + us );</span><br><span class="line">		UserDao ud = ctx.getBean(<span class="string">"userDaoJdbcImpl"</span>,UserDao<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"ud:"</span> + ud );			</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>



<h3 id="1-3-4-Autowired注解"><a href="#1-3-4-Autowired注解" class="headerlink" title="1.3.4 @Autowired注解"></a>1.3.4 @Autowired注解</h3><p>1) @Autowired的工作机制</p>
<ul>
<li>首先会通过当前被装配的属性的类型到IOC容器中去匹配对应的Bean对象,如果能唯一确定一个bean对象，则装配成功</li>
<li>当通过当前被装配的属性的类型匹配在IOC容器中匹配到多个对应的Bean对象时，<br>会再使用当前被装配的属性的名字与匹配到的Bean对象的id值再进行唯一确定，如果能确定唯一一个，则装配<br>成功，否则，抛出异常</li>
</ul>
<blockquote>
<p>expected single matching bean but found 2:<br>userDaoJdbcImpl,userDaoMyBatisImpl</p>
</blockquote>
<ul>
<li>如果被装配的属性在IOC容器中匹配不到任何一个Bean对象，也会抛出异常</li>
</ul>
<blockquote>
<p>expected at least 1 bean which qualifies as autowire candidate for<br>this dependency.</p>
<p>Dependency annotations:</p>
<p>@org.springframework.beans.factory.annotation.Autowired(required=true)}</p>
</blockquote>
<ul>
<li>如果匹配到多个Bean的情况，并且通过属性名也无法唯一确定一个Bean的时候，可以手动通过@Qualifier注解来具体指定装配哪个Bean对象.</li>
<li>@Autowired 注解中required的属性默认是true，表示属性必须被装配，可以改为false，表示可选.也就是<br>有就装配，没有就不装配.</li>
<li>@Autowired 和 @Qualifier 注解可以加在属性上，也可以加在方法上。</li>
</ul>
<h3 id="1-3-5-基于注解装配"><a href="#1-3-5-基于注解装配" class="headerlink" title="1.3.5 基于注解装配"></a>1.3.5 基于注解装配</h3><p>1) 在 控制层 和 业务层分别定义需要被装配的组件类型的属性,并在属性上标注注解</p>
<ul>
<li>在控制层中定义业务层类型的属性 和 相关方法</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> UserService userService ;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title">listAllUsers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		userService.doGetAllUser();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在业务层中定义持久层类型的属性 和相关方法</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Qualifier;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span>  <span class="keyword">implements</span> <span class="title">UserService</span></span>&#123;</span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> UserDao userDao ;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doGetAllUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		userDao.selectAllUsers();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>在持久层中定义相关方法</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDaoJdbcImpl</span> <span class="keyword">implements</span> <span class="title">UserDao</span>  </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">selectAllUsers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		System.out.println(<span class="string">"UserDaoJdbcImpl  selectAllUsers  Success ....."</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>2) 在测试方法中测试 控制层 业务层 持久层的调用</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ys.spring.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ys.spring.controller.UserController;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.ys.spring.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestSpring</span> </span>&#123;	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSpringXML</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">//1. 先创建Spring的容器对象</span></span><br><span class="line">		ApplicationContext ctx = </span><br><span class="line">				<span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"applicationContext.xml"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//2. 从Spring的容器中获取Bean对象</span></span><br><span class="line">		UserController uc = ctx.getBean(<span class="string">"userController"</span>, UserController<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"uc:"</span> + uc);</span><br><span class="line">		UserService us = ctx.getBean(<span class="string">"userServiceImpl"</span>,UserService<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"us:"</span> + us );</span><br><span class="line">		UserDao ud = ctx.getBean(<span class="string">"userDaoJdbcImpl"</span>,UserDao<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		System.out.println(<span class="string">"ud:"</span> + ud );</span><br><span class="line">		uc.listAllUsers();</span><br><span class="line">		<span class="comment">//【注意】id首字母要小写</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>JavaWeb</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>JavaWeb</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>解决Github连不上、ping不通的问题</title>
    <url>/2020/06/07/%E8%A7%A3%E5%86%B3Github%E8%BF%9E%E4%B8%8D%E4%B8%8A%E3%80%81ping%E4%B8%8D%E9%80%9A%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="修改host即可"><a href="#修改host即可" class="headerlink" title="修改host即可"></a>修改host即可</h1><p>Github连不上、ping不通、git clone特别慢等现象，通常是因为<code>github.global.ssl.fastly.net</code>域名被限制了。</p>
<p>因此，只要找到你当前线路最快的ip，修改一下host就能提速。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>一、在网站 <a href="https://www.ipaddress.com/" target="_blank" rel="noopener">https://www.ipaddress.com</a> 分别找这两个域名所对应的最快的ip地址</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">github.global.ssl.fastly.net</span><br><span class="line">github.com</span><br></pre></td></tr></table></figure></div>

<p>二、在<code>C:\Windows\System32\drivers\etc\hosts</code>里面做映射</p>
<p>注意要以<strong>自己查到</strong>的<strong>这两个域名所对应的最快IP地址</strong>为准。</p>
<p>在hosts文件最下方添加即可。</p>
<p>示例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">199.232.69.194 github.global.ssl.fastly.net</span><br><span class="line">140.82.114.4 github.com</span><br></pre></td></tr></table></figure></div>

<p>保存修改后，再登陆一般就木有问题了。</p>
]]></content>
      <categories>
        <category>Git&amp;Github</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Git&amp;Github</tag>
        <tag>bug解决</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis常见问题及扩展</title>
    <url>/2020/06/07/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E6%89%A9%E5%B1%95/</url>
    <content><![CDATA[<h1 id="缓存穿透、缓存雪崩、缓存击穿"><a href="#缓存穿透、缓存雪崩、缓存击穿" class="headerlink" title="缓存穿透、缓存雪崩、缓存击穿"></a>缓存穿透、缓存雪崩、缓存击穿</h1><p>1、缓存穿透是指查询一个一定不存在的数据。由于缓存命不中时会去查询数据库，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。</p>
<p>解决方案：</p>
<ul>
<li><p>是将空对象也缓存起来，并给它设置一个很短的过期时间，最长不超过5分钟</p>
</li>
<li><p>采用<strong>布隆过滤器</strong>，将所有可能存在的数据<strong>哈希</strong>到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力</p>
</li>
</ul>
<blockquote>
<p>布隆过滤器(bloom filter)： <a href="https://zhuanlan.zhihu.com/p/72378274" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/72378274</a> </p>
</blockquote>
<p>2、如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，就会造成缓存雪崩。</p>
<p>解决方案：</p>
<ul>
<li>尽量让失效的时间点不分布在同一个时间点</li>
</ul>
<p>3、缓存击穿，是指一个key非常热点，在不停的扛着大并发，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p>
<p>解决方案：</p>
<ul>
<li>可以设置key永不过期</li>
</ul>
<h1 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h1><p>主从复制中反客为主的自动版，如果主机Down掉，哨兵会从从机中选择一台作为主机，并将它设置为其他从机的主机，而且如果原来的主机再次启动的话也会成为从机。</p>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>字符串</td>
</tr>
<tr>
<td>list</td>
<td>可以重复的集合</td>
</tr>
<tr>
<td>set</td>
<td>不可以重复的集合</td>
</tr>
<tr>
<td>hash</td>
<td>类似于Map&lt;String,String&gt;</td>
</tr>
<tr>
<td>zset(sorted set）</td>
<td>带分数的set</td>
</tr>
</tbody></table>
<h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><p>1、RDB持久化：</p>
<ul>
<li><p>在指定的时间间隔内持久化</p>
</li>
<li><p>服务shutdown会自动持久化</p>
</li>
<li><p>输入bgsave也会持久化</p>
</li>
</ul>
<p>2、AOF :  以日志形式记录每个更新操作</p>
<ul>
<li><p>Redis重新启动时读取这个文件，重新执行新建、修改数据的命令恢复数据。</p>
</li>
<li><p>保存策略：</p>
<ul>
<li>推荐（并且也是默认）的措施为每秒持久化一次，这种策略可以兼顾速度和安全性。</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>比起RDB占用更多的磁盘空间</li>
<li>恢复备份速度要慢</li>
<li>每次读写都同步的话，有一定的性能压力</li>
<li>存在个别Bug，造成恢复不能</li>
</ul>
</li>
</ul>
<p><strong>选择策略：</strong></p>
<p>官方推荐：</p>
<p>如果对数据不敏感，可以选单独用RDB；不建议单独用AOF，因为可能出现Bug;如果只是做纯内存缓存，可以都不用。</p>
<h1 id="悲观锁、乐观锁"><a href="#悲观锁、乐观锁" class="headerlink" title="悲观锁、乐观锁"></a>悲观锁、乐观锁</h1><p>悲观锁：</p>
<p>执行操作前假设当前的操作肯定（或有很大几率）会被打断（悲观）。基于这个假设，我们在做操作前就会把相关资源锁定，不允许自己执行期间有其他操作干扰。</p>
<p>乐观锁：</p>
<p>执行操作前假设当前操作不会被打断（乐观）。基于这个假设，我们在做操作前不会锁定资源，万一发生了其他操作的干扰，那么本次操作将被放弃。</p>
<p><strong>Redis使用的就是乐观锁。</strong></p>
<h1 id="推荐参考："><a href="#推荐参考：" class="headerlink" title="推荐参考："></a>推荐参考：</h1><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/89620471" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/89620471</a> </p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>Redis</tag>
        <tag>布隆过滤器</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常用框架源码编译</title>
    <url>/2020/06/07/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B8%B8%E7%94%A8%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/</url>
    <content><![CDATA[<h1 id="源码编译通用步骤"><a href="#源码编译通用步骤" class="headerlink" title="源码编译通用步骤"></a>源码编译通用步骤</h1><h2 id="一、搭建编译环境"><a href="#一、搭建编译环境" class="headerlink" title="一、搭建编译环境"></a>一、搭建编译环境</h2><p>一般编译环境为Linux + JDK + Maven，有些框架可能需要别的环境支持，一般都会注明，在后面细说。以下教程都是基于Linux + JDK8环境编译。</p>
<ul>
<li><p>Linux和JDK环境这里不再赘述</p>
</li>
<li><p>MAVEN环境搭建</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1. 从apache网站拉取tar包并解压</span></span><br><span class="line">MVNTAR=$(curl http://maven.apache.org/download.cgi | grep -E <span class="string">"&gt;apache-maven-.*bin\.tar\.gz&lt;"</span> | sed <span class="string">'s/.*a href="\(.*\)".*/\1/g'</span>)</span><br><span class="line">curl <span class="variable">$MVNTAR</span> | tar zxC /opt/module</span><br><span class="line">mv /opt/module/$(basename <span class="variable">$MVNTAR</span> | cut -d - -f 1,2,3) /opt/module/maven</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 配置环境变量</span></span><br><span class="line">vim /etc/profile.d/my_env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加如下内容并保存退出</span></span><br><span class="line"><span class="built_in">export</span> M2_HOME=/opt/module/maven</span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME=/opt/module/maven</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;MAVEN_HOME&#125;</span>/bin:<span class="variable">$&#123;PATH&#125;</span></span><br></pre></td></tr></table></figure></div>

<p>完成后重启Xshell会话</p>
</li>
</ul>
<h2 id="二、下载源码"><a href="#二、下载源码" class="headerlink" title="二、下载源码"></a>二、下载源码</h2><p>下载你想要编译的框架的源码。一般源码下载有两种方式：</p>
<ol>
<li>想编译的版本已经发布release版，但是由于兼容性原因需要重新编译。这种情况直接从框架官网下载源码包并解压即可。</li>
<li>想测试框架还没发布的最新功能。此时从git托管服务器拉取最新源码，这时，我们需要git环境</li>
</ol>
<ul>
<li><p>Git环境搭建</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install -y epel-release</span><br><span class="line">sudo yum install -y git</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>到 <a href="https://git-wip-us.apache.org/repos/asf" target="_blank" rel="noopener">https://git-wip-us.apache.org/repos/asf</a> 查看想要编译的框架的git服务器，拉取源码(以Hive为例)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#新建源码存储目录</span></span><br><span class="line">mkdir -p /opt/software/<span class="built_in">source</span></span><br><span class="line"><span class="built_in">cd</span> /opt/software/<span class="built_in">source</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#拉取源码</span></span><br><span class="line">git <span class="built_in">clone</span> https://git-wip-us.apache.org/repos/asf/hive.git</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>进入拉取的源码目录，切换到自己想要的分支</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看所有本地和远程分支，这里也可以切换到之前版本的分支</span></span><br><span class="line"><span class="built_in">cd</span> hive</span><br><span class="line">git branch -a</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建本地分支同步远程分支</span></span><br><span class="line">git checkout -b 3.1 origin/branch-3.1</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>如果想切换到特定release的源码，使用git tag命令</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看所有tag</span></span><br><span class="line">git tag</span><br><span class="line"></span><br><span class="line"><span class="comment">#切换到想要的tag，这里以release-3.1.2为例</span></span><br><span class="line">git checkout rel/release-3.1.2</span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h2 id="三、查看编译说明"><a href="#三、查看编译说明" class="headerlink" title="三、查看编译说明"></a>三、查看编译说明</h2><p>一般来说，源码根目录都会有building.txt之类的文件作为编译说明，如果没有找到，也可以去官网查看编译说明。说明里一般都会注明前置要求，例如一些额外的编译环境要求等。</p>
<p>Hive没有前置要求，我们直接进入第四步</p>
<h2 id="四、对源码做必要修改"><a href="#四、对源码做必要修改" class="headerlink" title="四、对源码做必要修改"></a>四、对源码做必要修改</h2><p>一般我们只有在框架不兼容的情况下我们需要重新编译，不兼容一般是由于框架依赖版本不一致造成的，一般我们只需要编辑框架的pom.xml文件修改依赖版本即可。但是有些依赖新版本和旧版本不兼容，此时我们就需要对源码进行更多的修改。这些修改最好在IDE中进行。</p>
<p>Hive的guava版本和Hadoop 3.1.3的不兼容，我们修改其为27.0-jre</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">将</span><br><span class="line"><span class="tag">&lt;<span class="name">guava.version</span>&gt;</span>19.0<span class="tag">&lt;/<span class="name">guava.version</span>&gt;</span></span><br><span class="line">修改为</span><br><span class="line"><span class="tag">&lt;<span class="name">guava.version</span>&gt;</span>27.0-jre<span class="tag">&lt;/<span class="name">guava.version</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>这个依赖新老版本就不兼容，修改版本后我们需要对源码进行必要修改。详细修改步骤会在另外一篇教程中讲述</p>
<h2 id="五、编译"><a href="#五、编译" class="headerlink" title="五、编译"></a>五、编译</h2><p>准备工作全部做完，最后我们开始编译。一般的编译命令为：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn clean package -Pdist -DskipTests -Dmaven.javadoc.skip=<span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

<p>然后静待编译完成。这个过程会比较久，而且会从maven官网拉取大量jar包，所以要保证网络状况良好。</p>
<p>编译完成的Tar包的位置，各个框架都不一样，我们可以用下面的命令查找</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find ./ -name *.tar.gz</span><br></pre></td></tr></table></figure></div>

<h1 id="Hive编译"><a href="#Hive编译" class="headerlink" title="Hive编译"></a>Hive编译</h1><ul>
<li>拉取源码</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/software/<span class="built_in">source</span></span><br><span class="line">git <span class="built_in">clone</span> https://git-wip-us.apache.org/repos/asf/hive.git</span><br></pre></td></tr></table></figure></div>

<ul>
<li>修改pom.xml，将guava的版本改为如下版本</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;guava.version&gt;27.0-jre&lt;&#x2F;guava.version&gt;</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>修改以下文件中关于 com.google.common.util.concurrent.Futures#addCallback 的调用</p>
<ul>
<li>src\java\org\apache\hadoop\hive\llap\AsyncPbRpcProxy.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//173行</span></span><br><span class="line">Futures.addCallback(</span><br><span class="line">    future,</span><br><span class="line">    <span class="keyword">new</span> ResponseCallback&lt;U&gt;(</span><br><span class="line">        request.getCallback(), nodeId, <span class="keyword">this</span>)</span><br><span class="line">    ,executor);</span><br><span class="line"></span><br><span class="line"><span class="comment">//278行</span></span><br><span class="line">Futures.addCallback(requestManagerFuture, <span class="keyword">new</span> FutureCallback&lt;Void&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void result)</span> </span>&#123;</span><br><span class="line">        LOG.info(<span class="string">"RequestManager shutdown"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!(t <span class="keyword">instanceof</span> CancellationException)) &#123;</span><br><span class="line">            LOG.warn(<span class="string">"RequestManager shutdown with error"</span>, t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;, requestManagerExecutor);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\java\org\apache\hadoop\hive\llap\daemon\impl\AMReporter.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//162行</span></span><br><span class="line">Futures.addCallback(queueLookupFuture, <span class="keyword">new</span> FutureCallback&lt;Void&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void result)</span> </span>&#123;</span><br><span class="line">    LOG.info(<span class="string">"AMReporter QueueDrainer exited"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (t <span class="keyword">instanceof</span> CancellationException &amp;&amp; isShutdown.get()) &#123;</span><br><span class="line">      LOG.info(<span class="string">"AMReporter QueueDrainer exited as a result of a cancellation after shutdown"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG.error(<span class="string">"AMReporter QueueDrainer exited with error"</span>, t);</span><br><span class="line">      Thread.getDefaultUncaughtExceptionHandler().uncaughtException(Thread.currentThread(), t);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, queueLookupExecutor);</span><br><span class="line"></span><br><span class="line"><span class="comment">//266行</span></span><br><span class="line">Futures.addCallback(future, <span class="keyword">new</span> FutureCallback&lt;Void&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void result)</span> </span>&#123;</span><br><span class="line">    LOG.info(<span class="string">"Sent taskKilled for &#123;&#125;"</span>, taskAttemptId);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable t)</span> </span>&#123;</span><br><span class="line">    LOG.warn(<span class="string">"Failed to send taskKilled for &#123;&#125;. The attempt will likely time out."</span>,</span><br><span class="line">        taskAttemptId);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, executor);</span><br><span class="line"></span><br><span class="line"><span class="comment">//331行</span></span><br><span class="line">Futures.addCallback(future, <span class="keyword">new</span> FutureCallback&lt;Void&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void result)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Nothing to do.</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable t)</span> </span>&#123;</span><br><span class="line">    QueryIdentifier currentQueryIdentifier = amNodeInfo.getQueryIdentifier();</span><br><span class="line">    amNodeInfo.setAmFailed(<span class="keyword">true</span>);</span><br><span class="line">    LOG.warn(<span class="string">"Heartbeat failed to AM &#123;&#125;. Marking query as failed. query=&#123;&#125;"</span>,</span><br><span class="line">      amNodeInfo.amNodeId, currentQueryIdentifier, t);</span><br><span class="line">    queryFailedHandler.queryFailed(currentQueryIdentifier);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, executor);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\java\org\apache\hadoop\hive\llap\daemon\impl\LlapTaskReporter.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//131行</span></span><br><span class="line">Futures.addCallback(future, <span class="keyword">new</span> HeartbeatCallback(errorReporter), heartbeatExecutor);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\java\org\apache\hadoop\hive\llap\daemon\impl\TaskExecutorService.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//178行</span></span><br><span class="line">Futures.addCallback(future, <span class="keyword">new</span> WaitQueueWorkerCallback(), executionCompletionExecutorServiceRaw);</span><br><span class="line"></span><br><span class="line"><span class="comment">//692行</span></span><br><span class="line">Futures.addCallback(future, wrappedCallback, executionCompletionExecutorService);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\java\org\apache\hadoop\hive\llap\tezplugins\LlapTaskSchedulerService.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//747行</span></span><br><span class="line">Futures.addCallback(nodeEnablerFuture, <span class="keyword">new</span> LoggingFutureCallback(<span class="string">"NodeEnablerThread"</span>, LOG),nodeEnabledExecutor);</span><br><span class="line"></span><br><span class="line"><span class="comment">//751行</span></span><br><span class="line">Futures.addCallback(delayedTaskSchedulerFuture,</span><br><span class="line">    <span class="keyword">new</span> LoggingFutureCallback(<span class="string">"DelayedTaskSchedulerThread"</span>, LOG),delayedTaskSchedulerExecutor);</span><br><span class="line"></span><br><span class="line"><span class="comment">//755行</span></span><br><span class="line">Futures.addCallback(schedulerFuture, <span class="keyword">new</span> LoggingFutureCallback(<span class="string">"SchedulerThread"</span>, LOG),schedulerExecutor);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\java\org\apache\hadoop\hive\ql\exec\tez\WorkloadManager.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1089行</span></span><br><span class="line">Futures.addCallback(future, FATAL_ERROR_CALLBACK, timeoutPool);</span><br><span class="line"></span><br><span class="line"><span class="comment">//1923行</span></span><br><span class="line">Futures.addCallback(getFuture, <span class="keyword">this</span>,timeoutPool);</span><br><span class="line"></span><br><span class="line"><span class="comment">//1977行</span></span><br><span class="line">Futures.addCallback(waitFuture, <span class="keyword">this</span>, timeoutPool);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>src\test\org\apache\hadoop\hive\ql\exec\tez\SampleTezSessionState.java</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//121行</span></span><br><span class="line">Futures.addCallback(waitForAmRegFuture, <span class="keyword">new</span> FutureCallback&lt;Boolean&gt;() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Boolean result)</span> </span>&#123;</span><br><span class="line">    future.set(session);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Throwable t)</span> </span>&#123;</span><br><span class="line">    future.setException(t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;,timeoutPool);</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>编译</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn clean package -Pdist -DskipTests -Dmaven.javadoc.skip=<span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

<h1 id="Tez编译"><a href="#Tez编译" class="headerlink" title="Tez编译"></a>Tez编译</h1><ul>
<li><p>拉取源码</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/software/<span class="built_in">source</span></span><br><span class="line">git <span class="built_in">clone</span> https://git-wip-us.apache.org/repos/asf/tez.git</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>安装Tez必要环境</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install -y protobuf protobuf-static protobuf-devel</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>编译</p>
<p>查看编译说明，按照编译说明用下列命令编译</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> tez</span><br><span class="line">mvn clean package -Dhadoop.version=3.1.3 -Phadoop28 -P\!hadoop27 -DskipTests -Dmaven.javadoc.skip=<span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

</li>
</ul>
<h1 id="Phoenix编译"><a href="#Phoenix编译" class="headerlink" title="Phoenix编译"></a>Phoenix编译</h1><ul>
<li>拉取源码</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/software/<span class="built_in">source</span></span><br><span class="line">git <span class="built_in">clone</span> https://git-wip-us.apache.org/repos/asf/phoenix.git</span><br></pre></td></tr></table></figure></div>

<ul>
<li>编译</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> phoenix</span><br><span class="line">mvn clean package -DskipTests -Dhbase.profile=2.2 -Dhbase.version=2.2.4</span><br></pre></td></tr></table></figure></div>

<h1 id="Spark编译"><a href="#Spark编译" class="headerlink" title="Spark编译"></a>Spark编译</h1><ul>
<li>去spark官网下载源码，解压到/opt/software/source</li>
<li>进入该目录，编译</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./dev/make-distribution.sh --name without-hive --tgz -Pyarn -Phadoop-3.1 -Dhadoop.version=3.1.3 -Pparquet-provided -Porc-provided -Phadoop-provided</span><br></pre></td></tr></table></figure></div>



]]></content>
      <categories>
        <category>大数据</category>
        <category>源码编译</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>hive</tag>
        <tag>spark</tag>
        <tag>源码编译</tag>
        <tag>phoenix</tag>
        <tag>tez</tag>
      </tags>
  </entry>
  <entry>
    <title>HiveSQL之常用查询函数case</title>
    <url>/2020/05/26/HiveSQL%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0case/</url>
    <content><![CDATA[<h1 id="关键词：CASE-WHEN-THEN-ELSE-END"><a href="#关键词：CASE-WHEN-THEN-ELSE-END" class="headerlink" title="关键词：CASE  WHEN  THEN  ELSE  END"></a>关键词：CASE  WHEN  THEN  ELSE  END</h1><h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><table>
<thead>
<tr>
<th>name</th>
<th>dept_id</th>
<th>sex</th>
</tr>
</thead>
<tbody><tr>
<td>悟空</td>
<td>A</td>
<td>男</td>
</tr>
<tr>
<td>大海</td>
<td>A</td>
<td>男</td>
</tr>
<tr>
<td>宋宋</td>
<td>B</td>
<td>男</td>
</tr>
<tr>
<td>凤姐</td>
<td>A</td>
<td>女</td>
</tr>
<tr>
<td>婷姐</td>
<td>B</td>
<td>女</td>
</tr>
<tr>
<td>婷婷</td>
<td>B</td>
<td>女</td>
</tr>
</tbody></table>
<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>求出不同部门男女各多少人。结果如下：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A   2    1</span><br><span class="line">B   1    2</span><br></pre></td></tr></table></figure></div>

<h1 id="创建本地emp-sex-txt，导入数据"><a href="#创建本地emp-sex-txt，导入数据" class="headerlink" title="创建本地emp_sex.txt，导入数据"></a>创建本地emp_sex.txt，导入数据</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 datas]$ vim emp_sex.txt</span><br><span class="line">悟空	A	男</span><br><span class="line">大海	A	男</span><br><span class="line">宋宋	B	男</span><br><span class="line">凤姐	A	女</span><br><span class="line">婷姐	B	女</span><br><span class="line">婷婷	B	女</span><br></pre></td></tr></table></figure></div>

<h1 id="创建hive表并导入数据"><a href="#创建hive表并导入数据" class="headerlink" title="创建hive表并导入数据"></a>创建hive表并导入数据</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp_sex(</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>, </span><br><span class="line">dept_id <span class="keyword">string</span>, </span><br><span class="line">sex <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">"\t"</span>;</span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/module/datas/emp_sex.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> emp_sex;</span><br></pre></td></tr></table></figure></div>

<h1 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">  dept_id,</span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">case</span> sex <span class="keyword">when</span> <span class="string">'男'</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) male_count,</span><br><span class="line">  <span class="keyword">sum</span>(<span class="keyword">case</span> sex <span class="keyword">when</span> <span class="string">'女'</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) female_count</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">  emp_sex</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">  dept_id;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>首先注意CASE  WHEN  THEN  ELSE  END的缺一不可</li>
<li><strong>也要注意<code>sum</code>函数的用法，<code>sum(条件)</code>是经常会用到的方法！！！</strong><ul>
<li><strong>比如<code>sum(if XXX)</code>就常在HiveSQL里面使用。</strong></li>
<li>例如：<code>sum(if(dt=&#39;2020-05-27&#39;, order_count,0 )) order_count</code>，本质其实是一样的。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>hive</tag>
        <tag>SQL</tag>
        <tag>hivesql</tag>
      </tags>
  </entry>
  <entry>
    <title>一段有趣的spark_aggregate代码</title>
    <url>/2020/05/26/%E4%B8%80%E6%AE%B5%E6%9C%89%E8%B6%A3%E7%9A%84spark-aggregate%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>看到了一段非常有趣的关于spark中aggregate算子的代码，需要很细心才能给出正确答案。</p>
<p>在这里和大家分享。</p>
<h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TrySpark</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"aggTest"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">Array</span>(<span class="string">"12"</span>, <span class="string">"234"</span>, <span class="string">"345"</span>, <span class="string">"4567"</span>), <span class="number">2</span>)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">val</span> str: <span class="type">String</span> = rdd.aggregate(<span class="string">"0"</span>)((a, b) =&gt; <span class="type">Math</span>.max(a.length, b.length).toString, (x, y) =&gt; x + y)</span><br><span class="line">    println(str)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">val</span> str1: <span class="type">String</span> = rdd.aggregate(<span class="string">""</span>)((a, b) =&gt; <span class="type">Math</span>.min(a.length, b.length).toString, (x, y) =&gt; x + y)</span><br><span class="line">    println(str1)</span><br><span class="line">      </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="前方高能"><a href="#前方高能" class="headerlink" title="前方高能"></a>前方高能</h1><p>输出结果1</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">043</span><br><span class="line">11</span><br></pre></td></tr></table></figure></div>

<p>输出结果2</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">034</span><br><span class="line">11</span><br></pre></td></tr></table></figure></div>

<p>惊不惊喜，刺不刺激（手动狗头）。</p>
<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><p>aggregate：行动算子，意为【聚合】</p>
<p>函数签名</p>
<blockquote>
<p>def aggregate<code>[U: ClassTag]</code>(zeroValue: U)(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U): U</p>
</blockquote>
<p>函数说明</p>
<blockquote>
<p>分区的数据通过<strong>初始值</strong>和<strong>分区内</strong>的数据进行聚合，然后再和<strong>初始值</strong>进行<strong>分区间</strong>的数据聚合</p>
<ul>
<li>第一个括号内的参数为初始值</li>
<li>第二个括号中<ul>
<li>第一个参数为分区内要执行的函数，初始值和分区内元素依次<strong>聚合</strong></li>
<li>第二个参数为分区间要执行的函数，初始值和分区间元素依次<strong>聚合</strong></li>
</ul>
</li>
</ul>
</blockquote>
<p>代码详解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">Array</span>(<span class="string">"12"</span>, <span class="string">"234"</span>, <span class="string">"345"</span>, <span class="string">"4567"</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">rdd.aggregate(<span class="string">"0"</span>)((a, b) =&gt; <span class="type">Math</span>.max(a.length, b.length).toString, (x, y) =&gt; x + y)</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>首先注意rdd是两个分区，”12”, “234”一个分区，”345”, “4567”一个分区</p>
</li>
<li><p>执行分区内函数<code>Math.max(a.length, b.length).toString</code></p>
<ul>
<li>分区一<ul>
<li>“0”，“12”执行函数，输出“2”，【注意：函数后面有个toString】<strong>【聚合：上一步输出作为下一步输入】</strong></li>
<li>“2”，”234”执行函数，最终输出“3”</li>
</ul>
</li>
<li>分区二<ul>
<li>“0”，“345” =&gt; “3”</li>
<li>“3”，”4567” =&gt; 最终 “4”</li>
</ul>
</li>
</ul>
</li>
<li><p>执行分区间函数<code>(x, y) =&gt; x + y</code>，其实就是一个字符串拼接，但是因为<strong>分区</strong>的原因</p>
<ul>
<li>不一定哪个分区先执行完，所以会出现两种情况的字符串拼接：“034” or “043”</li>
</ul>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">rdd.aggregate(<span class="string">""</span>)((a, b) =&gt; <span class="type">Math</span>.min(a.length, b.length).toString, (x, y) =&gt; x + y)</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>rdd是两个分区，”12”, “234”一个分区，”345”, “4567”一个分区</p>
</li>
<li><p>执行分区内函数<code>Math.min(a.length, b.length).toString</code></p>
<ul>
<li>分区一<ul>
<li>“”，“12”执行函数，输出“0”，【注意：函数后面有个toString】<strong>【聚合：上一步输出作为下一步输入】</strong></li>
<li>“0”，”234”执行函数，最终输出“1”，<strong>【注意：“0”的长度是1】</strong></li>
</ul>
</li>
<li>分区二<ul>
<li>“”，“345” =&gt; “0”</li>
<li>“0”，”4567” =&gt; 最终 “1”</li>
</ul>
</li>
</ul>
</li>
<li><p>执行分区间函数<code>(x, y) =&gt; x + y</code>，字符串拼接，“”+“1”+“1” =&gt; “11”</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>spark常用算子join</title>
    <url>/2020/05/25/spark%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90join/</url>
    <content><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>JOIN函数签名</p>
<blockquote>
<p>def join<code>[W]</code>(other: RDD[(K, W)]): RDD[(K, (V, W))]</p>
</blockquote>
<p>函数说明</p>
<ul>
<li>spark RDD <strong>转换算子</strong></li>
<li>(对照函数签名)在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素连接在一起的(K,(V,W))的RDD</li>
</ul>
<h1 id="重点示例"><a href="#重点示例" class="headerlink" title="重点示例"></a>重点示例</h1><ul>
<li>join</li>
<li>leftOuterJoin</li>
<li>rightOuterJoin</li>
<li>fullOuterJoin</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JoinTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.创建SparkConf</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"JoinTest"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.创建SparkContext</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.创建两个RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd1: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = sc.makeRDD(<span class="type">Array</span>((<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"a"</span>, <span class="number">2</span>), (<span class="string">"b"</span>, <span class="number">1</span>), (<span class="string">"c"</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = sc.makeRDD(<span class="type">Array</span>((<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">2</span>), (<span class="string">"d"</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4.测试各种JOIN【 注意返回值 】</span></span><br><span class="line">    <span class="keyword">val</span> result1: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = rdd1.join(rdd2)</span><br><span class="line">    <span class="keyword">val</span> result2: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Option</span>[<span class="type">Int</span>]))] = rdd1.leftOuterJoin(rdd2)</span><br><span class="line">    <span class="keyword">val</span> result3: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Option</span>[<span class="type">Int</span>], <span class="type">Int</span>))] = rdd1.rightOuterJoin(rdd2)</span><br><span class="line">    <span class="keyword">val</span> result4: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Option</span>[<span class="type">Int</span>], <span class="type">Option</span>[<span class="type">Int</span>]))] = rdd1.fullOuterJoin(rdd2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5.打印</span></span><br><span class="line">    result1.foreach(println)</span><br><span class="line">    println(<span class="string">"======================&gt;&gt;&gt;"</span>)</span><br><span class="line">    result2.foreach(println)</span><br><span class="line">    println(<span class="string">"======================&gt;&gt;&gt;"</span>)</span><br><span class="line">    result3.foreach(println)</span><br><span class="line">    println(<span class="string">"======================&gt;&gt;&gt;"</span>)</span><br><span class="line">    result4.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6.关闭连接</span></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>输出结果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(b,(1,1))</span><br><span class="line">(a,(1,1))</span><br><span class="line">(a,(2,1))</span><br><span class="line">(b,(1,2))</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt;</span><br><span class="line">(c,(1,None))</span><br><span class="line">(a,(1,Some(1)))</span><br><span class="line">(a,(2,Some(1)))</span><br><span class="line">(b,(1,Some(1)))</span><br><span class="line">(b,(1,Some(2)))</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt;</span><br><span class="line">(d,(None,1))</span><br><span class="line">(a,(Some(1),1))</span><br><span class="line">(a,(Some(2),1))</span><br><span class="line">(b,(Some(1),1))</span><br><span class="line">(b,(Some(1),2))</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt;</span><br><span class="line">(d,(None,Some(1)))</span><br><span class="line">(c,(Some(1),None))</span><br><span class="line">(a,(Some(1),Some(1)))</span><br><span class="line">(a,(Some(2),Some(1)))</span><br><span class="line">(b,(Some(1),Some(1)))</span><br><span class="line">(b,(Some(1),Some(2)))</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>scala样例类转换成为JSON字符串</title>
    <url>/2020/05/25/scala%E6%A0%B7%E4%BE%8B%E7%B1%BB%E8%BD%AC%E6%8D%A2%E6%88%90%E4%B8%BAJSON%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<h1 id="JSON常用方法"><a href="#JSON常用方法" class="headerlink" title="JSON常用方法"></a>JSON常用方法</h1><p>Java中并没有内置JSON的解析，因此使用JSON需要借助第三方类库。</p>
<p>几个常用的 JSON 解析类库：</p>
<ul>
<li><a href="https://github.com/google/gson" target="_blank" rel="noopener">Gson</a>: 谷歌开发的 JSON 库，功能十分全面。</li>
<li><a href="https://github.com/alibaba/fastjson" target="_blank" rel="noopener">FastJson</a>: 阿里巴巴开发的 JSON 库，性能十分优秀。</li>
<li><a href="https://github.com/FasterXML/jackson" target="_blank" rel="noopener">Jackson</a>: 社区十分活跃且更新速度很快。</li>
</ul>
<p>maven依赖：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.47<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>JSON 对象与字符串的相互转化</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">作用</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>JSON.parseObject()</code></td>
<td align="left">从字符串解析 JSON 对象</td>
</tr>
<tr>
<td align="left">JSON.parseArray()</td>
<td align="left">从字符串解析 JSON 数组</td>
</tr>
<tr>
<td align="left"><code>JSON.toJSONString(obj/array)</code></td>
<td align="left">将 JSON 对象或 JSON 数组转化为字符串</td>
</tr>
</tbody></table>
<p>示例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JSONTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//从字符串解析JSON对象</span></span><br><span class="line">        JSONObject obj = JSON.parseObject(<span class="string">"&#123;\"name\":\"ys\"&#125;"</span>);</span><br><span class="line">        System.out.println(obj); <span class="comment">//&#123;"name":"ys"&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//将JSON对象转化为字符串</span></span><br><span class="line">        String objStr = JSON.toJSONString(obj);</span><br><span class="line">        System.out.println(objStr); <span class="comment">//&#123;"name":"ys"&#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="Scala样例类转换成JSON字符串"><a href="#Scala样例类转换成JSON字符串" class="headerlink" title="Scala样例类转换成JSON字符串"></a>Scala样例类转换成JSON字符串</h1><p>将<strong>Scala样例类</strong>转换成为JSON字符串，JSON.toJSONString(obj)会失效，所以使用如下方法：</p>
<p>maven依赖（json4s —&gt; json for scala）：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.json4s<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>json4s-native_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.json4s.native.<span class="type">Serialization</span></span><br><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> formats=org.json4s.<span class="type">DefaultFormats</span> <span class="comment">//隐式转换</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> orderInfoJson: <span class="type">String</span> = <span class="type">Serialization</span>.write(orderInfo)</span><br></pre></td></tr></table></figure></div>

<p>示例</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.bean.<span class="type">UserInfo</span></span><br><span class="line"><span class="keyword">import</span> org.json4s.native.<span class="type">Serialization</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JsonStrTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userInfo = <span class="type">UserInfo</span>(<span class="string">"1001"</span>,<span class="string">"name1"</span>,<span class="string">"5"</span>,<span class="string">"2020-05-25"</span>,<span class="string">"male"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> formats = org.json4s.<span class="type">DefaultFormats</span></span><br><span class="line">      </span><br><span class="line">    <span class="comment">//println(JSON.toJSONString(userInfo)) //报错</span></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">val</span> str = <span class="type">Serialization</span>.write(userInfo)</span><br><span class="line">    println(str)</span><br><span class="line">    <span class="comment">// &#123;"id":"1001","login_name":"name1","user_level":"5","birthday":"2020-05-25","gender":"male"&#125;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">val</span> nObject: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(str)  <span class="comment">//正常解析</span></span><br><span class="line">    println(nObject)</span><br><span class="line">    <span class="comment">// &#123;"birthday":"2020-05-25","login_name":"name1","gender":"male","user_level":"5","id":"1001"&#125;</span></span><br><span class="line">        </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>UserInfo.scala</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserInfo</span>(<span class="params">id:<span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    login_name:<span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    user_level:<span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    birthday:<span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    gender:<span class="type">String</span></span>)</span></span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>scala</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>scala</tag>
      </tags>
  </entry>
  <entry>
    <title>[精]ElasticSearch总结与思考</title>
    <url>/2020/05/18/ElasticSearch%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li><p>Elasticsearch，基于Lucene，隐藏复杂性，提供简单易用的RestfulAPI接口、JavaAPI接口（还有其他语言的API接口）。</p>
</li>
<li><p>Elasticsearch是一个实时分布式搜索和分析引擎。它用于全文搜索、结构化搜索、分析。</p>
<ul>
<li>全文检索：将非结构化数据中的一部分信息提取出来,重新组织,使其变得有一定结构,然后对此有一定结构的数据进行搜索,从而达到搜索相对较快的目的。</li>
<li>倒排索引：简单举例：根据关键词找包含其的文章（正常思维：在文章中找关键词）。</li>
<li>结构化检索：我想搜索商品分类为日化用品的商品都有哪些，select * from products where category_id=’日化用品’。</li>
<li>数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些。</li>
</ul>
</li>
<li><p>可以作为一个大型分布式集群（数百台服务器）技术，处理<strong>PB级</strong>数据，服务大公司；也可以运行在单机上，服务小公司.</p>
</li>
</ul>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul>
<li>维基百科，类似百度百科，牙膏，牙膏的维基百科，全文检索，高亮，搜索推荐。</li>
<li>The Guardian（国外新闻网站），类似搜狐新闻，用户行为日志（点击，浏览，收藏，评论）+ 社交网络数据（对某某新闻的相关看法），数据分析，给到每篇新闻文章的作者，让他知道他的文章的公众反馈（好，坏，热门，垃圾，鄙视，崇拜）。</li>
<li>Stack Overflow（国外的程序异常讨论论坛），IT问题，程序的报错，提交上去，有人会跟你讨论和回答，全文检索，搜索相关问题和答案，程序报错了，就会将报错信息粘贴到里面去，搜索有没有对应的答案。</li>
<li>GitHub（开源代码管理），搜索上千亿行代码。</li>
<li>国内：站内搜索（电商，招聘，门户，等等），IT系统搜索（OA，CRM，ERP，等等），数据分析（ES热门的一个使用场景）。</li>
</ul>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><p><strong>ElasticSearch与数据库类比</strong></p>
<table>
<thead>
<tr>
<th>关系型数据库（如Mysql）</th>
<th>非关系型数据库（Elasticsearch）</th>
</tr>
</thead>
<tbody><tr>
<td>数据库Database</td>
<td>索引Index</td>
</tr>
<tr>
<td>表Table</td>
<td>类型Type(<strong>6.0版本之后在一个索引下面只能有一个，7.0版本之后取消了Type</strong>)</td>
</tr>
<tr>
<td>数据行Row</td>
<td>文档Document(JSON格式)</td>
</tr>
<tr>
<td>数据列Column</td>
<td>字段Field</td>
</tr>
<tr>
<td>约束 Schema</td>
<td>映射Mapping</td>
</tr>
</tbody></table>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>1）解压elasticsearch-6.6.0.tar.gz到/opt/module目录下</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 software]$ tar -zxvf elasticsearch-6.6.0.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure></div>

<p>2）在/opt/module/elasticsearch-6.6.0路径下创建data文件夹</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 elasticsearch-6.6.0]$ mkdir data</span><br></pre></td></tr></table></figure></div>

<p>3）修改配置文件/opt/module/elasticsearch-6.6.0/config/elasticsearch.yml</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 config]$ pwd</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;elasticsearch-6.6.0&#x2F;config</span><br><span class="line">[ys@hadoop102 config]$ vim elasticsearch.yml</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-----------------------Cluster-----------------------</span></span><br><span class="line"><span class="attr">cluster.name:</span> <span class="string">my-application</span></span><br><span class="line"><span class="comment">#-----------------------Node-----------------------</span></span><br><span class="line"><span class="attr">node.name:</span> <span class="string">node-102</span></span><br><span class="line"><span class="comment">#-----------------------Paths-----------------------</span></span><br><span class="line"><span class="attr">path.data:</span> <span class="string">/opt/module/elasticsearch-6.6.0/data</span></span><br><span class="line"><span class="attr">path.logs:</span> <span class="string">/opt/module/elasticsearch-6.6.0/logs</span></span><br><span class="line"><span class="comment">#-----------------------Memory-----------------------</span></span><br><span class="line"><span class="attr">bootstrap.memory_lock:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">bootstrap.system_call_filter:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment">#-----------------------Network-----------------------</span></span><br><span class="line"><span class="attr">network.host:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.102</span> </span><br><span class="line"><span class="comment">#-----------------------Discovery-----------------------</span></span><br><span class="line"><span class="attr">discovery.zen.ping.unicast.hosts:</span> <span class="string">["192.168.9.102"]</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>（1）cluster.name</p>
<p>如果要配置集群需要两个节点上的elasticsearch配置的cluster.name相同，都启动可以自动组成集群，这里如果不改cluster.name则默认是cluster.name=my-application，</p>
<p>（2）nodename随意取但是集群内的各节点不能相同</p>
<p>（3）修改后的每行前面不能有空格，修改后的“：”后面必须有一个空格</p>
</blockquote>
<p>4）分发至hadoop103以及hadoop104，分发之后修改：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 module]$ xsync elasticsearch-6.6.0&#x2F;</span><br><span class="line"></span><br><span class="line">node.name: node-103</span><br><span class="line">network.host: 192.168.9.103</span><br><span class="line"></span><br><span class="line">node.name: node-104</span><br><span class="line">network.host: 192.168.9.104</span><br></pre></td></tr></table></figure></div>

<p>5）此时启动会报错，要配置linux系统环境（参考：<a href="http://blog.csdn.net/satiling/article/details/59697916）" target="_blank" rel="noopener">http://blog.csdn.net/satiling/article/details/59697916）</a></p>
<p>6）启动Elasticsearch</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 elasticsearch-6.6.0]$ bin&#x2F;elasticsearch</span><br></pre></td></tr></table></figure></div>

<p>7）测试elasticsearch</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 elasticsearch-6.6.0]$ curl http:&#x2F;&#x2F;hadoop102:9200</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"> &quot;name&quot; : &quot;node-102&quot;,</span><br><span class="line"> &quot;cluster_name&quot; : &quot;my-application&quot;,</span><br><span class="line"> &quot;cluster_uuid&quot; : &quot;KOpuhMgVRzW_9OTjMsHf2Q&quot;,</span><br><span class="line"> &quot;version&quot; : &#123;</span><br><span class="line">  &quot;number&quot; : &quot;6.6.0&quot;,</span><br><span class="line">  &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">  &quot;build_type&quot; : &quot;tar&quot;,</span><br><span class="line">  &quot;build_hash&quot; : &quot;eb782d0&quot;,</span><br><span class="line">  &quot;build_date&quot; : &quot;2018-06-29T21:59:26.107521Z&quot;,</span><br><span class="line">  &quot;build_snapshot&quot; : false,</span><br><span class="line">  &quot;lucene_version&quot; : &quot;7.3.1&quot;,</span><br><span class="line">  &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,</span><br><span class="line">  &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;</span><br><span class="line"> &#125;,</span><br><span class="line"> &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>8）停止集群</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -9 进程号</span><br></pre></td></tr></table></figure></div>

<p>9）群起脚本</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 bin]$ vi es.sh</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">es_home=/opt/module/elasticsearch</span><br><span class="line">case $1  in</span><br><span class="line"> "start") &#123;</span><br><span class="line"> for i in hadoop102 hadoop103 hadoop104</span><br><span class="line"> do</span><br><span class="line">  echo "==============$i=============="</span><br><span class="line">  ssh $i  "source /etc/profile;$&#123;es_home&#125;/bin/elasticsearch &gt;/dev/null 2&gt;&amp;1 &amp;"</span><br><span class="line"> done</span><br><span class="line">&#125;;;</span><br><span class="line">"stop") &#123;</span><br><span class="line"> for i in hadoop102 hadoop103 hadoop104</span><br><span class="line"> do</span><br><span class="line">  echo "==============$i=============="</span><br><span class="line">  ssh $i "ps -ef|grep $es_home |grep -v grep|awk '&#123;print \$2&#125;'|xargs kill" &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"> done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></div>

<h1 id="可视化工具Kibana"><a href="#可视化工具Kibana" class="headerlink" title="可视化工具Kibana"></a>可视化工具Kibana</h1><p>Kibana的安装</p>
<p>1、将kibana压缩包上传到虚拟机指定目录</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 software]$ tar -zxvf kibana-6.6.0-linux-x86_64.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure></div>

<p>2、修改相关配置，连接Elasticsearch</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 kibana]$ vim config&#x2F;kibana.yml</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Kibana is served by a back end server. This setting specifies the port to use.</span></span><br><span class="line"><span class="attr">server.port:</span> <span class="number">5601</span></span><br><span class="line"><span class="comment"># Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.</span></span><br><span class="line"><span class="comment"># The default is 'localhost', which usually means remote machines will not be able to connect.</span></span><br><span class="line"><span class="comment"># To allow connections from remote users, set this parameter to a non-loopback address.</span></span><br><span class="line"><span class="attr">server.host:</span> <span class="string">"192.168.9.102"</span></span><br><span class="line"><span class="string">...</span> <span class="string">...</span></span><br><span class="line"><span class="string">...</span> <span class="string">...</span></span><br><span class="line"><span class="comment"># The URL of the Elasticsearch instance to use for all your queries.</span></span><br><span class="line"><span class="attr">elasticsearch.url:</span> <span class="string">"http://192.168.9.102:9200"</span></span><br></pre></td></tr></table></figure></div>

<p>3、启动Kibana</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 kibana]$ bin&#x2F;kibana</span><br></pre></td></tr></table></figure></div>

<p>4、浏览器访问：<code>hadoop102:5601</code> 即可操作</p>
<h1 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h1><h2 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h2><h3 id="核心数据类型"><a href="#核心数据类型" class="headerlink" title="核心数据类型"></a>核心数据类型</h3><ul>
<li><p>字符串型：text(分词)、keyword(不分词)</p>
</li>
<li><p>数值型：long、integer、short、byte、double、float、half_float、scaled_float</p>
</li>
<li><p>日期类型：date</p>
</li>
</ul>
<h3 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h3><p>1、手动创建</p>
<ul>
<li>创建mapping</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_doc&quot;:&#123;</span><br><span class="line">      &quot;properties&quot;:&#123;</span><br><span class="line">        &quot;username&quot;:&#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;, </span><br><span class="line">          &quot;fields&quot;: &#123;</span><br><span class="line">            &quot;pinyin&quot;:&#123;</span><br><span class="line">              &quot;type&quot;: &quot;text&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>创建文档</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index1&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;username&quot;:&quot;haha heihei&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>查询</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET my_index1&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;username.pinyin&quot;: &quot;haha&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>2、自动创建</p>
<ul>
<li>直接插入文档</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;test_index&#x2F;_doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;username&quot;:&quot;alfred&quot;,</span><br><span class="line">  &quot;age&quot;:1,</span><br><span class="line">  &quot;birth&quot;:&quot;1991-12-15&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>查看mapping</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;test_index&#x2F;doc&#x2F;_mapping</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;test_index&quot;: &#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;age&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;birth&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;username&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">              &quot;keyword&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                &quot;ignore_above&quot;: 256</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="IK分词器"><a href="#IK分词器" class="headerlink" title="IK分词器"></a>IK分词器</h3><p>分词器主要应用在中文上，在ES中字符串类型有keyword和text两种。keyword默认不进行分词，而text是将每一个汉字拆开称为独立的词，这两种都是不适用于生产环境。</p>
<ul>
<li>keyword分词</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;keyword&quot;:&quot;我是程序员&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>结果展示（会报错error）</p>
<ul>
<li>text类型的分词</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot;我是程序员&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>结果展示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;我&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 0,</span><br><span class="line">      &quot;end_offset&quot;: 1,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;是&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 1,</span><br><span class="line">      &quot;end_offset&quot;: 2,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;程&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 2,</span><br><span class="line">      &quot;end_offset&quot;: 3,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;序&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 3,</span><br><span class="line">      &quot;end_offset&quot;: 4,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;员&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 4,</span><br><span class="line">      &quot;end_offset&quot;: 5,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 4</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="IK分词器安装"><a href="#IK分词器安装" class="headerlink" title="IK分词器安装"></a>IK分词器安装</h4><p>1）下载与安装的ES相对应的版本</p>
<p>2）解压elasticsearch-analysis-ik-6.6.0.zip，将解压后的IK文件夹拷贝到ES安装目录下的plugins目录下，并重命名文件夹为ik（什么名称都OK）</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 plugins]$ mkdir ik</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 software]$ unzip elasticsearch-analysis-ik-6.6.0.zip -d &#x2F;opt&#x2F;module&#x2F;elasticsearch-6.6.0&#x2F;plugins&#x2F;ik&#x2F;</span><br></pre></td></tr></table></figure></div>

<p>3）分发分词器目录</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 elasticsearch-6.6.0]$ xsync plugins&#x2F;</span><br></pre></td></tr></table></figure></div>

<p>4）重新启动Elasticsearch，即可加载IK分词器</p>
<p>5）IK测试</p>
<ul>
<li>ik_smart ：最少切分</li>
<li>ik_max_word：最细粒度划分</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class="line">  &quot;text&quot;:&quot;我是程序员&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;tokens&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;token&quot; : &quot;我&quot;,</span><br><span class="line">            &quot;start_offset&quot; : 0,</span><br><span class="line">            &quot;end_offset&quot; : 1,</span><br><span class="line">            &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">            &quot;position&quot; : 0</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;token&quot; : &quot;是&quot;,</span><br><span class="line">            &quot;start_offset&quot; : 1,</span><br><span class="line">            &quot;end_offset&quot; : 2,</span><br><span class="line">            &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">            &quot;position&quot; : 1</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;token&quot; : &quot;程序员&quot;,</span><br><span class="line">            &quot;start_offset&quot; : 2,</span><br><span class="line">            &quot;end_offset&quot; : 5,</span><br><span class="line">            &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">            &quot;position&quot; : 2</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>ik_max_word</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;我&quot;,&quot;是&quot;,&quot;程序员&quot;,&quot;程序&quot;,&quot;员&quot;</span><br></pre></td></tr></table></figure></div>

<h3 id="检索文档【重点】"><a href="#检索文档【重点】" class="headerlink" title="检索文档【重点】"></a>检索文档【重点】</h3><p>向Elasticsearch增加数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;atguigu&#x2F;doc&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; : &quot;John&quot;,</span><br><span class="line">    &quot;last_name&quot; :  &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot; :        25,</span><br><span class="line">    &quot;about&quot; :      &quot;I love to go rock climbing&quot;,</span><br><span class="line">    &quot;interests&quot;: [&quot;sports&quot;, &quot;music&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>查询数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 协议方法 索引&#x2F;类型&#x2F;文档编号</span><br><span class="line">GET &#x2F;atguigu&#x2F;doc&#x2F;1</span><br></pre></td></tr></table></figure></div>

<p>响应</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;atguigu&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 1,</span><br><span class="line">  &quot;found&quot;: true,</span><br><span class="line">  &quot;_source&quot;: &#123; &#x2F;&#x2F; 文档的原始数据JSON数据</span><br><span class="line">    &quot;first_name&quot;: &quot;John&quot;,</span><br><span class="line">    &quot;last_name&quot;: &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot;: 25,</span><br><span class="line">    &quot;about&quot;: &quot;I love to go rock climbing&quot;,</span><br><span class="line">    &quot;interests&quot;: [</span><br><span class="line">      &quot;sports&quot;,</span><br><span class="line">      &quot;music&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="元数据查询"><a href="#元数据查询" class="headerlink" title="元数据查询"></a>元数据查询</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _cat&#x2F;indices</span><br></pre></td></tr></table></figure></div>

<h4 id="全文档检索"><a href="#全文档检索" class="headerlink" title="全文档检索"></a>全文档检索</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 协议方法 索引&#x2F;类型&#x2F;_search</span><br><span class="line">GET &#x2F;atguigu&#x2F;_doc&#x2F;_search</span><br></pre></td></tr></table></figure></div>

<h4 id="字段全值匹配检索-filter"><a href="#字段全值匹配检索-filter" class="headerlink" title="字段全值匹配检索[filter]"></a>字段全值匹配检索[filter]</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET atguigu&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;about&quot;: &quot;I love to go rock climbing&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="字段分词匹配检索-match"><a href="#字段分词匹配检索-match" class="headerlink" title="字段分词匹配检索[match]"></a>字段分词匹配检索[match]</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET atguigu&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;about&quot;: &quot;I&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="字段模糊匹配检索-fuzzy"><a href="#字段模糊匹配检索-fuzzy" class="headerlink" title="字段模糊匹配检索[fuzzy]"></a>字段模糊匹配检索[fuzzy]</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET  test&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;fuzzy&quot;: &#123;</span><br><span class="line">      &quot;aa&quot;: &#123;</span><br><span class="line">        &quot;value&quot;: &quot;我是程序&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="聚合检索"><a href="#聚合检索" class="headerlink" title="聚合检索"></a>聚合检索</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET test&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;groupby_aa&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;aa&quot;,</span><br><span class="line">        &quot;size&quot;: 10</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="分页检索"><a href="#分页检索" class="headerlink" title="分页检索"></a>分页检索</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET movie_index&#x2F;movie&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">  &quot;from&quot;: 1,</span><br><span class="line">  &quot;size&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="索引别名-aliases"><a href="#索引别名-aliases" class="headerlink" title="索引别名 _aliases"></a>索引别名 _aliases</h3><p>索引别名就像一个快捷方式或软连接，可以指向一个或多个索引，也可以给任何一个需要索引名的API来使用。别名带给我们极大的灵活性，允许我们做下面这些：</p>
<p>1）给多个索引分组 (例如， last_three_months)</p>
<p>2）给索引的一个子集创建视图</p>
<p>3）在运行的集群中可以无缝的从一个索引切换到另一个索引</p>
<blockquote>
<p>说白了就是功能更强大的视图</p>
</blockquote>
<p>创建索引别名</p>
<ul>
<li>建表时直接声明</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT movie_chn_2020</span><br><span class="line">&#123;  &quot;aliases&quot;: &#123;</span><br><span class="line">      &quot;movie_chn_2020-query&quot;: &#123;&#125;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;movie&quot;:&#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;id&quot;:&#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot;:&#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">          , &quot;analyzer&quot;: &quot;ik_smart&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;doubanScore&quot;:&#123;</span><br><span class="line">          &quot;type&quot;: &quot;double&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;actorList&quot;:&#123;</span><br><span class="line">          &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;id&quot;:&#123;</span><br><span class="line">              &quot;type&quot;:&quot;long&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;name&quot;:&#123;</span><br><span class="line">              &quot;type&quot;:&quot;keyword&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>为已存在的索引增加别名</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST  _aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot;: [</span><br><span class="line">        &#123; &quot;add&quot;:    &#123; &quot;index&quot;: &quot;movie_chn_xxxx&quot;, &quot;alias&quot;: &quot;movie_chn_2020-query&quot; &#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li>也可以通过加过滤条件缩小查询范围，建立一个子集视图</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST  _aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot;: [</span><br><span class="line">        &#123; &quot;add&quot;:    </span><br><span class="line">            &#123; &quot;index&quot;: &quot;movie_chn_xxxx&quot;, </span><br><span class="line">              &quot;alias&quot;: &quot;movie_chn0919-query-zhhy&quot;,</span><br><span class="line">               &quot;filter&quot;: &#123;</span><br><span class="line">                  &quot;term&quot;: &#123;  &quot;actorList.id&quot;: &quot;3&quot;</span><br><span class="line">                 &#125;</span><br><span class="line">               &#125;</span><br><span class="line">			 &#125;</span><br><span class="line">		&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>查询别名：与使用普通索引没有区别</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET movie_chn_2020-query&#x2F;_search</span><br></pre></td></tr></table></figure></div>

<p>删除某个索引的别名</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST  _aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot;: [</span><br><span class="line">        &#123; &quot;remove&quot;:    &#123; &quot;index&quot;: &quot;movie_chn_xxxx&quot;, &quot;alias&quot;: &quot;movie_chn_2020-query&quot; &#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>为某个别名进行无缝切换</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST &#x2F;_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot;: [</span><br><span class="line">        &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;movie_chn_xxxx&quot;, &quot;alias&quot;: &quot;movie_chn_2020-query&quot; &#125;&#125;,</span><br><span class="line">        &#123; &quot;add&quot;:    &#123; &quot;index&quot;: &quot;movie_chn_yyyy&quot;, &quot;alias&quot;: &quot;movie_chn_2020-query&quot; &#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>查询别名列表</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET  _cat&#x2F;aliases?v</span><br></pre></td></tr></table></figure></div>

<h3 id="索引模板"><a href="#索引模板" class="headerlink" title="索引模板"></a>索引模板</h3><p>Index Template 索引模板，顾名思义，就是创建索引的模具，其中可以定义一系列规则来帮助我们构建符合特定业务需求的索引的mappings和 settings，通过使用 Index Template 可以让我们的索引具备可预知的一致性。</p>
<blockquote>
<p>常见的场景: 分割索引</p>
<p>分割索引就是根据时间间隔把一个业务索引切分成多个索引。比如把order_info 变成 order_info_20200101,order_info_20200102 …..</p>
<p>这样做的好处有两个：</p>
<p>1、结构变化的灵活性：因为elasticsearch不允许对数据结构进行修改。但是实际使用中索引的结构和配置难免变化，那么只要对下一个间隔的索引进行修改，原来的索引位置原状。这样就有了一定的灵活性。</p>
<p>2、查询范围优化：因为一般情况并不会查询全部时间周期的数据，那么通过切分索引，物理上减少了扫描数据的范围，也是对性能的优化。</p>
</blockquote>
<p>创建模板</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT _template&#x2F;template_movie2020</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index_patterns&quot;: [&quot;movie_test*&quot;],                  </span><br><span class="line">  &quot;settings&quot;: &#123;                                               </span><br><span class="line">    &quot;number_of_shards&quot;: 1</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aliases&quot; : &#123; </span><br><span class="line">    &quot;&#123;index&#125;-query&quot;: &#123;&#125;,</span><br><span class="line">    &quot;movie_test-query&quot;:&#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;mappings&quot;: &#123;                                          </span><br><span class="line">&quot;_doc&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;id&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;movie_name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot;: &quot;ik_smart&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>其中 “index_patterns”: [“movie_test*”],  的含义就是凡是往movie_test开头的索引写入数据时，如果索引不存在，那么es会根据此模板自动建立索引。</p>
<p>在 “aliases” 中用{index}表示，获得真正的创建的索引名。</p>
<p>测试：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST movie_test_2020xxxx&#x2F;_doc</span><br><span class="line">&#123;</span><br><span class="line">  &quot;id&quot;:&quot;333&quot;,</span><br><span class="line">  &quot;name&quot;:&quot;zhang3&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>查看系统中已有的模板清单</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET  _cat&#x2F;templates</span><br></pre></td></tr></table></figure></div>

<p>查看某个模板详情</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET  _template&#x2F;template_movie2020</span><br><span class="line">或者</span><br><span class="line">GET  _template&#x2F;template_movie*</span><br></pre></td></tr></table></figure></div>

<h2 id="JavaAPI操作"><a href="#JavaAPI操作" class="headerlink" title="JavaAPI操作"></a>JavaAPI操作</h2><p>maven依赖:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.5.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpmime<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.searchbox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jest<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.3.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.java.dev.jna<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jna<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.5.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.codehaus.janino<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.elasticsearch<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>elasticsearch<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">versison</span>&gt;</span>6.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>单条写入数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.ys.bean.Stu;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClient;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClientFactory;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.config.HttpClientConfig;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.core.Index;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ESWriter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//一、创建ES客户端对象</span></span><br><span class="line">        <span class="comment">//1.1 创建ES客户端的工厂对象</span></span><br><span class="line">        JestClientFactory jestClientFactory = <span class="keyword">new</span> JestClientFactory();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.2 创建配置信息</span></span><br><span class="line">        HttpClientConfig config = <span class="keyword">new</span> HttpClientConfig.Builder(<span class="string">"http://hadoop102:9200"</span>).build();</span><br><span class="line">        jestClientFactory.setHttpClientConfig(config);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.3 获取客户端对象</span></span><br><span class="line">        JestClient jestClient = jestClientFactory.getObject();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//二、写入数据</span></span><br><span class="line">        <span class="comment">//2.1 创建Action对象 --&gt; Index</span></span><br><span class="line">        Stu stu = <span class="keyword">new</span> Stu(<span class="string">"004"</span>, <span class="string">"少爷"</span>);</span><br><span class="line">        Index index = <span class="keyword">new</span> Index.Builder(stu)</span><br><span class="line">                .index(<span class="string">"stu_temp_01"</span>)</span><br><span class="line">                .type(<span class="string">"_doc"</span>)</span><br><span class="line">                .id(<span class="string">"1004"</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.2 执行写入数据操作</span></span><br><span class="line">        jestClient.execute(index);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//三、关闭资源</span></span><br><span class="line">        jestClient.shutdownClient();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>批量写入数据</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.ys.bean.Stu;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClient;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClientFactory;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.config.HttpClientConfig;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.core.Bulk;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.core.Index;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ESWriterByBulk</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//一、创建ES客户端对象</span></span><br><span class="line">        <span class="comment">//1.1 创建ES客户端的工厂对象</span></span><br><span class="line">        JestClientFactory jestClientFactory = <span class="keyword">new</span> JestClientFactory();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.2 创建配置信息</span></span><br><span class="line">        HttpClientConfig config = <span class="keyword">new</span> HttpClientConfig.Builder(<span class="string">"http://hadoop102:9200"</span>).build();</span><br><span class="line">        jestClientFactory.setHttpClientConfig(config);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.3 获取客户端对象</span></span><br><span class="line">        JestClient jestClient = jestClientFactory.getObject();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//二、批量写入</span></span><br><span class="line">        <span class="comment">//2.1 准备数据</span></span><br><span class="line">        Stu stu1 = <span class="keyword">new</span> Stu(<span class="string">"008"</span>, <span class="string">"麻瓜"</span>);</span><br><span class="line">        Stu stu2 = <span class="keyword">new</span> Stu(<span class="string">"009"</span>, <span class="string">"海格"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.2 创建Bulk.Builder对象</span></span><br><span class="line">        Bulk.Builder builder = <span class="keyword">new</span> Bulk.Builder();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.3 创建Index对象</span></span><br><span class="line">        Index index1 = <span class="keyword">new</span> Index.Builder(stu1).id(<span class="string">"1008"</span>).build();</span><br><span class="line">        Index index2 = <span class="keyword">new</span> Index.Builder(stu2).id(<span class="string">"1009"</span>).build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.4 赋值默认的索引名称及类型名</span></span><br><span class="line">        builder.defaultIndex(<span class="string">"stu_temp_01"</span>);</span><br><span class="line">        builder.defaultType(<span class="string">"_doc"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.5 添加Index之Bulk</span></span><br><span class="line">        builder.addAction(index1);</span><br><span class="line">        builder.addAction(index2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.6 真正构建Bulk对象</span></span><br><span class="line">        Bulk bulk = builder.build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.7 执行批量写入数据操作</span></span><br><span class="line">        jestClient.execute(bulk);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关闭连接</span></span><br><span class="line">        jestClient.shutdownClient();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>读取数据（这里不使用json串，可读性不好）</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClient;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.JestClientFactory;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.client.config.HttpClientConfig;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.core.Search;</span><br><span class="line"><span class="keyword">import</span> io.searchbox.core.SearchResult;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.index.query.BoolQueryBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.index.query.TermQueryBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.builder.SearchSourceBuilder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ESReader</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取客户端对象</span></span><br><span class="line">        <span class="comment">//1.1 创建ES客户端的工厂对象</span></span><br><span class="line">        JestClientFactory jestClientFactory = <span class="keyword">new</span> JestClientFactory();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.2 创建配置信息</span></span><br><span class="line">        HttpClientConfig config = <span class="keyword">new</span> HttpClientConfig.Builder(<span class="string">"http://hadoop102:9200"</span>).build();</span><br><span class="line">        jestClientFactory.setHttpClientConfig(config);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.3 获取客户端对象</span></span><br><span class="line">        JestClient jestClient = jestClientFactory.getObject();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.读取数据</span></span><br><span class="line">        <span class="comment">//2.0 创建查询条件</span></span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">        BoolQueryBuilder boolQueryBuilder = <span class="keyword">new</span> BoolQueryBuilder();</span><br><span class="line">        boolQueryBuilder.filter(<span class="keyword">new</span> TermQueryBuilder(<span class="string">"class_id"</span>, <span class="string">"190218"</span>));</span><br><span class="line">        searchSourceBuilder.query(boolQueryBuilder);</span><br><span class="line"></span><br><span class="line">        searchSourceBuilder.from(<span class="number">0</span>);</span><br><span class="line">        searchSourceBuilder.size(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.1 创建Search对象</span></span><br><span class="line">        Search search = <span class="keyword">new</span> Search.Builder(searchSourceBuilder.toString())</span><br><span class="line">                .addIndex(<span class="string">"student"</span>)</span><br><span class="line">                .addType(<span class="string">"_doc"</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.2 执行查询操作</span></span><br><span class="line">        SearchResult searchResult = jestClient.execute(search);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.3 解析searchResult</span></span><br><span class="line">        System.out.println(<span class="string">"查询数据"</span> + searchResult.getTotal() + <span class="string">"条！"</span>);</span><br><span class="line">        <span class="comment">// [json对应map是常见操作]</span></span><br><span class="line">        List&lt;SearchResult.Hit&lt;Map, Void&gt;&gt; hits = searchResult.getHits(Map<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="keyword">for</span> (SearchResult.Hit&lt;Map, Void&gt; hit : hits) &#123;</span><br><span class="line">            Map source = hit.source;</span><br><span class="line">            <span class="keyword">for</span> (Object key : source.keySet()) &#123;</span><br><span class="line">                System.out.println(hit.id + <span class="string">":"</span> + key.toString() + <span class="string">":"</span> + source.get(key).toString());</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">"*************"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关闭资源</span></span><br><span class="line">        jestClient.shutdownClient();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Stu.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Stu</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Stu</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Stu</span><span class="params">(String id, String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span> == o) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span> || getClass() != o.getClass()) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        Stu stu = (Stu) o;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (id != <span class="keyword">null</span> ? !id.equals(stu.id) : stu.id != <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> name != <span class="keyword">null</span> ? name.equals(stu.name) : stu.name == <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> result = id != <span class="keyword">null</span> ? id.hashCode() : <span class="number">0</span>;</span><br><span class="line">        result = <span class="number">31</span> * result + (name != <span class="keyword">null</span> ? name.hashCode() : <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Stu&#123;"</span> +</span><br><span class="line">                <span class="string">"id='"</span> + id + <span class="string">'\''</span> +</span><br><span class="line">                <span class="string">", name='"</span> + name + <span class="string">'\''</span> +</span><br><span class="line">                <span class="string">'&#125;'</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>elasticsearch</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>MyISAM与InnoDB的区别(详)</title>
    <url>/2020/05/14/MyISAM%E4%B8%8EInnoDB%E7%9A%84%E5%8C%BA%E5%88%AB-%E8%AF%A6/</url>
    <content><![CDATA[<h1 id="MyISAM与InnoDB的区别（详）"><a href="#MyISAM与InnoDB的区别（详）" class="headerlink" title="MyISAM与InnoDB的区别（详）"></a>MyISAM与InnoDB的区别（详）</h1><h2 id="1-事务"><a href="#1-事务" class="headerlink" title="1.事务"></a>1.事务</h2><ul>
<li>InnoDB支持事务，MyISAM不支持。</li>
</ul>
<p>对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；</p>
<blockquote>
<p>所以，博客中的《 <a href="http://www.yangsen94.top/2020/05/14/MySQL事务相关/" target="_blank" rel="noopener">MySQL事务相关</a> 》一文，是基于InnoDB引擎的。</p>
</blockquote>
<h2 id="2-外键"><a href="#2-外键" class="headerlink" title="2.外键"></a>2.外键</h2><ul>
<li>InnoDB支持外键，而MyISAM不支持。</li>
</ul>
<p>对一个包含外键的InnoDB表转为MYISAM会失败； </p>
<h2 id="3-索引"><a href="#3-索引" class="headerlink" title="3.索引"></a>3.索引</h2><ul>
<li><p>InnoDB是聚集索引，使用<strong>B+Tree</strong>作为索引结构，<strong>数据文件是和（主键）索引绑在一起的</strong>（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。</p>
</li>
<li><p>MyISAM是非聚集索引，也是使用<strong>B+Tree</strong>作为索引结构，<strong>索引和数据文件是分离的</strong>（联系本文第9点），索引保存的是数据文件的指针。主键索引和辅助索引是独立的。</p>
</li>
</ul>
<blockquote>
<p>也就是说：<strong>InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值</strong>；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。</p>
</blockquote>
<h2 id="4-表的具体行数"><a href="#4-表的具体行数" class="headerlink" title="4.表的具体行数"></a>4.表的具体行数</h2><ul>
<li>InnoDB不保存表的具体行数，执行<code>select count(*) from table</code>时需要全表扫描。</li>
<li>而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）；</li>
</ul>
<blockquote>
<p>那么为什么InnoDB没有了这个变量呢？</p>
<p>​        因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。InnoDB会尝试遍历一个尽可能小的索引除非优化器提示使用别的索引。如果二级索引不存在，InnoDB还会尝试去遍历其他聚簇索引.</p>
<p>​        如果索引并没有完全处于InnoDB维护的缓冲区（Buffer Pool）中，count操作会比较费时。可以建立一个记录总行数的表并让你的程序在INSERT/DELETE时更新对应的数据。和上面提到的问题一样，如果此时存在多个事务的话这种方案也不太好用。如果得到大致的行数值已经足够满足需求可以尝试：</p>
<p>SHOW TABLE STATUS</p>
</blockquote>
<h2 id="5-全文索引"><a href="#5-全文索引" class="headerlink" title="5.全文索引"></a>5.全文索引</h2><ul>
<li>Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；</li>
</ul>
<blockquote>
<p>5.7以后的InnoDB支持全文索引了。</p>
</blockquote>
<h2 id="6-表压缩"><a href="#6-表压缩" class="headerlink" title="6.表压缩"></a>6.表压缩</h2><ul>
<li>MyISAM表格可以被压缩后进行查询操作,压缩表是不能进行修改的(除非先将表解除压缩，修改数据，然后再次压缩)。压缩表可以极大地减少磁盘空间占用，因此也可以减少磁盘I/O，从而提升查询性能，压缩表也支持索引，但索引也只是只读的。</li>
</ul>
<h2 id="7-锁粒度"><a href="#7-锁粒度" class="headerlink" title="7.锁粒度"></a>7.锁粒度</h2><ul>
<li>InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁。</li>
</ul>
<blockquote>
<p>InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。</p>
<p>潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁 T_T。</p>
</blockquote>
<h2 id="8-主键"><a href="#8-主键" class="headerlink" title="8.主键"></a>8.主键</h2><ul>
<li>InnoDB表必须有主键（用户没有指定的话会自己找或生产一个主键），而Myisam可以没有</li>
</ul>
<h2 id="9-表数据文件存储"><a href="#9-表数据文件存储" class="headerlink" title="9.表数据文件存储"></a>9.表数据文件存储</h2><ul>
<li>Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI</li>
</ul>
<blockquote>
<p>Innodb：frm是表定义文件，ibd是数据文件（共享表空间和单独表空间）</p>
<p>Myisam：frm是表定义文件，myd是数据文件，myi是索引文件</p>
</blockquote>
<h2 id="索引选择"><a href="#索引选择" class="headerlink" title="索引选择"></a>索引选择</h2><blockquote>
<p>除非需要用到某些Innodb不具备的特性，并且没有其他办法可以代替，否则都应该优先选择innodb引擎。</p>
</blockquote>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><blockquote>
<p> <a href="https://blog.csdn.net/qq_35642036/article/details/82820178" target="_blank" rel="noopener">https://blog.csdn.net/qq_35642036/article/details/82820178</a>  （里面的图片值得参考）</p>
<p> <a href="https://www.cnblogs.com/timor0101/p/12883649.html" target="_blank" rel="noopener">https://www.cnblogs.com/timor0101/p/12883649.html</a> </p>
</blockquote>
]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>数据库</tag>
        <tag>面试</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL事务相关</title>
    <url>/2020/05/14/MySQL%E4%BA%8B%E5%8A%A1%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<h1 id="事务四大特性（ACID）"><a href="#事务四大特性（ACID）" class="headerlink" title="事务四大特性（ACID）"></a>事务四大特性（ACID）</h1><p><strong>1、原子性（Atomicity）：</strong></p>
<p>事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。</p>
<p>事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。</p>
<p>也就是说事务是一个不可分割的整体。</p>
<p>的基本单位 </p>
<p><strong>2、一致性（Consistency）：</strong></p>
<p>事务开始前和结束后，数据库的完整性约束没有被破坏 。</p>
<p>比如 A 向 B 转账，不可能 A 扣了钱，B 却没收到。 </p>
<p><strong>3、隔离性（Isolation）：</strong></p>
<p>同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。</p>
<p>比如 A 正在从一张银行卡中取钱，在 A 取钱的过程结束前，B 不能向这张卡转账。 </p>
<p><strong>4、持久性（Durability）：</strong></p>
<p>事务完成后，事务对数据库的所有更新将被保存到数据库，不 能回滚。 </p>
<h1 id="MySQL事务隔离级别"><a href="#MySQL事务隔离级别" class="headerlink" title="MySQL事务隔离级别"></a>MySQL事务隔离级别</h1><p>多个事务之间隔离的，相互独立的。</p>
<p>但是如果多个事务操作同一批数据，则会引发一些问题，设置不同的隔离级别就可以解决这些问题。</p>
<table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>读未提交（read-uncommitted）</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>不可重复读（read-committed）</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>可重复读（repeatable-read）</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>串行化（serializable）</td>
<td>否</td>
<td>否</td>
<td>否</td>
</tr>
</tbody></table>
<blockquote>
<p>隔离级别越高，效率越低。</p>
<p>大多数数据库的默认级别就是不可重复读（Read committed），比如Sql Server , Oracle</p>
<p><strong>【注意】MySQL的默认事务隔离级别是——可重复读</strong></p>
</blockquote>
<h1 id="事务并发存在的问题"><a href="#事务并发存在的问题" class="headerlink" title="事务并发存在的问题"></a>事务并发存在的问题</h1><p>1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。</p>
<p>（一个事务，读取到另一个事务中没有提交的数据）</p>
<p>2、不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据做了更新并提交，导致事务 A多次读取同一数据时，结果不一致 。</p>
<p>（在同一个事务中，两次读取到的数据不一样 ）</p>
<p>3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 </p>
<p>（一个事务操作(DML)数据表中所有记录，另一个事务添加了一条数据，则第一个事务查询不到添加的数据）</p>
<p>（ 一个事务(同一个read view)在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行）</p>
<blockquote>
<p>可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；</p>
<p>insert、update和delete会更新版本号，是当前读（当前版本）。 幻读只在<strong>当前读</strong>下才会出现。 </p>
</blockquote>
<blockquote>
<p>不可重复读的和幻读很容易混淆，<strong>不可重复读侧重于修改，幻读侧重于新增或删除</strong>。</p>
<p>解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表等方法</p>
</blockquote>
<p><strong>幻读产生的原因：</strong></p>
<ul>
<li>行锁只能锁住行，即使把所有的行记录都上锁，也阻止不了新插入的记录。 </li>
</ul>
<p><strong>解决幻读的其他方法：</strong></p>
<ul>
<li>将两行记录间的空隙加上锁，阻止新记录的插入；这个锁称为<strong>间隙锁</strong>。 </li>
</ul>
]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>数据库</tag>
        <tag>面试</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>[精]zookeeper总结与思考</title>
    <url>/2020/05/14/%E7%B2%BE-zookeeper%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。多作为集群提供服务的中间件.</p>
<p>Zookeeper从设计模式角度来理解，是一个基于<strong>观察者模式</strong>设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生了变化，Zookeeper就负责<strong>通知</strong>已经在Zookeeper上注册的那些观察者做出相应的反应.</p>
<blockquote>
<p>分布式系统: 分布式系统指由很多台计算机组成的一个整体。</p>
<p>这个整体一致对外,并且处理同一请求，系统对内透明，对外不透明。</p>
<p>内部的每台计算机都可以相互通信，例如使用RPC 或者是WebService。客户端向一个分布式系统发送的一次请求到接受到响应，有可能会经历多台计算机。</p>
</blockquote>
<p><strong>Zookeeper = 文件系统 + 通知机制</strong></p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>中心化集群，但是中心化集群易出现单点故障。</p>
<p><a href="https://pic.downk.cc/item/5ebcf7c7c2a9a83be53e07f7.png" data-fancybox="group" data-caption="zk特点" class="fancybox"><img alt="zk特点" title="zk特点" data-src="https://pic.downk.cc/item/5ebcf7c7c2a9a83be53e07f7.png" class="lazyload"></a></p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p><a href="https://pic.downk.cc/item/5ebcf7f5c2a9a83be53e3033.png" data-fancybox="group" data-caption="zk数据结构" class="fancybox"><img alt="zk数据结构" title="zk数据结构" data-src="https://pic.downk.cc/item/5ebcf7f5c2a9a83be53e3033.png" class="lazyload"></a></p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。</p>
<h1 id="二、安装及操作"><a href="#二、安装及操作" class="headerlink" title="二、安装及操作"></a>二、安装及操作</h1><p>需要提前安装JDK</p>
<p>两种部署方式：本地模式（standalone），分布式模式</p>
<h2 id="分布式安装部署"><a href="#分布式安装部署" class="headerlink" title="分布式安装部署"></a>分布式安装部署</h2><blockquote>
<p>版本：zookeeper-3.4.10</p>
</blockquote>
<p>1、规划</p>
<p>将在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。</p>
<p>2、解压安装</p>
<p>三台服务器分别解压：tar -zxvf zookeeper-3.4.10.tar.gz</p>
<p>解压后生成zookeeper-3.4.10目录</p>
<p>3、配置服务器编号</p>
<ul>
<li><p>在zookeeper-3.4.10目录下创建zkData：mkdir -p zkData</p>
</li>
<li><p>进入目录：cd  zkData</p>
</li>
<li><p>创建myid文件：touch myid</p>
</li>
<li><p>编辑文件：vim myid</p>
</li>
</ul>
<p>在文件中添加与server对应的编号：比如hadoop02添加2；</p>
<ul>
<li>在hadoop103、hadoop104上修改myid文件中内容为3、4</li>
</ul>
<p>4、修改配置文件</p>
<ul>
<li><p>zookeeper-3.4.10/conf这个目录下的zoo_sample.cfg重命名为zoo.cfg：mv zoo_sample.cfg zoo.cfg</p>
</li>
<li><p>打开zoo.cfg文件：vim zoo.cfg</p>
</li>
<li><p>在文件中修改数据存储路径配置：</p>
</li>
</ul>
<p>dataDir=/opt/module/zookeeper-3.4.10/zkData</p>
<ul>
<li>并且增加如下配置：</li>
</ul>
<p>#######################cluster##########################</p>
<p>server.2=hadoop102:2888:3888</p>
<p>server.3=hadoop103:2888:3888</p>
<p>server.4=hadoop104:2888:3888</p>
<ul>
<li>同步zoo.cfg配置文件到其他所有服务器</li>
</ul>
<blockquote>
<p>【配置参数解读】server.A=B:C:D</p>
<p>A是一个数字，表示这个是第几号服务器【myid】；</p>
<p>zk启动时读取myid文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p>B是这个服务器的ip地址；</p>
<p>C是这个服务器与集群中的Leader服务器交换信息的端口<strong>2888</strong>；【副本】</p>
<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口<strong>3888</strong>。【选举信息】</p>
<p>【扩展】<strong>2181</strong>，客户端访问端口</p>
</blockquote>
<p>5、相关操作</p>
<ul>
<li><p>三台服务器在zookeeper-3.4.10下分别启动：bin/zkServer.sh start</p>
</li>
<li><p>查看状态：bin/zkServer.sh status</p>
</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[ys@hadoop102 zookeeper-3.4.10]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">[ys@hadoop103 zookeeper-3.4.10]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line">[ys@hadoop104 zookeeper-3.4.5]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure></div>

<h2 id="客户端命令行操作"><a href="#客户端命令行操作" class="headerlink" title="客户端命令行操作"></a>客户端命令行操作</h2><p>启动客户端：bin/zkCli.sh</p>
<table>
<thead>
<tr>
<th>命令基本语法</th>
<th>功能描述</th>
</tr>
</thead>
<tbody><tr>
<td>help</td>
<td>显示所有操作命令</td>
</tr>
<tr>
<td>ls path [watch]</td>
<td>使用 ls 命令来查看当前znode中所包含的内容</td>
</tr>
<tr>
<td>ls2 path [watch]</td>
<td>（详细信息）查看当前节点数据并能看到更新次数等数据</td>
</tr>
<tr>
<td>create</td>
<td>普通创建<br>-s  含有序列<br>-e  临时（重启或者超时消失）</td>
</tr>
<tr>
<td>get path [watch]</td>
<td>获得节点的值</td>
</tr>
<tr>
<td>set</td>
<td>设置节点的具体值</td>
</tr>
<tr>
<td>stat</td>
<td>查看节点状态</td>
</tr>
<tr>
<td>delete</td>
<td>删除节点</td>
</tr>
<tr>
<td>rmr</td>
<td>递归删除节点</td>
</tr>
</tbody></table>
<h1 id="三、内部原理【重点】"><a href="#三、内部原理【重点】" class="headerlink" title="三、内部原理【重点】"></a>三、内部原理【重点】</h1><h2 id="选举机制【重点】"><a href="#选举机制【重点】" class="headerlink" title="选举机制【重点】"></a>选举机制【重点】</h2><ul>
<li><p>半数机制：</p>
<ul>
<li>集群中半数以上机器存活，集群可用。所以Zookeeper适合安装奇数台服务器。</li>
</ul>
</li>
<li><p>内部投票选举：</p>
<ul>
<li>Zookeeper虽然在配置文件中并没有指定Master和Slave。但是，Zookeeper工作时，是有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。</li>
</ul>
</li>
</ul>
<p>【举例】五台服务器组成的Zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。这些服务器依序启动，则：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">因为一共5台服务器，只有超过半数以上，即最少启动3台服务器，集群才能正常工作。</span><br><span class="line"></span><br><span class="line">（1）服务器1启动，发起一次选举。</span><br><span class="line">服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成；</span><br><span class="line">服务器1状态保持为LOOKING；</span><br><span class="line"></span><br><span class="line">（2）服务器2启动，再发起一次选举。</span><br><span class="line">服务器1和2分别投自己一票，此时服务器1发现服务器2的id比自己大，更改选票投给服务器2；</span><br><span class="line">此时服务器1票数0票，服务器2票数2票，不够半数以上（3票），选举无法完成；</span><br><span class="line">服务器1，2状态保持LOOKING；</span><br><span class="line"></span><br><span class="line">（3）服务器3启动，发起一次选举。</span><br><span class="line">与上面过程一样，服务器1和2先投自己一票，然后因为服务器3id最大，两者更改选票投给为服务器3；</span><br><span class="line">此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数（3票），服务器3当选Leader。</span><br><span class="line">服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；</span><br><span class="line"></span><br><span class="line">（4）服务器4启动，发起一次选举。</span><br><span class="line">此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。</span><br><span class="line">此时服务器4服从多数，更改选票信息为服务器3；</span><br><span class="line">服务器4并更改状态为FOLLOWING；</span><br><span class="line"></span><br><span class="line">（5）服务器5启动，同4一样投票给3，此时服务器3一共5票，服务器5为0票；</span><br><span class="line">服务器5并更改状态为FOLLOWING；</span><br><span class="line"></span><br><span class="line">最终Leader是服务器3，状态为LEADING；</span><br><span class="line">其余服务器是Follower，状态为FOLLOWING。</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>参考文章： <a href="https://blog.csdn.net/weixin_43291055/article/details/95451357" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43291055/article/details/95451357</a> </p>
<p>选举机制文章推荐：</p>
<p> <a href="https://www.cnblogs.com/shuaiandjun/p/9383655.html" target="_blank" rel="noopener">https://www.cnblogs.com/shuaiandjun/p/9383655.html</a> </p>
<p> <a href="https://blog.csdn.net/wyqwilliam/article/details/83537139" target="_blank" rel="noopener">https://blog.csdn.net/wyqwilliam/article/details/83537139</a> </p>
</blockquote>
<h2 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h2><p><a href="https://pic.downk.cc/item/5ebcf83cc2a9a83be53e6d2f.png" data-fancybox="group" data-caption="zk节点4大类型" class="fancybox"><img alt="zk节点4大类型" title="zk节点4大类型" data-src="https://pic.downk.cc/item/5ebcf83cc2a9a83be53e6d2f.png" class="lazyload"></a></p>
<h2 id="监听器原理【重点】"><a href="#监听器原理【重点】" class="headerlink" title="监听器原理【重点】"></a>监听器原理【重点】</h2><p><a href="https://pic.downk.cc/item/5ebcf87ac2a9a83be53ea28e.png" data-fancybox="group" data-caption="监听器原理" class="fancybox"><img alt="监听器原理" title="监听器原理" data-src="https://pic.downk.cc/item/5ebcf87ac2a9a83be53ea28e.png" class="lazyload"></a></p>
<h2 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h2><p><a href="https://pic.downk.cc/item/5ebcf898c2a9a83be53ebe79.png" data-fancybox="group" data-caption="写数据流程" class="fancybox"><img alt="写数据流程" title="写数据流程" data-src="https://pic.downk.cc/item/5ebcf898c2a9a83be53ebe79.png" class="lazyload"></a></p>
<h2 id="【案例】监听服务器节点动态上下线-zk工作机制"><a href="#【案例】监听服务器节点动态上下线-zk工作机制" class="headerlink" title="【案例】监听服务器节点动态上下线/zk工作机制"></a>【案例】监听服务器节点动态上下线/zk工作机制</h2><p><a href="https://pic.downk.cc/item/5ebcf8b1c2a9a83be53ed66b.png" data-fancybox="group" data-caption="zk工作机制" class="fancybox"><img alt="zk工作机制" title="zk工作机制" data-src="https://pic.downk.cc/item/5ebcf8b1c2a9a83be53ed66b.png" class="lazyload"></a></p>
<h3 id="API操作："><a href="#API操作：" class="headerlink" title="API操作："></a>API操作：</h3><p>1、maven依赖</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>2、集群上创建/servers节点</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 10] create /servers "servers"</span><br><span class="line">Created /servers</span><br></pre></td></tr></table></figure></div>

<p>3、服务器端向Zookeeper注册</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs.Ids;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> String connectString = <span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> sessionTimeout = <span class="number">2000</span>;</span><br><span class="line">	<span class="keyword">private</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">private</span> String parentNode = <span class="string">"/servers"</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 创建到zk的客户端连接</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">		</span><br><span class="line">		zk = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 注册服务器</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registServer</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">		String create = zk.create(parentNode + <span class="string">"/server"</span>, hostname.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">		</span><br><span class="line">		System.out.println(hostname +<span class="string">" is online "</span>+ create);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 业务功能</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		System.out.println(hostname+<span class="string">" is working ..."</span>);</span><br><span class="line">		</span><br><span class="line">		Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 1获取zk连接</span></span><br><span class="line">		DistributeServer server = <span class="keyword">new</span> DistributeServer();</span><br><span class="line">		server.getConnect();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 利用zk连接注册服务器信息</span></span><br><span class="line">		server.registServer(args[<span class="number">0</span>]);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 启动业务功能</span></span><br><span class="line">		server.business(args[<span class="number">0</span>]);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>4、客户端</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> String connectString = <span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> sessionTimeout = <span class="number">2000</span>;</span><br><span class="line">	<span class="keyword">private</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">private</span> String parentNode = <span class="string">"/servers"</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 创建到zk的客户端连接</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">		zk = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 再次启动监听</span></span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					getServerList();</span><br><span class="line">				&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 获取服务器列表信息</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getServerList</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1获取服务器子节点信息，并且对父节点进行监听</span></span><br><span class="line">		List&lt;String&gt; children = zk.getChildren(parentNode, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2存储服务器信息列表</span></span><br><span class="line">		ArrayList&lt;String&gt; servers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">        <span class="comment">// 3遍历所有节点，获取节点中的主机名称信息</span></span><br><span class="line">		<span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">			<span class="keyword">byte</span>[] data = zk.getData(parentNode + <span class="string">"/"</span> + child, <span class="keyword">false</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">			servers.add(<span class="keyword">new</span> String(data));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4打印服务器列表信息</span></span><br><span class="line">		System.out.println(servers);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 业务功能</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">		System.out.println(<span class="string">"client is working ..."</span>);</span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1获取zk连接</span></span><br><span class="line">		DistributeClient client = <span class="keyword">new</span> DistributeClient();</span><br><span class="line">		client.getConnect();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2获取servers的子节点信息，从中获取服务器信息列表</span></span><br><span class="line">		client.getServerList();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3业务进程启动</span></span><br><span class="line">		client.business();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="四、其他"><a href="#四、其他" class="headerlink" title="四、其他"></a>四、其他</h1><h2 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h2><p>1、zk常用端口号：</p>
<blockquote>
<p>2181，客户端访问端口<br>2888，zk内部信息通讯（数据）<br>3888，zk选举专用</p>
</blockquote>
<p>2、zk不能越级创建节点；</p>
<p>且创建节点一般要带有数据（除非数据是null），否则创建会失败</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] create /ys/sss "666"</span><br><span class="line">Node does not exist: /ys/sss</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] create /ys "666"    </span><br><span class="line">Created /ys</span><br><span class="line">...</span><br><span class="line">[zk: localhost:2181(CONNECTED) 16] create /ss null</span><br><span class="line">Created /ys </span><br><span class="line">[zk: localhost:2181(CONNECTED) 17] ls /</span><br><span class="line">[cluster, configs, controller, brokers, zookeeper, overseer, admin, isr_change_notification, controller_epoch, druid, aliases.json, live_nodes, collections, overseer_elect, spark, clusterstate.json, consumers, 【ss】, latest_producer_id_block, config, hbase, kylin]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 18] ls /ss</span><br><span class="line">[]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 19] get /ss</span><br><span class="line">null</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
<h2 id="常考面试题"><a href="#常考面试题" class="headerlink" title="常考面试题"></a>常考面试题</h2><ul>
<li><p>请简述ZooKeeper的选举机制</p>
<blockquote>
<p>半数机制：2n+1 </p>
<p>10 台服务器：3 台 zk</p>
<p>20 台服务器：5 台 zk</p>
<p>100 台服务器：11 台 zk</p>
<p>【注意】台数并不是越多越好。 太多选举时间过长影响性能。 </p>
</blockquote>
</li>
<li><p>ZooKeeper的监听原理</p>
</li>
<li><p>ZooKeeper的常用命令</p>
</li>
<li><p>ZooKeeper的部署方式有哪几种？集群中的角色有哪些？集群最少需要几台机器？</p>
<ul>
<li>部署方式单机模式、集群模式</li>
<li>角色：Leader和Follower</li>
<li>集群最少需要机器数：3</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>zookeeper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>JUnit常用注解</title>
    <url>/2020/05/12/JUnit%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="JUnit常用注解"><a href="#JUnit常用注解" class="headerlink" title="JUnit常用注解"></a>JUnit常用注解</h1><p>JUnit是 Java平台最常用的测试框架 。</p>
<p>本文重点阐述JUnit4版本的@Before、@After、@BeforeClass、@AfterClass四个注解。</p>
<h2 id="JUnit4，JUnit5注解对比"><a href="#JUnit4，JUnit5注解对比" class="headerlink" title="JUnit4，JUnit5注解对比"></a>JUnit4，JUnit5注解对比</h2><table>
<thead>
<tr>
<th>JUnit4</th>
<th>JUnit5</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>@BeforeClass</td>
<td>@BeforeAll</td>
<td>在当前类的<strong>所有测试方法</strong>之前执行。注解在【静态方法】上。</td>
</tr>
<tr>
<td>@AfterClass</td>
<td>@AfterAll</td>
<td>在当前类中的<strong>所有测试方法</strong>之后执行。注解在【静态方法】上。</td>
</tr>
<tr>
<td>@Before</td>
<td>@BeforeEach</td>
<td>在<strong>每个测试方法</strong>之前执行。注解在【非静态方法】上。</td>
</tr>
<tr>
<td>@After</td>
<td>@AfterEach</td>
<td>在<strong>每个测试方法</strong>之后执行。注解在【非静态方法】上。</td>
</tr>
</tbody></table>
<p>为什么 JUnit中@BeforeClass和@AfterClass标注的方法必须是static的 ？</p>
<p>其实和JUnit的运行机制有关：</p>
<blockquote>
<p>在JUnit中：每运行一个@Test方法，就会为该测试类新建一个新的实例。所以@BeforeClass和@AfterClass必须是static的，因为运行他们的时候，测试类还没有实例化。</p>
<p>这种设计有助于提高测试方法之间的独立性，因为每个@Test执行的时候，都新建了一个实例，这样的话，可以避免测试方法之间重用各个@Test方法里面的变量值。</p>
</blockquote>
<p>示例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JUintDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">        System.out.println(<span class="string">"test1 i="</span> + i); <span class="comment">//test1 i=1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"test2 i="</span> + i); <span class="comment">//test2 i=2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JunitTest</span> </span>&#123;</span><br><span class="line">    <span class="meta">@BeforeClass</span></span><br><span class="line">    <span class="comment">//【静态方法】</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">beforeClass</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"before class:begin this class================"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterClass</span></span><br><span class="line">    <span class="comment">//【静态方法】</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">afterClass</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"after class:end this class================="</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"before:begin test"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"after:end test"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"[this is a test!]"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Test2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"[this is another test!!!!!]"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>执行整个JunitTest文件，输出结果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">before class:begin this class&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">before:begin test</span><br><span class="line">[this is a test!]</span><br><span class="line">after:end test</span><br><span class="line">before:begin test</span><br><span class="line">[this is another test!!!!!]</span><br><span class="line">after:end test</span><br><span class="line">after class:end this class&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure></div>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>一整个JUnit4的单元测试用例执行顺序为： </p>
<p>​        @BeforeClass -&gt; @Before -&gt; @Test -&gt; @After -&gt; @AfterClass; </p>
<p>每一个单独的测试方法的调用顺序为： </p>
<p>​        @Before -&gt; @Test -&gt; @After; </p>
]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
        <tag>JUnit</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title>[SparkSQL]UDAF自定义聚合函数</title>
    <url>/2020/05/05/SparkSQL-UDAF%E8%87%AA%E5%AE%9A%E4%B9%89%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="SparkSQL-UDAF自定义聚合函数"><a href="#SparkSQL-UDAF自定义聚合函数" class="headerlink" title="[SparkSQL]UDAF自定义聚合函数"></a>[SparkSQL]UDAF自定义聚合函数</h1><p>SparkSql中，用户可以设定自己的自定义聚合函数（UserDefinedAggregateFunction）。</p>
<blockquote>
<p>需求：实现平均年龄</p>
</blockquote>
<p>user.json 文件：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">json</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"username"</span>: <span class="string">"lisi"</span>,<span class="attr">"userage"</span>: <span class="number">40</span>&#125;</span><br><span class="line">&#123;<span class="attr">"username"</span>: <span class="string">"zhangsan"</span>,<span class="attr">"userage"</span>: <span class="number">30</span>&#125;</span><br><span class="line">&#123;<span class="attr">"username"</span>: <span class="string">"wangwu"</span>,<span class="attr">"userage"</span>:<span class="number">20</span>&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="UDAF-弱类型"><a href="#UDAF-弱类型" class="headerlink" title="UDAF - 弱类型"></a>UDAF - 弱类型</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.&#123;<span class="type">MutableAggregationBuffer</span>, <span class="type">UserDefinedAggregateFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">DataType</span>, <span class="type">DoubleType</span>, <span class="type">LongType</span>, <span class="type">StructField</span>, <span class="type">StructType</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.util.<span class="type">AccumulatorV2</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQL_UDAF01</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"sparksql"</span>)</span><br><span class="line">        <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().config(sparkConf).getOrCreate()</span><br><span class="line">        <span class="comment">// TODO 读取JSON数据</span></span><br><span class="line">        <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.json(<span class="string">"input/user.json"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 使用自定义聚合函数实现年龄的平均值计算</span></span><br><span class="line">        <span class="comment">// buffer</span></span><br><span class="line">        <span class="comment">// select avg(age) from user</span></span><br><span class="line">        <span class="comment">// 创建自定义函数</span></span><br><span class="line">        <span class="keyword">val</span> udaf = <span class="keyword">new</span> <span class="type">MyAvgAgeUDAF</span></span><br><span class="line">        <span class="comment">// 注册UDAF函数</span></span><br><span class="line">        spark.udf.register(<span class="string">"avgAge"</span>, udaf)</span><br><span class="line"></span><br><span class="line">        df.createTempView(<span class="string">"user"</span>)</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">"select avgAge(userage) from user"</span>).show</span><br><span class="line"></span><br><span class="line">        spark.close</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * TODO 自定义聚合函数（UDAF）</span></span><br><span class="line"><span class="comment">     * 1. 继承UserDefinedAggregateFunction</span></span><br><span class="line"><span class="comment">     * 2. 重写方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">MyAvgAgeUDAF</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line">        <span class="comment">// TODO 传入聚合函数的数据结构</span></span><br><span class="line">        <span class="comment">// 1 =&gt; age =&gt; Long</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">            <span class="type">StructType</span>(<span class="type">Array</span>(</span><br><span class="line">                <span class="type">StructField</span>(<span class="string">"age"</span>, <span class="type">LongType</span>)</span><br><span class="line">            ))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 用于计算的缓冲区的数据结构</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">            <span class="type">StructType</span>(<span class="type">Array</span>(</span><br><span class="line">                <span class="type">StructField</span>(<span class="string">"totalage"</span>, <span class="type">LongType</span>),</span><br><span class="line">                <span class="type">StructField</span>(<span class="string">"totalcnt"</span>, <span class="type">LongType</span>)</span><br><span class="line">            ))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 输出结果的类型</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">DoubleType</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 函数稳定性（幂等性）</span></span><br><span class="line">        <span class="comment">// 给函数相同的输入值，计算结果也相同</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 用于计算的缓冲区初始化</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            buffer(<span class="number">0</span>) = <span class="number">0</span>L</span><br><span class="line">            buffer(<span class="number">1</span>) = <span class="number">0</span>L</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 将输入的值更新到缓冲区中</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            buffer(<span class="number">0</span>) = buffer.getLong(<span class="number">0</span>) + input.getLong(<span class="number">0</span>)</span><br><span class="line">            buffer(<span class="number">1</span>) = buffer.getLong(<span class="number">1</span>) + <span class="number">1</span>L</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 合并缓冲区</span></span><br><span class="line">        <span class="comment">// MutableAggregationBuffer 继承了Row</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            buffer1(<span class="number">0</span>) = buffer1.getLong(<span class="number">0</span>) + buffer2.getLong(<span class="number">0</span>)</span><br><span class="line">            buffer1(<span class="number">1</span>) = buffer1.getLong(<span class="number">1</span>) + buffer2.getLong(<span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 计算结果</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> = &#123;</span><br><span class="line">            buffer.getLong(<span class="number">0</span>).toDouble / buffer.getLong(<span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>输出：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">+<span class="comment">---------------------+</span></span><br><span class="line">|myavgageudaf(userage)|</span><br><span class="line">+<span class="comment">---------------------+</span></span><br><span class="line">|                 30.0|</span><br><span class="line">+<span class="comment">---------------------+</span></span><br></pre></td></tr></table></figure></div>

<h2 id="UDAF-强类型"><a href="#UDAF-强类型" class="headerlink" title="UDAF - 强类型"></a>UDAF - 强类型</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Dataset</span>, <span class="type">Encoder</span>, <span class="type">Encoders</span>, <span class="type">SparkSession</span>, <span class="type">TypedColumn</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Aggregator</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">UDAF02</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"myudaf"</span>)</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(conf).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.json(<span class="string">"input/user.json"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//封装为DataSet</span></span><br><span class="line">    <span class="keyword">val</span> ds: <span class="type">Dataset</span>[<span class="type">User01</span>] = df.as[<span class="type">User01</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建聚合函数</span></span><br><span class="line">    <span class="keyword">var</span> myAgeUdtf1 = <span class="keyword">new</span> <span class="type">MyAveragUDAF1</span></span><br><span class="line">    <span class="comment">//将聚合函数转换为查询的列</span></span><br><span class="line">    <span class="keyword">val</span> col: <span class="type">TypedColumn</span>[<span class="type">User01</span>, <span class="type">Double</span>] = myAgeUdtf1.toColumn</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询</span></span><br><span class="line">    ds.select(col).show()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//输入数据类型</span></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User01</span>(<span class="params">username: <span class="type">String</span>, userage: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">//缓存类型</span></span></span><br><span class="line"><span class="class">  <span class="title">case</span> <span class="title">class</span> <span class="title">AgeBuffer</span>(<span class="params">var sum: <span class="type">Long</span>, var count: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">/**</span></span></span><br><span class="line"><span class="class">    <span class="title">*</span> <span class="title">定义类继承org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">sql</span>.<span class="title">expressions</span>.<span class="title">Aggregator</span></span></span><br><span class="line"><span class="class">    <span class="title">*</span> <span class="title">重写类中的方法</span></span></span><br><span class="line"><span class="class">    <span class="title">*/</span></span></span><br><span class="line"><span class="class">  <span class="title">class</span> <span class="title">MyAveragUDAF1</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">User01</span>, <span class="type">AgeBuffer</span>, <span class="type">Double</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">      <span class="type">AgeBuffer</span>(<span class="number">0</span>L, <span class="number">0</span>L)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(b: <span class="type">AgeBuffer</span>, a: <span class="type">User01</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">      b.sum = b.sum + a.userage</span><br><span class="line">      b.count = b.count + <span class="number">1</span></span><br><span class="line">      b</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">AgeBuffer</span>, b2: <span class="type">AgeBuffer</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">      b1.sum = b1.sum + b2.sum</span><br><span class="line">      b1.count = b1.count + b2.count</span><br><span class="line">      b1</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(buff: <span class="type">AgeBuffer</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">      buff.sum.toDouble / buff.count</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//DataSet默认额编解码器，用于序列化，固定写法</span></span><br><span class="line">    <span class="comment">//自定义类型就是produce   自带类型根据类型选择</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">AgeBuffer</span>] = &#123;</span><br><span class="line">      <span class="type">Encoders</span>.product</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Double</span>] = &#123;</span><br><span class="line">      <span class="type">Encoders</span>.scalaDouble</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>输出：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">+<span class="comment">-----------------------------------------------------+</span></span><br><span class="line">|MyAveragUDAF1(com.atguigu.sparksql.UDAF_qiang$User01)|</span><br><span class="line">+<span class="comment">-----------------------------------------------------+</span></span><br><span class="line">|                                                 30.0|</span><br><span class="line">+<span class="comment">-----------------------------------------------------+</span></span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>spark</tag>
        <tag>sparksql</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap文章推荐</title>
    <url>/2020/04/30/HashMap%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h1 id="HashMap文章推荐"><a href="#HashMap文章推荐" class="headerlink" title="HashMap文章推荐"></a>HashMap文章推荐</h1><p><a href="https://zhuanlan.zhihu.com/p/21673805" target="_blank" rel="noopener">Java 8系列之重新认识HashMap</a></p>
<p>【强烈推荐】来自<strong>美团技术团队</strong>，里面的参考文章也非常好</p>
<p><a href="https://zhuanlan.zhihu.com/p/96426441" target="_blank" rel="noopener">《吊打面试官》系列-HashMap</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/97902016" target="_blank" rel="noopener">《吊打面试官》系列-ConcurrentHashMap &amp; HashTable</a></p>
<p>来自敖丙（蘑菇街大佬），从面试官角度阐述关键技术点，十分硬核，全是干货。</p>
<p><a href="https://zhuanlan.zhihu.com/p/125628540" target="_blank" rel="noopener">一个HashMap跟面试官扯了半个小时</a></p>
<p>面试者角度阐述HashMap。</p>
<p>有空闲时间的话，我自己也会出一篇，甚至是一系列的HashMap文章，</p>
<p>比如</p>
<ul>
<li>源码分析，</li>
<li>知识点总结，</li>
<li>常考面试题归档 等等</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
        <tag>hashmap</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Java IO相关总结归纳</title>
    <url>/2020/04/29/Java-IO%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%BD%92%E7%BA%B3/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>[spark]十一种方式实现WordCount</title>
    <url>/2020/04/27/spark-%E5%8D%81%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0WordCount/</url>
    <content><![CDATA[<h1 id="Spark-十一种方式实现WordCount"><a href="#Spark-十一种方式实现WordCount" class="headerlink" title="[Spark]十一种方式实现WordCount"></a>[Spark]十一种方式实现WordCount</h1><p>使用Spark中的11种方法实现经典的WordCount算法。</p>
<p>其中，10种SparkRDD（算子）+ 1种自定义累加器实现。</p>
<blockquote>
<p>特朗普：没人比我更懂WordCount！（滑稽）</p>
</blockquote>
<h2 id="Why-WordCount？"><a href="#Why-WordCount？" class="headerlink" title="Why WordCount？"></a>Why WordCount？</h2><ul>
<li>大数据中最经典的算法，相当于编程语言中的“Hello World”。</li>
<li>在大数据处理中，大多数复杂的问题通常被拆分成一个个小问题，这些小问题一般都是基于WordCount算法。所以，WordCount是重中之重，是大数据处理算法的基石。</li>
</ul>
<h2 id="10种Spark算子实现"><a href="#10种Spark算子实现" class="headerlink" title="10种Spark算子实现"></a>10种Spark算子实现</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * spark-使用十种[算子]实现wordcount</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RDDWordcount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"spark"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line">    <span class="comment">//    val rdd = sc.textFile("input/wc.txt").flatMap(datas =&gt; &#123;</span></span><br><span class="line">    <span class="comment">//      datas.split(" ")</span></span><br><span class="line">    <span class="comment">//    &#125;)</span></span><br><span class="line">    <span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">List</span>(<span class="string">"hadoop"</span>, <span class="string">"hello"</span>, <span class="string">"spark"</span>, <span class="string">"hello"</span>, <span class="string">"scala"</span>, <span class="string">"hello"</span>, <span class="string">"scala"</span>, <span class="string">"spark"</span>))</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================1===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.countByValue().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================2===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).countByKey().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================3===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).reduceByKey(_ + _).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================4===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).groupByKey().mapValues(_.size).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================5===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).aggregateByKey(<span class="number">0</span>)(_ + _, _ + _).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================6===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).foldByKey(<span class="number">0</span>)(_ + _).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================7===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).combineByKey(</span><br><span class="line">      (num: <span class="type">Int</span>) =&gt; num,</span><br><span class="line">      (x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">        x + y</span><br><span class="line">      &#125;,</span><br><span class="line">      (x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">        x + y</span><br><span class="line">      &#125;</span><br><span class="line">    ).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================8===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map((_, <span class="number">1</span>)).groupBy(_._1).map(kv =&gt; &#123;</span><br><span class="line">      (kv._1, kv._2.size)</span><br><span class="line">    &#125;).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================9===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.aggregate(mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]())(</span><br><span class="line">      (map, word) =&gt; &#123;</span><br><span class="line">        map(word) = map.getOrElse(word, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        map</span><br><span class="line">      &#125;,</span><br><span class="line">      (map1, map2) =&gt; &#123;</span><br><span class="line">        map1.foldLeft(map2)(</span><br><span class="line">          (finalMap, kv) =&gt; &#123;</span><br><span class="line">            finalMap(kv._1) = finalMap.getOrElse(kv._1, <span class="number">0</span>) + kv._2</span><br><span class="line">            finalMap</span><br><span class="line">          &#125;</span><br><span class="line">        )</span><br><span class="line">      &#125;</span><br><span class="line">    ).foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"=================10===================="</span>)</span><br><span class="line"></span><br><span class="line">    rdd.map(s =&gt; mutable.<span class="type">Map</span>(s -&gt; <span class="number">1</span>)).fold(mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]())(</span><br><span class="line">      (map1, map2) =&gt; &#123;</span><br><span class="line">        map1.foldLeft(map2)(</span><br><span class="line">          (finalMap, kv) =&gt; &#123;</span><br><span class="line">            finalMap(kv._1) = finalMap.getOrElse(kv._1, <span class="number">0</span>) + kv._2</span><br><span class="line">            finalMap</span><br><span class="line">          &#125;</span><br><span class="line">        )</span><br><span class="line">      &#125;</span><br><span class="line">    ).foreach(println)</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>输出结果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">=================<span class="number">1</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">2</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">3</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">4</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">5</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">6</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">7</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">8</span>====================</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">=================<span class="number">9</span>====================</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">(hello,<span class="number">3</span>)</span><br><span class="line">=================<span class="number">10</span>====================</span><br><span class="line">(hadoop,<span class="number">1</span>)</span><br><span class="line">(spark,<span class="number">2</span>)</span><br><span class="line">(scala,<span class="number">2</span>)</span><br><span class="line">(hello,<span class="number">3</span>)</span><br></pre></td></tr></table></figure></div>

<h2 id="自定义累加器实现"><a href="#自定义累加器实现" class="headerlink" title="自定义累加器实现"></a>自定义累加器实现</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.util.<span class="type">AccumulatorV2</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyAccTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"acc"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO Spark - 自定义累加器 - wordcount</span></span><br><span class="line">    <span class="comment">// 累加器可以不使用shuffle就完成数据的聚合功能</span></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.makeRDD(<span class="type">List</span>(<span class="string">"hadoop spark"</span>, <span class="string">"hello"</span>, <span class="string">"spark"</span>, <span class="string">"hello"</span>, <span class="string">"scala"</span>, <span class="string">"hello"</span>, <span class="string">"scala"</span>, <span class="string">"spark"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 1. 创建累加器</span></span><br><span class="line">    <span class="keyword">val</span> acc = <span class="keyword">new</span> <span class="type">WordCountAccumulator</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 2. 向Spark注册累加器</span></span><br><span class="line">    sc.register(acc, <span class="string">"wordcount"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 3. 使用累加器</span></span><br><span class="line">    rdd.foreach(</span><br><span class="line">      words =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> ws = words.split(<span class="string">" "</span>)</span><br><span class="line">        ws.foreach(</span><br><span class="line">          word =&gt; &#123;</span><br><span class="line">            acc.add(word)</span><br><span class="line">          &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    println(acc.value) <span class="comment">//Map(hadoop -&gt; 1, spark -&gt; 3, scala -&gt; 2, hello -&gt; 3)</span></span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 自定义累加器 Map&#123;(Word - Count), (Word - Count)&#125;</span></span><br><span class="line">  <span class="comment">// 1, 继承AccumulatorV2, 定义泛型</span></span><br><span class="line">  <span class="comment">//    IN :  向累加器传递的值的类型 , Out : 累加器的返回结果类型</span></span><br><span class="line">  <span class="comment">// 2. 重写方法</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">WordCountAccumulator</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> innerMap = mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 累加器是否初始化</span></span><br><span class="line">    <span class="comment">// Z</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = innerMap.isEmpty</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 复制累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]] = &#123;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">WordCountAccumulator</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 重置累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      innerMap.clear()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 累加数据</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(word: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> cnt = innerMap.getOrElse(word, <span class="number">0</span>)</span><br><span class="line">      innerMap.update(word, cnt + <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 合并累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">// 两个Map的合并</span></span><br><span class="line">      <span class="keyword">var</span> map1 = <span class="keyword">this</span>.innerMap</span><br><span class="line">      <span class="keyword">var</span> map2 = other.value</span><br><span class="line"></span><br><span class="line">      innerMap = map1.foldLeft(map2)(</span><br><span class="line">        (map, kv) =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> k = kv._1</span><br><span class="line">          <span class="keyword">val</span> v = kv._2</span><br><span class="line">          map(k) = map.getOrElse(k, <span class="number">0</span>) + v</span><br><span class="line">          map</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 获取累加器的值，就是累加器的返回结果</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = innerMap</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>输出结果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">Map</span>(spark -&gt; <span class="number">3</span>, hadoop -&gt; <span class="number">1</span>, scala -&gt; <span class="number">2</span>, hello -&gt; <span class="number">3</span>)</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>大数据</category>
        <category>spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>spark</tag>
        <tag>scala</tag>
        <tag>wordcount</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka高效读写数据</title>
    <url>/2020/04/27/kafka%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="kafka高效读写数据"><a href="#kafka高效读写数据" class="headerlink" title="kafka高效读写数据"></a>kafka高效读写数据</h1><h2 id="一、分布式集群"><a href="#一、分布式集群" class="headerlink" title="一、分布式集群"></a>一、分布式集群</h2><p>Kafka本身是分布式集群；同时采用分区技术，并发度高。  </p>
<blockquote>
<p>zookeeper在kafka中的作用：kafka集群中有一个broker会被选举成controller，负责管理集群broker的上下线，所有的topic分区副本分配和leader选举等工作。controller的管理工作都依赖于zk。</p>
</blockquote>
<h2 id="二、顺序写磁盘"><a href="#二、顺序写磁盘" class="headerlink" title="二、顺序写磁盘"></a>二、顺序写磁盘</h2><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<h2 id="三、零复制技术"><a href="#三、零复制技术" class="headerlink" title="三、零复制技术"></a>三、零复制技术</h2><p>kafka零复制技术示意图：</p>
<p><a href="https://pic.downk.cc/item/5ea7012ec2a9a83be5e629f2.png" data-fancybox="group" data-caption="kafka零拷贝技术" class="fancybox"><img alt="kafka零拷贝技术" title="kafka零拷贝技术" data-src="https://pic.downk.cc/item/5ea7012ec2a9a83be5e629f2.png" class="lazyload"></a></p>
<p>java复制技术示意图：</p>
<p>（仅仅复制文件，没有对于文件的应用，效率很低。</p>
<p>文件要经过操作系统层（OS层）Buffer缓存传给java应用层输入流，输入流再将数据写到输出流，输出流将数据写到OS层缓存，缓存在将数据写到新的文件。。。）</p>
<p><a href="https://pic.downk.cc/item/5ea701a6c2a9a83be5e6b749.png" data-fancybox="group" data-caption="java拷贝技术原理图解" class="fancybox"><img alt="java拷贝技术原理图解" title="java拷贝技术原理图解" data-src="https://pic.downk.cc/item/5ea701a6c2a9a83be5e6b749.png" class="lazyload"></a></p>
<p>因为java复制技术在拷贝文件时效率较低，所以对上图做出优化，如下图所示：</p>
<p>（应用层通知操作系统层：仅仅是复制文件，所以操作系统层就不会将数据传给应用层，直接在操作系统层复制文件即可。）</p>
<p><a href="https://pic.downk.cc/item/5ea701c6c2a9a83be5e6e1e8.png" data-fancybox="group" data-caption="零拷贝技术图解" class="fancybox"><img alt="零拷贝技术图解" title="零拷贝技术图解" data-src="https://pic.downk.cc/item/5ea701c6c2a9a83be5e6e1e8.png" class="lazyload"></a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>flume总结与思考</title>
    <url>/2020/04/24/%E7%B2%BE-flume%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>大数据</category>
        <category>flume</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>教程</tag>
        <tag>大数据</tag>
        <tag>面试</tag>
        <tag>flume</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka分区分配策略</title>
    <url>/2020/04/23/kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h1 id="kafka分区分配策略"><a href="#kafka分区分配策略" class="headerlink" title="kafka分区分配策略"></a>kafka分区分配策略</h1><p>kafka系列总结之：kafka分区分配策略[转载&amp;归纳]</p>
<ul>
<li>kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。</li>
<li>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据 </li>
</ul>
<p>kafka官网：</p>
<blockquote>
<p>kafka.apache.org</p>
</blockquote>
<p>kafka分区分配策略文章索引</p>
<p>1、 <a href="https://blog.csdn.net/u013256816/article/details/81123600" target="_blank" rel="noopener">Kafka分区分配策略（1）——RangeAssignor</a></p>
<p>2、 <a href="https://blog.csdn.net/u013256816/article/details/81123625" target="_blank" rel="noopener">Kafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor</a></p>
<p>3、 <a href="https://blog.csdn.net/u013256816/article/details/81123858" target="_blank" rel="noopener">Kafka分区分配策略（3）——自定义分区分配策略</a> </p>
<p>4、 <a href="https://blog.csdn.net/u013256816/article/details/81123907" target="_blank" rel="noopener">Kafka分区分配策略（4）——分配的实施</a></p>
<blockquote>
<p>[注]作者为 《深入理解Kafka:核心设计与实践原理》 的作者：朱忠华老师</p>
<p>作者更多kafka技术文章： <a href="https://blog.csdn.net/u013256816/category_6500871.html" target="_blank" rel="noopener">https://blog.csdn.net/u013256816/category_6500871.html</a> </p>
<p>作者个人博客： <a href="http://honeypps.com/" target="_blank" rel="noopener">http://honeypps.com/</a></p>
<p>作者CSDN博客： <a href="https://blog.csdn.net/u013256816" target="_blank" rel="noopener">https://blog.csdn.net/u013256816</a> </p>
</blockquote>
]]></content>
      <categories>
        <category>大数据</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>大数据</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>scala中的flatMap和foldLeft函数</title>
    <url>/2020/04/21/scala%E4%B8%AD%E7%9A%84flatMap%E5%92%8CfoldLeft%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="scala中的flatMap和foldLeft函数"><a href="#scala中的flatMap和foldLeft函数" class="headerlink" title="scala中的flatMap和foldLeft函数"></a>scala中的flatMap和foldLeft函数</h1><p>scala由于其函数式编程的特性，在大数据的处理中被广泛使用。</p>
<p>此文针对scala集合中两个常用的，却不太好理解的函数进行示例讲解。</p>
<h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><p>scala中最重要的函数之一，映射扁平化</p>
<p>把握以下三点即可：</p>
<blockquote>
<p>1、flatMap = map + flatten</p>
<p>2、什么类型调用的flatMap方法，则返回的也是什么类型</p>
<p>3、<strong>先对集合中的每个元素进行map，</strong></p>
<p>​      <strong>再对map后的每个元素（map后的每个元素必须还是集合）中的每个元素进行flatten</strong></p>
</blockquote>
<p>[注] 进行map的对象可以是只含一层的集合，但进行flatten操作的对象必需是至少含两层的集合</p>
<p>map和flatten示例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test0001</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    <span class="comment">// 集合映射</span></span><br><span class="line">    println(<span class="string">"map =&gt; "</span> + list.map(x=&gt;&#123;x*<span class="number">2</span>&#125;)) <span class="comment">//map =&gt; List(2, 4, 6, 8)</span></span><br><span class="line">    println(<span class="string">"map =&gt; "</span> + list.map(x=&gt;x*<span class="number">2</span>))   <span class="comment">//map =&gt; List(2, 4, 6, 8)</span></span><br><span class="line">    println(<span class="string">"map =&gt; "</span> + list.map(_*<span class="number">2</span>))      <span class="comment">//map =&gt; List(2, 4, 6, 8)</span></span><br><span class="line">    <span class="comment">// 集合扁平化</span></span><br><span class="line">    <span class="keyword">val</span> list1 = <span class="type">List</span>(</span><br><span class="line">      <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">      <span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    )</span><br><span class="line">    println(<span class="string">"flatten =&gt;"</span> + list1.flatten)   <span class="comment">//flatten =&gt;List(1, 2, 3, 4)</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>flatMap示例一：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> words = <span class="type">Set</span>(<span class="string">"scala"</span>, <span class="string">"spark"</span>, <span class="string">"hadoop"</span>)</span><br><span class="line"><span class="keyword">val</span> result = words.flatMap(x =&gt; x.toUpperCase)</span><br><span class="line">println(result)  <span class="comment">//Set(A, L, P, C, H, K, R, O, D, S)</span></span><br></pre></td></tr></table></figure></div>

<p>flatMap示例二：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> tuples: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">List</span>((<span class="string">"Hello Scala"</span>, <span class="number">4</span>), (<span class="string">"Hello Spark"</span>, <span class="number">2</span>))</span><br><span class="line"><span class="keyword">val</span> strings: <span class="type">List</span>[<span class="type">String</span>] = tuples.map(t=&gt;&#123;(t._1+<span class="string">" "</span>)*t._2&#125;)</span><br><span class="line"><span class="comment">//List(Hello Scala Hello Scala Hello Scala Hello Scala , Hello Spark Hello Spark )</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> flatMapList: <span class="type">List</span>[<span class="type">String</span>] = strings.flatMap(t=&gt;&#123;t.split(<span class="string">" "</span>)&#125;)</span><br><span class="line"><span class="comment">//List(Hello, Scala, Hello, Scala, Hello, Scala, Hello, Scala, Hello, Spark, Hello, Spark)</span></span><br></pre></td></tr></table></figure></div>

<p>flatMap示例三：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> linesList = <span class="type">List</span>((<span class="string">"Hello Scala"</span>, <span class="number">4</span>), (<span class="string">"Hello Spark"</span>, <span class="number">2</span>))</span><br><span class="line"><span class="keyword">val</span> flatMapList: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = linesList.flatMap(t =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> line: <span class="type">String</span> = t._1</span><br><span class="line">    <span class="keyword">val</span> words = line.split(<span class="string">" "</span>)</span><br><span class="line">    words.map(w =&gt; (w, t._2))</span><br><span class="line">&#125;)</span><br><span class="line">println(flatMapList)  <span class="comment">//List((Hello,4), (Scala,4), (Hello,2), (Spark,2))</span></span><br></pre></td></tr></table></figure></div>

<p>根据上述三个原则即可算出函数结果。</p>
<h2 id="foldLeft"><a href="#foldLeft" class="headerlink" title="foldLeft"></a>foldLeft</h2><p>集合折叠函数，fold、foldRight底层都是基于foldLeft函数。</p>
<p>所以本文用到的函数可以不用严格区分，主要阐述其原理。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fold</span></span>[<span class="type">A1</span> &gt;: <span class="type">A</span>](z: <span class="type">A1</span>)(op: (<span class="type">A1</span>, <span class="type">A1</span>) =&gt; <span class="type">A1</span>): <span class="type">A1</span> = foldLeft(z)(op)</span><br></pre></td></tr></table></figure></div>

<p>就是将集合的数据和集合之外的数据进行聚合操作。</p>
<p>fold方法有函数柯里化，有2个参数列表</p>
<ul>
<li><p>第一个参数列表：集合之外的数据</p>
</li>
<li><p>第二个参数列表：表示计算规则</p>
</li>
</ul>
<p>fold示例一：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment">// 集合折叠</span></span><br><span class="line">println(<span class="string">"fold =&gt; "</span> + list.fold(<span class="number">0</span>)(_+_))    <span class="comment">//10</span></span><br><span class="line"><span class="comment">// 集合折叠(左)</span></span><br><span class="line">println(<span class="string">"foldLeft =&gt; "</span> + list.foldLeft(<span class="number">0</span>)(_+_)) <span class="comment">//10</span></span><br></pre></td></tr></table></figure></div>

<p>  fold示例二：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Scala21_Collection_Method4</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 将两个Map集合进行合并(merge)处理</span></span><br><span class="line">    <span class="keyword">val</span> map1 = mutable.<span class="type">Map</span>(<span class="string">"a"</span> -&gt; <span class="number">1</span>, <span class="string">"b"</span> -&gt; <span class="number">2</span>, <span class="string">"c"</span> -&gt; <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">val</span> map2 = mutable.<span class="type">Map</span>(<span class="string">"a"</span> -&gt; <span class="number">4</span>, <span class="string">"d"</span> -&gt; <span class="number">5</span>, <span class="string">"c"</span> -&gt; <span class="number">6</span>)</span><br><span class="line">    <span class="comment">// Map( "a"-&gt;5, "b"-&gt;2, "c"-&gt;9 ,"d"-&gt;5)</span></span><br><span class="line">    <span class="keyword">val</span> map3 = map2.foldLeft(map1)(</span><br><span class="line">      (map, kv) =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> k = kv._1</span><br><span class="line">        <span class="keyword">val</span> v = kv._2</span><br><span class="line">        <span class="comment">//map.update(k, map.getOrElse(k, 0) + v)</span></span><br><span class="line">        map(k) = map.getOrElse(k, <span class="number">0</span>) + v</span><br><span class="line">        map</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    println(map3) <span class="comment">//Map(b -&gt; 2, d -&gt; 5, a -&gt; 5, c -&gt; 9)</span></span><br><span class="line">    </span><br><span class="line">    println(map1) <span class="comment">//Map(b -&gt; 2, d -&gt; 5, a -&gt; 5, c -&gt; 9)</span></span><br><span class="line">    println(map2) <span class="comment">//Map(d -&gt; 5, a -&gt; 4, c -&gt; 6)</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>原理示意图如下：</p>
<p><a href="https://pic.downk.cc/item/5e9f0b95c2a9a83be5c27ef7.png" data-fancybox="group" data-caption="folfLeft原理图" class="fancybox"><img alt="folfLeft原理图" title="folfLeft原理图" data-src="https://pic.downk.cc/item/5e9f0b95c2a9a83be5c27ef7.png" class="lazyload"></a></p>
<p><strong>总结：</strong></p>
<p><strong>其实，在foldleft函数中，第二个参数规定的就是，</strong></p>
<p><strong>foldleft第一个参数和foldleft调用者的第一个元素的运算规则</strong></p>
<p>可以用如下公式理解：</p>
<blockquote>
<p>a. foldLeft( b )( (b,a的第一个元素)=&gt;{} )</p>
</blockquote>
<p>（对应上面示意图：红色块为b，蓝色块为a）</p>
<p>只不过在此公式中b和a的第一个元素都是动态变化的：</p>
<p>​    b一直在迭代，a会继续往后顺序取后面的值。</p>
<p>​    <strong>其实函数最终返回值就是b的值（上面的例子map1和map3相等也能证明这一点，本质就是map1把值赋给了map3），且a不发生改变。</strong></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>scala</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Java空指针问题的本质</title>
    <url>/2020/04/18/Java%E7%A9%BA%E6%8C%87%E9%92%88%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%AC%E8%B4%A8/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题：sleep和wait的区别</title>
    <url>/2020/04/14/sleep%E5%92%8Cwait%E7%9A%84%E5%8C%BA%E5%88%AB%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="Java中sleep和wait方法的区别"><a href="#Java中sleep和wait方法的区别" class="headerlink" title="Java中sleep和wait方法的区别"></a>Java中sleep和wait方法的区别</h1><p> sleep和wait都能使线程处于阻塞状态，但二者有着本质区别。 </p>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">test_thread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread();</span><br><span class="line">        Thread t2 = <span class="keyword">new</span> Thread();</span><br><span class="line">        <span class="comment">//【本质区别】静态方法和成员方法</span></span><br><span class="line">        <span class="comment">//【静态方法】，绑定的是类。休眠的线程不是t1，是当前运行的main线程</span></span><br><span class="line">        <span class="comment">//和对象都没有关系，所以不存在什么对象锁</span></span><br><span class="line">        t1.sleep(<span class="number">1000</span>);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//【成员方法】，等待的线程就是t2</span></span><br><span class="line">        <span class="comment">//有同步/synchronized关键字才能拿到对象锁。</span></span><br><span class="line">        t2.wait();</span><br><span class="line">        t2.wait(<span class="number">1000</span>);<span class="comment">//wait也可以加等待时间</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//【扩展】scala中的伴生对象就是对静态语法的模拟</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>【核心】静态方法、成员方法<ol>
<li>sleep是Thread类的静态方法。sleep的作用是让线程休眠道制定的时间，在时间到达时恢复，也就是说sleep将在接到时间到达事件事恢复线程执行。</li>
<li>wait是Object的方法，也就是说可以对任意一个对象调用wait方法，调用wait方法将会属将调用者的线程挂起，直到其他线程调用同一个对象的notify方法才会重新激活调用者。 </li>
</ol>
</li>
<li>sleep方法没有释放锁（lock），而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。 </li>
<li>【使用范围】<ol>
<li>wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，</li>
<li>而sleep可以在任何地方使用</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Git使用小结</title>
    <url>/2020/04/13/Git%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="Git使用小结"><a href="#Git使用小结" class="headerlink" title="Git使用小结"></a>Git使用小结</h1><p>小结Git常用指令，以及如何将本地代码同步/更新到Github的常用指令</p>
<h2 id="一、初始配置"><a href="#一、初始配置" class="headerlink" title="一、初始配置"></a>一、初始配置</h2><p>git安装完成后，需要设置一下，在命令行输入 </p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name &quot;Your Name&quot;</span><br><span class="line">$ git config --global user.email &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure></div>

<p> <strong>–global</strong>参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 </p>
<h2 id="二、常用指令"><a href="#二、常用指令" class="headerlink" title="二、常用指令"></a>二、常用指令</h2><p>进入到自己的项目文件下右键选择Git Bash Here打开git客户端 </p>
<p>初始化项目：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure></div>

<p>将文件添加到本地仓库：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add</span><br></pre></td></tr></table></figure></div>

<p>将文件提交到仓库</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git commit -m &quot;注释内容&quot;</span><br></pre></td></tr></table></figure></div>

<p>关联远程项目（你的远程仓库地址）</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git remote add origin https:&#x2F;&#x2F;github.com&#x2F;xxxx&#x2F;xxx.git</span><br></pre></td></tr></table></figure></div>

<p>本地推送到远程（ <strong>第一次</strong>推送<strong>master分支</strong>的所有内容）</p>
<blockquote>
<p>由于远程库是空的，我们第一次推送<code>master</code>分支时，加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的<code>master</code>分支关联起来，在以后的推送或者拉取时就可以简化命令。 </p>
</blockquote>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure></div>

<p>查看Git状态</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure></div>

<h2 id="三、更新文件到Github"><a href="#三、更新文件到Github" class="headerlink" title="三、更新文件到Github"></a>三、更新文件到Github</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add</span><br><span class="line">git commit -m &quot;注释内容&quot;</span><br><span class="line">git pull origin master   #从远程抓取分支，使用git pull，如果有冲突，要先处理冲突</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure></div>

<p> 查看远程库信息：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>会显示可以抓取和推送的<code>origin</code>的地址。如果没有推送权限，就看不到push的地址。 </p>
</blockquote>
]]></content>
      <categories>
        <category>Git&amp;Github</category>
      </categories>
      <tags>
        <tag>Git&amp;Github</tag>
      </tags>
  </entry>
  <entry>
    <title>关于i=i++的分析与思考</title>
    <url>/2020/04/11/%E5%85%B3%E4%BA%8Ei-i-%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>关于HashMap的两道小面试题</title>
    <url>/2020/04/11/%E5%85%B3%E4%BA%8EHashMap%E7%9A%84%E4%B8%A4%E9%81%93%E5%B0%8F%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>String_StringBuffer_StringBuilder分析总结</title>
    <url>/2020/04/11/String_StringBuffer_StringBuilder%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="String-StringBuffer-StringBuilder分析总结"><a href="#String-StringBuffer-StringBuilder分析总结" class="headerlink" title="String_StringBuffer_StringBuilder分析总结"></a>String_StringBuffer_StringBuilder分析总结</h1><p>本文对Java语言中的String，StringBuffer，StringBuilder类进行分析对比，</p>
<p>并String类型进行简单原理分析。</p>
<h2 id="String，StringBuffer，StringBuilder的区别"><a href="#String，StringBuffer，StringBuilder的区别" class="headerlink" title="String，StringBuffer，StringBuilder的区别"></a>String，StringBuffer，StringBuilder的区别</h2><p><strong>1、可变与不可变</strong></p>
<p>　　String类中使用字符数组保存字符串，如下就是，因为有“final”修饰符，所以可以知道string对象是不可变的。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">char</span> value[];</span><br></pre></td></tr></table></figure></div>

<p>　　StringBuilder与StringBuffer都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，如下就是，可知这两种对象都是可变的。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] value;</span><br></pre></td></tr></table></figure></div>

<p><strong>2、是否多线程安全</strong></p>
<p>　　String中的对象是不可变的，也就可以理解为常量，<strong>显然线程安全</strong>。</p>
<p>　　AbstractStringBuilder是StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作，如expandCapacity、append、insert、indexOf等公共方法。</p>
<p>　　StringBuilder并没有对方法进行加同步锁，所以是<strong>非线程安全的</strong>。 </p>
<p>​        StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是<strong>线程安全的</strong>。看如下源码：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> StringBuffer <span class="title">reverse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.reverse();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> indexOf(str, <span class="number">0</span>);        <span class="comment">//存在 public synchronized int indexOf(String str, int fromIndex) 方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><strong>3、StringBuilder与StringBuffer共同点</strong></p>
<p>　　StringBuilder与StringBuffer有公共父类AbstractStringBuilder(<strong>抽象类</strong>)。</p>
<p>　　抽象类与接口的其中一个区别是：抽象类中可以定义一些子类的公共方法，子类只需要增加新的功能，不需要重复写已经存在的方法；而接口中只是对方法的申明和常量的定义。</p>
<p>　　StringBuilder、StringBuffer的方法都会调用AbstractStringBuilder中的公共方法，如super.append(…)。只是StringBuffer会在方法上加synchronized关键字，进行同步。</p>
<p>　　如果程序不是多线程的，那么使用StringBuilder效率高于StringBuffer。</p>
<h2 id="String相关"><a href="#String相关" class="headerlink" title="String相关"></a>String相关</h2><p>String类<strong>部分</strong>源码：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span></span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span>, <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;, <span class="title">CharSequence</span> </span>&#123;</span><br><span class="line">    <span class="comment">/** The value is used for character storage. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">char</span> value[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Cache the hash code for the string */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> hash; <span class="comment">// Default to 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/** use serialVersionUID from JDK 1.0.2 for interoperability */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6849794470754667710L</span>;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = <span class="string">""</span>.value;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(String original)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = original.value;</span><br><span class="line">        <span class="keyword">this</span>.hash = original.hash;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">(<span class="keyword">char</span> value[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.value = Arrays.copyOf(value, value.length);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> h = hash;</span><br><span class="line">        <span class="keyword">if</span> (h == <span class="number">0</span> &amp;&amp; value.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">char</span> val[] = value;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; value.length; i++) &#123;</span><br><span class="line">                h = <span class="number">31</span> * h + val[i];</span><br><span class="line">            &#125;</span><br><span class="line">            hash = h;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> h;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<p>说明：</p>
<ul>
<li>private final char value[];说明String不可变</li>
<li>其实不可变指的是其<strong>字符串内容</strong>不可变，<strong>字符串对象</strong>的地址其实是可以改变的，示例如下：</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String a = <span class="string">"ABCabc"</span>;</span><br><span class="line">System.out.println(<span class="string">"a = "</span> + a);  <span class="comment">//a = ABCabc</span></span><br><span class="line">a = a.replace(<span class="string">'A'</span>, <span class="string">'a'</span>);</span><br><span class="line">System.out.println(<span class="string">"a = "</span> + a);  <span class="comment">//a = aBCabc</span></span><br></pre></td></tr></table></figure></div>

<p>​        这个例子的本质是，字符串对象a指向了一个新的字符串数组。</p>
<ul>
<li>如果真的要去修改String内容的话，其实也是可以的，使用<strong>反射</strong>机制就可以实现，示例如下：</li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testReflection</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//创建字符串"Hello World"， 并赋给引用s</span></span><br><span class="line">    String s = <span class="string">"Hello World"</span>; </span><br><span class="line">     </span><br><span class="line">    System.out.println(<span class="string">"s = "</span> + s); <span class="comment">//Hello World</span></span><br><span class="line">     </span><br><span class="line">    <span class="comment">//获取String类中的value字段</span></span><br><span class="line">    Field valueFieldOfString = String.class.getDeclaredField("value");</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//改变value属性的访问权限</span></span><br><span class="line">    valueFieldOfString.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//获取s对象上的value属性的值</span></span><br><span class="line">    <span class="keyword">char</span>[] value = (<span class="keyword">char</span>[]) valueFieldOfString.get(s);</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//改变value所引用的数组中的第5个字符</span></span><br><span class="line">    value[<span class="number">5</span>] = <span class="string">'_'</span>;</span><br><span class="line">     </span><br><span class="line">    System.out.println(<span class="string">"s = "</span> + s);  <span class="comment">//Hello_World</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="参考博客："><a href="#参考博客：" class="headerlink" title="参考博客："></a>参考博客：</h2><blockquote>
<p><a href="https://www.cnblogs.com/leskang/p/6110631.html" target="_blank" rel="noopener">https://www.cnblogs.com/leskang/p/6110631.html</a> </p>
<p><a href="https://www.cnblogs.com/xudong-bupt/p/3961159.html" target="_blank" rel="noopener">https://www.cnblogs.com/xudong-bupt/p/3961159.html</a> </p>
</blockquote>
]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中final关键字小结</title>
    <url>/2020/04/10/Java%E4%B8%ADfinal%E5%85%B3%E9%94%AE%E5%AD%97%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="Java中final关键字小结"><a href="#Java中final关键字小结" class="headerlink" title="Java中final关键字小结"></a>Java中final关键字小结</h1><h2 id="一、final、finally、finalize的区别"><a href="#一、final、finally、finalize的区别" class="headerlink" title="一、final、finally、finalize的区别"></a>一、final、finally、finalize的区别</h2><p>final：</p>
<blockquote>
<p>修饰符（关键字）有三种用法：修饰类、变量和方法。</p>
<p>修饰类时，意味着它不能再派生出新的子类，即不能被继承，因此它和 abstract 是反义词。</p>
<p>修饰变量时，该变量使用中不被改变，必须在声明时给定初值，在引用中只能读取不可修改，即为常量。（下一节代码示例）</p>
<p>修饰方法时，也同样只能使用，不能在子类中被重写。 </p>
</blockquote>
<p>finally:</p>
<blockquote>
<p>通常放在 try…catch 的后面构造最终执行代码块，这就意味着程序无论正常执行还是发生异常，这里的代码只要 JVM 不关闭都能执行，可以将释放外部资源的代码写在finally块中。</p>
</blockquote>
<p>finalize：</p>
<blockquote>
<p>Object 类中定义的方法。</p>
<p>Java 中允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。</p>
<p>这个方法是由垃圾收集器在销毁对象时调用的，通过重写 finalize() 方法可以整理系统资源或者执行其他清理工作。</p>
</blockquote>
<h2 id="二、代码示例"><a href="#二、代码示例" class="headerlink" title="二、代码示例"></a>二、代码示例</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">zd_important_test_nbst</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        UserTest userTest = <span class="keyword">new</span> UserTest();</span><br><span class="line">        System.out.println(userTest.getA());</span><br><span class="line">        UserTest userTest1 = <span class="keyword">new</span> UserTest(<span class="number">6</span>);</span><br><span class="line">        System.out.println(userTest1.getA());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserTest</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * final修饰的变量，要么一开始就初始化（饿汉式），要么就在构造方法里初始化（懒汉式）。</span></span><br><span class="line"><span class="comment">     * 一旦初始化完成，就不能修改。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 【String中同样，使用private final修饰char[]】所以String是不可变的。</span></span><br><span class="line"><span class="comment">     * （通过反射可以破坏其不可变性）</span></span><br><span class="line"><span class="comment">     * 其他博客会提到上述内容。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> a;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UserTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>();</span><br><span class="line">        a = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UserTest</span><span class="params">(<span class="keyword">int</span> a)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.a = a;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//会报错，因为a是final</span></span><br><span class="line"><span class="comment">//    public void setA(int b) &#123;</span></span><br><span class="line"><span class="comment">//        this.a = b;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 以下为idea默认生成的hashcode和equals，可忽略</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 在Object的源码中，hashcode是native方法，使用c语言实现的，综合类的信息计算出的hashcode值</span></span><br><span class="line"><span class="comment">     * equals底层就是“==”</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span> == o) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span> || getClass() != o.getClass()) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        UserTest userTest = (UserTest) o;</span><br><span class="line">        <span class="keyword">return</span> a == userTest.a;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hash(a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>


]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java静态代码块的加载时机</title>
    <url>/2020/04/10/Java%E9%9D%99%E6%80%81%E4%BB%A3%E7%A0%81%E5%9D%97%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%97%B6%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="Java静态代码块的加载时机"><a href="#Java静态代码块的加载时机" class="headerlink" title="Java静态代码块的加载时机"></a>Java静态代码块的加载时机</h2><p>在java中，静态代码块其实并不是随着类的加载而加载。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL的执行顺序问题</title>
    <url>/2020/04/10/SQL%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="SQL的执行顺序问题"><a href="#SQL的执行顺序问题" class="headerlink" title="SQL的执行顺序问题"></a>SQL的执行顺序问题</h2><p>众所周知，sql的执行顺序：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">from... where...group by... having....select ... <span class="keyword">order</span> by... <span class="keyword">limit</span></span><br></pre></td></tr></table></figure></div>

<p>但是，有一个“bug”，在 <strong>MySQL</strong> 中：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">COUNT</span>(title) <span class="keyword">AS</span> t <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> title <span class="keyword">HAVING</span> t &gt;= <span class="number">2</span></span><br></pre></td></tr></table></figure></div>

<p>这样的语句是可以执行的。</p>
<p>正常来说，having在select之前执行，但是却可以使用select的别名，这是为什么呢？</p>
<p>查阅了一切资料，做出如下解释：</p>
<h4 id="解释一"><a href="#解释一" class="headerlink" title="解释一"></a>解释一</h4><blockquote>
<p>mysql的处理方式是中间生成虚拟表（或者叫临时表），而这个虚拟表的生成的列靠的就是select。</p>
<p>所以猜测类似having之后的操作，其实内部已经根据select生成了虚拟表，列自然也是as后的。</p>
</blockquote>
<h4 id="解释二"><a href="#解释二" class="headerlink" title="解释二"></a>解释二</h4><blockquote>
<p>之所以MYSQL可以这么做是因为MYSQL用的是临时表，</p>
<p>在having前已经产生了数据，所以可以用别名，但SQL Sever不可以，SQL是在having后才Select。</p>
</blockquote>
]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode经典10道题</title>
    <url>/2020/03/22/LeetCode%E7%BB%8F%E5%85%B810%E9%81%93%E9%A2%98/</url>
    <content><![CDATA[<h1 id="LeetCode题目精选"><a href="#LeetCode题目精选" class="headerlink" title="LeetCode题目精选"></a>LeetCode题目精选</h1><h2 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1. 两数之和"></a>1. 两数之和</h2><p>链接：<a href="https://leetcode-cn.com/problems/two-sum/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/two-sum/</a></p>
<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。</p>
<p>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">给定 nums &#x3D; [2, 7, 11, 15], target &#x3D; 9</span><br><span class="line"></span><br><span class="line">因为 nums[0] + nums[1] &#x3D; 2 + 7 &#x3D; 9</span><br><span class="line">所以返回 [0, 1]</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> complement = target - nums[i];</span><br><span class="line">            <span class="keyword">if</span> (map.containsKey(complement)) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; map.get(complement), i &#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            map.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"No two sum solution"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-爬楼梯"><a href="#2-爬楼梯" class="headerlink" title="2. 爬楼梯"></a>2. 爬楼梯</h2><p>链接：<a href="https://leetcode-cn.com/problems/climbing-stairs/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/climbing-stairs/</a></p>
<p>假设你正在爬楼梯。需要 n 阶你才能到达楼顶。</p>
<p>每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？</p>
<p>注意：给定 n 是一个正整数。</p>
<p>示例 1：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入： 2</span><br><span class="line">输出： 2</span><br><span class="line">解释： 有两种方法可以爬到楼顶。</span><br><span class="line">1.  1 阶 + 1 阶</span><br><span class="line">2.  2 阶</span><br></pre></td></tr></table></figure></div>

<p>示例 2：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入： 3</span><br><span class="line">输出： 3</span><br><span class="line">解释： 有三种方法可以爬到楼顶。</span><br><span class="line">1.  1 阶 + 1 阶 + 1 阶</span><br><span class="line">2.  1 阶 + 2 阶</span><br><span class="line">3.  2 阶 + 1 阶</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (n == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        dp[<span class="number">2</span>] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">3</span>; i &lt;= n; i++) &#123;</span><br><span class="line">            dp[i] = dp[i - <span class="number">1</span>] + dp[i - <span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="3-翻转二叉树"><a href="#3-翻转二叉树" class="headerlink" title="3. 翻转二叉树"></a>3. 翻转二叉树</h2><p>链接：<a href="https://leetcode-cn.com/problems/invert-binary-tree/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/invert-binary-tree/</a></p>
<p>翻转一棵二叉树。</p>
<p>示例：</p>
<p>输入：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">     4</span><br><span class="line">   &#x2F;   \</span><br><span class="line">  2     7</span><br><span class="line"> &#x2F; \   &#x2F; \</span><br><span class="line">1   3 6   9</span><br></pre></td></tr></table></figure></div>

<p>输出：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">     4</span><br><span class="line">   &#x2F;   \</span><br><span class="line">  7     2</span><br><span class="line"> &#x2F; \   &#x2F; \</span><br><span class="line">9   6 3   1</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TreeNode <span class="title">invertTree</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    TreeNode right = invertTree(root.right);</span><br><span class="line">    TreeNode left = invertTree(root.left);</span><br><span class="line">    root.left = right;</span><br><span class="line">    root.right = left;</span><br><span class="line">    <span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="4-反转链表"><a href="#4-反转链表" class="headerlink" title="4. 反转链表"></a>4. 反转链表</h2><p>链接：<a href="https://leetcode-cn.com/problems/reverse-linked-list/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-linked-list/</a></p>
<p>反转一个单链表。</p>
<p>示例:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL</span><br><span class="line">输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">reverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    ListNode prev = <span class="keyword">null</span>;</span><br><span class="line">    ListNode curr = head;</span><br><span class="line">    <span class="keyword">while</span> (curr != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ListNode nextTemp = curr.next;</span><br><span class="line">        curr.next = prev;</span><br><span class="line">        prev = curr;</span><br><span class="line">        curr = nextTemp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> prev;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="5-LRU缓存机制"><a href="#5-LRU缓存机制" class="headerlink" title="5. LRU缓存机制"></a>5. LRU缓存机制</h2><p>链接：<a href="https://leetcode-cn.com/problems/lru-cache/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/lru-cache/</a></p>
<p>运用你所掌握的数据结构，设计和实现一个  LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。</p>
<p>获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。<br>写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。</p>
<p>进阶:</p>
<p>你是否可以在 O(1) 时间复杂度内完成这两种操作？</p>
<p>示例:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LRUCache cache &#x3D; new LRUCache( 2 &#x2F;* 缓存容量 *&#x2F; );</span><br><span class="line"></span><br><span class="line">cache.put(1, 1);</span><br><span class="line">cache.put(2, 2);</span><br><span class="line">cache.get(1);       &#x2F;&#x2F; 返回  1</span><br><span class="line">cache.put(3, 3);    &#x2F;&#x2F; 该操作会使得密钥 2 作废</span><br><span class="line">cache.get(2);       &#x2F;&#x2F; 返回 -1 (未找到)</span><br><span class="line">cache.put(4, 4);    &#x2F;&#x2F; 该操作会使得密钥 1 作废</span><br><span class="line">cache.get(1);       &#x2F;&#x2F; 返回 -1 (未找到)</span><br><span class="line">cache.get(3);       &#x2F;&#x2F; 返回  3</span><br><span class="line">cache.get(4);       &#x2F;&#x2F; 返回  4</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">Integer</span>, <span class="title">Integer</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(capacity, <span class="number">0.75F</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getOrDefault(key, -<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.put(key, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;Integer, Integer&gt; eldest)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> size() &gt; capacity; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * LRUCache 对象会以如下语句构造和调用:</span></span><br><span class="line"><span class="comment"> * LRUCache obj = new LRUCache(capacity);</span></span><br><span class="line"><span class="comment"> * int param_1 = obj.get(key);</span></span><br><span class="line"><span class="comment"> * obj.put(key,value);</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure></div>

<h2 id="6-最长回文子串"><a href="#6-最长回文子串" class="headerlink" title="6. 最长回文子串"></a>6. 最长回文子串</h2><p>链接：<a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/</a></p>
<p>给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。</p>
<p>示例 1：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;babad&quot;</span><br><span class="line">输出: &quot;bab&quot;</span><br><span class="line">注意: &quot;aba&quot; 也是一个有效答案。</span><br></pre></td></tr></table></figure></div>

<p>示例 2：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;cbbd&quot;</span><br><span class="line">输出: &quot;bb&quot;</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">longestPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s == <span class="keyword">null</span> || s.length() &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">    <span class="keyword">int</span> start = <span class="number">0</span>, end = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.length(); i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> len1 = expandAroundCenter(s, i, i);</span><br><span class="line">        <span class="keyword">int</span> len2 = expandAroundCenter(s, i, i + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> len = Math.max(len1, len2);</span><br><span class="line">        <span class="keyword">if</span> (len &gt; end - start) &#123;</span><br><span class="line">            start = i - (len - <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">            end = i + len / <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s.substring(start, end + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">expandAroundCenter</span><span class="params">(String s, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> L = left, R = right;</span><br><span class="line">    <span class="keyword">while</span> (L &gt;= <span class="number">0</span> &amp;&amp; R &lt; s.length() &amp;&amp; s.charAt(L) == s.charAt(R)) &#123;</span><br><span class="line">        L--;</span><br><span class="line">        R++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> R - L - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="7-有效的括号"><a href="#7-有效的括号" class="headerlink" title="7. 有效的括号"></a>7. 有效的括号</h2><p>链接：<a href="https://leetcode-cn.com/problems/valid-parentheses/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-parentheses/</a></p>
<p>给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。</p>
<p>有效字符串需满足：<br>    1. 左括号必须用相同类型的右括号闭合。<br>    2. 左括号必须以正确的顺序闭合。</p>
<p>注意空字符串可被认为是有效字符串。</p>
<p>示例 1:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;()&quot;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure></div>

<p>示例 2:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;()[]&#123;&#125;&quot;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure></div>

<p>示例 3:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;(]&quot;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure></div>

<p>示例 4:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;([)]&quot;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure></div>

<p>示例 5:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: &quot;&#123;[]&#125;&quot;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Hash table that takes care of the mappings.</span></span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;Character, Character&gt; mappings;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialize hash map with mappings. This simply makes the code easier to read.</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Solution</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.mappings = <span class="keyword">new</span> HashMap&lt;Character, Character&gt;();</span><br><span class="line">    <span class="keyword">this</span>.mappings.put(<span class="string">')'</span>, <span class="string">'('</span>);</span><br><span class="line">    <span class="keyword">this</span>.mappings.put(<span class="string">'&#125;'</span>, <span class="string">'&#123;'</span>);</span><br><span class="line">    <span class="keyword">this</span>.mappings.put(<span class="string">']'</span>, <span class="string">'['</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValid</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize a stack to be used in the algorithm.</span></span><br><span class="line">    Stack&lt;Character&gt; stack = <span class="keyword">new</span> Stack&lt;Character&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.length(); i++) &#123;</span><br><span class="line">      <span class="keyword">char</span> c = s.charAt(i);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// If the current character is a closing bracket.</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.mappings.containsKey(c)) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Get the top element of the stack. If the stack is empty, set a dummy value of '#'</span></span><br><span class="line">        <span class="keyword">char</span> topElement = stack.empty() ? <span class="string">'#'</span> : stack.pop();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the mapping for this bracket doesn't match the stack's top element, return false.</span></span><br><span class="line">        <span class="keyword">if</span> (topElement != <span class="keyword">this</span>.mappings.get(c)) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// If it was an opening bracket, push to the stack.</span></span><br><span class="line">        stack.push(c);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the stack still contains elements, then it is an invalid expression.</span></span><br><span class="line">    <span class="keyword">return</span> stack.isEmpty();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="8-数组中的第K个最大元素"><a href="#8-数组中的第K个最大元素" class="headerlink" title="8. 数组中的第K个最大元素"></a>8. 数组中的第K个最大元素</h2><p>链接：<a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/kth-largest-element-in-an-array/</a></p>
<p>在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。</p>
<p>示例 1:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [3,2,1,5,6,4] 和 k &#x3D; 2</span><br><span class="line">输出: 5</span><br></pre></td></tr></table></figure></div>

<p>示例 2:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: [3,2,3,1,2,4,5,5,6] 和 k &#x3D; 4</span><br><span class="line">输出: 4</span><br></pre></td></tr></table></figure></div>

<p>说明:</p>
<p>你可以假设 k 总是有效的，且 1 ≤ k ≤ 数组的长度。</p>
<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> [] nums;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tmp = <span class="keyword">this</span>.nums[a];</span><br><span class="line">    <span class="keyword">this</span>.nums[a] = <span class="keyword">this</span>.nums[b];</span><br><span class="line">    <span class="keyword">this</span>.nums[b] = tmp;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span> pivot_index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> pivot = <span class="keyword">this</span>.nums[pivot_index];</span><br><span class="line">    <span class="comment">// 1. move pivot to end</span></span><br><span class="line">    swap(pivot_index, right);</span><br><span class="line">    <span class="keyword">int</span> store_index = left;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. move all smaller elements to the left</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = left; i &lt;= right; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.nums[i] &lt; pivot) &#123;</span><br><span class="line">        swap(store_index, i);</span><br><span class="line">        store_index++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. move pivot to its final place</span></span><br><span class="line">    swap(store_index, right);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> store_index;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">quickselect</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span> k_smallest)</span> </span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    Returns the k-th smallest element of list within left..right.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (left == right) <span class="comment">// If the list contains only one element,</span></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.nums[left];  <span class="comment">// return that element</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// select a random pivot_index</span></span><br><span class="line">    Random random_num = <span class="keyword">new</span> Random();</span><br><span class="line">    <span class="keyword">int</span> pivot_index = left + random_num.nextInt(right - left); </span><br><span class="line">    </span><br><span class="line">    pivot_index = partition(left, right, pivot_index);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the pivot is on (N - k)th smallest position</span></span><br><span class="line">    <span class="keyword">if</span> (k_smallest == pivot_index)</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.nums[k_smallest];</span><br><span class="line">    <span class="comment">// go left side</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (k_smallest &lt; pivot_index)</span><br><span class="line">      <span class="keyword">return</span> quickselect(left, pivot_index - <span class="number">1</span>, k_smallest);</span><br><span class="line">    <span class="comment">// go right side</span></span><br><span class="line">    <span class="keyword">return</span> quickselect(pivot_index + <span class="number">1</span>, right, k_smallest);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findKthLargest</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.nums = nums;</span><br><span class="line">    <span class="keyword">int</span> size = nums.length;</span><br><span class="line">    <span class="comment">// kth largest is (N - k)th smallest</span></span><br><span class="line">    <span class="keyword">return</span> quickselect(<span class="number">0</span>, size - <span class="number">1</span>, size - k);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="9-实现-Trie-前缀树"><a href="#9-实现-Trie-前缀树" class="headerlink" title="9. 实现 Trie (前缀树)"></a>9. 实现 Trie (前缀树)</h2><p>实现一个 Trie (前缀树)，包含 insert, search, 和 startsWith 这三个操作。</p>
<p>示例:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Trie trie &#x3D; new Trie();</span><br><span class="line"></span><br><span class="line">trie.insert(&quot;apple&quot;);</span><br><span class="line">trie.search(&quot;apple&quot;);   &#x2F;&#x2F; 返回 true</span><br><span class="line">trie.search(&quot;app&quot;);     &#x2F;&#x2F; 返回 false</span><br><span class="line">trie.startsWith(&quot;app&quot;); &#x2F;&#x2F; 返回 true</span><br><span class="line">trie.insert(&quot;app&quot;);   </span><br><span class="line">trie.search(&quot;app&quot;);     &#x2F;&#x2F; 返回 true</span><br></pre></td></tr></table></figure></div>

<p>说明:</p>
<ul>
<li>你可以假设所有的输入都是由小写字母 a-z 构成的。</li>
<li>保证所有输入均为非空字符串。</li>
</ul>
<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> TrieNode root;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Trie</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        root = <span class="keyword">new</span> TrieNode();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Inserts a word into the trie.</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(String word)</span> </span>&#123;</span><br><span class="line">        TrieNode node = root;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; word.length(); i++) &#123;</span><br><span class="line">            <span class="keyword">char</span> currentChar = word.charAt(i);</span><br><span class="line">            <span class="keyword">if</span> (!node.containsKey(currentChar)) &#123;</span><br><span class="line">                node.put(currentChar, <span class="keyword">new</span> TrieNode());</span><br><span class="line">            &#125;</span><br><span class="line">            node = node.get(currentChar);</span><br><span class="line">        &#125;</span><br><span class="line">        node.setEnd();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// search a prefix or whole key in trie and</span></span><br><span class="line">    <span class="comment">// returns the node where search ends</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> TrieNode <span class="title">searchPrefix</span><span class="params">(String word)</span> </span>&#123;</span><br><span class="line">        TrieNode node = root;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; word.length(); i++) &#123;</span><br><span class="line">           <span class="keyword">char</span> curLetter = word.charAt(i);</span><br><span class="line">           <span class="keyword">if</span> (node.containsKey(curLetter)) &#123;</span><br><span class="line">               node = node.get(curLetter);</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Returns if the word is in the trie.</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">search</span><span class="params">(String word)</span> </span>&#123;</span><br><span class="line">       TrieNode node = searchPrefix(word);</span><br><span class="line">       <span class="keyword">return</span> node != <span class="keyword">null</span> &amp;&amp; node.isEnd();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="10-编辑距离"><a href="#10-编辑距离" class="headerlink" title="10. 编辑距离"></a>10. 编辑距离</h2><p>链接：<a href="https://leetcode-cn.com/problems/edit-distance/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/edit-distance/</a></p>
<p>给定两个单词 word1 和 word2，计算出将 word1 转换成 word2 所使用的最少操作数 。</p>
<p>你可以对一个单词进行如下三种操作：<br>    1. 插入一个字符<br>    2. 删除一个字符<br>    3. 替换一个字符</p>
<p>示例 1:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: word1 &#x3D; &quot;horse&quot;, word2 &#x3D; &quot;ros&quot;</span><br><span class="line">输出: 3</span><br><span class="line">解释: </span><br><span class="line">horse -&gt; rorse (将 &#39;h&#39; 替换为 &#39;r&#39;)</span><br><span class="line">rorse -&gt; rose (删除 &#39;r&#39;)</span><br><span class="line">rose -&gt; ros (删除 &#39;e&#39;)</span><br></pre></td></tr></table></figure></div>

<p>示例 2:</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入: word1 &#x3D; &quot;intention&quot;, word2 &#x3D; &quot;execution&quot;</span><br><span class="line">输出: 5</span><br><span class="line">解释: </span><br><span class="line">intention -&gt; inention (删除 &#39;t&#39;)</span><br><span class="line">inention -&gt; enention (将 &#39;i&#39; 替换为 &#39;e&#39;)</span><br><span class="line">enention -&gt; exention (将 &#39;n&#39; 替换为 &#39;x&#39;)</span><br><span class="line">exention -&gt; exection (将 &#39;n&#39; 替换为 &#39;c&#39;)</span><br><span class="line">exection -&gt; execution (插入 &#39;u&#39;)</span><br></pre></td></tr></table></figure></div>

<p>题解：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(String word1, String word2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = word1.length();</span><br><span class="line">    <span class="keyword">int</span> m = word2.length();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if one of the strings is empty</span></span><br><span class="line">    <span class="keyword">if</span> (n * m == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> n + m;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// array to store the convertion history</span></span><br><span class="line">    <span class="keyword">int</span> [][] d = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>][m + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// init boundaries</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n + <span class="number">1</span>; i++) &#123;</span><br><span class="line">      d[i][<span class="number">0</span>] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; m + <span class="number">1</span>; j++) &#123;</span><br><span class="line">      d[<span class="number">0</span>][j] = j;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DP compute </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n + <span class="number">1</span>; i++) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; m + <span class="number">1</span>; j++) &#123;</span><br><span class="line">        <span class="keyword">int</span> left = d[i - <span class="number">1</span>][j] + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> down = d[i][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> left_down = d[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">if</span> (word1.charAt(i - <span class="number">1</span>) != word2.charAt(j - <span class="number">1</span>))</span><br><span class="line">          left_down += <span class="number">1</span>;</span><br><span class="line">        d[i][j] = Math.min(left, Math.min(down, left_down));</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> d[n][m];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
        <tag>算法与数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap底层实现源码分析</title>
    <url>/2020/03/16/HashMap%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="HashMap底层实现原理"><a href="#HashMap底层实现原理" class="headerlink" title="HashMap底层实现原理"></a>HashMap底层实现原理</h1><h2 id="0-样例数据"><a href="#0-样例数据" class="headerlink" title="0.样例数据"></a>0.样例数据</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CollectionTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//唯一的工作初始化负债因子（this.loadFactor = DEFAULT_LOAD_FACTOR）为0.75f</span></span><br><span class="line">        Map&lt;String,Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//添加kv</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> i = <span class="number">65</span>; i &lt; <span class="number">91</span>; i++) &#123;</span><br><span class="line">            map.put(String.valueOf(i),count);</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//第一种遍历方式</span></span><br><span class="line">        Set&lt;String&gt; keySet = map.keySet();</span><br><span class="line">        Iterator&lt;String&gt; iterator = keySet.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">            String key = iterator.next();</span><br><span class="line">            System.out.println(key+ <span class="string">" =&gt; "</span> + map.get(key));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"******************************"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//第二种遍历方式</span></span><br><span class="line">        Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; iteratorMap = map.entrySet().iterator();</span><br><span class="line">        <span class="keyword">while</span> (iteratorMap.hasNext()) &#123;</span><br><span class="line">            Map.Entry&lt;String, Integer&gt; mapEntry = iteratorMap.next();</span><br><span class="line">            System.out.println(mapEntry);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">"******************************"</span>);</span><br><span class="line">        <span class="comment">//第三种遍历方式</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Integer&gt; entry : map.entrySet()) &#123;</span><br><span class="line">            System.out.println(entry.getKey() + <span class="string">" =&gt; "</span> + entry.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-类信息"><a href="#1-类信息" class="headerlink" title="1. 类信息"></a>1. 类信息</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">Serializable</span> </span>&#123;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-基本属性"><a href="#2-基本属性" class="headerlink" title="2. 基本属性"></a>2. 基本属性</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">362498820763181265L</span>; <span class="comment">//序列化版本号</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// 默认容量16(左移4位相当于乘以2的4次方)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;<span class="comment">//最大容量（1073741824）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;<span class="comment">//默认负载因子</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>; <span class="comment">//链表节点转换红黑树节点的阈值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>; <span class="comment">//红黑树节点转换链表节点的阈值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;<span class="comment">// 转红黑树时, table的最小长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 基本hash节点, 继承自Entry，此时的Node节点就是相当于Entry节点的实现</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.hash = hash;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>        </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>      </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> key + <span class="string">"="</span> + value; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123;</span><br><span class="line">        V oldValue = value;</span><br><span class="line">        value = newValue;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Map.Entry) &#123;</span><br><span class="line">            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;</span><br><span class="line">            <span class="keyword">if</span> (Objects.equals(key, e.getKey()) &amp;&amp;</span><br><span class="line">                    Objects.equals(value, e.getValue()))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> Node&lt;K,V&gt;[] table; <span class="comment">//hashMap数组的表示</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; <span class="comment">//entry节点</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size; <span class="comment">//数组长度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount; <span class="comment">//添加的元素个数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> threshold; <span class="comment">//合理的初始化数组长度，根据tableSizeFor()得到，用于手动设置时使用</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor; <span class="comment">//负载因子，用于手动设置时使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器一：定义Node[]数组初始长度</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> + initialCapacity);</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">    <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> + loadFactor);</span><br><span class="line">    <span class="comment">//为Node[]数组设置负债因子</span></span><br><span class="line">    <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">    <span class="comment">//为Node[]数组设置一个合理的值</span></span><br><span class="line">    <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//初始化Node[]数组长度，根据传入的值以2的n次方对数组进行扩容</span></span><br><span class="line"><span class="comment">//（例如：存入传入值为9，数组容量为16，在(8,16]范围内将不会再次扩容）。</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= <span class="number">1</span> &lt;&lt; <span class="number">30</span>) ? <span class="number">1</span> &lt;&lt; <span class="number">30</span> : n + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器二：调用HashMap(int initialCapacity, float loadFactor)构造器</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//构造器三：仅创建HashMap对象，并初始化负债因子为0.75f</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 红黑树节点</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    TreeNode&lt;K,V&gt; parent;  <span class="comment">// red-black tree links</span></span><br><span class="line">    TreeNode&lt;K,V&gt; left;</span><br><span class="line">    TreeNode&lt;K,V&gt; right;</span><br><span class="line">    TreeNode&lt;K,V&gt; prev;    <span class="comment">// needed to unlink next upon deletion</span></span><br><span class="line">    <span class="keyword">boolean</span> red;</span><br><span class="line">    TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Returns root of tree containing this node.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> TreeNode&lt;K,V&gt; <span class="title">root</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (TreeNode&lt;K,V&gt; r = <span class="keyword">this</span>, p;;) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((p = r.parent) == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            r = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="3-hash算法"><a href="#3-hash算法" class="headerlink" title="3. hash算法"></a>3. hash算法</h2><p>HashMap定位数组索引位置，直接决定了hash方法的离散性能。下面是定位哈希桶数组的源码：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算key的hash值</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> h;</span><br><span class="line">        <span class="comment">// 1.先拿到key的hashCode值,基本数据类型会使用其包装类重载的hashCode()方法去计算hash值，引用数据类型根据是否重写去计算 </span></span><br><span class="line">        <span class="comment">// 2.将hashCode的高16位参与运算</span></span><br><span class="line">        <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将(tab.length - 1) 与 hash值进行&amp;运算</span></span><br><span class="line">    <span class="keyword">int</span> index = (tab.length - <span class="number">1</span>) &amp; hash;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//对值进行Hash计算</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h = hash;</span><br><span class="line">    <span class="keyword">if</span> (h == <span class="number">0</span> &amp;&amp; value.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">char</span> val[] = valu</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 当KEY值为A测试数据，A的hash为: 31 * hash + ANSI码值65</span></span><br><span class="line"><span class="comment">        * 当KEY值为AB测试数据，AB的hash为：31 * 65 + 66</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; value.length; i++) &#123;</span><br><span class="line">            h = <span class="number">31</span> * h + val[i];</span><br><span class="line">        &#125;</span><br><span class="line">        hash = h;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>HashMap底层数组的长度总是2的n次方，并且取模运算为“h mod table.length”，对应上面的公式，可以得到该运算等同于“h &amp; (table.length - 1)”。这是HashMap在速度上的优化，因为&amp;比%具有更高的效率。</p>
<p>在JDK1.8的实现中，还优化了高位运算的算法，将hashCode的高16位与hashCode进行异或运算，主要是为了在table的length较小的时候，让高位也参与运算，并且不会有太大的开销。</p>
<h2 id="4-get方法"><a href="#4-get方法" class="headerlink" title="4. get方法"></a>4. get方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//调用的GET方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//实际执行的GET方法</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">	Node&lt;K,V&gt;[] tab; </span><br><span class="line">    Node&lt;K,V&gt; first, e; </span><br><span class="line">    <span class="keyword">int</span> n; K k;</span><br><span class="line">    <span class="comment">// table不为空 &amp;&amp; table长度大于0 &amp;&amp; table索引位置(根据hash值计算出)节点不为空</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp; (first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// first的key等于传入的key则返回first对象</span></span><br><span class="line">        <span class="keyword">if</span> (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            <span class="keyword">return</span> first;</span><br><span class="line">        <span class="comment">//first的key不等于传入的key则说明是链表，向下遍历</span></span><br><span class="line">        <span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 判断是否为TreeNode，是则为红黑树</span></span><br><span class="line">            <span class="comment">// 如果是红黑树节点，则调用红黑树的查找目标节点方法getTreeNode</span></span><br><span class="line">            <span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                <span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">            <span class="comment">//走下列步骤表示是链表，循环至节点的key与传入的key值相等</span></span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">return</span> e;</span><br><span class="line">            &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//找不到符合的返回空</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="5-put方法"><a href="#5-put方法" class="headerlink" title="5. put方法"></a>5. put方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//掉用的PUT方法，hash(key)调用本例中的hash()方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//实际执行的PUT方法 </span></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent, <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab;</span><br><span class="line">    Node&lt;K,V&gt; p;</span><br><span class="line">    <span class="keyword">int</span> n, i;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// table是否为空或者length等于0, 如果是则调用resize方法进行初始化</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 通过hash值计算索引位置, 如果table表该索引位置节点为空则新增一个</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>) <span class="comment">// 将索引位置的头节点赋值给p</span></span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">else</span> &#123; <span class="comment">// table表该索引位置不为空</span></span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        <span class="comment">//判断p节点的hash值和key值是否跟传入的hash值和key值相等</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            e = p; <span class="comment">// 如果相等, 则p节点即为要查找的目标节点，赋值给e</span></span><br><span class="line">        <span class="comment">// 判断p节点是否为TreeNode, 如果是则调用红黑树的putTreeVal方法查找目标节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        <span class="comment">// 走到这代表p节点为普通链表节点</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 遍历此链表, binCount用于统计节点数</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="comment">//p.next为空代表目标节点不存在</span></span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//新增一个节点插入链表尾部</span></span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">                    <span class="comment">//如果节点数目超过8个，调用treeifyBin方法将该链表转换为红黑树</span></span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//e节点的hash值和key值都与传入的相等, 则e即为目标节点,跳出循环</span></span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// e不为空则代表根据传入的hash值和key值查找到了节点,将该节点的value覆盖,返回oldValue</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e); <span class="comment">// 用于LinkedHashMap</span></span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//map修改次数加1</span></span><br><span class="line">    ++modCount;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//map节点数加1，如果超过阀值，则扩容</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict); <span class="comment">// 用于LinkedHashMap</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>从上面的源码分析可以看出</p>
<p>1、如果节点已经存在，则更新原值</p>
<p>2、如果节点不存在，则插入数组中，如果数组已经有值，则判断是非是红黑树，如果是，则调用红黑树方法插入</p>
<p>3、如果插入的是链表，插入尾部，然后判断节点数是否超过8，如果超过，则转换为红黑树</p>
<p>4、先插入的数据，后面判断是否超过阀值再进行的扩容</p>
<p>putTreeVal,插入红黑树方法就不看了，看下treeifyBin方法，该方法是将链表转化为红黑树,</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">treeifyBin</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> hash)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n, index; </span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="comment">// table为空或者table的长度小于64, 进行扩容</span></span><br><span class="line">    <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) </span><br><span class="line">        resize();</span><br><span class="line">    <span class="comment">// 根据hash值计算索引值, 遍历该索引位置的链表</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> ((e = tab[index = (n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;   </span><br><span class="line">        TreeNode&lt;K,V&gt; hd = <span class="keyword">null</span>, tl = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            TreeNode&lt;K,V&gt; p = replacementTreeNode(e, <span class="keyword">null</span>); <span class="comment">// 链表节点转红黑树节点</span></span><br><span class="line">            <span class="keyword">if</span> (tl == <span class="keyword">null</span>)    <span class="comment">// tl为空代表为第一次循环</span></span><br><span class="line">                hd = p; <span class="comment">// 头结点</span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                p.prev = tl;    <span class="comment">// 当前节点的prev属性设为上一个节点</span></span><br><span class="line">                tl.next = p;    <span class="comment">// 上一个节点的next属性设置为当前节点</span></span><br><span class="line">            &#125;</span><br><span class="line">            tl = p; <span class="comment">// tl赋值为p, 在下一次循环中作为上一个节点</span></span><br><span class="line">        &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);    <span class="comment">// e指向下一个节点</span></span><br><span class="line">        <span class="comment">// 将table该索引位置赋值为新转的TreeNode的头节点</span></span><br><span class="line">        <span class="keyword">if</span> ((tab[index] = hd) != <span class="keyword">null</span>) </span><br><span class="line">            hd.treeify(tab);    <span class="comment">// 以头结点为根结点, 构建红黑树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>可以看到，会先判断tab的节点数是否超过64，如果没超过，则进行扩容，如果超过了才会转换为红黑树</p>
<p>可以得到两个结论</p>
<p>1、什么时候转换为红黑树</p>
<p>当链表数目超过8,并且map节点数量超过64，才会转换为红黑树</p>
<p>2、什么时候扩容（前提是map数目没有超过最大容量值  1&lt;&lt;30 ）</p>
<p>新增节点时，发生了碰撞，并且节点数目超过阀值</p>
<p>新增节点时，发生了碰撞，节点数量木有超过阀值，但是链表数目&gt;8,map节点&lt;64时</p>
<p>再看下resize()方法</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">        <span class="comment">//oldTab保存未扩容的tab</span></span><br><span class="line">        Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">        <span class="comment">//oldTab最大容量</span></span><br><span class="line">        <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">        <span class="comment">//oldTab阀值</span></span><br><span class="line">        <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">        <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//如果老map有值</span></span><br><span class="line">        <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 老table的容量超过最大容量值，设置阈值为Integer.MAX_VALUE，返回老表</span></span><br><span class="line">            <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">                threshold = Integer.MAX_VALUE;</span><br><span class="line">                <span class="keyword">return</span> oldTab;</span><br><span class="line">            <span class="comment">//老table的容量没有超过最大容量值，将新容量赋值为老容量*2，如果新容量&lt;最大容量并且老容量&gt;=16, 则将新阈值设置为原来的两倍</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                    oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">                newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) <span class="comment">// 老表的容量为0, 老表的阈值大于0, 是因为初始容量被放入阈值</span></span><br><span class="line">            newCap = oldThr;    <span class="comment">// 则将新表的容量设置为老表的阈值</span></span><br><span class="line">        <span class="keyword">else</span> &#123;   <span class="comment">//老表的容量为0, 老表的阈值为0, 则为空表，设置默认容量和阈值</span></span><br><span class="line">            newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">            newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果新阈值为空, 则通过新的容量*负载因子获得新阈值</span></span><br><span class="line">        <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ?</span><br><span class="line">                    (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将当前阈值赋值为刚计算出来的新的阈值</span></span><br><span class="line">        threshold = newThr;</span><br><span class="line">        <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">        table = newTab;  <span class="comment">// 将当前的表赋值为新定义的表</span></span><br><span class="line">        <span class="comment">// 如果老表不为空, 则需遍历将节点赋值给新表</span></span><br><span class="line">        <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">                Node&lt;K,V&gt; e;</span><br><span class="line">                <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123; <span class="comment">// 将索引值为j的老表头节点赋值给e</span></span><br><span class="line">                    oldTab[j] = <span class="keyword">null</span>; <span class="comment">//将老表的节点设置为空, 以便垃圾收集器回收空间</span></span><br><span class="line">                    <span class="comment">// 如果e.next为空, 则代表老表的该位置只有1个节点,</span></span><br><span class="line">                    <span class="comment">// 通过hash值计算新表的索引位置, 直接将该节点放在该位置</span></span><br><span class="line">                    <span class="keyword">if</span> (e.next == <span class="keyword">null</span>) <span class="comment">//</span></span><br><span class="line">                        newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                    <span class="comment">//e.next不为空,判断是否是红黑树</span></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                        ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                    <span class="comment">//是普通链表</span></span><br><span class="line">                    <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                        Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; next;</span><br><span class="line">                        <span class="keyword">do</span> &#123;</span><br><span class="line">                            next = e.next;</span><br><span class="line">                            <span class="comment">//如果e的hash值与老表的容量进行与运算为0,则扩容后的索引位置跟老表的索引位置一样</span></span><br><span class="line">                            <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                                <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                    loHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                    loTail.next = e;</span><br><span class="line">                                loTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">//如果e的hash值与老表的容量进行与运算为1,则扩容后的索引位置为:</span></span><br><span class="line">                            <span class="comment">//	老表的索引位置＋oldCap</span></span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line">                                <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                    hiHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                    hiTail.next = e;</span><br><span class="line">                                hiTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                        <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            loTail.next = <span class="keyword">null</span>; <span class="comment">// 最后一个节点的next设为空</span></span><br><span class="line">                            newTab[j] = loHead; <span class="comment">// 将原索引位置的节点设置为对应的头结点</span></span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            hiTail.next = <span class="keyword">null</span>; <span class="comment">// 最后一个节点的next设为空</span></span><br><span class="line">                            newTab[j + oldCap] = hiHead; <span class="comment">// 将索引位置为原索引+oldCap的节点设置为对应的头结点</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newTab;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<p>可以看出，扩容时，节点重hash只分布在原索引位置与原索引+oldCap位置，为什么呢</p>
<p>假设老表的容量为16，即oldCap=16，则新表容量为16*2=32，假设节点1的hash值为0000 0000 0000 0000 0000 1111 0000 1010，节点2的hash值为0000 0000 0000 0000 0000 1111 0001 1010，则节点1和节点2在老表的索引位置计算如下图计算1，由于老表的长度限制，节点1和节点2的索引位置只取决于节点hash值的最后4位。再看计算2，计算2为新表的索引计算，可以知道如果两个节点在老表的索引位置相同，则新表的索引位置只取决于节点hash值倒数第5位的值，而此位置的值刚好为老表的容量值16，此时节点在新表的索引位置只有两种情况：原索引位置和原索引+oldCap位置（在此例中即为10和10+16=26）。由于结果只取决于节点hash值的倒数第5位，而此位置的值刚好为老表的容量值16，因此此时新表的索引位置的计算可以替换为计算3，直接使用节点的hash值与老表的容量16进行位于运算，如果结果为0则该节点在新表的索引位置为原索引位置，否则该节点在新表的索引位置为原索引+oldCap位置。</p>
<h2 id="6-remove-方法"><a href="#6-remove-方法" class="headerlink" title="6. remove()方法"></a>6. remove()方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = removeNode(hash(key), key, <span class="keyword">null</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)) == <span class="keyword">null</span> ?</span><br><span class="line">        <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">removeNode</span><span class="params">(<span class="keyword">int</span> hash, Object key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">boolean</span> matchValue, <span class="keyword">boolean</span> movable)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, index;</span><br><span class="line">    <span class="comment">// 如果table不为空并且根据hash值计算出来的索引位置不为空, 将该位置的节点赋值给p</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (p = tab[index = (n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        Node&lt;K,V&gt; node = <span class="keyword">null</span>, e; K k; V v;</span><br><span class="line">        <span class="comment">// 如果p的hash值和key都与入参的相同, 则p即为目标节点, 赋值给node</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            node = p;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((e = p.next) != <span class="keyword">null</span>) &#123;    <span class="comment">// 否则向下遍历节点</span></span><br><span class="line">            <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)  <span class="comment">// 如果p是TreeNode则调用红黑树的方法查找节点</span></span><br><span class="line">                node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">do</span> &#123;    <span class="comment">// 遍历链表查找符合条件的节点</span></span><br><span class="line">                    <span class="comment">// 当节点的hash值和key与传入的相同,则该节点即为目标节点</span></span><br><span class="line">                    <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                        ((k = e.key) == key ||</span><br><span class="line">                         (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                        node = e;    <span class="comment">// 赋值给node, 并跳出循环</span></span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    p = e;  <span class="comment">// p节点赋值为本次结束的e</span></span><br><span class="line">                &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>); <span class="comment">// 指向像一个节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果node不为空(即根据传入key和hash值查找到目标节点)，则进行移除操作</span></span><br><span class="line">        <span class="keyword">if</span> (node != <span class="keyword">null</span> &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                             (value != <span class="keyword">null</span> &amp;&amp; value.equals(v)))) &#123; </span><br><span class="line">            <span class="keyword">if</span> (node <span class="keyword">instanceof</span> TreeNode)   <span class="comment">// 如果是TreeNode则调用红黑树的移除方法</span></span><br><span class="line">                ((TreeNode&lt;K,V&gt;)node).removeTreeNode(<span class="keyword">this</span>, tab, movable);</span><br><span class="line">            <span class="comment">// 走到这代表节点是普通链表节点</span></span><br><span class="line">            <span class="comment">// 如果node是该索引位置的头结点则直接将该索引位置的值赋值为node的next节点</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (node == p)</span><br><span class="line">                tab[index] = node.next;</span><br><span class="line">            <span class="comment">// 否则将node的上一个节点的next属性设置为node的next节点, </span></span><br><span class="line">            <span class="comment">// 即将node节点移除, 将node的上下节点进行关联(链表的移除)    </span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                p.next = node.next;</span><br><span class="line">            ++modCount; <span class="comment">// 修改次数+1</span></span><br><span class="line">            --size; <span class="comment">// table的总节点数-1</span></span><br><span class="line">            afterNodeRemoval(node); <span class="comment">// 供LinkedHashMap使用</span></span><br><span class="line">            <span class="keyword">return</span> node;    <span class="comment">// 返回被移除的节点</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="7-JDK1-7和1-8的区别"><a href="#7-JDK1-7和1-8的区别" class="headerlink" title="7. JDK1.7和1.8的区别"></a>7. JDK1.7和1.8的区别</h2><p>1、JDK1.7的时候使用的是数组+ 单链表的数据结构。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的数据结构（当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率）</p>
<p>2、JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，那么他们为什么要这样做呢？因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。</p>
<p>3、扩容后数据存储位置的计算方式也不一样：1. 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&amp;（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 &amp; length-1），而在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，而不再是JDK1.7的那种异或的方法。但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的储存方式。</p>
<p>4、jdk1.7 先扩容再put ，jdk1.8 先put再扩容</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>易错点</tag>
        <tag>Java</tag>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Comparable和Comparator底层源码分析</title>
    <url>/2020/03/15/Comparable%E5%92%8CComparator%E5%BA%95%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="1-Comparable源码分析"><a href="#1-Comparable源码分析" class="headerlink" title="1. Comparable源码分析"></a>1. Comparable源码分析</h1><h2 id="1-1创建Java工程，实现Comparable接口"><a href="#1-1创建Java工程，实现Comparable接口" class="headerlink" title="1.1创建Java工程，实现Comparable接口"></a>1.1创建Java工程，实现Comparable接口</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"><span class="comment">//实现Serializable，标识该类可被序列化</span></span><br><span class="line"><span class="comment">//实现Comparable接口，让此类可以利用Collections.sort()进行排序</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">User</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span>,<span class="title">Comparable</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> String address;<span class="comment">//transient修饰，标识该类序列化时此字段不需要进行存储</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(String name,<span class="keyword">int</span> age,String address)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(name);</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.address = address;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getAddress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> address;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(T o)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//在此处打上断点，方便进行调试</span></span><br><span class="line">        <span class="keyword">int</span> returnInt = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(age&gt;o.getAge())&#123;</span><br><span class="line">            returnInt=<span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(age==o.getAge())&#123;</span><br><span class="line">            returnInt=<span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(age&lt;o.getAge())&#123;</span><br><span class="line">            returnInt=-<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> returnInt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-2-编写测试类"><a href="#1-2-编写测试类" class="headerlink" title="1.2 编写测试类"></a>1.2 编写测试类</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestComparable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        User u1 = <span class="keyword">new</span> User(<span class="string">"caililiang1"</span>,<span class="number">20</span>,<span class="string">"hubei1"</span>);</span><br><span class="line">        User u2 = <span class="keyword">new</span> User(<span class="string">"caililiang2"</span>,<span class="number">30</span>,<span class="string">"hubei2"</span>);</span><br><span class="line">        User u3 = <span class="keyword">new</span> User(<span class="string">"caililiang3"</span>,<span class="number">25</span>,<span class="string">"hubei3"</span>);</span><br><span class="line">        User u4 = <span class="keyword">new</span> User(<span class="string">"caililiang4"</span>,<span class="number">28</span>,<span class="string">"hubei4"</span>);</span><br><span class="line">        User u5 = <span class="keyword">new</span> User(<span class="string">"caililiang5"</span>,<span class="number">23</span>,<span class="string">"hubei5"</span>);</span><br><span class="line"></span><br><span class="line">        List&lt;User&gt; list = <span class="keyword">new</span> ArrayList&lt;User&gt;();</span><br><span class="line">        list.add(u1);</span><br><span class="line">        list.add(u2);</span><br><span class="line">        list.add(u3);</span><br><span class="line">        list.add(u4);</span><br><span class="line">        list.add(u5);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">            User u =list.get(i);</span><br><span class="line">            System.out.println(u.getName()+<span class="string">"---&gt;"</span>+u.getAge());</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"排序后---------------------"</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//在此处打上断点，方便进行调试</span></span><br><span class="line">        Collections.sort(list);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">            User u =list.get(i);</span><br><span class="line">            System.out.println(u.getName()+<span class="string">"---&gt;"</span>+u.getAge());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-3-Collections类中的泛型方法sort"><a href="#1-3-Collections类中的泛型方法sort" class="headerlink" title="1.3 Collections类中的泛型方法sort()"></a>1.3 Collections类中的泛型方法sort()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 此处 &lt;T extends Comparable&lt;? super T&gt;&gt; 的意思是：</span></span><br><span class="line"><span class="comment">// 1.&lt;T extends Comparable&gt;表示比较对象的类必须是Comparable 的子类。</span></span><br><span class="line"><span class="comment">// 2.Comparable&lt;? super T&gt;表示是Comparable实现类及以上。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T extends Comparable&lt;? <span class="keyword">super</span> T&gt;&gt; <span class="function"><span class="keyword">void</span> <span class="title">sort</span><span class="params">(List&lt;T&gt; list)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//调用List接口中的sort()方法</span></span><br><span class="line">       list.sort(<span class="keyword">null</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-4-List接口中的默认方法sort"><a href="#1-4-List接口中的默认方法sort" class="headerlink" title="1.4 List接口中的默认方法sort()"></a>1.4 List接口中的默认方法sort()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 由于本例中采用的是ArrayList集合，ArrayList集合对List接口中的sort()方法进行了重写，</span></span><br><span class="line"><span class="comment">// 因此实际在DeBug的过程中会执行ArrayLIst类中的sort()方法    </span></span><br><span class="line"><span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> E&gt; c)</span> </span>&#123;</span><br><span class="line">        Object[] a = <span class="keyword">this</span>.toArray();</span><br><span class="line">        Arrays.sort(a, (Comparator) c);</span><br><span class="line">        ListIterator&lt;E&gt; i = <span class="keyword">this</span>.listIterator();</span><br><span class="line">        <span class="keyword">for</span> (Object e : a) &#123;</span><br><span class="line">            i.next();</span><br><span class="line">            i.set((E) e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-5-ArrayList集合中的方法sort"><a href="#1-5-ArrayList集合中的方法sort" class="headerlink" title="1.5 ArrayList集合中的方法sort()"></a>1.5 ArrayList集合中的方法sort()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> expectedModCount = modCount;</span><br><span class="line">    <span class="comment">//此方法直接调用Arrays类中sort()方法</span></span><br><span class="line">    Arrays.sort((E[]) elementData, <span class="number">0</span>, size, c);</span><br><span class="line">    <span class="keyword">if</span> (modCount != expectedModCount) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">    &#125;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="1-6-Arrays类中的sort-方法"><a href="#1-6-Arrays类中的sort-方法" class="headerlink" title="1.6 Arrays类中的sort()方法"></a>1.6 Arrays类中的sort()方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">sort</span><span class="params">(T[] a, <span class="keyword">int</span> fromIndex, <span class="keyword">int</span> toIndex, Comparator&lt;? <span class="keyword">super</span> T&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//在1.3中传入的 c值为null,所以调用sort(a, fromIndex, toIndex)方法</span></span><br><span class="line">    <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">        sort(a, fromIndex, toIndex);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        rangeCheck(a.length, fromIndex, toIndex);</span><br><span class="line">        <span class="keyword">if</span> (LegacyMergeSort.userRequested)</span><br><span class="line">            legacyMergeSort(a, fromIndex, toIndex, c);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            TimSort.sort(a, fromIndex, toIndex, c, <span class="keyword">null</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Object[] a, <span class="keyword">int</span> fromIndex, <span class="keyword">int</span> toIndex)</span> </span>&#123;</span><br><span class="line">    rangeCheck(a.length, fromIndex, toIndex);</span><br><span class="line">    <span class="keyword">if</span> (LegacyMergeSort.userRequested)</span><br><span class="line">        <span class="comment">//归并排序</span></span><br><span class="line">        legacyMergeSort(a, fromIndex, toIndex);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">//二进制插入排序</span></span><br><span class="line">        ComparableTimSort.sort(a, fromIndex, toIndex, <span class="keyword">null</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>解析：源码里首先判断是否采用传统的排序方法,LegacyMergeSort.userRequested属性默认为false,也就是说默认选中 ComparableTimSort.sort(a)方法(传统归并排序在1.5及之前是默认排序方法，1.5之后默认执行ComparableTimSort.sort()方法。除非程序中强制要求使用传统归并排序,语句如下：System.setProperty(“java.util.Arrays.useLegacyMergeSort”, “true”))<br>继续看 ComparableTimSort.sort(a)源码</p>
<h2 id="1-7-ComparableTimSort类中的sort-方法"><a href="#1-7-ComparableTimSort类中的sort-方法" class="headerlink" title="1.7 ComparableTimSort类中的sort()方法"></a>1.7 ComparableTimSort类中的sort()方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Object[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi, Object[] work, <span class="keyword">int</span> workBase, <span class="keyword">int</span> workLen)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">assert</span> a != <span class="keyword">null</span> &amp;&amp; lo &gt;= <span class="number">0</span> &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length;</span><br><span class="line">       </span><br><span class="line">       <span class="comment">//nRemaining表示没有排序的对象个数，方法执行前，如果这个数小于2，就不需要排序了。</span></span><br><span class="line">       <span class="comment">//如果2&lt;= nRemaining &lt;=32,即MIN_MERGE的初始值，表示需要排序的数组是小数组</span></span><br><span class="line">       <span class="comment">//可以使用mini-TimSort方法进行排序，否则需要使用归并排序。</span></span><br><span class="line">       <span class="keyword">int</span> nRemaining  = hi - lo;</span><br><span class="line">       <span class="keyword">if</span> (nRemaining &lt; <span class="number">2</span>)</span><br><span class="line">           <span class="keyword">return</span>;  <span class="comment">// Arrays of size 0 and 1 are always sorted</span></span><br><span class="line"></span><br><span class="line">       <span class="comment">// If array is small, do a "mini-TimSort" with no merges</span></span><br><span class="line">       <span class="keyword">if</span> (nRemaining &lt; MIN_MERGE) &#123;</span><br><span class="line">           <span class="comment">//调用重写的compareTo()方法</span></span><br><span class="line">           <span class="keyword">int</span> initRunLen = countRunAndMakeAscending(a, lo, hi);</span><br><span class="line">           <span class="comment">//只看这一句</span></span><br><span class="line">           binarySort(a, lo, hi, lo + initRunLen);</span><br><span class="line">           <span class="keyword">return</span>;</span><br><span class="line">       &#125;</span><br><span class="line">    ......</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//这里才是真正的调用compareTo()方法对当前对象进行比较</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">countRunAndMakeAscending</span><span class="params">(Object[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">assert</span> lo &lt; hi;</span><br><span class="line">       <span class="keyword">int</span> runHi = lo + <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">if</span> (runHi == hi)</span><br><span class="line">           <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Find end of run, and reverse range if descending</span></span><br><span class="line">       <span class="keyword">if</span> (((Comparable) a[runHi++]).compareTo(a[lo]) &lt; <span class="number">0</span>) &#123; <span class="comment">// 降序排列</span></span><br><span class="line">           <span class="keyword">while</span> (runHi &lt; hi &amp;&amp; ((Comparable) a[runHi]).compareTo(a[runHi - <span class="number">1</span>]) &lt; <span class="number">0</span>)</span><br><span class="line">               runHi++;</span><br><span class="line">           reverseRange(a, lo, runHi);</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;<span class="comment">// 升序排列</span></span><br><span class="line">           <span class="keyword">while</span> (runHi &lt; hi &amp;&amp; ((Comparable) a[runHi]).compareTo(a[runHi - <span class="number">1</span>]) &gt;= <span class="number">0</span>)</span><br><span class="line">               runHi++;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> runHi - lo;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//这里才是真正的进行排序。</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">binarySort</span><span class="params">(Object[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">assert</span> lo &lt;= start &amp;&amp; start &lt;= hi;</span><br><span class="line">       <span class="keyword">if</span> (start == lo)</span><br><span class="line">           start++;</span><br><span class="line">       <span class="keyword">for</span> ( ; start &lt; hi; start++) &#123;</span><br><span class="line">           Comparable pivot = (Comparable) a[start];</span><br><span class="line"></span><br><span class="line">           <span class="comment">// Set left (and right) to the index where a[start] (pivot) belongs</span></span><br><span class="line">           <span class="keyword">int</span> left = lo;</span><br><span class="line">           <span class="keyword">int</span> right = start;</span><br><span class="line">           <span class="keyword">assert</span> left &lt;= right;</span><br><span class="line">           <span class="comment">/*</span></span><br><span class="line"><span class="comment">            * Invariants:</span></span><br><span class="line"><span class="comment">            *   pivot &gt;= all in [lo, left).</span></span><br><span class="line"><span class="comment">            *   pivot &lt;  all in [right, start).</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">           <span class="keyword">while</span> (left &lt; right) &#123;</span><br><span class="line">               <span class="keyword">int</span> mid = (left + right) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">               <span class="keyword">if</span> (pivot.compareTo(a[mid]) &lt; <span class="number">0</span>)</span><br><span class="line">                   right = mid;</span><br><span class="line">               <span class="keyword">else</span></span><br><span class="line">                   left = mid + <span class="number">1</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">assert</span> left == right;</span><br><span class="line"></span><br><span class="line">           <span class="comment">/*</span></span><br><span class="line"><span class="comment">            * The invariants still hold: pivot &gt;= all in [lo, left) and</span></span><br><span class="line"><span class="comment">            * pivot &lt; all in [left, start), so pivot belongs at left.  Note</span></span><br><span class="line"><span class="comment">            * that if there are elements equal to pivot, left points to the</span></span><br><span class="line"><span class="comment">            * first slot after them -- that's why this sort is stable.</span></span><br><span class="line"><span class="comment">            * Slide elements over to make room for pivot.</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">           <span class="keyword">int</span> n = start - left;  <span class="comment">// The number of elements to move</span></span><br><span class="line">           <span class="comment">// Switch is just an optimization for arraycopy in default case</span></span><br><span class="line">           <span class="keyword">switch</span> (n) &#123;</span><br><span class="line">               <span class="keyword">case</span> <span class="number">2</span>:  a[left + <span class="number">2</span>] = a[left + <span class="number">1</span>];</span><br><span class="line">               <span class="keyword">case</span> <span class="number">1</span>:  a[left + <span class="number">1</span>] = a[left];</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">               <span class="keyword">default</span>: System.arraycopy(a, left, a, left + <span class="number">1</span>, n);</span><br><span class="line">           &#125;</span><br><span class="line">           a[left] = pivot;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="2-Comparator源码分析"><a href="#2-Comparator源码分析" class="headerlink" title="2. Comparator源码分析"></a>2. Comparator源码分析</h1><h2 id="2-1-创建JavaBean"><a href="#2-1-创建JavaBean" class="headerlink" title="2.1 创建JavaBean"></a>2.1 创建JavaBean</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> String address;<span class="comment">//transient修饰，标识该类序列化时此字段不需要进行存储</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">People</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">People</span><span class="params">(String name,<span class="keyword">int</span> age,String address)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(name);</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.address = address;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getAddress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> address;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-2-创建外部比较器"><a href="#2-2-创建外部比较器" class="headerlink" title="2.2 创建外部比较器"></a>2.2 创建外部比较器</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Comparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PeopleComparator</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">People</span>&gt; <span class="keyword">implements</span> <span class="title">Comparator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(T o1, T o2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> returnInt = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(o1.getAge()&gt;o2.getAge())&#123;</span><br><span class="line">            returnInt = <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(o1.getAge()==o2.getAge())&#123;</span><br><span class="line">            returnInt = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(o1.getAge()&lt;o2.getAge())&#123;</span><br><span class="line">            returnInt = -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> returnInt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-3-创建测试类"><a href="#2-3-创建测试类" class="headerlink" title="2.3 创建测试类"></a>2.3 创建测试类</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestComparator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        People u1 = <span class="keyword">new</span> People(<span class="string">"caililiang1"</span>,<span class="number">20</span>,<span class="string">"hubei1"</span>);</span><br><span class="line">        People u2 = <span class="keyword">new</span> People(<span class="string">"caililiang2"</span>,<span class="number">30</span>,<span class="string">"hubei2"</span>);</span><br><span class="line">        People u3 = <span class="keyword">new</span> People(<span class="string">"caililiang3"</span>,<span class="number">25</span>,<span class="string">"hubei3"</span>);</span><br><span class="line">        People u4 = <span class="keyword">new</span> People(<span class="string">"caililiang4"</span>,<span class="number">28</span>,<span class="string">"hubei4"</span>);</span><br><span class="line">        People u5 = <span class="keyword">new</span> People(<span class="string">"caililiang5"</span>,<span class="number">23</span>,<span class="string">"hubei5"</span>);</span><br><span class="line"></span><br><span class="line">        List&lt;People&gt; list = <span class="keyword">new</span> ArrayList&lt;People&gt;();</span><br><span class="line">        list.add(u1);</span><br><span class="line">        list.add(u2);</span><br><span class="line">        list.add(u3);</span><br><span class="line">        list.add(u4);</span><br><span class="line">        list.add(u5);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">            People u =list.get(i);</span><br><span class="line">            System.out.println(u.getName()+<span class="string">"---&gt;"</span>+u.getAge());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"排序后---------------------"</span>);</span><br><span class="line"></span><br><span class="line">        Collections.sort(list,<span class="keyword">new</span> PeopleComparator());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">            People u =list.get(i);</span><br><span class="line">            System.out.println(u.getName()+<span class="string">"---&gt;"</span>+u.getAge());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-4-Collections类中的泛型方法sort"><a href="#2-4-Collections类中的泛型方法sort" class="headerlink" title="2.4 Collections类中的泛型方法sort()"></a>2.4 Collections类中的泛型方法sort()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"unchecked"</span>, <span class="string">"rawtypes"</span>&#125;)</span><br><span class="line"><span class="comment">//此处调用的是sort方法的重载方法，与案例一中不同</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">sort</span><span class="params">(List&lt;T&gt; list, Comparator&lt;? <span class="keyword">super</span> T&gt; c)</span> </span>&#123;</span><br><span class="line">       list.sort(c);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-5-ArrayList集合中的方法sort"><a href="#2-5-ArrayList集合中的方法sort" class="headerlink" title="2.5 ArrayList集合中的方法sort()"></a>2.5 ArrayList集合中的方法sort()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> expectedModCount = modCount;</span><br><span class="line">    Arrays.sort((E[]) elementData, <span class="number">0</span>, size, c);</span><br><span class="line">    <span class="keyword">if</span> (modCount != expectedModCount) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">    &#125;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-6-Arrays类中的sort-方法"><a href="#2-6-Arrays类中的sort-方法" class="headerlink" title="2.6 Arrays类中的sort()方法"></a>2.6 Arrays类中的sort()方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">sort</span><span class="params">(T[] a, <span class="keyword">int</span> fromIndex, <span class="keyword">int</span> toIndex, Comparator&lt;? <span class="keyword">super</span> T&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">        sort(a, fromIndex, toIndex);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        rangeCheck(a.length, fromIndex, toIndex);</span><br><span class="line">        <span class="keyword">if</span> (LegacyMergeSort.userRequested)</span><br><span class="line">            legacyMergeSort(a, fromIndex, toIndex, c);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="comment">//本次进入这里进行排序</span></span><br><span class="line">            TimSort.sort(a, fromIndex, toIndex, c, <span class="keyword">null</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-7-TimSort类下的sort-方法"><a href="#2-7-TimSort类下的sort-方法" class="headerlink" title="2.7 TimSort类下的sort()方法"></a>2.7 TimSort类下的sort()方法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">sort</span><span class="params">(T[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi, Comparator&lt;? <span class="keyword">super</span> T&gt; c, T[] work, <span class="keyword">int</span> workBase, <span class="keyword">int</span> workLen)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> c != <span class="keyword">null</span> &amp;&amp; a != <span class="keyword">null</span> &amp;&amp; lo &gt;= <span class="number">0</span> &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> nRemaining  = hi - lo;</span><br><span class="line">    <span class="keyword">if</span> (nRemaining &lt; <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span>;  <span class="comment">// Arrays of size 0 and 1 are always sorted</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// If array is small, do a "mini-TimSort" with no merges</span></span><br><span class="line">    <span class="keyword">if</span> (nRemaining &lt; MIN_MERGE) &#123;</span><br><span class="line">        <span class="keyword">int</span> initRunLen = countRunAndMakeAscending(a, lo, hi, c);</span><br><span class="line">        binarySort(a, lo, hi, lo + initRunLen, c);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"> <span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">binarySort</span><span class="params">(T[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi, <span class="keyword">int</span> start, Comparator&lt;? <span class="keyword">super</span> T&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> lo &lt;= start &amp;&amp; start &lt;= hi;</span><br><span class="line">    <span class="keyword">if</span> (start == lo)</span><br><span class="line">        start++;</span><br><span class="line">    <span class="keyword">for</span> ( ; start &lt; hi; start++) &#123;</span><br><span class="line">        T pivot = a[start];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Set left (and right) to the index where a[start] (pivot) belongs</span></span><br><span class="line">        <span class="keyword">int</span> left = lo;</span><br><span class="line">        <span class="keyword">int</span> right = start;</span><br><span class="line">        <span class="keyword">assert</span> left &lt;= right;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Invariants:</span></span><br><span class="line"><span class="comment">         *   pivot &gt;= all in [lo, left).</span></span><br><span class="line"><span class="comment">         *   pivot &lt;  all in [right, start).</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">while</span> (left &lt; right) &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (left + right) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (c.compare(pivot, a[mid]) &lt; <span class="number">0</span>)</span><br><span class="line">                right = mid;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                left = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">assert</span> left == right;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * The invariants still hold: pivot &gt;= all in [lo, left) and</span></span><br><span class="line"><span class="comment">         * pivot &lt; all in [left, start), so pivot belongs at left.  Note</span></span><br><span class="line"><span class="comment">         * that if there are elements equal to pivot, left points to the</span></span><br><span class="line"><span class="comment">         * first slot after them -- that's why this sort is stable.</span></span><br><span class="line"><span class="comment">         * Slide elements over to make room for pivot.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">int</span> n = start - left;  <span class="comment">// The number of elements to move</span></span><br><span class="line">        <span class="comment">// Switch is just an optimization for arraycopy in default case</span></span><br><span class="line">        <span class="keyword">switch</span> (n) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:  a[left + <span class="number">2</span>] = a[left + <span class="number">1</span>];</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:  a[left + <span class="number">1</span>] = a[left];</span><br><span class="line">                     <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>: System.arraycopy(a, left, a, left + <span class="number">1</span>, n);</span><br><span class="line">        &#125;</span><br><span class="line">        a[left] = pivot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><ol>
<li><p>Comparable 此接口强行对实现它的每个类的对象进行整体排序。这种排序被称为类的<em>自然排序</em>，类的<strong>compareTo()</strong>方法被称为它的<em>自然比较方法</em>。  实现此接口的对象列表（集合和数组）可以通过 Collections.sort和 Arrays.sort 进行自动排序。实现此接口的对象可以用作有序映射中的键或有序集合中的元素，无需指定比较器。</p>
<p>Arrays.sort(people)</p>
</li>
<li><p>Comparator 是比较器，排序时，需要新建比较器对象，将比较器和对象一起传递过去就可以比大小，可称为“<em>外部排序</em>”。比较器是定义在要比较对象的外部的, 必须要重写<strong>compare()</strong>方法，而需要比较的类的结构不需要有任何变化。并且在Comparator 里面用户可以自己实现复杂的可以通用的逻辑,使其可以匹配一些比较简单的对象,那样就可以节省很多重复劳动了。</p>
<p>Arrays.sort(people,new PersonCompartor());</p>
</li>
<li><p>关于两个类的具体应用场景可以理解为，自己在创建一个工程时可以使用Comparable进行排序，当工程创建完毕时添加新的排序功能时，可以使用Comparator，无需改变类的结构。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客安装及部署</title>
    <url>/2020/03/12/Hexo%E5%8D%9A%E5%AE%A2%E5%AE%89%E8%A3%85%E5%8F%8A%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h1><blockquote>
<p>node -v #查看node版本<br>npm -v #查看npm版本<br>npm install -g cnpm –registry=<a href="http://registry.npm.taobao.org" target="_blank" rel="noopener">http://registry.npm.taobao.org</a> #安装淘宝的cnpm 管理器<br>cnpm -v #查看cnpm版本</p>
</blockquote>
<h1 id="hexo安装及配置"><a href="#hexo安装及配置" class="headerlink" title="hexo安装及配置"></a>hexo安装及配置</h1><blockquote>
<p>hexo -v #查看hexo版本<br>mkdir blog #创建blog目录<br>cd blog #进入blog目录<br>sudo hexo init #生成博客 初始化博客</p>
<p>hexo s #启动本地博客服务<br><a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> #本地访问地址<br>hexo n “我的第一篇文章” #创建新的文章</p>
</blockquote>
<p>在blog目录下</p>
<a id="more"></a>
<blockquote>
<p>hexo clean #清理<br>hexo g #生成<br>#Github创建一个新的仓库 YourGithubName.github.io<br>cnpm install –save hexo-deployer-git #在blog目录下安装git部署插件</p>
</blockquote>
<p>配置_config.yml</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">git</span></span><br><span class="line"><span class="attr">repo:</span> <span class="string">https://github.com/YourGithubName/YourGithubName.github.io.git</span></span><br><span class="line"><span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure></div>

<p>部署到Github仓库里</p>
<blockquote>
<p>hexo d</p>
<p><a href="https://YourGithubName.github.io/" target="_blank" rel="noopener">https://YourGithubName.github.io/</a> #访问这个地址可以查看博客</p>
</blockquote>
<h2 id="yilia主题配置"><a href="#yilia主题配置" class="headerlink" title="yilia主题配置"></a>yilia主题配置</h2><ul>
<li>下载yilia主题到本地<ul>
<li>git clone <a href="https://github.com/litten/hexo-theme-yilia.git" target="_blank" rel="noopener">https://github.com/litten/hexo-theme-yilia.git</a> themes/yilia</li>
</ul>
</li>
<li>修改hexo根目录下的 _config.yml 文件 </li>
</ul>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">yilia</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>部署到github<ul>
<li>hexo clean #清理一下</li>
<li>hexo g #生成</li>
<li>hexo d #部署到远程Github仓库</li>
</ul>
</li>
<li>查看博客 ：  <a href="https://YourGithubName.github.io/" target="_blank" rel="noopener">https://YourGithubName.github.io/</a> </li>
</ul>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>ArrayList底层实现源码分析(JDK1.8)</title>
    <url>/2020/03/12/ArrayList%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90_JDK1.8/</url>
    <content><![CDATA[<h2 id="1-类信息"><a href="#1-类信息" class="headerlink" title="1. 类信息"></a>1. 类信息</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-基本属性"><a href="#2-基本属性" class="headerlink" title="2. 基本属性"></a>2. 基本属性</h2><a id="more"></a>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义序列化ID，主要是为了表示不同的版本的兼容性</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">8683452581122892189L</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//默认的数组存储容量(ArrayList底层是数组结构)</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//当指定数组的容量为0时使用这个常量赋值</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object[] EMPTY_ELEMENTDATA = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//默认空参构造函数时使用这个常量赋值</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//真正存放数据的对象数组，transient标识不被序列化</span></span><br><span class="line"><span class="keyword">transient</span> Object[] elementData;</span><br><span class="line"></span><br><span class="line"><span class="comment">//数组中的真实元素个数，该值小于或等于elementData.length</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size;</span><br><span class="line"></span><br><span class="line"><span class="comment">//最大数组长度：0x7fffffff - 8</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_ARRAY_SIZE = Integer.MAX_VALUE - <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器一：创建具有初始化长度的list</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//对传入的值进行合法检测</span></span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.elementData = <span class="keyword">new</span> Object[initialCapacity];</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (initialCapacity == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.elementData = EMPTY_ELEMENTDATA;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Capacity: "</span>+ initialCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器二：默认空参构造器</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器三：创建具有初始化值的集合，可传入的集合类型父类是Collection即可，此处是多态的一个应用</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//将传入的集合转化为数组</span></span><br><span class="line">    elementData = c.toArray();</span><br><span class="line">    <span class="comment">//判断elementData数组长度</span></span><br><span class="line">    <span class="keyword">if</span> ((size = elementData.length) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// elementData转化的数组如果不是Object的子类，就对当前数组进行复制，重新赋值给elementData</span></span><br><span class="line">        <span class="keyword">if</span> (elementData.getClass() != Object[]<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">            <span class="title">elementData</span> </span>= Arrays.copyOf(elementData, size, Object[]<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">//如果数组长度为0，复制为EMPTY_ELEMENTDATA</span></span><br><span class="line">        <span class="keyword">this</span>.elementData = EMPTY_ELEMENTDATA;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="3-add-E-e-方法"><a href="#3-add-E-e-方法" class="headerlink" title="3. add(E e) 方法"></a>3. add(E e) 方法</h2><p>ArrayList集合创建时，默认初始化长度为0，通过add( )方法在添加元素时对数组长度进行动态赋值。添加第一个元素时，长度为10。当添加的元素个数超过10时，会进行首次扩容，容量为原数组长度的1.5倍。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="comment">//此方法是添加元素的方法，另外还有一个重载方法</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//调用ensureCapacityInternal方法，初始化数组长度（默认为10）</span></span><br><span class="line">       ensureCapacityInternal(size + <span class="number">1</span>); </span><br><span class="line">       <span class="comment">//为数组复制</span></span><br><span class="line">       elementData[size++] = e;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line"><span class="comment">//初始化数组长度，默认值为10</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureCapacityInternal</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//判断如果数组长度为0，对长度进行初始化</span></span><br><span class="line">       <span class="keyword">if</span> (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;</span><br><span class="line">           <span class="comment">//从默认数组长度（10）和添加的元素个数（添加第一个元素时size=0,minCapacity=size+1）中取出最大值</span></span><br><span class="line">           <span class="comment">//作为数组初始化长度</span></span><br><span class="line">           minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//再次确定数组容量</span></span><br><span class="line">       ensureExplicitCapacity(minCapacity);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//再次确定数组容量</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureExplicitCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//对数组元素个数进行统计</span></span><br><span class="line">       modCount++;</span><br><span class="line">       <span class="comment">//如果数组长度超过10，就对数组长度进行扩容</span></span><br><span class="line">       <span class="comment">//那第一次扩容举例：minCapacity值为11，DEFAULT_CAPACITY值为10</span></span><br><span class="line">       <span class="keyword">if</span> (minCapacity - elementData.length &gt; <span class="number">0</span>)</span><br><span class="line">           <span class="comment">//对数组进行扩容，默认为老数组的1.5倍</span></span><br><span class="line">           grow(minCapacity);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//对数组进行扩容，默认为老数组的1.5倍</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//老数组容量：minCapacity</span></span><br><span class="line">       <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">       <span class="comment">//新数组容量：是老数组长度的1.5倍</span></span><br><span class="line">       <span class="keyword">int</span> newCapacity = oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</span><br><span class="line">       <span class="comment">//对新数组容量进行合法检测</span></span><br><span class="line">       <span class="keyword">if</span> (newCapacity - minCapacity &lt; <span class="number">0</span>)</span><br><span class="line">           newCapacity = minCapacity;</span><br><span class="line">       <span class="comment">//MAX_ARRAY_SIZE：0x7fffffff - 8</span></span><br><span class="line">       <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">           <span class="comment">//如果超过最大数组长度，再次进行扩容</span></span><br><span class="line">           newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">       <span class="comment">//对原数组进行复制</span></span><br><span class="line">       elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hugeCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) </span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">       <span class="comment">//三元运算符，如果超过最大数组长度返回Integer最大值：0x7fffffff</span></span><br><span class="line">       <span class="keyword">return</span> (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="4-add-int-idnex-E-element"><a href="#4-add-int-idnex-E-element" class="headerlink" title="4. add (int idnex,E element)"></a>4. add (int idnex,E element)</h2><p>从源码中可以看出，与add(E e)方法大致一致，主要的差异是增加了一行代码：System.arraycopy(elementData, index, elementData, index + 1, size - index)，从index位置开始以及之后的数据，整体拷贝到index+1开始的位置，然后再把新加入的数据放在index这个位置，而之前的数据不需要移动。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//在指定位置添加元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//判断index是否在范围内</span></span><br><span class="line">    rangeCheckForAdd(index);</span><br><span class="line">    <span class="comment">//与add(E e)方法一致，对数组长度进行初始化</span></span><br><span class="line">    ensureCapacityInternal(size + <span class="number">1</span>);</span><br><span class="line">    <span class="comment">//对原数组从index位置进行拷贝，复制到index+1的位置，elementData[index]此时为空</span></span><br><span class="line">    <span class="comment">//System.arraycopy是一个native方法，意味着这个方法是C/C++语言实现的，我们无法再以普通的方式去查看这些方法了</span></span><br><span class="line">    System.arraycopy(elementData, index, elementData, index + <span class="number">1</span>, size - index);</span><br><span class="line">    <span class="comment">//为该下标赋值</span></span><br><span class="line">    elementData[index] = element;</span><br><span class="line">    size++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//判断index是否在范围内的具体实现</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rangeCheckForAdd</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (index &gt; size || index &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(outOfBoundsMsg(index));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p> arraycopy(elementData, index, elementData, index + 1, size - index)函数中各个参数对应的意义：（原数组，原数组的开始位置，目标数组，目标数组的开始位置，拷贝的个数）</p>
<h2 id="5-remove-int-index"><a href="#5-remove-int-index" class="headerlink" title="5. remove(int index)"></a>5. remove(int index)</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="comment">//移除指定index下的元素</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//index是否合法检测</span></span><br><span class="line">       rangeCheck(index);</span><br><span class="line">       modCount++;</span><br><span class="line">       <span class="comment">//指定index下的元素</span></span><br><span class="line">       E oldValue = elementData(index);</span><br><span class="line">       <span class="comment">//移除后数组长度</span></span><br><span class="line">       <span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">           System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index, numMoved);</span><br><span class="line">       <span class="comment">//为最后一个元素赋值为null</span></span><br><span class="line">       elementData[--size] = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">return</span> oldValue;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//返回指定index下的元素</span></span><br><span class="line"><span class="function">E <span class="title">elementData</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> (E) elementData[index];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//根据元素（对象）移除该元素</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</span><br><span class="line">               <span class="keyword">if</span> (elementData[index] == <span class="keyword">null</span>) &#123;</span><br><span class="line">                   fastRemove(index);</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</span><br><span class="line">               <span class="keyword">if</span> (o.equals(elementData[index])) &#123;</span><br><span class="line">                   fastRemove(index);</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//类似于remove()方法</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">fastRemove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">       modCount++;</span><br><span class="line">       <span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">           System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index, numMoved);</span><br><span class="line">       elementData[--size] = <span class="keyword">null</span>; </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>
<p>remove方法与add正好是一个相反的操作，移除一个元素，会影响到一批数字的位置移动，所以也是比较耗性能。核心代码都是调用了java.lang.System.arraycopy(Object src, int srcPos, Object dest, int destPos, int length)方法</p>
<h2 id="6-get-int-index"><a href="#6-get-int-index" class="headerlink" title="6. get(int index)"></a>6. get(int index)</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//根据指定下标获取元素值</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    rangeCheck(index);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> elementData(index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="7-set-int-index-E-element"><a href="#7-set-int-index-E-element" class="headerlink" title="7. set(int index, E element)"></a>7. set(int index, E element)</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//修改指定index下的元素值</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">set</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    rangeCheck(index);</span><br><span class="line"></span><br><span class="line">    E oldValue = elementData(index);</span><br><span class="line">    elementData[index] = element;</span><br><span class="line">    <span class="keyword">return</span> oldValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="8-clear"><a href="#8-clear" class="headerlink" title="8. clear()"></a>8. clear()</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//清空所有元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// clear to let GC do its work</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">        elementData[i] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    size = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="9-contains-Object-o"><a href="#9-contains-Object-o" class="headerlink" title="9. contains(Object o)"></a>9. contains(Object o)</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//查询是否包含某个元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> indexOf(o) &gt;= <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//具体的实现方法，如果不包含返回-1</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            <span class="keyword">if</span> (elementData[i]==<span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            <span class="keyword">if</span> (o.equals(elementData[i]))</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h2><p>  基于数组实现的List在随机访问和遍历的效率比较高，但是往指定位置加入元素或者删除指定位置的元素效率比较低。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>易错点</tag>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
