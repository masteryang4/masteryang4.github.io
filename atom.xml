<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>MasterYangBlog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://masteryang4.github.io/"/>
  <updated>2020-08-10T02:08:22.677Z</updated>
  <id>https://masteryang4.github.io/</id>
  
  <author>
    <name>Yang4</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>jvm小结</title>
    <link href="https://masteryang4.github.io/2020/08/10/jvm%E5%B0%8F%E7%BB%93/"/>
    <id>https://masteryang4.github.io/2020/08/10/jvm%E5%B0%8F%E7%BB%93/</id>
    <published>2020-08-09T16:47:43.000Z</published>
    <updated>2020-08-10T02:08:22.677Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JVM简介"><a href="#JVM简介" class="headerlink" title="JVM简介"></a>JVM简介</h1><h2 id="JVM作用"><a href="#JVM作用" class="headerlink" title="JVM作用"></a>JVM作用</h2><p>在Java语言中，最重要的莫过于Java虚拟机。为什么需要有Java虚拟机呢？</p><p>Java 作为一门高级程序语言，它的语法非常复杂，抽象程度也很高。因此，直接在硬件上运行这种复杂的程序并不现实。所以呢，在运行 Java 程序之前，我们需要对其进行一番转换。</p><p>转换的过程为通过编译器将 Java 程序转换成该虚拟机所能识别的指令序列，也称 Java 字节码。Java虚拟机会将字节码，即class文件加载到JVM中。由JVM进行解释和执行。除了 Java 外，Scala、Clojure、Groovy，以及时下热门的 Kotlin，这些语言都可以运行在 Java 虚拟机之上</p><p><strong>JVM是运行在操作系统之上的，它与硬件没有直接的交互</strong></p><h2 id="JVM分类"><a href="#JVM分类" class="headerlink" title="JVM分类"></a>JVM分类</h2><p>​    Sun Classis VM: 世界上第一款商用的虚拟机，已经完全淘汰。</p><p>​    <strong>HotSpot VM</strong>： Sun JDK和OpenJDK中所带的虚拟机，也是目前使用范围最广的Java虚拟机。最初由一家名为“Longview Technologies”的小公司设计，后被Sun公司收购。</p><p>​    Jrockit: 由BEA公司开发的专注于服务器端应用的虚拟机。号称世界上最快的虚拟机。优势在于其垃圾收集器和MissionControl服务套件。BEA Jrockit Mission Control在2005年12月推出，它是一组以极低的开销来监控、管理和分析生产环境中的应用程序的工具。它包括三个独立的应用程序：内存泄露检测器（Memory Leak Detector），JVM运行时分析器（Runtime Analyzer）和管理控制台(Management Console)。</p><p>​    J9：J9由IBM公司开发，曾广泛应用于IBM公司系统内部及IBM小型机上。现已经捐献给Eclipse基金会。</p><h2 id="JVM组成"><a href="#JVM组成" class="headerlink" title="JVM组成"></a>JVM组成</h2><p><a href="https://pic.downk.cc/item/5f2fd48114195aa594db6a78.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fd48114195aa594db6a78.png" class="lazyload"></a></p><p>Java 虚拟机将运行时内存区域划分为五个部分，分别为<strong>方法区、堆、PC 寄存器、Java 方法栈和本地方法栈。</strong>执行 Java 代码首先需要使用类加载器将它编译而成的 class 文件加载到 Java 虚拟机中。加载后的 Java 类会被存放于方法区（Method Area）中。实际运行时，虚拟机会执行方法区内的代码。</p><p>在虚拟机中，方法区和堆为线程共享，也是垃圾回收的重点照顾区域。栈空间为线程私有，基本不会出现垃圾回收。</p><p>Java 虚拟机将栈细分为面向 Java 方法的 Java 方法栈，面向本地方法（用 C++ 写的 native 方法）的本地方法栈，以及存放各个线程执行位置的 PC 寄存器(程序计数器)。</p><p>在运行过程中，每当调用进入一个 Java 方法，Java 虚拟机会在当前线程的 Java 方法栈中生成一个栈帧(栈的一片区域)，用以存放局部变量以及字节码的操作数。这个栈帧的大小是提前计算好的，而且 Java 虚拟机不要求栈帧在内存空间里连续分布。当退出当前执行的方法时，不管是正常返回还是异常返回，Java 虚拟机均会弹出当前线程的当前栈帧，并将之舍弃。</p><h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><p><strong>类加载器，即ClassLoader,它负责加载class文件</strong>，class文件在文件开头有特定的文件标示，并且ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。</p><p><a href="https://pic.downk.cc/item/5f2fd49314195aa594db6eb3.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fd49314195aa594db6eb3.png" class="lazyload"></a></p><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>虚拟机自带的类加载器：</p><p><strong>启动类加载器</strong>（Bootstrap）：主要负责加载jre中的最为基础、最为重要的类。如$JAVA_HOME/jre/lib/rt.jar（runtime）等，以及由虚拟机参数 -Xbootclasspath 指定的类。由于它由由C++代码实现，没有对应的java对象，因此在java中，尝试获取此类时，只能使用null来指代。</p><p><strong>扩展类加载器</strong>（Extension），由Java代码实现，用于加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类，以及由系统变量 java.ext.dirs 指定的类。如$JAVA_HOME/jre/lib/ext/*.jar。</p><p><strong>应用程序类加载器</strong>（AppClassLoader）,由Java代码实现， 它负责加载应用程序路径下的类。（这里的应用程序路径，便是指虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径。）默认情况下，应用程序中包含的类便是由应用类加载器加载的。</p><p><strong>用户自定义的加载器</strong>：Java.lang.ClassLoader的子类，用户可以定制类的加载方式。例如可以对 class 文件进行加密，加载时再利用自定义的类加载器对其解密。</p><p>除了BootStrap Class Loader，其他的类加载器，都是Java.lang.ClassLoader的子类。其他的类加载器都由加载sum.misc.Launcher类后得到。</p><h2 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h2><p>双亲委派模型：每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。</p><p>优势：</p><p>①这采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以<strong>避免类的重复加载</strong>，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。</p><p>②其次是考虑到安全因素，<strong>防止java核心api中定义类型不会被用户恶意替换和篡改</strong>，从而引发错误。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.lang;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">String</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"自己伪造的String"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h1 id="JVM内存模型"><a href="#JVM内存模型" class="headerlink" title="JVM内存模型"></a>JVM内存模型</h1><p><a href="https://pic.downk.cc/item/5f2fd48114195aa594db6a78.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fd48114195aa594db6a78.png" class="lazyload"></a></p><h2 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h2><p><strong>Execution Engine执行引擎负责解释命令，提交操作系统执行</strong>。在 HotSpot 里面，将字节码翻译为机器码的翻译过程有两种形式：第一种是解释执行，即逐条将字节码翻译成机器码并执行；第二种是即时编译（Just-In-Time compilation，JIT），即将一个方法中包含的所有字节码编译成机器码后再执行。</p><p>前者的优势在于无需等待编译，而后者的优势在于实际运行速度更快。HotSpot 默认采用混合模式，综合了解释执行和即时编译两者的优点。它会先解释执行字节码，而后将其中反复执行的热点代码，以方法为单位进行即时编译。</p><h2 id="Native-Interface-amp-Native-Method-Stack"><a href="#Native-Interface-amp-Native-Method-Stack" class="headerlink" title="Native Interface  &amp;  Native Method Stack"></a>Native Interface  &amp;  Native Method Stack</h2><p>在每个操作系统内部，都定义了很多本地方法库，例如windows中以.dll文件为主，Linux总以.so文件为主。</p><p>这些本地方法库中，定义了很多调用本地操作系统的方法，也称之为本地方法接口(Native Interface)。</p><p>本地方法接口的作用是融合不同的编程语言为 Java 所用，它的初衷是融合 C/C++程序，Java 诞生的时候是 C/C++横行的时候，要想立足，必须要调用 C/C++程序，于是就在内存中专门开辟了一块区域处理标记为native的代码，它的具体做法是 Native Method Stack中登记 native方法，在Execution Engine 执行时加载native libraie（本地方法库）。</p><p>​    目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，或者是使用Java语言开发安卓操作系统的硬件驱动等。</p><p>​    例如：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Object</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">registerNatives</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        registerNatives();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">native</span> Class&lt;?&gt; getClass();</span><br></pre></td></tr></table></figure></div><h2 id="PC寄存器（程序计数器）"><a href="#PC寄存器（程序计数器）" class="headerlink" title="PC寄存器（程序计数器）"></a>PC寄存器（程序计数器）</h2><p><strong>每个线程都有一个程序计数器，是线程私有的,就是一个指针</strong>，指向方法区中的方法字节码（用来存储指向下一条指令的地址,就是即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。</p><p>​    PC寄存器主要负责计数和调度。它可以看作是当前线程所执行的字节码的行号指示器。由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域。</p><h2 id="方法区（Method-Area）"><a href="#方法区（Method-Area）" class="headerlink" title="方法区（Method Area）"></a>方法区（Method Area）</h2><p>方法区是被所有线程共享，所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，<strong>所有定义的方法的信息都保存在该区域，此区属于共享区间</strong>。</p><p>​    <strong>静态变量+常量+类信息(构造方法/接口定义)+运行时常量池存在方法区中</strong>。</p><p>​    But</p><p>​    实例变量存在堆内存中,和方法区无关。</p><p>​    方法区是《Java虚拟机规范》中规定的一个概念，在JDK1.7之前，HotSpot使用永久区实现方法区。</p><p>​    1.8之后，由元空间实现。</p><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p>栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就结束，生命周期和线程一致，是线程私有的。</p><p>一个线程中的每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。<strong>8种基本类型的变量+对象的引用变量+实例方法都是在函数的栈内存中分配</strong>。</p><p>在栈区域规定了两种异常状态：如果线程请求的栈深度大于虚拟机所允许的深度，则抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，在扩展是无法申请到足够的内存，就会抛出OutOfMemoryError异常。</p><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><h3 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h3><p>堆是java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。堆内存的大小是可以调节的（通过 -Xmx 和 -Xms 控制）。</p><p>所有的对象实例以及数组都要在堆上分配。</p><p>如果堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p><p>​    java堆是垃圾收集器管理的主要区域，因此也被成为“GC堆”（Garbage Collected Heap）。</p><p><strong>堆内存逻辑上分为三部分：</strong></p><p>​    Young Generation Space  新生区(新生代)          Young/New</p><p>​    Tenure generation space  养老区(养老代)           Old/ Tenure</p><p>​    Permanent Space     永久区(永久代)（1.8后为元空间）  Perm</p><p><a href="https://pic.downk.cc/item/5f2fda7a14195aa594dd52be.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fda7a14195aa594dd52be.png" class="lazyload"></a></p><h3 id="物理设计"><a href="#物理设计" class="headerlink" title="物理设计"></a>物理设计</h3><p><strong>在Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )</strong>。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收</p><p><a href="https://pic.downk.cc/item/5f2fda8c14195aa594dd579d.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fda8c14195aa594dd579d.png" class="lazyload"></a></p><p>新生代分为eden区、s0区、s1区，s0和s1也被称为from和to区域，他们是两块大小相等并且可以互换角色的空间。绝大多数情况下，对象首先分配在eden区，在新生代回收后，如果对象还存活，则进入s0或s1区，之后每经过一次新生代回收，如果对象存活则它的年龄就加1，对象达到一定的年龄（默认15）后，则进入老年代。</p><h2 id="永久区"><a href="#永久区" class="headerlink" title="永久区"></a>永久区</h2><p>永久存储区是一个常驻内存区域，用于存放JDK自身所携带的 Class,Interface 的元数据，也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会轻易被垃圾回收器回收掉的，关闭 JVM 才会释放此区域所占用的内存。</p><p>如果出现java.lang.OutOfMemoryError: PermGen space，说明是Java虚拟机对永久代Perm内存设置不够。一般出现这种情况，都是程序启动需要加载大量的第三方jar包。例如：在一个Tomcat下部署了太多的应用。或者大量动态反射生成的类不断被加载，最终导致Perm区被占满。 </p><p>Jdk1.6及之前： 有永久代, 常量池1.6在方法区</p><p>Jdk1.7：     有永久代，但已经逐步“去永久代”，常量池1.7在堆</p><p>Jdk1.8及之后： 无永久代，常量池1.8在元空间</p><p>实际而言，方法区（Method Area）和堆一样，是各个线程共享的内存区域，它用于存储虚拟机加载的：类信息+普通常量+静态常量+编译器编译后的代码等等，虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap(非堆)，目的就是要和堆分开。</p><p>对于HotSpot虚拟机，很多开发者习惯将方法区称之为“永久代(Parmanent Gen)” ，但严格本质上说两者不同，或者说使用永久代来实现方法区而已，永久代是方法区(相当于是一个接口interface)的一个实现，jdk1.7的版本中，已经将原本放在永久代的字符串常量池移走。</p><p>常量池（Constant Pool）是方法区的一部分，Class文件除了有类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池，这部分内容将在类加载后进入方法区的运行时常量池中存放。</p><h1 id="JVM参数设置"><a href="#JVM参数设置" class="headerlink" title="JVM参数设置"></a>JVM参数设置</h1><h2 id="常见参数设置"><a href="#常见参数设置" class="headerlink" title="常见参数设置"></a>常见参数设置</h2><p><a href="https://pic.downk.cc/item/5f2fdad414195aa594dd6ab3.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fdad414195aa594dd6ab3.png" class="lazyload"></a></p><p>1.7的堆结构</p><table><thead><tr><th>参数名</th><th>含义</th></tr></thead><tbody><tr><td>-XX:+PrintGC</td><td>每次触发GC的时候打印相关日志</td></tr><tr><td>-XX:+UseSerialGC</td><td>串行回收</td></tr><tr><td>-XX:+PrintGCDetails</td><td>更详细的GC日志</td></tr><tr><td>-Xms</td><td>堆初始值(默认为物理内存的1/64)</td></tr><tr><td>-Xmx</td><td>堆最大可用值(默认为物理内存的1/4)</td></tr><tr><td>-Xmn</td><td>新生代堆初始值</td></tr><tr><td>-XX:SurvivorRatio</td><td>用来设置新生代中eden空间和from/to空间的比例，默认为8</td></tr><tr><td>-XX:NewRatio</td><td>配置新生代与老年代占比，默认1:2</td></tr><tr><td>-Xss</td><td>每个线程的堆栈大小，默认为1M，此值不能设置过大，否则会减少线程并发数。</td></tr></tbody></table><p>VM初始分配的堆内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的堆内存由-Xmx指定，默认是物理内存的1/4。默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；</p><p>空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小。</p><p>查看当前JVM内存</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">System.out.print(<span class="string">"最大内存"</span>);</span><br><span class="line">System.out.println(Runtime.getRuntime().maxMemory() / <span class="number">1024.0</span> / <span class="number">1024</span> + <span class="string">"M"</span>);</span><br><span class="line">System.out.print(<span class="string">"当前可用内存"</span>);</span><br><span class="line">System.out.println(Runtime.getRuntime().freeMemory() / <span class="number">1024.0</span> / <span class="number">1024</span> + <span class="string">"M"</span>);</span><br><span class="line">System.out.print(<span class="string">"当前申请内存"</span>);</span><br><span class="line">System.out.println(Runtime.getRuntime().totalMemory() / <span class="number">1024.0</span> / <span class="number">1024</span> + <span class="string">"M"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>设置示例：</p><p>​    -Xms20m -Xmx20m -Xmn1m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC代表</p><p>  堆内存初始化值20m,堆内存最大值20m，新生代最大值可用1m，eden空间和from/to空间的比例为2/1，打印详细的GC信息，使用串行GC回收器。</p><h2 id="常见异常"><a href="#常见异常" class="headerlink" title="常见异常"></a>常见异常</h2><h3 id="OutOfMemoryError"><a href="#OutOfMemoryError" class="headerlink" title="OutOfMemoryError"></a>OutOfMemoryError</h3><p>错误原因: java.lang.OutOfMemoryError: Java heap space 堆内存溢出</p><p>解决办法:调大堆内存大小 </p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// -Xms1m -Xmx10m -XX:+PrintGCDetails</span></span><br><span class="line"></span><br><span class="line">List&lt;Object&gt; listObject = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">System.out.println(<span class="string">"i:"</span> + i);</span><br><span class="line">Byte[] bytes = <span class="keyword">new</span> Byte[<span class="number">1</span> * <span class="number">1024</span> * <span class="number">1024</span>];</span><br><span class="line">listObject.add(bytes);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"添加成功..."</span>);</span><br></pre></td></tr></table></figure></div><h3 id="StackOverflowError"><a href="#StackOverflowError" class="headerlink" title="StackOverflowError"></a>StackOverflowError</h3><p>错误原因: java.lang.StackOverflowError表示为栈内存溢出，一般产生于递归调用。</p><p>解决办法:设置线程最大调用深度，默认是1M</p><p>-Xss5m 设置最大调用深度</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StackTest</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> count;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">count</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">count++;</span><br><span class="line">count(); </span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">System.out.println(<span class="string">"最大深度:"</span>+count);</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"> count();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h1 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h1><h2 id="GC简介"><a href="#GC简介" class="headerlink" title="GC简介"></a>GC简介</h2><p>JVM中的Garbage Collection，简称GC，它会不定时去堆内存中清理不可达对象。</p><p>如果一个对象变成了不可达对象，这并不代表它会立刻被回收。在GC时，不可达的对象并不会立刻回收。</p><p>垃圾回收在一个Java程序中的执行是自动执行的，不受外界干预的。程序员唯一能做的就是通过调用System.gc() 方法来”建议”执行垃圾收集器，但其是否可以执行，什么时候执行却都是不可知的。这也是垃圾收集器的最主要的缺点。当然相对于它给程序员带来的巨大方便性而言，这个缺点是瑕不掩瑜的。</p><h2 id="finalize"><a href="#finalize" class="headerlink" title="finalize()"></a>finalize()</h2><p>Java技术使用finalize()方法在垃圾收集器将对象从内存中清除出去前，做必要的清理工作。</p><p>这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的。它是在Object类中定义的，因此所有的类都继承了它。子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。</p><h2 id="GC的工作特点"><a href="#GC的工作特点" class="headerlink" title="GC的工作特点"></a>GC的工作特点</h2><p>在GC工作中，通过某种算法来对JVM中的内存区域进行检测，对检测到的不可达对象，进行垃圾回收。</p><p><strong>理论上GC过程中会频繁收集Young区，很少收集Old区，基本不动Perm区（元空间/方法区）。</strong></p><h2 id="GC的分类"><a href="#GC的分类" class="headerlink" title="GC的分类"></a>GC的分类</h2><p>JVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。因此GC按照回收的区域又分了两种类型，一种是普通GC（minor GC），一种是全局GC（major GC or Full GC），</p><p>　　新生代GC（minor GC）：只针对新生代区域的GC。</p><p>​       老年代GC（major GC or Full GC）：针对老年代的GC，偶尔伴随对新生代的GC以及对永久代的GC。 一般情况下，当出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程）。</p><p>MajorGC 的速度一般会比 Minor GC 慢 10倍以上。</p><p>Minor GC触发机制：当年轻代满时就会触发Minor GC，这里的年轻代满指的是Eden区满，Survivor满不会引发GC。</p><p>Full GC触发机制：当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代，当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载</p><h2 id="标记不可达对象"><a href="#标记不可达对象" class="headerlink" title="标记不可达对象"></a>标记不可达对象</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p><strong>引用计数法就是如果一个对象没有被任何引用指向，则可视之为垃圾。这种方法的缺点就是不能检测到循环指向的存在。</strong></p><p>首先需要声明，至少主流的Java虚拟机里面都没有选用引用计数算法来管理内存。 </p><p>什么是引用计数算法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加１；当引用失效时，计数器值减１.任何时刻计数器值为０的对象就是不可能再被使用的。</p><p>主流的java虚拟机中没有使用引用计数法的最主要的原因是它很难解决对象之间相互循环引用的问题。</p><p>例如：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyObject</span> </span>&#123;</span><br><span class="line"><span class="keyword">public</span> Object ref;</span><br><span class="line"><span class="keyword">public</span> String name;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">MyObject myObject1 = <span class="keyword">new</span> MyObject();</span><br><span class="line">MyObject myObject2 = <span class="keyword">new</span> MyObject();</span><br><span class="line">myObject1.ref=myObject2;</span><br><span class="line">myObject2.ref=myObject1;</span><br><span class="line">myObject1=<span class="keyword">null</span>;</span><br><span class="line">myObject2=<span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>将myObject1和myObject2赋值为null后，虚拟机依然无法回收，因为他们还相互指向和依赖。</p><h3 id="GC-ROOTS算法"><a href="#GC-ROOTS算法" class="headerlink" title="GC ROOTS算法"></a>GC ROOTS算法</h3><p>根搜索算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。<strong>真正标记对象为可回收状态至少要标记两次.</strong></p><p><strong>简单理解，可以理解为堆外指向堆内的引用。</strong></p><p>以下对象可以选取GC ROOTS节点：</p><p>(1). 虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象。</p><p>(2). 方法区中的类静态属性引用的对象。</p><p>(3). 方法区中常量引用的对象。</p><p>(4). 本地方法栈中JNI(Native方法)引用的对象。</p><h2 id="垃圾回收的三种方式"><a href="#垃圾回收的三种方式" class="headerlink" title="垃圾回收的三种方式"></a>垃圾回收的三种方式</h2><p>当标记完所有的存活对象时，我们便可以进行死亡对象的回收工作了。主流的基础回收方式可分为三种。</p><h3 id="清除"><a href="#清除" class="headerlink" title="清除"></a>清除</h3><p>第一种是清除（sweep），即把死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表（free list）之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。</p><p>清除这种回收方式的原理及其简单，但是有两个缺点。一是会造成内存碎片。由于 Java 虚拟机的堆中对象必须是连续分布的，因此可能出现总空闲内存足够，但是无法分配的极端情况。另一个则是分配效率较低。如果是一块连续的内存空间，那么我们可以通过指针加法（pointer bumping）来做分配。而对于空闲列表，Java 虚拟机则需要逐个访问列表中的项，来查找能够放入新建对象的空闲内存。</p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>第二种是压缩（compact），即把存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销。</p><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>第三种则是复制（copy），即把内存区域分为两等分，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针指向的内存区域中，并且交换 from 指针和 to 指针的内容。复制这种回收方式同样能够解决内存碎片化的问题，但是它的缺点也极其明显，即堆空间的使用效率极其低下。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>回收死亡对象的内存共有三种方式，分别为：会造成内存碎片的清除、性能开销较大的压缩、以及堆使用效率较低的复制。当然，现代的垃圾回收器往往会综合上述几种回收方式，综合它们优点的同时规避它们的缺点。</p><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h3><p>在Java的大部分应用场景下，对象的存活复合这样一个规律，即大部分的 Java 对象只存活一小段时间，而存活下来的小部分 Java 对象则会存活很长一段时间。</p><p>​    基于这样一个规律，在JVM中，使用分代回收思想来回收垃圾。简单来说，就是将堆空间划分为两代，分别叫做新生代和老年代。新生代用来存储新建的对象。当对象存活时间够长时，则将其移动到老年代。</p><p>​    Java 虚拟机可以给不同代使用不同的回收算法。对于新生代，我们猜测大部分的 Java 对象只存活一小段时间，那么便可以频繁地采用耗时较短的垃圾回收算法，让大部分的垃圾都能够在新生代被回收掉。</p><p>对于老年代，由于大部分的垃圾已经在新生代中被回收了，而在老年代中的对象有大概率会继续存活。一般在堆空间即将或者已经耗尽时，才会触发触发针对老年代的回收。这时候，Java 虚拟机往往需要做一次全堆扫描，耗时也将不计成本。（当然，现代的垃圾回收器都在并发收集的道路上发展，来避免这种全堆扫描的情况。）</p><h3 id="堆的划分"><a href="#堆的划分" class="headerlink" title="堆的划分"></a>堆的划分</h3><p>Java 虚拟机将堆划分为新生代和老年代。其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区。</p><p>默认情况下，Java 虚拟机采取的是一种动态分配的策略（对应 Java 虚拟机参数 -XX:+UsePSAdaptiveSurvivorSizePolicy），根据生成对象的速率，以及 Survivor 区的使用情况动态调整 Eden 区和 Survivor 区的比例。</p><p>当然，你也可以通过参数 -XX:SurvivorRatio 来固定这个比例。但是需要注意的是，其中一个 Survivor 区会一直为空，因此比例越低浪费的堆空间将越高。</p><h3 id="标记复制-Mark-Copying-算法"><a href="#标记复制-Mark-Copying-算法" class="headerlink" title="标记复制(Mark-Copying)算法"></a>标记复制(Mark-Copying)算法</h3><p>当我们调用 new 指令时，它会在 Eden 区中划出一块作为存储对象的内存。当 Eden 区的空间耗尽了怎么办？这个时候 Java 虚拟机便会触发一次 Minor GC，来收集新生代的垃圾。存活下来的对象，则会被送到 Survivor 区。</p><p>​    新生代共有两个 Survivor 区，我们分别用 from 和 to 来指代。其中 to 指向的 Survivior 区是空的。当发生 Minor GC 时，Eden 区和 from 指向的 Survivor 区中的存活对象会被复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，以保证下一次 Minor GC 时，to 指向的 Survivor 区还是空的。</p><p>​    Java 虚拟机会记录 Survivor 区中的对象一共被来回复制了几次。如果一个对象被复制的次数为 15（对应虚拟机参数 -XX:+MaxTenuringThreshold），那么该对象将被晋升（promote）至老年代。另外，如果单个 Survivor 区已经被占用了 50%（对应虚拟机参数 -XX:TargetSurvivorRatio），那么较高复制次数的对象也会被晋升至老年代。</p><p>​    万一存活对象数量比较多，那么To域的内存可能不够存放，这个时候会借助老年代的空间。</p><p>​    因此Minor GC使用的则是标记-复制算法。将 Survivor 区中的老存活对象晋升到老年代，然后将剩下的存活对象和 Eden 区的存活对象复制到另一个 Survivor 区中。理想情况下，Eden 区中的对象基本都死亡了，那么需要复制的数据将非常少，因此采用这种标记 - 复制算法的效果极好。</p><p><a href="https://pic.downk.cc/item/5f2fe32914195aa594dfc01c.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5f2fe32914195aa594dfc01c.png" class="lazyload"></a></p><blockquote><p><strong>口诀：复制必交换，谁空谁为to</strong></p></blockquote><h3 id="标记清除-Mark-Sweep-算法"><a href="#标记清除-Mark-Sweep-算法" class="headerlink" title="标记清除(Mark-Sweep)算法"></a>标记清除(Mark-Sweep)算法</h3><p>老年代一般是由标记清除或者是标记清除与标记整理的混合实现。</p><p>​    标记清除算法一般应用于老年代,因为老年代的对象生命周期比较长。该算法先对所有可访问的对象，做个标记再遍历堆，把未被标记的对象回收（标记活的）。</p><p>​    缺点：</p><p>①回收时，应用需要挂起，也就是stop the world，导致用户体验非常差劲</p><p>②由于需要遍历全堆对象，效率比较低（递归与全堆对象遍历）。</p><p>③造成内存碎片化</p><h3 id="标记压缩-Mark–Compact-算法"><a href="#标记压缩-Mark–Compact-算法" class="headerlink" title="标记压缩(Mark–Compact)算法"></a>标记压缩(Mark–Compact)算法</h3><p>标记清除算法和标记压缩算法非常相同，但是标记压缩算法在标记清除算法之上解决内存碎片化。</p><p>优点：解决内存碎片化问题。也消除了复制算法当中，内存减半的高额代价</p><p>缺点：效率低，压缩阶段，由于移动了可用对象，需要去更新引用。</p><h3 id="标记清除压缩-Mark-Sweep-Compact-算法"><a href="#标记清除压缩-Mark-Sweep-Compact-算法" class="headerlink" title="标记清除压缩(Mark-Sweep-Compact)算法"></a>标记清除压缩(Mark-Sweep-Compact)算法</h3><p>标记清除压缩(Mark-Sweep-Compact)算法是标记清除算法和标记压缩算法的结合算法。其原理和标记清除算法一致，只不过会在多次GC后，进行一次Compact操作！</p><h2 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h2><h3 id="串行回收和并行回收"><a href="#串行回收和并行回收" class="headerlink" title="串行回收和并行回收"></a>串行回收和并行回收</h3><p>串行回收: JDK1.5前的默认算法 缺点是只有一个线程，执行垃圾回收时程序停止的时间比较长。</p><p>并行回收: 多个线程执行垃圾回收适合于高吞吐量的系统，回收时系统会停止运行。</p><h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><p>串行收集器是最古老，最稳定以及效率高的收集器，是一个单线程的收集器，在进行垃圾收集时候，必须暂停其他所有的工作线程（Stop The World）直到它收集结束。</p><p>特点：CPU利用率最高，停顿时间即用户等待时间比较长。</p><p>适用场景：小型应用。</p><p>通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器。</p><h3 id="Parallel-New收集器"><a href="#Parallel-New收集器" class="headerlink" title="Parallel New收集器"></a>Parallel New收集器</h3><p><strong>Parallel New</strong>收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代采用复制算法、老年代采用标记-压缩</p><p>参数控制：-XX:+UseParNewGC 使用ParNew收集器</p><p>-XX:ParallelGCThreads 限制线程数量</p><h3 id="Parallel-Scavenge收集器-jdk1-8默认"><a href="#Parallel-Scavenge收集器-jdk1-8默认" class="headerlink" title="Parallel Scavenge收集器(jdk1.8默认)"></a>Parallel Scavenge收集器(jdk1.8默认)</h3><p>Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩，采用多线程来通过扫描并压缩堆。</p><p>特点：停顿时间短，回收效率高，对吞吐量要求高。</p><p>适用场景：大型应用，科学计算，大规模数据采集等。</p><p>通过JVM参数 -XX:+UseParallelGC 打开并发标记扫描垃圾回收器。</p><h3 id="cms收集器【重点】"><a href="#cms收集器【重点】" class="headerlink" title="cms收集器【重点】"></a>cms收集器【重点】</h3><p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： </p><ul><li><p>初始标记（CMS initial mark）</p></li><li><p>并发标记（CMS concurrent mark）</p></li><li><p>并发预处理</p></li><li><p>重新标记（CMS remark）</p></li><li><p>并发清除（CMS concurrent sweep）</p></li><li><p>并发重置</p></li></ul><p>其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 </p><p>由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。</p><p>优点:并发收集、低停顿 </p><p>缺点：产生大量空间碎片、并发阶段会降低吞吐量</p><p>采用“标记-清除”算法实现，使用多线程的算法去扫描堆，对发现未使用的对象进行回收。</p><p>特点：响应时间优先，减少垃圾收集停顿时间。</p><p>适应场景：大型服务器等。</p><p>通过JVM参数 -XX:+UseConcMarkSweepGC设置</p><h3 id="G1收集器-jdk1-9默认-【重点】"><a href="#G1收集器-jdk1-9默认-【重点】" class="headerlink" title="G1收集器(jdk1.9默认)【重点】"></a>G1收集器(jdk1.9默认)【重点】</h3><p>G1（Garbage First）是一个横跨新生代和老年代的垃圾回收器。实际上，它已经打乱了前面所说的堆结构，直接将堆分成极其多个区域。每个区域都可以充当 Eden 区、Survivor 区或者老年代中的一个。它采用的是标记-压缩算法，而且和 CMS 一样都能够在应用程序运行过程中并发地进行垃圾回收。G1 能够针对每个细分的区域来进行垃圾回收。在选择进行垃圾回收的区域时，它会优先回收死亡对象较多的区域。这也是 G1 名字的由来。</p><p>特点：支持很大的堆，高吞吐量</p><pre><code>--支持多CPU和垃圾回收线程--在主线程暂停的情况下，使用并行收集--在主线程运行的情况下，使用并发收集</code></pre><p>实时目标：可配置在N毫秒内最多只占用M毫秒的时间进行垃圾回收</p><p>通过JVM参数 -XX:+UseG1GC 使用G1垃圾回收器</p><p>注意:  并发是指一个处理器同时处理多个任务。 </p><p>并行是指多个处理器或者是多核的处理器同时处理多个不同的任务。 </p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>针对新生代的垃圾回收器共有三个：<strong>Serial，Parallel Scavenge和 Parallel New</strong>。这三个采用的都是标记-复制算法。其中，Serial 是一个单线程的，Parallel New 可以看成 Serial 的多线程版本。Parallel Scavenge 和 Parallel New 类似，但更加注重吞吐率。此外，Parallel Scavenge 不能与 CMS 一起使用。</p><p>针对老年代的垃圾回收器也有三个：<strong>Serial Old 和Parallel Old</strong>，以及 <strong>CMS</strong>。Serial Old 和 Parallel Old 都是标记-压缩算法。同样，前者是单线程的，而后者可以看成前者的多线程版本。</p><p>CMS 采用的是标记-清除算法，并且是并发的。除了少数几个操作需要 Stop-the-world 之外，它可以在应用程序运行过程中进行垃圾回收。在并发收集失败的情况下，Java 虚拟机会使用其他两个压缩型垃圾回收器进行一次垃圾回收。由于 G1 的出现，CMS 在 Java 9 中已被废弃。</p><blockquote><p>推荐参考： <a href="https://blog.csdn.net/okForrest27/article/details/107330039" target="_blank" rel="noopener">https://blog.csdn.net/okForrest27/article/details/107330039</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;JVM简介&quot;&gt;&lt;a href=&quot;#JVM简介&quot; class=&quot;headerlink&quot; title=&quot;JVM简介&quot;&gt;&lt;/a&gt;JVM简介&lt;/h1&gt;&lt;h2 id=&quot;JVM作用&quot;&gt;&lt;a href=&quot;#JVM作用&quot; class=&quot;headerlink&quot; title=&quot;JVM
      
    
    </summary>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/categories/Java/"/>
    
      <category term="JVM" scheme="https://masteryang4.github.io/categories/Java/JVM/"/>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/tags/Java/"/>
    
      <category term="JVM" scheme="https://masteryang4.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>判断一个链表是否有环</title>
    <link href="https://masteryang4.github.io/2020/08/09/%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF/"/>
    <id>https://masteryang4.github.io/2020/08/09/%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF/</id>
    <published>2020-08-09T15:58:09.000Z</published>
    <updated>2020-08-09T15:59:03.052Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>怎么能够更高效地判断一个链表是否有环？</p><p>首先创建两个指针p1和p2（在Java里就是两个对象引用），让它们同时指向这个链表的头节点。</p><p>然后开始一个大循环，在循环体中，让指针p1每次向后移动1个节点，让指针p2每次向后移动2个节点，然后比较两个指针指向的节点是否相同。如果相同，则可以判断出链表有环，如果不同，则继续下一次循环。</p><h1 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h1><p>假设链表的节点数量为n，则该算法的时间复杂度为O(n)。</p><p>除两个指针外，没有使用任何额外的存储空间，所以空间复杂度是O(1)</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedListCycle</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断是否有环</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> head  链表头节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isCycle</span><span class="params">(Node head)</span> </span>&#123;</span><br><span class="line">        Node p1 = head;</span><br><span class="line">        Node p2 = head;</span><br><span class="line">        <span class="keyword">while</span> (p2!=<span class="keyword">null</span> &amp;&amp; p2.next!=<span class="keyword">null</span>)&#123; <span class="comment">// 【注意】</span></span><br><span class="line">            p1 = p1.next;</span><br><span class="line">            p2 = p2.next.next;</span><br><span class="line">            <span class="keyword">if</span>(p1 == p2)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 链表节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> data;</span><br><span class="line">        Node next;</span><br><span class="line">        Node(<span class="keyword">int</span> data) &#123;</span><br><span class="line">            <span class="keyword">this</span>.data = data;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Node node1 = <span class="keyword">new</span> Node(<span class="number">5</span>);</span><br><span class="line">        Node node2 = <span class="keyword">new</span> Node(<span class="number">3</span>);</span><br><span class="line">        Node node3 = <span class="keyword">new</span> Node(<span class="number">7</span>);</span><br><span class="line">        Node node4 = <span class="keyword">new</span> Node(<span class="number">2</span>);</span><br><span class="line">        Node node5 = <span class="keyword">new</span> Node(<span class="number">6</span>);</span><br><span class="line">        node1.next = node2;</span><br><span class="line">        node2.next = node3;</span><br><span class="line">        node3.next = node4;</span><br><span class="line">        node4.next = node5;</span><br><span class="line">        node5.next = node2;</span><br><span class="line"></span><br><span class="line">        System.out.println(isCycle(node1));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p><strong>如果链表有环，如何求出环的长？</strong></p><p>当两个指针首次相遇，证明链表有环的时候，让两个指针从相遇点继续循环前进，并统计前进的循环次数，直到两个指针第2次相遇。此时，统计出来的前进次数就是环长。</p><p>因为指针p1每次走1步，指针p2每次走2步，两者的速度差是1步。当两个指针再次相遇时，p2比p1多走了整整1圈因此，环长 = 每一次速度差 × 前进次数 = 前进次数</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><blockquote><p><a href="https://www.cnblogs.com/zhaoqingqing/p/11853924.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhaoqingqing/p/11853924.html</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;怎么能够更高效地判断一个链表是否有环？&lt;/p&gt;
&lt;p&gt;首先创建两个指针p1和p2（在Java里就是两个对象引用），让它们同时
      
    
    </summary>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="链表" scheme="https://masteryang4.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>链表反转</title>
    <link href="https://masteryang4.github.io/2020/08/09/%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/"/>
    <id>https://masteryang4.github.io/2020/08/09/%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/</id>
    <published>2020-08-09T15:56:45.000Z</published>
    <updated>2020-08-09T15:57:49.241Z</updated>
    
    <content type="html"><![CDATA[<h1 id="反转单链表"><a href="#反转单链表" class="headerlink" title="反转单链表"></a>反转单链表</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL</span><br><span class="line">输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL</span><br></pre></td></tr></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">reverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">    ListNode prev = <span class="keyword">null</span>;</span><br><span class="line">    ListNode curr = head;</span><br><span class="line">    <span class="keyword">while</span> (curr != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ListNode nextTemp = curr.next;</span><br><span class="line">        curr.next = prev;</span><br><span class="line">        prev = curr;</span><br><span class="line">        curr = nextTemp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> prev;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;反转单链表&quot;&gt;&lt;a href=&quot;#反转单链表&quot; class=&quot;headerlink&quot; title=&quot;反转单链表&quot;&gt;&lt;/a&gt;反转单链表&lt;/h1&gt;&lt;div class=&quot;code-area-wrap&quot;&gt;&lt;div class=&quot;highlight-tools&quot;&gt;&lt;i c
      
    
    </summary>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="链表" scheme="https://masteryang4.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>堆排序总结</title>
    <link href="https://masteryang4.github.io/2020/08/09/%E5%A0%86%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"/>
    <id>https://masteryang4.github.io/2020/08/09/%E5%A0%86%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/</id>
    <published>2020-08-09T15:49:30.000Z</published>
    <updated>2020-08-09T15:56:25.771Z</updated>
    
    <content type="html"><![CDATA[<h1 id="堆的定义"><a href="#堆的定义" class="headerlink" title="堆的定义"></a>堆的定义</h1><p>堆是一种数据结构，一种叫做完全二叉树的数据结构。</p><h1 id="堆的性质"><a href="#堆的性质" class="headerlink" title="堆的性质"></a>堆的性质</h1><p>这里我们用到两种堆，其实也算是一种。</p><p>大顶堆：每个节点的值都大于或者等于它的左右子节点的值。</p><p>小顶堆：每个节点的值都小于或者等于它的左右子节点的值。</p><p>把这种逻辑结构映射到数组中 ，数组arr逻辑上就是一个堆。</p><p><strong>从这里我们可以得出以下性质</strong></p><p>对于大顶堆：arr[i] &gt;= arr[2i + 1] &amp;&amp; arr[i] &gt;= arr[2i + 2]</p><p>对于小顶堆：arr[i] &lt;= arr[2i + 1] &amp;&amp; arr[i] &lt;= arr[2i + 2]</p><h1 id="堆排序的基本思想"><a href="#堆排序的基本思想" class="headerlink" title="堆排序的基本思想"></a>堆排序的基本思想</h1><p>1、将要排序的序列构造成一个大顶堆，根据大顶堆的性质，当前堆的根节点（堆顶）就是序列中最大的元素；</p><p>2、将堆顶元素和最后一个元素交换，然后将剩下的节点重新构造成一个大顶堆；<br>3、重复步骤2，如此反复，从第一次构建大顶堆开始，每一次构建，我们都能获得一个序列的最大值，然后把它放到大顶堆的尾部。最后，就得到一个有序的序列了。 </p><p><strong>那么，该如何知道最后一个非叶子节点的位置，也就是索引值？</strong></p><p>对于一个完全二叉树，在填满的情况下（非叶子节点都有两个子节点），每一层的元素个数是上一层的二倍，根节点数量是1，所以最后一层的节点数量，一定是之前所有层节点总数+1，所以，我们能找到最后一层的第一个节点的索引，即节点总数/2（根节点索引为0），这也就是第一个叶子节点，所以第一个非叶子节点的索引就是第一个叶子结点的索引-1。那么对于填不满的二叉树呢？这个计算方式仍然适用，当我们从上往下，从左往右填充二叉树的过程中，第一个叶子节点，一定是序列长度/2，所以第一个非叶子节点的索引就是arr.length / 2 -1。</p><p>现在找到了最后一个非叶子节点，即元素值为2的节点，比较它的左右节点的值，是否比他大，如果大就换位置。这里因为1&lt;2，所以，不需要任何操作，继续比较下一个，即元素值为8的节点，它的左节点值为9比它本身大，所以需要交换</p><h1 id="java代码实现"><a href="#java代码实现" class="headerlink" title="java代码实现"></a>java代码实现</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">8</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">4</span>&#125;;</span><br><span class="line">        heapSort(arr);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">        <span class="comment">//[1, 2, 3, 4, 5, 6, 7, 8]</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">heapSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (arr == <span class="keyword">null</span> || arr.length == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> len = arr.length;</span><br><span class="line">        <span class="comment">// 构建大顶堆，这里其实就是把待排序序列，变成一个大顶堆结构的数组</span></span><br><span class="line">        buildMaxHeap(arr, len);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交换堆顶和当前末尾的节点，重置大顶堆</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = len - <span class="number">1</span>; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">            swap(arr, <span class="number">0</span>, i);</span><br><span class="line">            len--;</span><br><span class="line">            heapify(arr, <span class="number">0</span>, len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">buildMaxHeap</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从最后一个非叶节点开始向前遍历，调整节点性质，使之成为大顶堆</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = (<span class="keyword">int</span>) Math.floor(len / <span class="number">2</span>) - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            heapify(arr, i, len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">heapify</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> i, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 先根据堆性质，找出它左右节点的索引</span></span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">2</span> * i + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">2</span> * i + <span class="number">2</span>;</span><br><span class="line">        <span class="comment">// 默认当前节点（父节点）是最大值。</span></span><br><span class="line">        <span class="keyword">int</span> largestIndex = i;</span><br><span class="line">        <span class="keyword">if</span> (left &lt; len &amp;&amp; arr[left] &gt; arr[largestIndex]) &#123;</span><br><span class="line">            <span class="comment">// 如果有左节点，并且左节点的值更大，更新最大值的索引</span></span><br><span class="line">            largestIndex = left;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (right &lt; len &amp;&amp; arr[right] &gt; arr[largestIndex]) &#123;</span><br><span class="line">            <span class="comment">// 如果有右节点，并且右节点的值更大，更新最大值的索引</span></span><br><span class="line">            largestIndex = right;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (largestIndex != i) &#123;</span><br><span class="line">            <span class="comment">// 如果最大值不是当前非叶子节点的值，那么就把当前节点和最大值的子节点值互换</span></span><br><span class="line">            swap(arr, i, largestIndex);</span><br><span class="line">            <span class="comment">// 因为互换之后，子节点的值变了，如果该子节点也有自己的子节点，仍需要再次调整。</span></span><br><span class="line">            heapify(arr, largestIndex, len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> temp = arr[i];</span><br><span class="line">        arr[i] = arr[j];</span><br><span class="line">        arr[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h1 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h1><p>堆排序是一种选择排序，整体主要由构建初始堆+交换堆顶元素和末尾元素并重建堆两部分组成。其中构建初始堆经推导复杂度为O(n)，在交换并重建堆的过程中，需交换n-1次，而重建堆的过程中，根据完全二叉树的性质，[log2(n-1),log2(n-2)…1]逐步递减，近似为nlogn。所以堆排序时间复杂度一般认为就是O(nlogn)级。 </p><p>最好和最坏的情况时间复杂度都是O(nlogn)，空间复杂度O(1)。 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;堆的定义&quot;&gt;&lt;a href=&quot;#堆的定义&quot; class=&quot;headerlink&quot; title=&quot;堆的定义&quot;&gt;&lt;/a&gt;堆的定义&lt;/h1&gt;&lt;p&gt;堆是一种数据结构，一种叫做完全二叉树的数据结构。&lt;/p&gt;
&lt;h1 id=&quot;堆的性质&quot;&gt;&lt;a href=&quot;#堆的性质&quot; cla
      
    
    </summary>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="算法与数据结构" scheme="https://masteryang4.github.io/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="排序算法" scheme="https://masteryang4.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    
      <category term="二叉树" scheme="https://masteryang4.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>Synchronized与Lock的区别</title>
    <link href="https://masteryang4.github.io/2020/08/09/Synchronized%E4%B8%8ELock%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://masteryang4.github.io/2020/08/09/Synchronized%E4%B8%8ELock%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-08-09T15:46:01.000Z</published>
    <updated>2020-08-09T15:47:20.852Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Synchronized与Lock的区别"><a href="#Synchronized与Lock的区别" class="headerlink" title="Synchronized与Lock的区别"></a>Synchronized与Lock的区别</h1><p><strong>参考一</strong></p><ol><li><p>来源：<br>lock是一个接口，而synchronized是java的一个关键字，synchronized是内置的语言实现；</p></li><li><p>异常是否释放锁：<br>synchronized在发生异常时候会自动释放占有的锁，因此不会出现死锁；</p><p>而lock发生异常时候，不会主动释放占有的锁，必须手动unlock来释放锁，可能引起死锁的发生。（所以最好将同步代码块用try catch包起来，finally中写入unlock，避免死锁的发生。）</p></li><li><p>是否响应中断<br>lock等待锁过程中可以用interrupt来中断等待，而synchronized只能等待锁的释放，不能响应中断；</p></li><li><p>是否知道获取锁<br>Lock可以通过trylock来知道有没有获取锁，而synchronized不能；</p></li><li><p>Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）</p></li><li><p>在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。</p></li><li><p>synchronized使用Object对象本身的wait 、notify、notifyAll调度机制，而Lock可以使用Condition进行线程之间的调度，</p></li></ol><p><strong>参考二</strong></p><p>1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；</p><p>2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；</p><p>3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；</p><p>4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；</p><p>5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）</p><p>6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。</p><blockquote><p>参考： <a href="https://www.cnblogs.com/iyyy/p/7993788.html" target="_blank" rel="noopener">https://www.cnblogs.com/iyyy/p/7993788.html</a> </p><p>​            <a href="https://blog.csdn.net/hefenglian/article/details/82383569" target="_blank" rel="noopener">https://blog.csdn.net/hefenglian/article/details/82383569</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Synchronized与Lock的区别&quot;&gt;&lt;a href=&quot;#Synchronized与Lock的区别&quot; class=&quot;headerlink&quot; title=&quot;Synchronized与Lock的区别&quot;&gt;&lt;/a&gt;Synchronized与Lock的区别&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/categories/Java/"/>
    
      <category term="JUC" scheme="https://masteryang4.github.io/categories/Java/JUC/"/>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/tags/Java/"/>
    
      <category term="JUC" scheme="https://masteryang4.github.io/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>flink系列12电商用户行为分析</title>
    <link href="https://masteryang4.github.io/2020/08/09/flink%E7%B3%BB%E5%88%9712%E7%94%B5%E5%95%86%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/"/>
    <id>https://masteryang4.github.io/2020/08/09/flink%E7%B3%BB%E5%88%9712%E7%94%B5%E5%95%86%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/</id>
    <published>2020-08-09T15:44:47.000Z</published>
    <updated>2020-08-10T02:09:24.908Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据集解析"><a href="#数据集解析" class="headerlink" title="数据集解析"></a>数据集解析</h2><h3 id="淘宝数据集解析"><a href="#淘宝数据集解析" class="headerlink" title="淘宝数据集解析"></a>淘宝数据集解析</h3><p>我们准备了一份淘宝用户行为数据集，保存为csv文件。本数据集包含了淘宝上某一天随机一百万用户的所有行为（包括点击、购买、收藏、喜欢）。数据集的每一行表示一条用户行为，由用户ID、商品ID、商品类目ID、行为类型和时间戳组成，并以逗号分隔。关于数据集中每一列的详细描述如下：</p><table><thead><tr><th>字段名</th><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>userId</td><td>Long</td><td>脱敏后的用户ID</td></tr><tr><td>itemId</td><td>Long</td><td>脱敏后的商品ID</td></tr><tr><td>categoryId</td><td>Int</td><td>脱敏后的商品所属类别ID</td></tr><tr><td>behavior</td><td>String</td><td>用户行为类型，包括：(‘pv’, ‘buy’, ‘cart’, ‘fav’)</td></tr><tr><td>timestamp</td><td>Long</td><td>行为发生的时间戳，单位秒</td></tr></tbody></table><h3 id="Apache服务器日志数据集解析"><a href="#Apache服务器日志数据集解析" class="headerlink" title="Apache服务器日志数据集解析"></a>Apache服务器日志数据集解析</h3><p>这里以apache服务器的一份log为例，每一行日志记录了访问者的IP、userId、访问时间、访问方法以及访问的url，具体描述如下：</p><table><thead><tr><th>字段名</th><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>ip</td><td>String</td><td>访问的IP</td></tr><tr><td>userId</td><td>Long</td><td>访问的userId</td></tr><tr><td>eventTime</td><td>Long</td><td>访问时间</td></tr><tr><td>method</td><td>String</td><td>访问方法 GET/POST/PUT/DELETE</td></tr><tr><td>url</td><td>String</td><td>访问的url</td></tr></tbody></table><h2 id="实时热门商品统计"><a href="#实时热门商品统计" class="headerlink" title="实时热门商品统计"></a>实时热门商品统计</h2><p>首先要实现的是实时热门商品统计，我们将会基于UserBehavior数据集来进行分析。</p><p><em>基本需求</em></p><ul><li>每隔5分钟输出最近一小时内点击量最多的前N个商品</li><li>点击量用浏览次数(“pv”)来衡量</li></ul><p><em>解决思路</em></p><p>. 在所有用户行为数据中，过滤出浏览(“pv”)行为进行统计 . 构建滑动窗口，窗口长度为1小时，滑动距离为5分钟 . 窗口计算使用增量聚合函数和全窗口聚合函数相结合的方法 . 使用窗口结束时间作为key，对DataStream进行keyBy()操作 . 将KeyedStream中的元素存储到ListState中，当水位线超过窗口结束时间时，排序输出</p><p><em>数据准备</em></p><p>将数据文件UserBehavior.csv复制到资源文件目录src/main/resources下。</p><p><em>程序主体</em></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 把数据需要ETL成UserBehavior类型</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserBehavior</span>(<span class="params">userId: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        itemId: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        categoryId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        behavior: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        timestamp: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">全窗口聚合函数输出的数据类型</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">ItemViewCount</span>(<span class="params">itemId: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                         windowEnd: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                         count: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"> </span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">HotItems</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 创建一个 StreamExecutionEnvironment</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="comment">// 设定Time类型为EventTime</span></span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="comment">// 为了打印到控制台的结果不乱序，</span></span><br><span class="line">    <span class="comment">// 我们配置全局的并发为1，这里改变并发对结果正确性没有影响</span></span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      <span class="comment">// 以window下为例，需替换成数据集的绝对路径</span></span><br><span class="line">      .readTextFile(<span class="string">"YOUR_PATH\\resources\\UserBehavior.csv"</span>)</span><br><span class="line">      .map(line =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> linearray = line.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">UserBehavior</span>(linearray(<span class="number">0</span>).toLong,</span><br><span class="line">                     linearray(<span class="number">1</span>).toLong,</span><br><span class="line">                     linearray(<span class="number">2</span>).toInt,</span><br><span class="line">                     linearray(<span class="number">3</span>),</span><br><span class="line">                     linearray(<span class="number">4</span>).toLong)</span><br><span class="line">      &#125;)</span><br><span class="line">      <span class="comment">// 过滤出点击事件</span></span><br><span class="line">      .filter(_.behavior == <span class="string">"pv"</span>)</span><br><span class="line">      <span class="comment">// 指定时间戳和Watermark，这里我们已经知道了数据集的时间戳是单调递增的了。</span></span><br><span class="line">      .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>)</span><br><span class="line">      <span class="comment">// 根据商品Id分流</span></span><br><span class="line">      .keyBy(_.itemId)</span><br><span class="line">      <span class="comment">// 开窗操作</span></span><br><span class="line">      .timeWindow(<span class="type">Time</span>.minutes(<span class="number">60</span>), <span class="type">Time</span>.minutes(<span class="number">5</span>))</span><br><span class="line">      <span class="comment">// 窗口计算操作</span></span><br><span class="line">      .aggregate(<span class="keyword">new</span> <span class="type">CountAgg</span>(), <span class="keyword">new</span> <span class="type">WindowResultFunction</span>())</span><br><span class="line">      <span class="comment">// 根据窗口结束时间分流</span></span><br><span class="line">      .keyBy(_.windowEnd)</span><br><span class="line">      <span class="comment">// 求点击量前3名的商品</span></span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">TopNHotItems</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印结果</span></span><br><span class="line">    stream.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 别忘了执行</span></span><br><span class="line">    env.execute(<span class="string">"Hot Items Job"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><blockquote><p>真实业务场景一般都是乱序的，所以一般不用<code>assignAscendingTimestamps</code>，而是使用<code>BoundedOutOfOrdernessTimestampExtractor</code>。</p></blockquote><p><em>增量聚合函数逻辑编写</em></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// COUNT统计的聚合函数实现，每出现一条记录就加一</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountAgg</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">UserBehavior</span>, <span class="type">Long</span>, <span class="type">Long</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Long</span> = <span class="number">0</span>L</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(userBehavior: <span class="type">UserBehavior</span>, acc: <span class="type">Long</span>): <span class="type">Long</span> = acc + <span class="number">1</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: <span class="type">Long</span>): <span class="type">Long</span> = acc</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc1: <span class="type">Long</span>, acc2: <span class="type">Long</span>): <span class="type">Long</span> = acc1 + acc2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p><em>全窗口聚合函数逻辑编写</em></p><p>其实就是将增量聚合的结果包上一层窗口信息和key的信息。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用于输出窗口的结果</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WindowResultFunction</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[<span class="type">Long</span>, <span class="type">ItemViewCount</span>, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                        context: <span class="type">Context</span>,</span><br><span class="line">                        elements: <span class="type">Iterable</span>[<span class="type">Long</span>],</span><br><span class="line">                        out: <span class="type">Collector</span>[<span class="type">ItemViewCount</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    out.collect(<span class="type">ItemViewCount</span>(key, context.window.getEnd, elements.iterator.next()))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>现在我们就得到了每个商品在每个窗口的点击量的数据流。</p><p><em>计算最热门TopN商品</em></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopNHotItems</span>(<span class="params">topSize: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">Long</span>, <span class="type">ItemViewCount</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="comment">// 惰性赋值一个状态变量</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> itemState = getRuntimeContext.getListState(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[<span class="type">ItemViewCount</span>](<span class="string">"items"</span>, <span class="type">Types</span>.of[<span class="type">ItemViewCount</span>])</span><br><span class="line">  )</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// 来一条数据都会调用一次</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: <span class="type">ItemViewCount</span>,</span><br><span class="line">                              ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">Long</span>,</span><br><span class="line">                                <span class="type">ItemViewCount</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">                              out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    itemState.add(value)</span><br><span class="line">    ctx.timerService().registerEventTimeTimer(value.windowEnd + <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// 定时器事件</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(</span><br><span class="line">    ts: <span class="type">Long</span>,</span><br><span class="line">    ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">Long</span>, <span class="type">ItemViewCount</span>, <span class="type">String</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">    out: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">  ): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> allItems: <span class="type">ListBuffer</span>[<span class="type">ItemViewCount</span>] = <span class="type">ListBuffer</span>()</span><br><span class="line">    <span class="comment">// 导入一些隐式类型转换</span></span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line">    <span class="keyword">for</span> (item &lt;- itemState.get) &#123;</span><br><span class="line">      allItems += item</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 清空状态变量，释放空间</span></span><br><span class="line">    itemState.clear()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 降序排列</span></span><br><span class="line">    <span class="keyword">val</span> sortedItems = allItems.sortBy(-_.count).take(topSize)</span><br><span class="line">    <span class="keyword">val</span> result = <span class="keyword">new</span> <span class="type">StringBuilder</span></span><br><span class="line">    result.append(<span class="string">"====================================\n"</span>)</span><br><span class="line">    result.append(<span class="string">"时间: "</span>).append(<span class="keyword">new</span> <span class="type">Timestamp</span>(ts - <span class="number">1</span>)).append(<span class="string">"\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- sortedItems.indices) &#123;</span><br><span class="line">      <span class="keyword">val</span> currentItem = sortedItems(i)</span><br><span class="line">      result.append(<span class="string">"No"</span>)</span><br><span class="line">        .append(i+<span class="number">1</span>)</span><br><span class="line">        .append(<span class="string">":"</span>)</span><br><span class="line">        .append(<span class="string">"  商品ID="</span>)</span><br><span class="line">        .append(currentItem.itemId)</span><br><span class="line">        .append(<span class="string">"  浏览量="</span>)</span><br><span class="line">        .append(currentItem.count)</span><br><span class="line">        .append(<span class="string">"\n"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    result.append(<span class="string">"====================================\n\n"</span>)</span><br><span class="line">    <span class="type">Thread</span>.sleep(<span class="number">1000</span>)</span><br><span class="line">    out.collect(result.toString())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p><em>更换Kafka作为数据源</em></p><p>实际生产环境中，我们的数据流往往是从Kafka获取到的。如果要让代码更贴近生产实际，我们只需将source更换为Kafka即可：</p><blockquote><p>注意：这里Kafka的版本要用2.2！</p></blockquote><p>添加依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>编写代码：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">properties.setProperty(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"consumer-group"</span>)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"key.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"value.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](</span><br><span class="line">    <span class="string">"hotitems"</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),</span><br><span class="line">    properties)</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></div><p>当然，根据实际的需要，我们还可以将Sink指定为Kafka、ES、Redis或其它存储，这里就不一一展开实现了。</p><p><em>kafka生产者程序</em></p><p>添加依赖</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>编写代码：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KafkaProducerUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    writeToKafka(<span class="string">"hotitems"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">writeToKafka</span></span>(topic: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> props = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">    props.put(</span><br><span class="line">      <span class="string">"key.serializer"</span>,</span><br><span class="line">      <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span></span><br><span class="line">    )</span><br><span class="line">    props.put(</span><br><span class="line">      <span class="string">"value.serializer"</span>,</span><br><span class="line">      <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](props)</span><br><span class="line">    <span class="keyword">val</span> bufferedSource = io.<span class="type">Source</span>.fromFile(<span class="string">"UserBehavior.csv文件的绝对路径"</span>)</span><br><span class="line">    <span class="keyword">for</span> (line &lt;- bufferedSource.getLines) &#123;</span><br><span class="line">      <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](topic, line)</span><br><span class="line">      producer.send(record)</span><br><span class="line">    &#125;</span><br><span class="line">    producer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="实时流量统计"><a href="#实时流量统计" class="headerlink" title="实时流量统计"></a>实时流量统计</h2><ul><li>基本需求<ul><li>从web服务器的日志中，统计实时的访问流量</li><li>统计每分钟的ip访问量，取出访问量最大的5个地址，每5秒更新一次</li></ul></li><li>解决思路<ul><li>将apache服务器日志中的时间，转换为时间戳，作为Event Time</li><li>构建滑动窗口，窗口长度为1分钟，滑动距离为5秒</li></ul></li></ul><p><em>数据准备</em></p><p>将apache服务器的日志文件apache.log复制到资源文件目录src/main/resources下，我们将从这里读取数据。</p><p><em>代码实现</em></p><p>我们现在要实现的模块是“实时流量统计”。对于一个电商平台而言，用户登录的入口流量、不同页面的访问流量都是值得分析的重要数据，而这些数据，可以简单地从web服务器的日志中提取出来。我们在这里实现最基本的“页面浏览数”的统计，也就是读取服务器日志中的每一行log，统计在一段时间内用户访问url的次数。</p><p>具体做法为：每隔5秒，输出最近10分钟内访问量最多的前N个URL。可以看出，这个需求与之前“实时热门商品统计”非常类似，所以我们完全可以借鉴此前的代码。</p><p>完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.project</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">Timestamp</span></span><br><span class="line"><span class="keyword">import</span> java.text.<span class="type">SimpleDateFormat</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">AggregateFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.<span class="type">ListStateDescriptor</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.typeutils.<span class="type">Types</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions</span><br><span class="line">.timestamps.<span class="type">BoundedOutOfOrdernessTimestampExtractor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.function.<span class="type">ProcessWindowFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ApacheLogAnalysis</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ApacheLogEvent</span>(<span class="params">ip: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                            userId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                            eventTime: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                            method: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                            url: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">case</span> <span class="title">class</span> <span class="title">UrlViewCount</span>(<span class="params">url: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          windowEnd: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          count: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">def</span> <span class="title">main</span>(<span class="params">args: <span class="type">Array</span>[<span class="type">String</span>]</span>)</span>: <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      <span class="comment">// 文件的绝对路径</span></span><br><span class="line">      .readTextFile(<span class="string">"apache.log的绝对路径"</span>)</span><br><span class="line">      .map(line =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> linearray = line.split(<span class="string">" "</span>)</span><br><span class="line">        <span class="comment">// 把时间戳ETL成毫秒</span></span><br><span class="line">        <span class="keyword">val</span> simpleDateFormat = <span class="keyword">new</span> <span class="type">SimpleDateFormat</span>(<span class="string">"dd/MM/yyyy:HH:mm:ss"</span>)</span><br><span class="line">        <span class="keyword">val</span> timestamp = simpleDateFormat.parse(linearray(<span class="number">3</span>)).getTime</span><br><span class="line">        <span class="type">ApacheLogEvent</span>(linearray(<span class="number">0</span>),</span><br><span class="line">                       linearray(<span class="number">2</span>),</span><br><span class="line">                       timestamp,</span><br><span class="line">                       linearray(<span class="number">5</span>),</span><br><span class="line">                       linearray(<span class="number">6</span>))</span><br><span class="line">      &#125;)</span><br><span class="line">      .assignTimestampsAndWatermarks(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">ApacheLogEvent</span>](</span><br><span class="line">          <span class="type">Time</span>.milliseconds(<span class="number">1000</span>)</span><br><span class="line">        ) &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(t: <span class="type">ApacheLogEvent</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            t.eventTime</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line">      .keyBy(_.url)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.minutes(<span class="number">10</span>), <span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">      .aggregate(<span class="keyword">new</span> <span class="type">CountAgg</span>(), <span class="keyword">new</span> <span class="type">WindowResultFunction</span>())</span><br><span class="line">      .keyBy(_.windowEnd)</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">TopNHotUrls</span>(<span class="number">5</span>))</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"Traffic Analysis Job"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">CountAgg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">ApacheLogEvent</span>, <span class="type">Long</span>, <span class="type">Long</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Long</span> = <span class="number">0</span>L</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(apacheLogEvent: <span class="type">ApacheLogEvent</span>, acc: <span class="type">Long</span>): <span class="type">Long</span> = acc + <span class="number">1</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: <span class="type">Long</span>): <span class="type">Long</span> = acc</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc1: <span class="type">Long</span>, acc2: <span class="type">Long</span>): <span class="type">Long</span> = acc1 + acc2</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">WindowResultFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[<span class="type">Long</span>, <span class="type">UrlViewCount</span>, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>, context: <span class="type">Context</span>, elements: <span class="type">Iterable</span>[<span class="type">Long</span>], out: <span class="type">Collector</span>[<span class="type">UrlViewCount</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      out.collect(<span class="type">UrlViewCount</span>(key, context.window.getEnd, elements.iterator.next()))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">TopNHotUrls</span>(<span class="params">topSize: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">Long</span>, <span class="type">UrlViewCount</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> urlState = getRuntimeContext.getListState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[<span class="type">UrlViewCount</span>](</span><br><span class="line">        <span class="string">"urlState-state"</span>,</span><br><span class="line">        <span class="type">Types</span>.of[<span class="type">UrlViewCount</span>]</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      input: <span class="type">UrlViewCount</span>,</span><br><span class="line">      context: <span class="type">KeyedProcessFunction</span>[<span class="type">Long</span>, <span class="type">UrlViewCount</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">      collector: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">// 每条数据都保存到状态中</span></span><br><span class="line">      urlState.add(input)</span><br><span class="line">      context</span><br><span class="line">        .timerService</span><br><span class="line">        .registerEventTimeTimer(input.windowEnd + <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(</span><br><span class="line">      timestamp: <span class="type">Long</span>,</span><br><span class="line">      ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">Long</span>, <span class="type">UrlViewCount</span>, <span class="type">String</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">// 获取收到的所有URL访问量</span></span><br><span class="line">      <span class="keyword">val</span> allUrlViews: <span class="type">ListBuffer</span>[<span class="type">UrlViewCount</span>] = <span class="type">ListBuffer</span>()</span><br><span class="line">      <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line">      <span class="keyword">for</span> (urlView &lt;- urlState.get) &#123;</span><br><span class="line">        allUrlViews += urlView</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 提前清除状态中的数据，释放空间</span></span><br><span class="line">      urlState.clear()</span><br><span class="line">      <span class="comment">// 按照访问量从大到小排序</span></span><br><span class="line">      <span class="keyword">val</span> sortedUrlViews = allUrlViews.sortBy(_.count)(<span class="type">Ordering</span>.<span class="type">Long</span>.reverse)</span><br><span class="line">        .take(topSize)</span><br><span class="line">      <span class="comment">// 将排名信息格式化成 String, 便于打印</span></span><br><span class="line">      <span class="keyword">var</span> result: <span class="type">StringBuilder</span> = <span class="keyword">new</span> <span class="type">StringBuilder</span></span><br><span class="line">      result</span><br><span class="line">        .append(<span class="string">"====================================\n"</span>)</span><br><span class="line">        .append(<span class="string">"时间: "</span>)</span><br><span class="line">        .append(<span class="keyword">new</span> <span class="type">Timestamp</span>(timestamp - <span class="number">1</span>))</span><br><span class="line">        .append(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (i &lt;- sortedUrlViews.indices) &#123;</span><br><span class="line">        <span class="keyword">val</span> currentUrlView: <span class="type">UrlViewCount</span> = sortedUrlViews(i)</span><br><span class="line">        <span class="comment">// e.g.  No1：  URL=/blog/tags/firefox?flav=rss20  流量=55</span></span><br><span class="line">        result</span><br><span class="line">          .append(<span class="string">"No"</span>)</span><br><span class="line">          .append(i + <span class="number">1</span>)</span><br><span class="line">          .append(<span class="string">": "</span>)</span><br><span class="line">          .append(<span class="string">"  URL="</span>)</span><br><span class="line">          .append(currentUrlView.url)</span><br><span class="line">          .append(<span class="string">"  流量="</span>)</span><br><span class="line">          .append(currentUrlView.count)</span><br><span class="line">          .append(<span class="string">"\n"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      result</span><br><span class="line">        .append(<span class="string">"====================================\n\n"</span>)</span><br><span class="line">      <span class="comment">// 控制输出频率，模拟实时滚动结果</span></span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">1000</span>)</span><br><span class="line">      out.collect(result.toString)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="Uv统计的布隆过滤器实现"><a href="#Uv统计的布隆过滤器实现" class="headerlink" title="Uv统计的布隆过滤器实现"></a>Uv统计的布隆过滤器实现</h2><p>依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ysss.<span class="type">UserBehavior</span>.<span class="type">UserAction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.function.<span class="type">ProcessWindowFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.triggers.&#123;<span class="type">Trigger</span>, <span class="type">TriggerResult</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.triggers.<span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.<span class="type">Jedis</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">UvWithBloomFilter</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .readTextFile(<span class="string">"UserBehavior.csv的绝对路径"</span>)</span><br><span class="line">      .map(line =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> arr = line.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">UserAction</span>(arr(<span class="number">0</span>), arr(<span class="number">1</span>), arr(<span class="number">2</span>), arr(<span class="number">3</span>), arr(<span class="number">4</span>).toLong * <span class="number">1000</span>)</span><br><span class="line">      &#125;)</span><br><span class="line">      .assignAscendingTimestamps(_.ts)</span><br><span class="line">      .filter(_.behavior == <span class="string">"pv"</span>)</span><br><span class="line">      .map(r =&gt; (<span class="string">"dummyKey"</span>, r.userId))</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.minutes(<span class="number">60</span>), <span class="type">Time</span>.minutes(<span class="number">5</span>))</span><br><span class="line">      .trigger(<span class="keyword">new</span> <span class="type">MyTrigger123</span>)</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">MyProcess</span>)</span><br><span class="line"></span><br><span class="line">    stream.print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[(<span class="type">String</span>, <span class="type">String</span>),</span></span><br><span class="line"><span class="class">      (<span class="type">Long</span>, <span class="type">Long</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> jedis = <span class="keyword">new</span> <span class="type">Jedis</span>(<span class="string">"localhost"</span>, <span class="number">6379</span>)</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> bloom = <span class="keyword">new</span> <span class="type">Bloom</span>(<span class="number">1</span> &lt;&lt; <span class="number">29</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                         context: <span class="type">Context</span>,</span><br><span class="line">                         vals: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">String</span>)],</span><br><span class="line">                         out: <span class="type">Collector</span>[(<span class="type">Long</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> storeKey = context.window.getEnd.toString</span><br><span class="line">      <span class="keyword">var</span> count = <span class="number">0</span>L</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (jedis.hget(<span class="string">"UvCountHashTable"</span>, storeKey) != <span class="literal">null</span>) &#123;</span><br><span class="line">        count = jedis.hget(<span class="string">"UvCountHashTable"</span>, storeKey).toLong</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> userId = vals.last._2</span><br><span class="line">      <span class="keyword">val</span> offset = bloom.hash(userId, <span class="number">61</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> isExist = jedis.getbit(storeKey, offset)</span><br><span class="line">      <span class="keyword">if</span> (!isExist) &#123;</span><br><span class="line">        jedis.setbit(storeKey, offset, <span class="literal">true</span>)</span><br><span class="line">        jedis.hset(<span class="string">"UvCountHashTable"</span>, storeKey, (count + <span class="number">1</span>).toString)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//      out.collect((count, storeKey.toLong))</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyTrigger123</span> <span class="keyword">extends</span> <span class="title">Trigger</span>[(<span class="type">String</span>, <span class="type">String</span>), <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onEventTime</span></span>(time: <span class="type">Long</span>,</span><br><span class="line">                             window: <span class="type">TimeWindow</span>,</span><br><span class="line">                             ctx: <span class="type">TriggerContext</span>): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (ctx.getCurrentWatermark &gt;= window.getEnd) &#123;</span><br><span class="line">        <span class="keyword">val</span> jedis = <span class="keyword">new</span> <span class="type">Jedis</span>(<span class="string">"localhost"</span>, <span class="number">6379</span>)</span><br><span class="line">        <span class="keyword">val</span> key = window.getEnd.toString</span><br><span class="line">        <span class="type">TriggerResult</span>.<span class="type">FIRE_AND_PURGE</span></span><br><span class="line">        println(key, jedis.hget(<span class="string">"UvCountHashTable"</span>, key))</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">TriggerResult</span>.<span class="type">CONTINUE</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onProcessingTime</span></span>(</span><br><span class="line">      time: <span class="type">Long</span>,</span><br><span class="line">      window: <span class="type">TimeWindow</span>,</span><br><span class="line">      ctx: <span class="type">TriggerContext</span></span><br><span class="line">    ): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">      <span class="type">TriggerResult</span>.<span class="type">CONTINUE</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">clear</span></span>(</span><br><span class="line">      window: <span class="type">TimeWindow</span>,</span><br><span class="line">      ctx: <span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line">    ): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onElement</span></span>(element: (<span class="type">String</span>, <span class="type">String</span>),</span><br><span class="line">                           timestamp: <span class="type">Long</span>,</span><br><span class="line">                           window: <span class="type">TimeWindow</span>,</span><br><span class="line">                           ctx: <span class="type">TriggerContext</span>): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">      <span class="type">TriggerResult</span>.<span class="type">FIRE_AND_PURGE</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Bloom</span>(<span class="params">size: <span class="type">Long</span></span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> cap = size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hash</span></span>(value: <span class="type">String</span>, seed: <span class="type">Int</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">      <span class="keyword">var</span> result = <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until value.length) &#123;</span><br><span class="line">        result = result * seed + value.charAt(i)</span><br><span class="line">      &#125;</span><br><span class="line">      (cap - <span class="number">1</span>) &amp; result</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="APP分渠道数据统计"><a href="#APP分渠道数据统计" class="headerlink" title="APP分渠道数据统计"></a>APP分渠道数据统计</h2><p>完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.&#123;<span class="type">Calendar</span>, <span class="type">UUID</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">RichParallelSourceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">SourceFunction</span>.<span class="type">SourceContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.function.<span class="type">ProcessWindowFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AppMarketingByChannel</span> </span>&#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">MarketingUserBehavior</span>(<span class="params">userId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                                   behavior: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                                   channel: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                                   ts: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">class</span> <span class="title">SimulatedEventSource</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>[<span class="type">MarketingUserBehavior</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> running = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> channelSet = <span class="type">Seq</span>(<span class="string">"AppStore"</span>, <span class="string">"XiaomiStore"</span>)</span><br><span class="line">    <span class="keyword">val</span> behaviorTypes = <span class="type">Seq</span>(<span class="string">"BROWSE"</span>, <span class="string">"CLICK"</span>)</span><br><span class="line">    <span class="keyword">val</span> rand = <span class="keyword">new</span> <span class="type">Random</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceContext</span>[<span class="type">MarketingUserBehavior</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">while</span> (running) &#123;</span><br><span class="line">        <span class="keyword">val</span> userId = <span class="type">UUID</span>.randomUUID().toString</span><br><span class="line">        <span class="keyword">val</span> behaviorType = behaviorTypes(rand.nextInt(behaviorTypes.size))</span><br><span class="line">        <span class="keyword">val</span> channel = channelSet(rand.nextInt(channelSet.size))</span><br><span class="line">        <span class="keyword">val</span> ts = <span class="type">Calendar</span>.getInstance().getTimeInMillis</span><br><span class="line"></span><br><span class="line">        ctx.collect(<span class="type">MarketingUserBehavior</span>(userId, behaviorType, channel, ts))</span><br><span class="line"></span><br><span class="line">        <span class="type">Thread</span>.sleep(<span class="number">10</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = running = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .addSource(<span class="keyword">new</span> <span class="type">SimulatedEventSource</span>)</span><br><span class="line">      .assignAscendingTimestamps(_.ts)</span><br><span class="line">      .filter(_.behavior != <span class="string">"UNINSTALL"</span>)</span><br><span class="line">      .map(r =&gt; &#123;</span><br><span class="line">        ((r.channel, r.behavior), <span class="number">1</span>L)</span><br><span class="line">      &#125;)</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>), <span class="type">Time</span>.seconds(<span class="number">1</span>))</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">MarketingCountByChannel</span>)</span><br><span class="line">    stream.print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MarketingCountByChannel</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[((<span class="type">String</span>, <span class="type">String</span>), <span class="type">Long</span>),</span></span><br><span class="line"><span class="class">      (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Long</span>), (<span class="type">String</span>, <span class="type">String</span>), <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key:  (<span class="type">String</span>,<span class="type">String</span>),</span><br><span class="line">                         context: <span class="type">Context</span>,</span><br><span class="line">                         elements: <span class="type">Iterable</span>[((<span class="type">String</span>, <span class="type">String</span>), <span class="type">Long</span>)],</span><br><span class="line">                         out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      out.collect((key._1, elements.size, context.window.getEnd))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="APP不分渠道数据统计"><a href="#APP不分渠道数据统计" class="headerlink" title="APP不分渠道数据统计"></a>APP不分渠道数据统计</h2><p>完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ysss.<span class="type">AppMarketingByChannel</span>.<span class="type">SimulatedEventSource</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.function.<span class="type">ProcessWindowFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AppMarketingStatistics</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .addSource(<span class="keyword">new</span> <span class="type">SimulatedEventSource</span>)</span><br><span class="line">      .assignAscendingTimestamps(_.ts)</span><br><span class="line">      .filter(_.behavior != <span class="string">"UNINSTALL"</span>)</span><br><span class="line">      .map(r =&gt; &#123;</span><br><span class="line">        (<span class="string">"dummyKey"</span>, <span class="number">1</span>L)</span><br><span class="line">      &#125;)</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>), <span class="type">Time</span>.seconds(<span class="number">1</span>))</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">MarketingCountTotal</span>)</span><br><span class="line">    stream.print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MarketingCountTotal</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[(<span class="type">String</span>, <span class="type">Long</span>),</span></span><br><span class="line"><span class="class">      (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Long</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                         context: <span class="type">Context</span>,</span><br><span class="line">                         elements: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Long</span>)],</span><br><span class="line">                         out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      out.collect((key, elements.size, context.window.getEnd))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="恶意登陆实现"><a href="#恶意登陆实现" class="headerlink" title="恶意登陆实现"></a>恶意登陆实现</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ysss.<span class="type">FlinkCepExample</span>.<span class="type">LoginEvent</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ListStateDescriptor</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.typeutils.<span class="type">Types</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.cep.scala.pattern.<span class="type">Pattern</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">LoginFailWithoutCEP</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .fromElements(</span><br><span class="line">        <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"0.0.0.0"</span>, <span class="string">"fail"</span>, <span class="string">"1"</span>),</span><br><span class="line">        <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"0.0.0.0"</span>, <span class="string">"success"</span>, <span class="string">"2"</span>),</span><br><span class="line">        <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"0.0.0.0"</span>, <span class="string">"fail"</span>, <span class="string">"3"</span>),</span><br><span class="line">        <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"0.0.0.0"</span>, <span class="string">"fail"</span>, <span class="string">"4"</span>)</span><br><span class="line">      )</span><br><span class="line">      .assignAscendingTimestamps(_.ts.toLong * <span class="number">1000</span>)</span><br><span class="line">      .keyBy(_.userId)</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">MatchFunction</span>)</span><br><span class="line"></span><br><span class="line">    stream.print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MatchFunction</span> <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">LoginEvent</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> loginState = getRuntimeContext.getListState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[<span class="type">LoginEvent</span>](<span class="string">"login-fail"</span>, <span class="type">Types</span>.of[<span class="type">LoginEvent</span>])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> timestamp = getRuntimeContext.getState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Long</span>](<span class="string">"ts"</span>, <span class="type">Types</span>.of[<span class="type">Long</span>])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      value: <span class="type">LoginEvent</span>,</span><br><span class="line">      ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">LoginEvent</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (value.loginStatus == <span class="string">"fail"</span>) &#123;</span><br><span class="line">        loginState.add(value)</span><br><span class="line">        <span class="keyword">if</span> (!timestamp.value()) &#123;</span><br><span class="line">          timestamp.update(value.ts.toLong * <span class="number">1000</span> + <span class="number">5000</span>L)</span><br><span class="line">          ctx</span><br><span class="line">            .timerService()</span><br><span class="line">            .registerEventTimeTimer(value.ts.toLong * <span class="number">1000</span> + <span class="number">5000</span>L)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (value.loginStatus == <span class="string">"success"</span>) &#123;</span><br><span class="line">        loginState.clear()</span><br><span class="line">        ctx</span><br><span class="line">          .timerService()</span><br><span class="line">          .deleteEventTimeTimer(timestamp.value())</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(</span><br><span class="line">      ts: <span class="type">Long</span>,</span><br><span class="line">      ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">LoginEvent</span>, <span class="type">String</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> allLogins = <span class="type">ListBuffer</span>[<span class="type">LoginEvent</span>]()</span><br><span class="line">      <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line">      <span class="keyword">for</span> (login &lt;- loginState.get) &#123;</span><br><span class="line">        allLogins += login</span><br><span class="line">      &#125;</span><br><span class="line">      loginState.clear()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (allLogins.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        out.collect(<span class="string">"5s以内连续两次登陆失败"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="订单支付实时监控"><a href="#订单支付实时监控" class="headerlink" title="订单支付实时监控"></a>订单支付实时监控</h2><ul><li>基本需求<ul><li>用户下单之后，应设置订单失效时间，以提高用户支付的意愿，并降低系统风险</li><li>用户下单后15分钟未支付，则输出监控信息</li></ul></li><li>解决思路<ul><li>利用CEP库进行事件流的模式匹配，并设定匹配的时间间隔</li></ul></li></ul><h3 id="使用Flink-CEP来实现"><a href="#使用Flink-CEP来实现" class="headerlink" title="使用Flink CEP来实现"></a>使用Flink CEP来实现</h3><p>在电商平台中，最终创造收入和利润的是用户下单购买的环节；更具体一点，是用户真正完成支付动作的时候。用户下单的行为可以表明用户对商品的需求，但在现实中，并不是每次下单都会被用户立刻支付。当拖延一段时间后，用户支付的意愿会降低。所以为了让用户更有紧迫感从而提高支付转化率，同时也为了防范订单支付环节的安全风险，电商网站往往会对订单状态进行监控，设置一个失效时间（比如15分钟），如果下单后一段时间仍未支付，订单就会被取消。</p><p>我们将会利用CEP库来实现这个功能。我们先将事件流按照订单号orderId分流，然后定义这样的一个事件模式：在15分钟内，事件“create”与“pay”严格紧邻：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> orderPayPattern = <span class="type">Pattern</span>.begin[<span class="type">OrderEvent</span>](<span class="string">"begin"</span>)</span><br><span class="line">  .where(_.eventType == <span class="string">"create"</span>)</span><br><span class="line">  .next(<span class="string">"next"</span>)</span><br><span class="line">  .where(_.eventType == <span class="string">"pay"</span>)</span><br><span class="line">  .within(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br></pre></td></tr></table></figure></div><p>这样调用.select方法时，就可以同时获取到匹配出的事件和超时未匹配的事件了。 在src/main/scala下继续创建OrderTimeout.scala文件，新建一个单例对象。定义样例类OrderEvent，这是输入的订单事件流；另外还有OrderResult，这是输出显示的订单状态结果。由于没有现成的数据，我们还是用几条自定义的示例数据来做演示。 完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.cep.scala.<span class="type">CEP</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.cep.scala.pattern.<span class="type">Pattern</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">Map</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderEvent</span>(<span class="params">orderId: <span class="type">String</span>, eventType: <span class="type">String</span>, eventTime: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">OrderTimeout</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> orderEventStream = env.fromCollection(<span class="type">List</span>(</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"1"</span>, <span class="string">"create"</span>, <span class="string">"1558430842"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"create"</span>, <span class="string">"1558430843"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"pay"</span>, <span class="string">"1558430844"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"3"</span>, <span class="string">"pay"</span>, <span class="string">"1558430942"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"4"</span>, <span class="string">"pay"</span>, <span class="string">"1558430943"</span>)</span><br><span class="line">    )).assignAscendingTimestamps(_.eventTime.toLong * <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//    val orders: DataStream[String] = env</span></span><br><span class="line"><span class="comment">//      .socketTextStream("localhost", 9999)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    val orderEventStream = orders</span></span><br><span class="line"><span class="comment">//      .map(s =&gt; &#123;</span></span><br><span class="line"><span class="comment">//        println(s)</span></span><br><span class="line"><span class="comment">//        val slist = s.split("\\|")</span></span><br><span class="line"><span class="comment">//        println(slist)</span></span><br><span class="line"><span class="comment">//        OrderEvent(slist(0), slist(1), slist(2))</span></span><br><span class="line"><span class="comment">//      &#125;)</span></span><br><span class="line"><span class="comment">//      .assignAscendingTimestamps(_.eventTime.toLong * 1000)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> orderPayPattern = <span class="type">Pattern</span>.begin[<span class="type">OrderEvent</span>](<span class="string">"begin"</span>)</span><br><span class="line">      .where(_.eventType.equals(<span class="string">"create"</span>))</span><br><span class="line">      .next(<span class="string">"next"</span>)</span><br><span class="line">      .where(_.eventType.equals(<span class="string">"pay"</span>))</span><br><span class="line">      .within(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> orderTimeoutOutput = <span class="type">OutputTag</span>[<span class="type">OrderEvent</span>](<span class="string">"orderTimeout"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> patternStream = <span class="type">CEP</span>.pattern(</span><br><span class="line">      orderEventStream.keyBy(<span class="string">"orderId"</span>), orderPayPattern)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> timeoutFunction = (</span><br><span class="line">      map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">OrderEvent</span>]],</span><br><span class="line">      timestamp: <span class="type">Long</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">OrderEvent</span>]</span><br><span class="line">    ) =&gt; &#123;</span><br><span class="line">      print(timestamp)</span><br><span class="line">      <span class="keyword">val</span> orderStart = map.get(<span class="string">"begin"</span>).get.head</span><br><span class="line">      out.collect(orderStart)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> selectFunction = (</span><br><span class="line">      map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">OrderEvent</span>]],</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">OrderEvent</span>]</span><br><span class="line">    ) =&gt; &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> timeoutOrder = patternStream</span><br><span class="line">      .flatSelect(orderTimeoutOutput)(timeoutFunction)(selectFunction)</span><br><span class="line"></span><br><span class="line">    timeoutOrder.getSideOutput(orderTimeoutOutput).print()</span><br><span class="line"></span><br><span class="line">    env.execute</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="使用Process-Function实现订单超时需求"><a href="#使用Process-Function实现订单超时需求" class="headerlink" title="使用Process Function实现订单超时需求"></a>使用Process Function实现订单超时需求</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.project</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.<span class="type">ValueStateDescriptor</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.typeutils.<span class="type">Types</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">OrderTimeoutWIthoutCep</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderEvent</span>(<span class="params">orderId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                        eventTime: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">def</span> <span class="title">main</span>(<span class="params">args: <span class="type">Array</span>[<span class="type">String</span>]</span>)</span>: <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .fromElements(</span><br><span class="line">        <span class="type">OrderEvent</span>(<span class="string">"1"</span>, <span class="string">"create"</span>, <span class="string">"2"</span>),</span><br><span class="line">        <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"create"</span>, <span class="string">"3"</span>),</span><br><span class="line">        <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"pay"</span>, <span class="string">"4"</span>)</span><br><span class="line">      )</span><br><span class="line">      .assignAscendingTimestamps(_.eventTime.toLong * <span class="number">1000</span>L)</span><br><span class="line">      .keyBy(_.orderId)</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">OrderMatchFunc</span>)</span><br><span class="line"></span><br><span class="line">    stream.print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">OrderMatchFunc</span> <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">OrderEvent</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> orderState = getRuntimeContext.getState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">OrderEvent</span>](<span class="string">"saved order"</span>, <span class="type">Types</span>.of[<span class="type">OrderEvent</span>])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: <span class="type">OrderEvent</span>,</span><br><span class="line">                                ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">OrderEvent</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">                                out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (value.eventType.equals(<span class="string">"create"</span>)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (orderState.value() == <span class="literal">null</span>) &#123; <span class="comment">// 为什么要判空？因为可能出现`pay`先到的情况</span></span><br><span class="line">          <span class="comment">// 如果orderState为空，保存`create`事件</span></span><br><span class="line">          orderState.update(value)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 保存`pay`事件</span></span><br><span class="line">        orderState.update(value)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      ctx.timerService().registerEventTimeTimer(value.eventTime.toLong * <span class="number">1000</span> + <span class="number">5000</span>L)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(timestamp: <span class="type">Long</span>,</span><br><span class="line">                         ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">OrderEvent</span>, <span class="type">String</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">                         out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> savedOrder = orderState.value()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (savedOrder != <span class="literal">null</span> &amp;&amp; savedOrder.eventType.equals(<span class="string">"create"</span>)) &#123;</span><br><span class="line">        out.collect(<span class="string">"超时订单的ID为："</span> + savedOrder.orderId)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      orderState.clear()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="实时对帐：实现两条流的Join"><a href="#实时对帐：实现两条流的Join" class="headerlink" title="实时对帐：实现两条流的Join"></a>实时对帐：实现两条流的Join</h2><p>完整代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.co.<span class="type">CoProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">OutputTag</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderEvent</span>(<span class="params">orderId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventTime: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">PayEvent</span>(<span class="params">orderId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    eventTime: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">TwoStreamsJoin</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> unmatchedOrders = <span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">OrderEvent</span>](<span class="string">"unmatchedOrders"</span>)&#123;&#125;</span><br><span class="line">  <span class="keyword">val</span> unmatchedPays = <span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">PayEvent</span>](<span class="string">"unmatchedPays"</span>)&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> orders = env</span><br><span class="line">      .fromCollection(<span class="type">List</span>(</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"1"</span>, <span class="string">"create"</span>, <span class="string">"1558430842"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"create"</span>, <span class="string">"1558430843"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"1"</span>, <span class="string">"pay"</span>, <span class="string">"1558430844"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"2"</span>, <span class="string">"pay"</span>, <span class="string">"1558430845"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"3"</span>, <span class="string">"create"</span>, <span class="string">"1558430849"</span>),</span><br><span class="line">      <span class="type">OrderEvent</span>(<span class="string">"3"</span>, <span class="string">"pay"</span>, <span class="string">"1558430849"</span>)</span><br><span class="line">    )).assignAscendingTimestamps(_.eventTime.toLong * <span class="number">1000</span>)</span><br><span class="line">      .keyBy(<span class="string">"orderId"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pays = env.fromCollection(<span class="type">List</span>(</span><br><span class="line">      <span class="type">PayEvent</span>(<span class="string">"1"</span>, <span class="string">"weixin"</span>, <span class="string">"1558430847"</span>),</span><br><span class="line">      <span class="type">PayEvent</span>(<span class="string">"2"</span>, <span class="string">"zhifubao"</span>, <span class="string">"1558430848"</span>),</span><br><span class="line">      <span class="type">PayEvent</span>(<span class="string">"4"</span>, <span class="string">"zhifubao"</span>, <span class="string">"1558430850"</span>)</span><br><span class="line">    )).assignAscendingTimestamps(_.eventTime.toLong * <span class="number">1000</span>)</span><br><span class="line">      .keyBy(<span class="string">"orderId"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> processed = orders</span><br><span class="line">      .connect(pays)</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">EnrichmentFunction</span>)</span><br><span class="line"></span><br><span class="line">    processed.getSideOutput[<span class="type">PayEvent</span>](unmatchedPays).print()</span><br><span class="line">    processed.getSideOutput[<span class="type">OrderEvent</span>](unmatchedOrders).print()</span><br><span class="line"></span><br><span class="line">    env.execute</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">EnrichmentFunction</span> <span class="keyword">extends</span> <span class="title">CoProcessFunction</span>[</span></span><br><span class="line"><span class="class">    <span class="type">OrderEvent</span>, <span class="type">PayEvent</span>, (<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)] </span>&#123;</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> orderState: <span class="type">ValueState</span>[<span class="type">OrderEvent</span>] = getRuntimeContext</span><br><span class="line">      .getState(<span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">OrderEvent</span>](<span class="string">"saved order"</span>,</span><br><span class="line">        classOf[<span class="type">OrderEvent</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> payState: <span class="type">ValueState</span>[<span class="type">PayEvent</span>] = getRuntimeContext</span><br><span class="line">      .getState(<span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">PayEvent</span>](<span class="string">"saved pay"</span>,</span><br><span class="line">        classOf[<span class="type">PayEvent</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement1</span></span>(</span><br><span class="line">      order: <span class="type">OrderEvent</span>,</span><br><span class="line">      context: <span class="type">CoProcessFunction</span>[<span class="type">OrderEvent</span>,</span><br><span class="line">        <span class="type">PayEvent</span>, (<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> pay = payState.value()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (pay != <span class="literal">null</span>) &#123;</span><br><span class="line">        payState.clear()</span><br><span class="line">        out.collect((order, pay))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        orderState.update(order)</span><br><span class="line">        <span class="comment">// as soon as the watermark arrives,</span></span><br><span class="line">        <span class="comment">// we can stop waiting for the corresponding pay</span></span><br><span class="line">        context.timerService</span><br><span class="line">          .registerEventTimeTimer(order.eventTime.toLong * <span class="number">1000</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement2</span></span>(</span><br><span class="line">      pay: <span class="type">PayEvent</span>,</span><br><span class="line">      context: <span class="type">CoProcessFunction</span>[<span class="type">OrderEvent</span>,</span><br><span class="line">        <span class="type">PayEvent</span>,(<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> order = orderState.value()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (order != <span class="literal">null</span>) &#123;</span><br><span class="line">        orderState.clear()</span><br><span class="line">        out.collect((order, pay))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        payState.update(pay)</span><br><span class="line">        context</span><br><span class="line">          .timerService</span><br><span class="line">          .registerEventTimeTimer(pay.eventTime.toLong * <span class="number">1000</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(</span><br><span class="line">      timestamp: <span class="type">Long</span>,</span><br><span class="line">      ctx: <span class="type">CoProcessFunction</span>[<span class="type">OrderEvent</span>,</span><br><span class="line">        <span class="type">PayEvent</span>, (<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]#<span class="type">OnTimerContext</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">OrderEvent</span>, <span class="type">PayEvent</span>)]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (payState.value != <span class="literal">null</span>) &#123;</span><br><span class="line">        ctx.output(unmatchedPays, payState.value)</span><br><span class="line">        payState.clear()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (orderState.value != <span class="literal">null</span>) &#123;</span><br><span class="line">        ctx.output(unmatchedOrders, orderState.value)</span><br><span class="line">        orderState.clear()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;数据集解析&quot;&gt;&lt;a href=&quot;#数据集解析&quot; class=&quot;headerlink&quot; title=&quot;数据集解析&quot;&gt;&lt;/a&gt;数据集解析&lt;/h2&gt;&lt;h3 id=&quot;淘宝数据集解析&quot;&gt;&lt;a href=&quot;#淘宝数据集解析&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Runnable和Callable的区别</title>
    <link href="https://masteryang4.github.io/2020/08/09/Runnable%E5%92%8CCallable%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://masteryang4.github.io/2020/08/09/Runnable%E5%92%8CCallable%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-08-09T15:41:17.000Z</published>
    <updated>2020-08-09T15:45:48.297Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Runnable和Callable的区别"><a href="#Runnable和Callable的区别" class="headerlink" title="Runnable和Callable的区别"></a>Runnable和Callable的区别</h1><p> Java多线程有两个重要的接口，Runnable和Callable，分别提供一个run方法和call方法，二者是有较大差异的。 </p><p><strong>1）Runnable提供run方法，无法通过throws抛出异常，所有CheckedException必须在run方法内部处理。</strong></p><p><strong>Callable提供call方法，直接抛出Exception异常。</strong></p><p><strong>2）Runnable的run方法无返回值，</strong></p><p><strong>Callable的call方法提供返回值用来表示任务运行的结果</strong></p><p><strong>3）Runnable可以作为Thread构造器的参数，通过开启新的线程来执行，也可以通过线程池来执行。</strong></p><p><strong>而Callable只能通过线程池执行。</strong></p><p><strong>4）Runnable接口中的落地方法是call方法；Callable接口中的落地方法是run方法</strong></p><blockquote><p>参考： <a href="https://blog.csdn.net/mryang125/article/details/81878168" target="_blank" rel="noopener">https://blog.csdn.net/mryang125/article/details/81878168</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Runnable和Callable的区别&quot;&gt;&lt;a href=&quot;#Runnable和Callable的区别&quot; class=&quot;headerlink&quot; title=&quot;Runnable和Callable的区别&quot;&gt;&lt;/a&gt;Runnable和Callable的区别&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/categories/Java/"/>
    
      <category term="JUC" scheme="https://masteryang4.github.io/categories/Java/JUC/"/>
    
    
      <category term="Java" scheme="https://masteryang4.github.io/tags/Java/"/>
    
      <category term="JUC" scheme="https://masteryang4.github.io/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记节选一</title>
    <link href="https://masteryang4.github.io/2020/08/08/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E8%8A%82%E9%80%89%E4%B8%80/"/>
    <id>https://masteryang4.github.io/2020/08/08/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E8%8A%82%E9%80%89%E4%B8%80/</id>
    <published>2020-08-08T12:19:58.000Z</published>
    <updated>2020-08-08T12:20:53.671Z</updated>
    
    <content type="html"><![CDATA[<p>今天这个故事，关于人是如何废掉的。</p><p>1995年，美国旧金山举行过一个全球精英会议。500名政经精英在会上，为全球化的世界进行分析与规划。</p><p>大家一致认为：</p><p>1，八二定律真切地存在。</p><p>2，竞争会越来越激烈，而80%的人，将越来越贫穷，地位越来越下降，淘汰率也越来越高。</p><p>可是问题来了，这80%的loser，与其余20%的精英之间，必然存在冲突。</p><p>冲突如果剧烈，社会就会动荡。如何解决这一问题呢？</p><p>布热津斯基就此提出了著名的“奶头乐”理论。</p><p>所谓奶头乐，就是指采取娱乐化、低智化、游戏化、低成本、轻易就能获取刺激性快乐的办法，卸除底层人口的不满。</p><p>所以，娱乐要越多越好，游戏要越普及越好，综艺与真人秀要随处可见，低智的、无逻辑的、甚至堪称脑残的偶像剧要一部接一部。</p><p>当这些东西触手可及，底层人就会安分下来，快乐地、毫无怨言地、无知无觉地继续贫穷，继续无所得，然后虚度一生。</p><p>这虽然是大洋彼岸的事件，但奶头乐的现象，在我们身边同样存在。</p><p>曾有人说过，给一个人一根网线，一个小房间，一个外卖电话，就足以毁了一个人。</p><p>因为，当一个人置身于充满感官刺激的娱乐、碎片化的信息和无规则的游戏中时，你的注意力全部被占据，时间全被消耗，你的欲望能轻易被满足，自律会一点一点丧失，意志力逐渐瘫软。</p><p>你不会再思考。也不再向往艰难的事业。你会恐惧挑战，恐惧前行。</p><p>你会在一个接一个的综艺中，在一坨又一坨的微博资讯里，一阵接一阵的低质量欢娱中，走向你的颓废。</p><p>王尔德说过一句话：“人生只有两种悲剧，一种是：一直得不到。另一种是：太容易得到。”</p><p>一直得不到，是为永生遗憾。</p><p>太容易得到，要么会变味（边际效用递减），要么会上瘾（沉溺于直接刺激）。无论哪一种，都绝非善事。</p><p>要知道，人真正能成长，取决于不断的自我挑战。</p><p>是明知很苦，仍然前行；明知不易，仍然投入。</p><p>当一个人不断突破，在杂乱的信息里分花错柳，在活色生香的影像中保持高强度自律，目标明确，遇山开路，遇水搭桥，终于在某一天，他获得“我真的做到了”的大高潮，这种高峰体验，会令他受益一生。</p><p>因为，这才是真正的幸福——努力过，实现过，我无悔。</p><p>第二个故事，关于多任务执行所带来的消耗。</p><p>一个熟人，也是写字的。</p><p>文笔好，细节把控一流，出过多篇爆文。倘若一直专注写下去，不说成为名作家，至少，凭借一支笔，也能活得体面又阔绰。</p><p>可惜，她同时做了太多事。</p><p>前天她在做教材编改；今天她在接待领导，陪饭陪酒陪唱歌，想在就职的工作里混上一官半职；又过几天，她说自己正在和老公疯狂撕逼，打得天翻地覆，鸡犬不宁；没多久，开始做公益，准备去贫困山区支教；</p><p>但这个决心没下几天，又变了，说要开直播，做网红，教人搭配衣服和化妆；</p><p>直播没做几天，又生出一事儿，说有朋友拉她入伙，一起干房产，决定以后也同时做房地产销售……</p><p>就这样，她一份漂亮的成绩单也没有交出来。</p><p>几年过去了，我们早已经做出了或大或小的成就，只有她，仍然一无所成，甚至仍然赤贫。</p><p>是谁说，什么都做，就等于什么都没做。</p><p>人的精力是有限的。</p><p>假设精力总量是100，分在10个任务上，那就每个任务，都只能使上10%的精力与注意力。</p><p>这种低质的投入，当然带不来高回报。</p><p>而你还会一天到晚说：“好累啊，忙得没个停，也没赚到半个钱……”</p><p>为什么会这样？</p><p>就因为，当举足轻重的一件事VS无足轻重的多数事，理智的人，都会选择前者。他们知道，只有将80%以上的精力，都投注在前者上，才会真正有成效，也会真正为自己带来收益。</p><p>冯仑曾经讲过一件事。</p><p>一个著名的企业，大家都眼睁睁地看着它走下坡路。曾经的业内标杆，如今成了大家的负面教材。曾经金光闪闪放光彩，如今黯然无光危机重重。</p><p>为什么会这样？</p><p>因为老板的心散了。</p><p>为了资本，什么项目都开。这也做，那也做，主营项目停滞不前，结果哪个业务都没有精进。</p><p>企业如此，人也一样。</p><p>倘若你也不想穷忙而无所得，那么，谨记一条：用80%，甚至90%的精力，去做最最最最重要的那件事。</p><p>这样，才会带来真正的成长。</p><p>一个人的废掉，往往是悄无声息的。</p><p>它没有预警，也没有提示，但你反观自己，如果有如下症状，就应该警醒了：</p><p>一是太懒。懒于改变，懒于坚持。 </p><p>二是太闲。将时间与注意力，都放在索取低密度的信息、瞬间回报的快感中。 </p><p>三是太无逻辑。一旦做事，眉毛胡子一把抓，抓不到重点，也摸不清门路，光阴消耗，疲累不堪，一无所得。</p><p>如果你还喜欢找借口，推诿责任，不面对，不学习，不负责，那你就是行走的危险二字。 </p><p>时代正在大洗牌。贪图“奶头乐”的人，会逐渐被淘汰。迷恋感官愉悦的人，会在睁眼时，发现自己已跟不上时代的滚滚车流。</p><p>如果你想活得更无愧此生，改变趁当下，学习趁此时。不要再敷衍自己。因为生命已在追问：“你，到底赋予我什么意义？” </p><blockquote><p>*作者：周冲，2015年离开体制，放弃公职，从事自由写作。新书《我更喜欢努力的自己》正在热卖中。微博：周冲周冲 </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天这个故事，关于人是如何废掉的。&lt;/p&gt;
&lt;p&gt;1995年，美国旧金山举行过一个全球精英会议。500名政经精英在会上，为全球化的世界进行分析与规划。&lt;/p&gt;
&lt;p&gt;大家一致认为：&lt;/p&gt;
&lt;p&gt;1，八二定律真切地存在。&lt;/p&gt;
&lt;p&gt;2，竞争会越来越激烈，而80%的人，将
      
    
    </summary>
    
    
      <category term="其他" scheme="https://masteryang4.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="其他" scheme="https://masteryang4.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
      <category term="读书笔记" scheme="https://masteryang4.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>flink系列11Table API 和 Flink SQL</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9711Table-API-%E5%92%8C-Flink-SQL/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9711Table-API-%E5%92%8C-Flink-SQL/</id>
    <published>2020-07-02T03:51:53.000Z</published>
    <updated>2020-07-02T03:56:32.076Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Table-API-和-Flink-SQL"><a href="#Table-API-和-Flink-SQL" class="headerlink" title="Table API 和 Flink SQL"></a>Table API 和 Flink SQL</h1><h2 id="整体介绍"><a href="#整体介绍" class="headerlink" title="整体介绍"></a>整体介绍</h2><h3 id="什么是-Table-API-和-Flink-SQL"><a href="#什么是-Table-API-和-Flink-SQL" class="headerlink" title="什么是 Table API 和 Flink SQL"></a>什么是 Table API 和 Flink SQL</h3><p>Flink本身是批流统一的处理框架，所以Table API和SQL，就是批流统一的上层处理API。目前功能尚未完善，处于活跃的开发阶段。</p><p>Table API是一套内嵌在Java和Scala语言中的查询API，它允许我们以非常直观的方式，组合来自一些关系运算符的查询（比如select、filter和join）。而对于Flink SQL，就是直接可以在代码中写SQL，来实现一些查询（Query）操作。Flink的SQL支持，基于实现了SQL标准的Apache Calcite（Apache开源SQL解析工具）。</p><p>无论输入是批输入还是流式输入，在这两套API中，指定的查询都具有相同的语义，得到相同的结果。</p><h3 id="需要引入的依赖"><a href="#需要引入的依赖" class="headerlink" title="需要引入的依赖"></a>需要引入的依赖</h3><p>Table API和SQL需要引入的依赖有两个：planner和bridge。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-scala-bridge_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><ul><li>flink-table-planner：planner计划器，是table API最主要的部分，提供了运行时环境和生成程序执行计划的planner；</li><li>flink-table-api-scala-bridge：bridge桥接器，主要负责table API和 DataStream/DataSet API的连接支持，按照语言分java和scala。</li></ul><p>这里的两个依赖，是IDE环境下运行需要添加的；如果是生产环境，lib目录下默认已经有了planner，就只需要有bridge就可以了。</p><p>当然，如果想使用用户自定义函数，或是跟kafka做连接，需要有一个SQL client，这个包含在flink-table-common里。</p><h3 id="两种planner（old-amp-blink）的区别"><a href="#两种planner（old-amp-blink）的区别" class="headerlink" title="两种planner（old &amp; blink）的区别"></a>两种planner（old &amp; blink）的区别</h3><ol><li>批流统一：Blink将批处理作业，视为流式处理的特殊情况。所以，blink不支持表和DataSet之间的转换，批处理作业将不转换为DataSet应用程序，而是跟流处理一样，转换为DataStream程序来处理。</li><li>因为批流统一，Blink planner也不支持BatchTableSource，而使用有界的StreamTableSource代替。</li><li>Blink planner只支持全新的目录，不支持已弃用的ExternalCatalog。</li><li>旧planner和Blink planner的FilterableTableSource实现不兼容。旧的planner会把PlannerExpressions下推到filterableTableSource中，而blink planner则会把Expressions下推。</li><li>基于字符串的键值配置选项仅适用于Blink planner。</li><li>PlannerConfig在两个planner中的实现不同。</li><li>Blink planner会将多个sink优化在一个DAG中（仅在TableEnvironment上受支持，而在StreamTableEnvironment上不受支持）。而旧planner的优化总是将每一个sink放在一个新的DAG中，其中所有DAG彼此独立。</li><li>旧的planner不支持目录统计，而Blink planner支持。</li></ol><h2 id="API调用"><a href="#API调用" class="headerlink" title="API调用"></a>API调用</h2><h3 id="基本程序结构"><a href="#基本程序结构" class="headerlink" title="基本程序结构"></a>基本程序结构</h3><p>Table API 和 SQL 的程序结构，与流式处理的程序结构类似；也可以近似地认为有这么几步：首先创建执行环境，然后定义source、transform和sink。</p><p>具体操作流程如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = ...  <span class="comment">// 创建表的执行环境</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一张表，用于读取数据</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"inputTable"</span>)</span><br><span class="line"><span class="comment">// 注册一张表，用于把计算结果输出</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"outputTable"</span>)</span><br><span class="line"><span class="comment">// 通过 Table API 查询算子，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> result = tableEnv.from(<span class="string">"inputTable"</span>).select(...)</span><br><span class="line"><span class="comment">// 通过 SQL查询语句，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">"SELECT ... FROM inputTable ..."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果表写入输出表中</span></span><br><span class="line">result.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure></div><h3 id="创建表环境"><a href="#创建表环境" class="headerlink" title="创建表环境"></a>创建表环境</h3><p>创建表环境最简单的方式，就是基于流处理执行环境，调create方法直接创建：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env)</span><br></pre></td></tr></table></figure></div><p>表环境（TableEnvironment）是flink中集成Table API &amp; SQL的核心概念。它负责:</p><ul><li>注册catalog</li><li>在内部 catalog 中注册表</li><li>执行 SQL 查询</li><li>注册用户自定义函数</li><li>将 DataStream 或 DataSet 转换为表</li><li>保存对 ExecutionEnvironment 或 StreamExecutionEnvironment 的引用</li></ul><p>在创建TableEnv的时候，可以多传入一个EnvironmentSettings或者TableConfig参数，可以用来配置TableEnvironment的一些特性。</p><p>比如，配置老版本的流式查询（Flink-Streaming-Query）：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span></span><br><span class="line">  .newInstance()</span><br><span class="line">  .useOldPlanner()      <span class="comment">// 使用老版本planner</span></span><br><span class="line">  .inStreamingMode()    <span class="comment">// 流处理模式</span></span><br><span class="line">  .build()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br></pre></td></tr></table></figure></div><p>基于老版本的批处理环境（Flink-Batch-Query）：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> batchEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> batchTableEnv = <span class="type">BatchTableEnvironment</span>.create(batchEnv)</span><br></pre></td></tr></table></figure></div><p>基于blink版本的流处理环境（Blink-Streaming-Query）：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bsSettings = <span class="type">EnvironmentSettings</span></span><br><span class="line">  .newInstance()</span><br><span class="line">  .useBlinkPlanner()</span><br><span class="line">  .inStreamingMode()</span><br><span class="line">  .build()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> bsTableEnv = <span class="type">StreamTableEnvironment</span>.create(env, bsSettings)</span><br></pre></td></tr></table></figure></div><p>基于blink版本的批处理环境（Blink-Batch-Query）：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bbSettings = <span class="type">EnvironmentSettings</span></span><br><span class="line">  .newInstance()</span><br><span class="line">  .useBlinkPlanner()</span><br><span class="line">  .inBatchMode().build()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> bbTableEnv = <span class="type">TableEnvironment</span>.create(bbSettings)</span><br></pre></td></tr></table></figure></div><h3 id="在Catalog中注册表"><a href="#在Catalog中注册表" class="headerlink" title="在Catalog中注册表"></a>在Catalog中注册表</h3><h4 id="表（Table）的概念"><a href="#表（Table）的概念" class="headerlink" title="表（Table）的概念"></a>表（Table）的概念</h4><p>TableEnvironment可以注册目录Catalog，并可以基于Catalog注册表。它会维护一个Catalog-Table表之间的map。</p><p>表（Table）是由一个“标识符”来指定的，由3部分组成：Catalog名、数据库（database）名和对象名（表名）。如果没有指定目录或数据库，就使用当前的默认值。</p><p>表可以是常规的（Table，表），或者虚拟的（View，视图）。常规表（Table）一般可以用来描述外部数据，比如文件、数据库表或消息队列的数据，也可以直接从 DataStream转换而来。视图可以从现有的表中创建，通常是table API或者SQL查询的一个结果。</p><h4 id="连接到文件系统（Csv格式）"><a href="#连接到文件系统（Csv格式）" class="headerlink" title="连接到文件系统（Csv格式）"></a>连接到文件系统（Csv格式）</h4><p>连接外部系统在Catalog中注册表，直接调用tableEnv.connect()就可以，里面参数要传入一个ConnectorDescriptor，也就是connector描述器。对于文件系统的connector而言，flink内部已经提供了，就叫做FileSystem()。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">  .connect(<span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))  <span class="comment">// 定义表数据来源，外部连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">OldCsv</span>())    <span class="comment">// 定义从外部系统读取数据之后的格式化方法</span></span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )    <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>)    <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure></div><p>这是旧版本的csv格式描述器。由于它是非标的，跟外部系统对接并不通用，所以将被弃用，以后会被一个符合RFC-4180标准的新format描述器取代。新的描述器就叫Csv()，但flink没有直接提供，需要引入依赖flink-csv：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-csv<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>代码非常类似，只需要把withFormat里的OldCsv改成Csv就可以了。</p><h4 id="连接到Kafka"><a href="#连接到Kafka" class="headerlink" title="连接到Kafka"></a>连接到Kafka</h4><p>kafka的连接器flink-kafka-connector中，1.10版本的已经提供了Table API的支持。我们可以在 connect方法中直接传入一个叫做Kafka的类，这就是kafka连接器的描述器ConnectorDescriptor。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">  .connect(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">      .version(<span class="string">"0.11"</span>) <span class="comment">// 定义kafka的版本</span></span><br><span class="line">      .topic(<span class="string">"sensor"</span>) <span class="comment">// 定义主题</span></span><br><span class="line">      .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>)</span><br><span class="line">      .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">  )</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaInputTable"</span>)</span><br></pre></td></tr></table></figure></div><p>当然也可以连接到ElasticSearch、MySql、HBase、Hive等外部系统，实现方式基本上是类似的。</p><h3 id="表的查询"><a href="#表的查询" class="headerlink" title="表的查询"></a>表的查询</h3><p>利用外部系统的连接器connector，我们可以读写数据，并在环境的Catalog中注册表。接下来就可以对表做查询转换了。</p><p>Flink给我们提供了两种查询方式：Table API和 SQL。</p><h4 id="Table-API的调用"><a href="#Table-API的调用" class="headerlink" title="Table API的调用"></a>Table API的调用</h4><p>Table API是集成在Scala和Java语言内的查询API。与SQL不同，Table API的查询不会用字符串表示，而是在宿主语言中一步一步调用完成的。</p><p>Table API基于代表一张“表”的Table类，并提供一整套操作处理的方法API。这些方法会返回一个新的Table对象，这个对象就表示对输入表应用转换操作的结果。有些关系型转换操作，可以由多个方法调用组成，构成链式调用结构。例如table.select(…).filter(…)，其中select（…）表示选择表中指定的字段，filter(…)表示筛选条件。</p><p>代码中的实现如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable: <span class="type">Table</span> = tableEnv.from(<span class="string">"inputTable"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultTable: <span class="type">Table</span> = senorTable</span><br><span class="line">  .select(<span class="string">"id, temperature"</span>)</span><br><span class="line">  .filter(<span class="string">"id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h4><p>Flink的SQL集成，基于的是Apache Calcite，它实现了SQL标准。在Flink中，用常规字符串来定义SQL查询语句。SQL 查询的结果，是一个新的 Table。</p><p>代码实现如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">  .sqlQuery(<span class="string">"select id, temperature from inputTable where id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure></div><p>或者：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, temperature</span></span><br><span class="line"><span class="string">    |from inputTable</span></span><br><span class="line"><span class="string">    |where id = 'sensor_1'</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure></div><p>当然，也可以加上聚合操作，比如我们统计每个sensor温度数据出现的个数，做个count统计：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> aggResultTable = sensorTable</span><br><span class="line">  .groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'id</span>.count as <span class="symbol">'count</span>)</span><br></pre></td></tr></table></figure></div><p>SQL的实现：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> aggResultSqlTable = tableEnv</span><br><span class="line">  .sqlQuery(<span class="string">"select id, count(id) as cnt from inputTable group by id"</span>)</span><br></pre></td></tr></table></figure></div><p>这里Table API里指定的字段，前面加了一个单引号<code>&#39;</code>，这是Table API中定义的Expression类型的写法，可以很方便地表示一个表中的字段。</p><p>字段可以直接全部用双引号引起来，也可以用半边单引号+字段名的方式。以后的代码中，一般都用后一种形式。</p><h3 id="将DataStream转换成表"><a href="#将DataStream转换成表" class="headerlink" title="将DataStream转换成表"></a>将DataStream转换成表</h3><p>Flink允许我们把Table和DataStream做转换：我们可以基于一个DataStream，先流式地读取数据源，然后map成样例类，再把它转成Table。Table的列字段（column fields），就是样例类里的字段，这样就不用再麻烦地定义schema了。</p><h4 id="代码表达"><a href="#代码表达" class="headerlink" title="代码表达"></a>代码表达</h4><p>代码中实现非常简单，直接用tableEnv.fromDataStream()就可以了。默认转换后的 Table schema 和 DataStream 中的字段定义一一对应，也可以单独指定出来。</p><p>这就允许我们更换字段的顺序、重命名，或者只选取某些字段出来，相当于做了一次map操作（或者Table API的 select操作）。</p><p>代码具体如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sensorTable: <span class="type">Table</span> = tableEnv.fromDataStream(dataStream)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sensorTable2 = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure></div><h4 id="数据类型与Table-schema的对应"><a href="#数据类型与Table-schema的对应" class="headerlink" title="数据类型与Table schema的对应"></a>数据类型与Table schema的对应</h4><p>在上节的例子中，DataStream 中的数据类型，与表的 Schema 之间的对应关系，是按照样例类中的字段名来对应的（name-based mapping），所以还可以用as做重命名。</p><p>另外一种对应方式是，直接按照字段的位置来对应（position-based mapping），对应的过程中，就可以直接指定新的字段名了。</p><p>基于名称的对应：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv</span><br><span class="line">  .fromDataStream(dataStream, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>, <span class="symbol">'id</span> as <span class="symbol">'myId</span>, <span class="symbol">'temperature</span>)</span><br></pre></td></tr></table></figure></div><p>基于位置的对应：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv</span><br><span class="line">  .fromDataStream(dataStream, <span class="symbol">'myId</span>, <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure></div><p>Flink的DataStream和 DataSet API支持多种类型。</p><p>组合类型，比如元组（内置Scala和Java元组）、POJO、Scala case类和Flink的Row类型等，允许具有多个字段的嵌套数据结构，这些字段可以在Table的表达式中访问。其他类型，则被视为原子类型。</p><p>元组类型和原子类型，一般用位置对应会好一些；如果非要用名称对应，也是可以的：</p><p>元组类型，默认的名称是 “_1”, “_2”；而原子类型，默认名称是 ”f0”。</p><h3 id="创建临时视图（Temporary-View）"><a href="#创建临时视图（Temporary-View）" class="headerlink" title="创建临时视图（Temporary View）"></a>创建临时视图（Temporary View）</h3><p>创建临时视图的第一种方式，就是直接从DataStream转换而来。同样，可以直接对应字段转换；也可以在转换的时候，指定相应的字段。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, dataStream)</span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>,</span><br><span class="line">  dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure></div><p>另外，当然还可以基于Table创建视图：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, sensorTable)</span><br></pre></td></tr></table></figure></div><p>View和Table的Schema完全相同。事实上，在Table API中，可以认为View和Table是等价的。</p><h3 id="输出表"><a href="#输出表" class="headerlink" title="输出表"></a>输出表</h3><p>表的输出，是通过将数据写入 TableSink 来实现的。TableSink 是一个通用接口，可以支持不同的文件格式、存储数据库和消息队列。</p><p>具体实现，输出表最直接的方法，就是通过 Table.insertInto() 方法将一个 Table 写入注册过的 TableSink 中。</p><h4 id="输出到文件"><a href="#输出到文件" class="headerlink" title="输出到文件"></a>输出到文件</h4><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注册输出表</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"…\\resources\\out.txt"</span>)</span><br><span class="line">  ) <span class="comment">// 定义到文件系统的连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>()) <span class="comment">// 定义格式化方法，Csv格式</span></span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"outputTable"</span>) <span class="comment">// 创建临时表</span></span><br><span class="line"></span><br><span class="line">resultSqlTable.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="更新模式（Update-Mode）"><a href="#更新模式（Update-Mode）" class="headerlink" title="更新模式（Update Mode）"></a>更新模式（Update Mode）</h4><p>在流处理过程中，表的处理并不像传统定义的那样简单。</p><p>对于流式查询（Streaming Queries），需要声明如何在（动态）表和外部连接器之间执行转换。与外部系统交换的消息类型，由更新模式（update mode）指定。</p><p>Flink Table API中的更新模式有以下三种：</p><ol><li>追加模式（Append Mode）</li></ol><p>在追加模式下，表（动态表）和外部连接器只交换插入（Insert）消息。</p><ol><li>撤回模式（Retract Mode）</li></ol><p>在撤回模式下，表和外部连接器交换的是：添加（Add）和撤回（Retract）消息。</p><ul><li>插入（Insert）会被编码为添加消息；</li><li>删除（Delete）则编码为撤回消息；</li><li>更新（Update）则会编码为，已更新行（上一行）的撤回消息，和更新行（新行）的添加消息。</li></ul><p>在此模式下，不能定义key，这一点跟upsert模式完全不同。</p><ol><li>Upsert（更新插入）模式</li></ol><p>在Upsert模式下，动态表和外部连接器交换Upsert和Delete消息。</p><p>这个模式需要一个唯一的key，通过这个key可以传递更新消息。为了正确应用消息，外部连接器需要知道这个唯一key的属性。</p><ul><li>插入（Insert）和更新（Update）都被编码为Upsert消息；</li><li>删除（Delete）编码为Delete信息。</li></ul><p>这种模式和Retract模式的主要区别在于，Update操作是用单个消息编码的，所以效率会更高。</p><h4 id="输出到Kafka"><a href="#输出到Kafka" class="headerlink" title="输出到Kafka"></a>输出到Kafka</h4><p>除了输出到文件，也可以输出到Kafka。我们可以结合前面Kafka作为输入数据，构建数据管道，kafka进，kafka出。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到 kafka</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">    .version(<span class="string">"0.11"</span>)</span><br><span class="line">    .topic(<span class="string">"sinkTest"</span>)</span><br><span class="line">    .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>)</span><br><span class="line">    .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">  )</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaOutputTable"</span>)</span><br><span class="line">  </span><br><span class="line">resultTable.insertInto(<span class="string">"kafkaOutputTable"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="输出到ElasticSearch"><a href="#输出到ElasticSearch" class="headerlink" title="输出到ElasticSearch"></a>输出到ElasticSearch</h4><p>ElasticSearch的connector可以在upsert（update+insert，更新插入）模式下操作，这样就可以使用Query定义的键（key）与外部系统交换UPSERT/DELETE消息。</p><p>另外，对于“仅追加”（append-only）的查询，connector还可以在append 模式下操作，这样就可以与外部系统只交换insert消息。</p><p>es目前支持的数据格式，只有Json，而flink本身并没有对应的支持，所以还需要引入依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>代码实现如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到es</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Elasticsearch</span>()</span><br><span class="line">    .version(<span class="string">"6"</span>)</span><br><span class="line">    .host(<span class="string">"localhost"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)</span><br><span class="line">    .index(<span class="string">"sensor"</span>)</span><br><span class="line">    .documentType(<span class="string">"temp"</span>)</span><br><span class="line">  )</span><br><span class="line">  .inUpsertMode()           <span class="comment">// 指定是 Upsert 模式</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Json</span>())</span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"count"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"esOutputTable"</span>)</span><br><span class="line">  </span><br><span class="line">aggResultTable.insertInto(<span class="string">"esOutputTable"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="输出到MySql"><a href="#输出到MySql" class="headerlink" title="输出到MySql"></a>输出到MySql</h4><p>Flink专门为Table API的jdbc连接提供了flink-jdbc连接器，我们需要先引入依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-jdbc_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>jdbc连接的代码实现比较特殊，因为没有对应的java/scala类实现ConnectorDescriptor，所以不能直接tableEnv.connect()。不过Flink SQL留下了执行DDL的接口：tableEnv.sqlUpdate()。</p><p>对于jdbc的创建表操作，天生就适合直接写DDL来实现，所以我们的代码可以这样写：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到 Mysql</span></span><br><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table jdbcOutputTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  cnt bigint not null</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'jdbc',</span></span><br><span class="line"><span class="string">    |  'connector.url' = 'jdbc:mysql://localhost:3306/test',</span></span><br><span class="line"><span class="string">    |  'connector.table' = 'sensor_count',</span></span><br><span class="line"><span class="string">    |  'connector.driver' = 'com.mysql.jdbc.Driver',</span></span><br><span class="line"><span class="string">    |  'connector.username' = 'root',</span></span><br><span class="line"><span class="string">    |  'connector.password' = '123456'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL)</span><br><span class="line">aggResultSqlTable.insertInto(<span class="string">"jdbcOutputTable"</span>)</span><br></pre></td></tr></table></figure></div><h3 id="将表转换成DataStream"><a href="#将表转换成DataStream" class="headerlink" title="将表转换成DataStream"></a>将表转换成DataStream</h3><p>表可以转换为DataStream或DataSet。这样，自定义流处理或批处理程序就可以继续在 Table API或SQL查询的结果上运行了。</p><p>将表转换为DataStream或DataSet时，需要指定生成的数据类型，即要将表的每一行转换成的数据类型。通常，最方便的转换类型就是Row。当然，因为结果的所有字段类型都是明确的，我们也经常会用元组类型来表示。</p><p>表作为流式查询的结果，是动态更新的。所以，将这种动态查询转换成的数据流，同样需要对表的更新操作进行编码，进而有不同的转换模式。</p><p>Table API中表到DataStream有两种模式：</p><ul><li>追加模式（Append Mode）</li></ul><p>用于表只会被插入（Insert）操作更改的场景。</p><ul><li>撤回模式（Retract Mode）</li></ul><p>用于任何场景。有些类似于更新模式中Retract模式，它只有Insert和Delete两类操作。</p><p>得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据，Delete）。</p><p>代码实现如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv</span><br><span class="line">  .toAppendStream[<span class="type">Row</span>](resultTable)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> aggResultStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = tableEnv</span><br><span class="line">  .toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)](aggResultTable)</span><br><span class="line"></span><br><span class="line">resultStream.print(<span class="string">"result"</span>)</span><br><span class="line">aggResultStream.print(<span class="string">"aggResult"</span>)</span><br></pre></td></tr></table></figure></div><p>所以，没有经过groupby之类聚合操作，可以直接用toAppendStream来转换；而如果经过了聚合，有更新操作，一般就必须用toRetractDstream。</p><h3 id="Query的解释和执行"><a href="#Query的解释和执行" class="headerlink" title="Query的解释和执行"></a>Query的解释和执行</h3><p>Table API提供了一种机制来解释（Explain）计算表的逻辑和优化查询计划。这是通过TableEnvironment.explain（table）方法或TableEnvironment.explain（）方法完成的。</p><p>explain方法会返回一个字符串，描述三个计划：</p><ul><li>未优化的逻辑查询计划</li><li>优化后的逻辑查询计划</li><li>实际执行计划</li></ul><p>我们可以在代码中查看执行计划：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> explaination: <span class="type">String</span> = tableEnv.explain(resultTable)</span><br><span class="line">println(explaination)</span><br></pre></td></tr></table></figure></div><p>Query的解释和执行过程，老planner和blink planner大体是一致的，又有所不同。整体来讲，Query都会表示成一个逻辑查询计划，然后分两步解释：</p><ol><li>优化查询计划</li><li>解释成 DataStream 或者 DataSet程序</li></ol><p>而Blink版本是批流统一的，所以所有的Query，只会被解释成DataStream程序；另外在批处理环境TableEnvironment下，Blink版本要到tableEnv.execute()执行调用才开始解释。</p><h2 id="流处理中的特殊概念"><a href="#流处理中的特殊概念" class="headerlink" title="流处理中的特殊概念"></a>流处理中的特殊概念</h2><p>Table API和SQL，本质上还是基于关系型表的操作方式；而关系型表、关系代数，以及SQL本身，一般是有界的，更适合批处理的场景。这就导致在进行流处理的过程中，理解会稍微复杂一些，需要引入一些特殊概念。</p><h3 id="流处理和关系代数（表，及SQL）的区别"><a href="#流处理和关系代数（表，及SQL）的区别" class="headerlink" title="流处理和关系代数（表，及SQL）的区别"></a>流处理和关系代数（表，及SQL）的区别</h3><table><thead><tr><th></th><th>关系代数（表）/SQL</th><th>流处理</th></tr></thead><tbody><tr><td>处理的数据对象</td><td>字段元组的有界集合</td><td>字段元组的无限序列</td></tr><tr><td>查询（Query）对数据的访问</td><td>可以访问到完整的数据输入</td><td>无法访问所有数据，必须持续等待流式输入</td></tr><tr><td>查询终止条件</td><td>生成固定大小的结果集后终止</td><td>永不停止，根据持续收到的数据不断更新查询结果</td></tr></tbody></table><p>可以看到，其实关系代数（主要就是指关系型数据库中的表）和SQL，主要就是针对批处理的，这和流处理有天生的隔阂。</p><h3 id="动态表（Dynamic-Tables）"><a href="#动态表（Dynamic-Tables）" class="headerlink" title="动态表（Dynamic Tables）"></a>动态表（Dynamic Tables）</h3><p>因为流处理面对的数据，是连续不断的，这和我们熟悉的关系型数据库中保存的“表”完全不同。所以，如果我们把流数据转换成Table，然后执行类似于table的select操作，结果就不是一成不变的，而是随着新数据的到来，会不停更新。</p><p>我们可以随着新数据的到来，不停地在之前的基础上更新结果。这样得到的表，在Flink Table API概念里，就叫做“动态表”（Dynamic Tables）。</p><p>动态表是Flink对流数据的Table API和SQL支持的核心概念。与表示批处理数据的静态表不同，动态表是随时间变化的。动态表可以像静态的批处理表一样进行查询，查询一个动态表会产生持续查询（Continuous Query）。连续查询永远不会终止，并会生成另一个动态表。查询（Query）会不断更新其动态结果表，以反映其动态输入表上的更改。</p><h3 id="流式持续查询的过程"><a href="#流式持续查询的过程" class="headerlink" title="流式持续查询的过程"></a>流式持续查询的过程</h3><p>下图显示了流、动态表和连续查询的关系：</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/stream-query-stream.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/stream-query-stream.png" class="lazyload"></a></p><p>流式持续查询的过程为：</p><ol><li>流被转换为动态表。</li><li>对动态表计算连续查询，生成新的动态表。</li><li>生成的动态表被转换回流。</li></ol><h4 id="将流转换成表（Table）"><a href="#将流转换成表（Table）" class="headerlink" title="将流转换成表（Table）"></a>将流转换成表（Table）</h4><p>为了处理带有关系查询的流，必须先将其转换为表。</p><p>从概念上讲，流的每个数据记录，都被解释为对结果表的插入（Insert）修改。因为流式持续不断的，而且之前的输出结果无法改变。本质上，我们其实是从一个、只有插入操作的changelog（更新日志）流，来构建一个表。</p><p>为了更好地说明动态表和持续查询的概念，我们来举一个具体的例子。</p><p>比如，我们现在的输入数据，就是用户在网站上的访问行为，数据类型（Schema）如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang"></div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  user:  VARCHAR,   // 用户名</span><br><span class="line">  cTime: TIMESTAMP, // 访问某个URL的时间戳</span><br><span class="line">  url:   VARCHAR    // 用户访问的URL</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>下图显示了如何将访问URL事件流，或者叫点击事件流（左侧）转换为表（右侧）。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/append-mode.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/append-mode.png" class="lazyload"></a></p><p>随着插入更多的访问事件流记录，生成的表将不断增长。</p><h4 id="持续查询（Continuous-Query）"><a href="#持续查询（Continuous-Query）" class="headerlink" title="持续查询（Continuous Query）"></a>持续查询（Continuous Query）</h4><p>持续查询，会在动态表上做计算处理，并作为结果生成新的动态表。与批处理查询不同，连续查询从不终止，并根据输入表上的更新更新其结果表。</p><p>在任何时间点，连续查询的结果在语义上，等同于在输入表的快照上，以批处理模式执行的同一查询的结果。</p><p>在下面的示例中，我们展示了对点击事件流中的一个持续查询。</p><p>这个Query很简单，是一个分组聚合做count统计的查询。它将用户字段上的clicks表分组，并统计访问的url数。图中显示了随着时间的推移，当clicks表被其他行更新时如何计算查询。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/query-groupBy-cnt.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/query-groupBy-cnt.png" class="lazyload"></a></p><h4 id="将动态表转换成流"><a href="#将动态表转换成流" class="headerlink" title="将动态表转换成流"></a>将动态表转换成流</h4><p>与常规的数据库表一样，动态表可以通过插入（Insert）、更新（Update）和删除（Delete）更改，进行持续的修改。将动态表转换为流或将其写入外部系统时，需要对这些更改进行编码。Flink的Table API和SQL支持三种方式对动态表的更改进行编码：</p><ol><li>仅追加（Append-only）流</li></ol><p>仅通过插入（Insert）更改，来修改的动态表，可以直接转换为“仅追加”流。这个流中发出的数据，就是动态表中新增的每一行。</p><ol><li>撤回（Retract）流</li></ol><p>Retract流是包含两类消息的流，添加（Add）消息和撤回（Retract）消息。</p><p>动态表通过将INSERT 编码为add消息、DELETE 编码为retract消息、UPDATE编码为被更改行（前一行）的retract消息和更新后行（新行）的add消息，转换为retract流。</p><p>下图显示了将动态表转换为Retract流的过程。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/undo-redo-mode.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/undo-redo-mode.png" class="lazyload"></a></p><ol><li>Upsert（更新插入）流</li></ol><p>Upsert流包含两种类型的消息：Upsert消息和delete消息。转换为upsert流的动态表，需要有唯一的键（key）。</p><p>通过将INSERT和UPDATE更改编码为upsert消息，将DELETE更改编码为DELETE消息，就可以将具有唯一键（Unique Key）的动态表转换为流。</p><p>下图显示了将动态表转换为upsert流的过程。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/redo-mode.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/redo-mode.png" class="lazyload"></a></p><p>这些概念我们之前都已提到过。需要注意的是，在代码里将动态表转换为DataStream时，仅支持Append和Retract流。而向外部系统输出动态表的TableSink接口，则可以有不同的实现，比如之前我们讲到的ES，就可以有Upsert模式。</p><h3 id="时间特性"><a href="#时间特性" class="headerlink" title="时间特性"></a>时间特性</h3><p>基于时间的操作（比如Table API和SQL中窗口操作），需要定义相关的时间语义和时间数据来源的信息。所以，Table可以提供一个逻辑上的时间字段，用于在表处理程序中，指示时间和访问相应的时间戳。</p><p>时间属性，可以是每个表schema的一部分。一旦定义了时间属性，它就可以作为一个字段引用，并且可以在基于时间的操作中使用。</p><p>时间属性的行为类似于常规时间戳，可以访问，并且进行计算。</p><h4 id="处理时间（Processing-Time）"><a href="#处理时间（Processing-Time）" class="headerlink" title="处理时间（Processing Time）"></a>处理时间（Processing Time）</h4><p>处理时间语义下，允许表处理程序根据机器的本地时间生成结果。它是时间的最简单概念。它既不需要提取时间戳，也不需要生成watermark。</p><p>定义处理时间属性有三种方法：在DataStream转化时直接指定；在定义Table Schema时指定；在创建表的DDL中指定。</p><ol><li>DataStream转化成Table时指定</li></ol><p>由DataStream转换成表时，可以在后面指定字段名来定义Schema。在定义Schema期间，可以使用.proctime，定义处理时间字段。</p><p>注意，这个proctime属性只能通过附加逻辑字段，来扩展物理schema。因此，只能在schema定义的末尾定义它。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义好 DataStream</span></span><br><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv</span><br><span class="line">  .fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'pt</span>.proctime)</span><br></pre></td></tr></table></figure></div><ol><li>定义Table Schema时指定</li></ol><p>这种方法其实也很简单，只要在定义Schema的时候，加上一个新的字段，并指定成proctime就可以了。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">  .connect(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"..\\sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">      .field(<span class="string">"pt"</span>, <span class="type">DataTypes</span>.<span class="type">TIMESTAMP</span>(<span class="number">3</span>))</span><br><span class="line">      .proctime()    <span class="comment">// 指定 pt字段为处理时间</span></span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure></div><ol><li>创建表的DDL中指定</li></ol><p>在创建表的DDL中，增加一个字段并指定成proctime，也可以指定当前的时间字段。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  pt AS PROCTIME()</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure></div><p>注意：运行这段DDL，必须使用Blink Planner。</p><h4 id="事件时间（Event-Time）"><a href="#事件时间（Event-Time）" class="headerlink" title="事件时间（Event Time）"></a>事件时间（Event Time）</h4><p>事件时间语义，允许表处理程序根据每个记录中包含的时间生成结果。这样即使在有乱序事件或者延迟事件时，也可以获得正确的结果。</p><p>为了处理无序事件，并区分流中的准时和迟到事件；Flink需要从事件数据中，提取时间戳，并用来推进事件时间的进展（watermark）。</p><ol><li>DataStream转化成Table时指定</li></ol><p>在DataStream转换成Table，schema的定义期间，使用.rowtime可以定义事件时间属性。注意，必须在转换的数据流中分配时间戳和watermark。</p><p>在将数据流转换为表时，有两种定义时间属性的方法。根据指定的.rowtime字段名是否存在于数据流的架构中，timestamp字段可以：</p><ul><li>作为新字段追加到schema</li><li>替换现有字段</li></ul><p>在这两种情况下，定义的事件时间戳字段，都将保存DataStream中事件时间戳的值。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line">  .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>L)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv</span><br><span class="line">  .fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'temperature</span>)</span><br><span class="line"><span class="comment">// 或者，直接追加字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable2 = tableEnv</span><br><span class="line">  .fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'rt</span>.rowtime)</span><br></pre></td></tr></table></figure></div><ol><li>定义Table Schema时指定</li></ol><p>这种方法只要在定义Schema的时候，将事件时间字段，并指定成rowtime就可以了。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">  .connect(<span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">      .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">      .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .rowtime(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">Rowtime</span>()</span><br><span class="line">          .timestampsFromField(<span class="string">"timestamp"</span>)    <span class="comment">// 从字段中提取时间戳</span></span><br><span class="line">          .watermarksPeriodicBounded(<span class="number">1000</span>)    <span class="comment">// watermark延迟1秒</span></span><br><span class="line">      )</span><br><span class="line">      .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure></div><ol><li>创建表的DDL中指定</li></ol><p>事件时间属性，是使用CREATE TABLE DDL中的WARDMARK语句定义的。watermark语句，定义现有事件时间字段上的watermark生成表达式，该表达式将事件时间字段标记为事件时间属性。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  rt AS TO_TIMESTAMP( FROM_UNIXTIME(ts) ),</span></span><br><span class="line"><span class="string">    |  watermark for rt as rt - interval '1' second</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure></div><p>这里FROM_UNIXTIME是系统内置的时间函数，用来将一个整数（秒数）转换成“YYYY-MM-DD hh:mm:ss”格式（默认，也可以作为第二个String参数传入）的日期时间字符串（date time string）；然后再用TO_TIMESTAMP将其转换成Timestamp。</p><h2 id="窗口（Windows）"><a href="#窗口（Windows）" class="headerlink" title="窗口（Windows）"></a>窗口（Windows）</h2><p>时间语义，要配合窗口操作才能发挥作用。最主要的用途，当然就是开窗口、根据时间段做计算了。下面我们就来看看Table API和SQL中，怎么利用时间字段做窗口操作。</p><p>在Table API和SQL中，主要有两种窗口：Group Windows和Over Windows</p><h3 id="分组窗口（Group-Windows）"><a href="#分组窗口（Group-Windows）" class="headerlink" title="分组窗口（Group Windows）"></a>分组窗口（Group Windows）</h3><p>分组窗口（Group Windows）会根据时间或行计数间隔，将行聚合到有限的组（Group）中，并对每个组的数据执行一次聚合函数。</p><p>Table API中的Group Windows都是使用.window（w:GroupWindow）子句定义的，并且必须由as子句指定一个别名。为了按窗口对表进行分组，窗口的别名必须在group by子句中，像常规的分组字段一样引用。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>) <span class="comment">// 定义窗口，别名 w</span></span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>)  <span class="comment">// 以属性a和窗口w作为分组的key</span></span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'b</span>.sum)  <span class="comment">// 聚合字段b的值，求和</span></span><br></pre></td></tr></table></figure></div><p>或者，还可以把窗口的相关信息，作为字段添加到结果表中：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>)</span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>) </span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'w</span>.start, <span class="symbol">'w</span>.end, <span class="symbol">'w</span>.rowtime, <span class="symbol">'b</span>.count)</span><br></pre></td></tr></table></figure></div><p>Table API提供了一组具有特定语义的预定义Window类，这些类会被转换为底层DataStream或DataSet的窗口操作。</p><p>Table API支持的窗口定义，和我们熟悉的一样，主要也是三种：滚动（Tumbling）、滑动（Sliding）和会话（Session）。</p><h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p>滚动窗口（Tumbling windows）要用Tumble类来定义，另外还有三个方法：</p><ul><li>over：定义窗口长度</li><li>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</li><li>as：别名，必须出现在后面的groupBy中</li></ul><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Tumbling Event-time Window（事件时间字段rowtime</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'rowtime</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// Tumbling Processing-time Window（处理时间字段proctime）</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// Tumbling Row-count Window (类似于计数窗口，按处理时间排序，10行一组)</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>rows on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>滑动窗口（Sliding windows）要用Slide类来定义，另外还有四个方法：</p><ul><li>over：定义窗口长度</li><li>every：定义滑动步长</li><li>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</li><li>as：别名，必须出现在后面的groupBy中</li></ul><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sliding Event-time Window</span></span><br><span class="line">.window(<span class="type">Slide</span> over <span class="number">10.</span>minutes every <span class="number">5.</span>minutes on <span class="symbol">'rowtime</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// Sliding Processing-time window</span></span><br><span class="line">.window(<span class="type">Slide</span> over <span class="number">10.</span>minutes every <span class="number">5.</span>minutes on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// Sliding Row-count window</span></span><br><span class="line">.window(<span class="type">Slide</span> over <span class="number">10.</span>rows every <span class="number">5.</span>rows on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p>会话窗口（Session windows）要用Session类来定义，另外还有三个方法：</p><ul><li>withGap：会话时间间隔</li><li>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</li><li>as：别名，必须出现在后面的groupBy中</li></ul><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Session Event-time Window</span></span><br><span class="line">.window(<span class="type">Session</span> withGap <span class="number">10.</span>minutes on <span class="symbol">'rowtime</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// Session Processing-time Window</span></span><br><span class="line">.window(<span class="type">Session</span> withGap <span class="number">10.</span>minutes on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><h3 id="Over-Windows"><a href="#Over-Windows" class="headerlink" title="Over Windows"></a>Over Windows</h3><p>Over window聚合是标准SQL中已有的（Over子句），可以在查询的SELECT子句中定义。Over window 聚合，会针对每个输入行，计算相邻行范围内的聚合。Over windows使用.window（w:overwindows*）子句定义，并在select()方法中通过别名来引用。</p><p>比如这样：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">OverWindow</span>] as <span class="symbol">'w</span>)</span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'b</span>.sum over <span class="symbol">'w</span>, <span class="symbol">'c</span>.min over <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><p>Table API提供了Over类，来配置Over窗口的属性。可以在事件时间或处理时间，以及指定为时间间隔、或行计数的范围内，定义Over windows。</p><p>无界的over window是使用常量指定的。也就是说，时间间隔要指定UNBOUNDED_RANGE，或者行计数间隔要指定UNBOUNDED_ROW。而有界的over window是用间隔的大小指定的。</p><p>实际代码应用如下：</p><ol><li>无界的 over window</li></ol><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无界的事件时间over window (时间字段 "rowtime")</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'rowtime</span> preceding <span class="type">UNBOUNDED_RANGE</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">//无界的处理时间over window (时间字段"proctime")</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'proctime</span> preceding <span class="type">UNBOUNDED_RANGE</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// 无界的事件时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'rowtime</span> preceding <span class="type">UNBOUNDED_ROW</span> as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">//无界的处理时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'proctime</span> preceding <span class="type">UNBOUNDED_ROW</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><ol><li>有界的over window</li></ol><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有界的事件时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'rowtime</span> preceding <span class="number">1.</span>minutes as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// 有界的处理时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'proctime</span> preceding <span class="number">1.</span>minutes as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// 有界的事件时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'rowtime</span> preceding <span class="number">10.</span>rows as <span class="symbol">'w</span>)</span><br><span class="line"><span class="comment">// 有界的处理时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line">.window(<span class="type">Over</span> partitionBy <span class="symbol">'a</span> orderBy <span class="symbol">'proctime</span> preceding <span class="number">10.</span>rows as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure></div><h3 id="SQL中窗口的定义"><a href="#SQL中窗口的定义" class="headerlink" title="SQL中窗口的定义"></a>SQL中窗口的定义</h3><p>我们已经了解了在Table API里window的调用方式，同样，我们也可以在SQL中直接加入窗口的定义和使用。</p><h4 id="Group-Windows"><a href="#Group-Windows" class="headerlink" title="Group Windows"></a>Group Windows</h4><p>Group Windows在SQL查询的Group BY子句中定义。与使用常规GROUP BY子句的查询一样，使用GROUP BY子句的查询会计算每个组的单个结果行。</p><p>SQL支持以下Group窗口函数:</p><ul><li>TUMBLE(time_attr, interval)</li></ul><p>定义一个滚动窗口，第一个参数是时间字段，第二个参数是窗口长度。</p><ul><li>HOP(time_attr, interval, interval)</li></ul><p>定义一个滑动窗口，第一个参数是时间字段，第二个参数是窗口滑动步长，第三个是窗口长度。</p><ul><li>SESSION(time_attr, interval)</li></ul><p>定义一个会话窗口，第一个参数是时间字段，第二个参数是窗口间隔（Gap）。</p><p>另外还有一些辅助函数，可以用来选择Group Window的开始和结束时间戳，以及时间属性。</p><p>这里只写TUMBLE_<em>，滑动和会话窗口是类似的（HOP_</em>，SESSION_*）。</p><ul><li>TUMBLE_START(time_attr, interval)</li><li>TUMBLE_END(time_attr, interval)</li><li>TUMBLE_ROWTIME(time_attr, interval)</li><li>TUMBLE_PROCTIME(time_attr, interval)</li></ul><h4 id="Over-Windows-1"><a href="#Over-Windows-1" class="headerlink" title="Over Windows"></a>Over Windows</h4><p>由于Over本来就是SQL内置支持的语法，所以这在SQL中属于基本的聚合操作。所有聚合必须在同一窗口上定义，也就是说，必须是相同的分区、排序和范围。目前仅支持在当前行范围之前的窗口（无边界和有边界）。</p><p>注意，ORDER BY必须在单一的时间属性上指定。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"></span><br><span class="line">// 也可以做多个聚合</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> w, <span class="keyword">SUM</span>(amount) <span class="keyword">OVER</span> w</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure></div><h3 id="代码练习（以分组滚动窗口为例）"><a href="#代码练习（以分组滚动窗口为例）" class="headerlink" title="代码练习（以分组滚动窗口为例）"></a>代码练习（以分组滚动窗口为例）</h3><p>我们可以综合学习过的内容，用一段完整的代码实现一个具体的需求。例如，可以开一个滚动窗口，统计10秒内出现的每个sensor的个数。</p><p>代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">  env.setParallelism(<span class="number">1</span>)</span><br><span class="line">  env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> streamFromFile: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"sensor.txt"</span>)</span><br><span class="line">  <span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = streamFromFile</span><br><span class="line">    .map( data =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">      <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>).trim,</span><br><span class="line">        dataArray(<span class="number">1</span>).trim.toLong, dataArray(<span class="number">2</span>).trim.toDouble)</span><br><span class="line">    &#125;)</span><br><span class="line">    .assignTimestampsAndWatermarks(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">SensorReading</span>](</span><br><span class="line">        <span class="type">Time</span>.seconds(<span class="number">1</span>)</span><br><span class="line">      ) &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(</span><br><span class="line">          element: <span class="type">SensorReading</span></span><br><span class="line">        ): <span class="type">Long</span> = element.timestamp * <span class="number">1000</span>L</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> settings: <span class="type">EnvironmentSettings</span> = <span class="type">EnvironmentSettings</span></span><br><span class="line">    .newInstance()</span><br><span class="line">    .useOldPlanner()</span><br><span class="line">    .inStreamingMode()</span><br><span class="line">    .build()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> tableEnv: <span class="type">StreamTableEnvironment</span> = <span class="type">StreamTableEnvironment</span></span><br><span class="line">    .create(env, settings)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> dataTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">    .fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>.rowtime)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> resultTable: <span class="type">Table</span> = dataTable</span><br><span class="line">    .window(<span class="type">Tumble</span> over <span class="number">10.</span>seconds on <span class="symbol">'timestamp</span> as <span class="symbol">'tw</span>)</span><br><span class="line">    .groupBy(<span class="symbol">'id</span>, <span class="symbol">'tw</span>)</span><br><span class="line">    .select(<span class="symbol">'id</span>, <span class="symbol">'id</span>.count)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sqlDataTable: <span class="type">Table</span> = dataTable</span><br><span class="line">    .select(<span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br><span class="line">  <span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">    .sqlQuery(<span class="string">"select id, count(id) from "</span> </span><br><span class="line">      + sqlDataTable </span><br><span class="line">      + <span class="string">" group by id,tumble(ts,interval '10' second)"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 把 Table转化成数据流</span></span><br><span class="line">  <span class="keyword">val</span> resultDstream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = resultSqlTable</span><br><span class="line">    .toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)]</span><br><span class="line">  resultDstream.filter(_._1).print()</span><br><span class="line">  env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="函数（Functions）"><a href="#函数（Functions）" class="headerlink" title="函数（Functions）"></a>函数（Functions）</h2><p>Flink Table 和 SQL内置了很多SQL中支持的函数；如果有无法满足的需要，则可以实现用户自定义的函数（UDF）来解决。</p><h3 id="系统内置函数"><a href="#系统内置函数" class="headerlink" title="系统内置函数"></a>系统内置函数</h3><p>Flink Table API 和 SQL为用户提供了一组用于数据转换的内置函数。SQL中支持的很多函数，Table API和SQL都已经做了实现，其它还在快速开发扩展中。</p><p>以下是一些典型函数的举例，全部的内置函数，可以参考官网介绍。</p><ul><li>比较函数</li></ul><p>SQL：</p><p>value1 = value2</p><p>value1 &gt; value2</p><p>Table API：</p><p>ANY1 === ANY2</p><p>ANY1 &gt; ANY2</p><ul><li>逻辑函数</li></ul><p>SQL：</p><p>boolean1 OR boolean2</p><p>boolean IS FALSE</p><p>NOT boolean</p><p>Table API：</p><p>BOOLEAN1 || BOOLEAN2</p><p>BOOLEAN.isFalse</p><p>!BOOLEAN</p><ul><li>算术函数</li></ul><p>SQL：</p><p>numeric1 + numeric2</p><p>POWER(numeric1, numeric2)</p><p>Table API：</p><p>NUMERIC1 + NUMERIC2</p><p>NUMERIC1.power(NUMERIC2)</p><ul><li>字符串函数</li></ul><p>SQL：</p><p>string1 || string2</p><p>UPPER(string)</p><p>CHAR_LENGTH(string)</p><p>Table API：</p><p>STRING1 + STRING2</p><p>STRING.upperCase()</p><p>STRING.charLength()</p><ul><li>时间函数</li></ul><p>SQL：</p><p>DATE string</p><p>TIMESTAMP string</p><p>CURRENT_TIME</p><p>INTERVAL string range</p><p>Table API：</p><p>STRING.toDate</p><p>STRING.toTimestamp</p><p>currentTime()</p><p>NUMERIC.days</p><p>NUMERIC.minutes</p><ul><li>聚合函数</li></ul><p>SQL：</p><p>COUNT(*)</p><p>SUM([ ALL | DISTINCT ] expression)</p><p>RANK()</p><p>ROW_NUMBER()</p><p>Table API：</p><p>FIELD.count</p><p>FIELD.sum0</p><h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>用户定义函数（User-defined Functions，UDF）是一个重要的特性，因为它们显著地扩展了查询（Query）的表达能力。一些系统内置函数无法解决的需求，我们可以用UDF来自定义实现。</p><h4 id="注册用户自定义函数UDF"><a href="#注册用户自定义函数UDF" class="headerlink" title="注册用户自定义函数UDF"></a>注册用户自定义函数UDF</h4><p>在大多数情况下，用户定义的函数必须先注册，然后才能在查询中使用。不需要专门为Scala 的Table API注册函数。</p><p>函数通过调用registerFunction（）方法在TableEnvironment中注册。当用户定义的函数被注册时，它被插入到TableEnvironment的函数目录中，这样Table API或SQL解析器就可以识别并正确地解释它。</p><h4 id="标量函数（Scalar-Functions）"><a href="#标量函数（Scalar-Functions）" class="headerlink" title="标量函数（Scalar Functions）"></a>标量函数（Scalar Functions）</h4><p>用户定义的标量函数，可以将0、1或多个标量值，映射到新的标量值。</p><p>为了定义标量函数，必须在org.apache.flink.table.functions中扩展基类Scalar Function，并实现（一个或多个）求值（evaluation，eval）方法。标量函数的行为由求值方法决定，求值方法必须公开声明并命名为eval（直接def声明，没有override）。求值方法的参数类型和返回类型，确定了标量函数的参数和返回类型。</p><p>在下面的代码中，我们定义自己的HashCode函数，在TableEnvironment中注册它，并在查询中调用它。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义一个标量函数</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HashCode</span>(<span class="params"> factor: <span class="type">Int</span> </span>) <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>( s: <span class="type">String</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">    s.hashCode * factor</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>主函数中调用，计算sensor id的哈希值（前面部分照抄，流环境、表环境、读取source、建表）：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.&#123;<span class="type">EnvironmentSettings</span>, <span class="type">Tumble</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.<span class="type">ScalarFunction</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TableUDFExample1</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">      .useBlinkPlanner()</span><br><span class="line">      .inStreamingMode()</span><br><span class="line">      .build()</span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    <span class="keyword">val</span> hashCode = <span class="keyword">new</span> <span class="type">HashCode</span>(<span class="number">10</span>)</span><br><span class="line">    tEnv.registerFunction(<span class="string">"hashCode"</span>, <span class="keyword">new</span> <span class="type">HashCode</span>(<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">val</span> table = tEnv.fromDataStream(stream, <span class="symbol">'id</span>)</span><br><span class="line">    <span class="comment">// table api 写法</span></span><br><span class="line">    table</span><br><span class="line">      .select(<span class="symbol">'id</span>, hashCode(<span class="symbol">'id</span>))</span><br><span class="line">      .toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)]</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sql 写法</span></span><br><span class="line">    tEnv.createTemporaryView(<span class="string">"t"</span>, table, <span class="symbol">'id</span>)</span><br><span class="line">    tEnv</span><br><span class="line">      .sqlQuery(<span class="string">"SELECT id, hashCode(id) FROM t"</span>)</span><br><span class="line">      .toAppendStream[(<span class="type">String</span>, <span class="type">Int</span>)]</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">HashCode</span>(<span class="params">factor: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(s: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      s.hashCode() * factor</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h4 id="表函数（Table-Functions）"><a href="#表函数（Table-Functions）" class="headerlink" title="表函数（Table Functions）"></a>表函数（Table Functions）</h4><p>与用户定义的标量函数类似，用户定义的表函数，可以将0、1或多个标量值作为输入参数；与标量函数不同的是，它可以返回任意数量的行作为输出，而不是单个值。</p><p>为了定义一个表函数，必须扩展org.apache.flink.table.functions中的基类TableFunction并实现（一个或多个）求值方法。表函数的行为由其求值方法决定，求值方法必须是public的，并命名为eval。求值方法的参数类型，决定表函数的所有有效参数。</p><p>返回表的类型由TableFunction的泛型类型确定。求值方法使用protected collect（T）方法发出输出行。</p><p>在Table API中，Table函数需要与.joinLateral或.leftOuterJoinLateral一起使用。</p><p>joinLateral算子，会将外部表中的每一行，与表函数（TableFunction，算子的参数是它的表达式）计算得到的所有行连接起来。</p><p>而leftOuterJoinLateral算子，则是左外连接，它同样会将外部表中的每一行与表函数计算生成的所有行连接起来；并且，对于表函数返回的是空表的外部行，也要保留下来。</p><p>在SQL中，则需要使用Lateral Table（），或者带有ON TRUE条件的左连接。</p><p>下面的代码中，我们将定义一个表函数，在表环境中注册它，并在查询中调用它。</p><p>自定义TableFunction：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义TableFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Split</span>(<span class="params">separator: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">TableFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)]</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    str.split(separator).foreach(</span><br><span class="line">      word =&gt; collect((word, word.length))</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>接下来，就是在代码中调用。首先是Table API的方式：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Table API中调用，需要用joinLateral</span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">  .joinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))   <span class="comment">// as对输出行的字段重命名</span></span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// 或者用leftOuterJoinLateral</span></span><br><span class="line"><span class="keyword">val</span> resultTable2 = sensorTable</span><br><span class="line">  .leftOuterJoinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">resultTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure></div><p>然后是SQL的方式：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"split"</span>, split)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, word, length</span></span><br><span class="line"><span class="string">    |from</span></span><br><span class="line"><span class="string">    |sensor, LATERAL TABLE(split(id)) AS newsensor(word, length)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 或者用左连接的方式</span></span><br><span class="line"><span class="keyword">val</span> resultSqlTable2 = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT id, word, length</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |  LEFT JOIN </span></span><br><span class="line"><span class="string">    |  LATERAL TABLE(split(id)) AS newsensor(word, length) </span></span><br><span class="line"><span class="string">    |  ON TRUE</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultSqlTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">resultSqlTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="聚合函数（Aggregate-Functions）"><a href="#聚合函数（Aggregate-Functions）" class="headerlink" title="聚合函数（Aggregate Functions）"></a>聚合函数（Aggregate Functions）</h4><p>用户自定义聚合函数（User-Defined Aggregate Functions，UDAGGs）可以把一个表中的数据，聚合成一个标量值。用户定义的聚合函数，是通过继承AggregateFunction抽象类实现的。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/udagg-mechanism.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/udagg-mechanism.png" class="lazyload"></a></p><p>上图中显示了一个聚合的例子。</p><p>假设现在有一张表，包含了各种饮料的数据。该表由三列（id、name和price）、五行组成数据。现在我们需要找到表中所有饮料的最高价格，即执行max（）聚合，结果将是一个数值。</p><p>AggregateFunction的工作原理如下。</p><ul><li>首先，它需要一个累加器，用来保存聚合中间结果的数据结构（状态）。可以通过调用AggregateFunction的createAccumulator（）方法创建空累加器。</li><li>随后，对每个输入行调用函数的accumulate（）方法来更新累加器。</li><li>处理完所有行后，将调用函数的getValue（）方法来计算并返回最终结果。</li></ul><p>AggregationFunction要求必须实现的方法：</p><ul><li>createAccumulator()</li><li>accumulate()</li><li>getValue()</li></ul><p>除了上述方法之外，还有一些可选择实现的方法。其中一些方法，可以让系统执行查询更有效率，而另一些方法，对于某些场景是必需的。例如，如果聚合函数应用在会话窗口（session group window）的上下文中，则merge（）方法是必需的。</p><ul><li>retract() </li><li>merge() </li><li>resetAccumulator()</li></ul><p>接下来我们写一个自定义AggregateFunction，计算一下每个sensor的平均温度值。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义AggregateFunction的Accumulator</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTempAcc</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> sum: <span class="type">Double</span> = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">var</span> count: <span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTemp</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">Double</span>, <span class="type">AvgTempAcc</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>(accumulator: <span class="type">AvgTempAcc</span>): <span class="type">Double</span> = accumulator.sum / accumulator.count</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">AvgTempAcc</span> = <span class="keyword">new</span> <span class="type">AvgTempAcc</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(accumulator: <span class="type">AvgTempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    accumulator.sum += temp</span><br><span class="line">    accumulator.count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>接下来就可以在代码中调用了。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> avgTemp = <span class="keyword">new</span> <span class="type">AvgTemp</span>()</span><br><span class="line"><span class="comment">// Table API的调用</span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">  .groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .aggregate(avgTemp(<span class="symbol">'temperature</span>) as <span class="symbol">'avgTemp</span>)</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'avgTemp</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// SQL的实现</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"avgTemp"</span>, avgTemp)</span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT</span></span><br><span class="line"><span class="string">    |id, avgTemp(temperature)</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |GROUP BY id</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure></div><h4 id="表聚合函数（Table-Aggregate-Functions）"><a href="#表聚合函数（Table-Aggregate-Functions）" class="headerlink" title="表聚合函数（Table Aggregate Functions）"></a>表聚合函数（Table Aggregate Functions）</h4><p>用户定义的表聚合函数（User-Defined Table Aggregate Functions，UDTAGGs），可以把一个表中数据，聚合为具有多行和多列的结果表。这跟AggregateFunction非常类似，只是之前聚合结果是一个标量值，现在变成了一张表。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/udtagg-mechanism.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/udtagg-mechanism.png" class="lazyload"></a></p><p>比如现在我们需要找到表中所有饮料的前2个最高价格，即执行top2()表聚合。我们需要检查5行中的每一行，得到的结果将是一个具有排序后前2个值的表。</p><p>用户定义的表聚合函数，是通过继承TableAggregateFunction抽象类来实现的。</p><p>TableAggregateFunction的工作原理如下。</p><ul><li>首先，它同样需要一个累加器（Accumulator），它是保存聚合中间结果的数据结构。通过调用TableAggregateFunction的createAccumulator()方法可以创建空累加器。</li><li>随后，对每个输入行调用函数的accumulate()方法来更新累加器。</li><li>处理完所有行后，将调用函数的emitValue()方法来计算并返回最终结果。</li></ul><p>AggregationFunction要求必须实现的方法：</p><ul><li>createAccumulator()</li><li>accumulate()</li></ul><p>除了上述方法之外，还有一些可选择实现的方法。</p><ul><li>retract() </li><li>merge() </li><li>resetAccumulator() </li><li>emitValue() </li><li>emitUpdateWithRetract()</li></ul><p>接下来我们写一个自定义TableAggregateFunction，用来提取每个sensor最高的两个温度值。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 先定义一个 Accumulator</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2TempAcc</span></span>&#123;</span><br><span class="line">  <span class="keyword">var</span> highestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">  <span class="keyword">var</span> secondHighestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 TableAggregateFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2Temp</span> <span class="keyword">extends</span> <span class="title">TableAggregateFunction</span>[(<span class="type">Double</span>, <span class="type">Int</span>), <span class="type">Top2TempAcc</span>]</span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Top2TempAcc</span> = <span class="keyword">new</span> <span class="type">Top2TempAcc</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">Top2TempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    <span class="keyword">if</span>( temp &gt; acc.highestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = acc.highestTemp</span><br><span class="line">      acc.highestTemp = temp</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>( temp &gt; acc.secondHighestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = temp</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">emitValue</span></span>(acc: <span class="type">Top2TempAcc</span>, out: <span class="type">Collector</span>[(<span class="type">Double</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> =&#123;</span><br><span class="line">    out.collect(acc.highestTemp, <span class="number">1</span>)</span><br><span class="line">    out.collect(acc.secondHighestTemp, <span class="number">2</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>接下来就可以在代码中调用了。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个表聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> top2Temp = <span class="keyword">new</span> <span class="type">Top2Temp</span>()</span><br><span class="line"><span class="comment">// Table API的调用</span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">  .groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .flatAggregate( top2Temp(<span class="symbol">'temperature</span>) as (<span class="symbol">'temp</span>, <span class="symbol">'rank</span>) )</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'temp</span>, <span class="symbol">'rank</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure></div><h2 id="使用Table-API结合SQL实现TopN需求"><a href="#使用Table-API结合SQL实现TopN需求" class="headerlink" title="使用Table API结合SQL实现TopN需求"></a>使用Table API结合SQL实现TopN需求</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.project.topnhotitems</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">Timestamp</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ysss.project.util.<span class="type">UserBehavior</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.&#123;<span class="type">EnvironmentSettings</span>, <span class="type">Tumble</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HotItemsTable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="comment">// 有关Blink的配置，样板代码</span></span><br><span class="line">    <span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">      .useBlinkPlanner()</span><br><span class="line">      .inStreamingMode()</span><br><span class="line">      .build()</span><br><span class="line">    <span class="comment">// 创建流式表的环境</span></span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">// 使用事件时间</span></span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="comment">// 过滤出pv事件，并抽取时间戳</span></span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .readTextFile(<span class="string">"`UserBehavior.csv`的绝对路径"</span>)</span><br><span class="line">      .map(line =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> arr = line.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">UserBehavior</span>(arr(<span class="number">0</span>).toLong,</span><br><span class="line">          arr(<span class="number">1</span>).toLong, arr(<span class="number">2</span>).toInt, arr(<span class="number">3</span>), arr(<span class="number">4</span>).toLong * <span class="number">1000</span>)</span><br><span class="line">      &#125;)</span><br><span class="line">      .filter(_.behavior == <span class="string">"pv"</span>)</span><br><span class="line">      .assignAscendingTimestamps(_.timestamp)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从流中提取两个字段，时间戳；itemId，组成一张表</span></span><br><span class="line">    <span class="keyword">val</span> table = tEnv.fromDataStream(stream, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'itemId</span>)</span><br><span class="line">    <span class="keyword">val</span> t = table</span><br><span class="line">      .window(<span class="type">Tumble</span> over <span class="number">60.</span>minutes on <span class="symbol">'timestamp</span> as <span class="symbol">'w</span>) <span class="comment">// 一小时滚动窗口</span></span><br><span class="line">      .groupBy(<span class="symbol">'itemId</span>, <span class="symbol">'w</span>)                               <span class="comment">// 根据itemId和窗口进行分组</span></span><br><span class="line">      .aggregate(<span class="symbol">'itemId</span>.count as <span class="symbol">'icount</span>)                <span class="comment">// 对itemId进行计数</span></span><br><span class="line">      .select(<span class="symbol">'itemId</span>, <span class="symbol">'icount</span>, <span class="symbol">'w</span>.end as <span class="symbol">'windowEnd</span>)     <span class="comment">// 查询三个字段</span></span><br><span class="line">      .toAppendStream[(<span class="type">Long</span>, <span class="type">Long</span>, <span class="type">Timestamp</span>)]            <span class="comment">// 转换成DataStream</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建临时表</span></span><br><span class="line">    tEnv.createTemporaryView(<span class="string">"topn"</span>, t, <span class="symbol">'itemId</span>, <span class="symbol">'icount</span>, <span class="symbol">'windowEnd</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// topN查询，Blink支持的特性</span></span><br><span class="line">    <span class="keyword">val</span> result = tEnv.sqlQuery(</span><br><span class="line">      <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        |SELECT *</span></span><br><span class="line"><span class="string">        |FROM (</span></span><br><span class="line"><span class="string">        |    SELECT *,</span></span><br><span class="line"><span class="string">        |        ROW_NUMBER() OVER</span></span><br><span class="line"><span class="string">        |        (PARTITION BY windowEnd ORDER BY icount DESC) as row_num</span></span><br><span class="line"><span class="string">        |    FROM topn)</span></span><br><span class="line"><span class="string">        |WHERE row_num &lt;= 5</span></span><br><span class="line"><span class="string">        |"</span><span class="string">""</span>.stripMargin</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">// 使用toRetractStream转换成DataStream，用来实时更新排行榜</span></span><br><span class="line">    <span class="comment">// true代表insert, false代表delete</span></span><br><span class="line">    result.toRetractStream[(<span class="type">Long</span>, <span class="type">Long</span>, <span class="type">Timestamp</span>, <span class="type">Long</span>)].print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="只使用Flink-SQL实现TopN需求"><a href="#只使用Flink-SQL实现TopN需求" class="headerlink" title="只使用Flink SQL实现TopN需求"></a>只使用Flink SQL实现TopN需求</h2><p>代码</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.<span class="type">Timestamp</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ysss.project.util.<span class="type">UserBehavior</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.&#123;<span class="type">EnvironmentSettings</span>, <span class="type">Tumble</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HotItemsSQL</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">      .useBlinkPlanner()</span><br><span class="line">      .inStreamingMode()</span><br><span class="line">      .build()</span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="keyword">val</span> stream = env</span><br><span class="line">      .readTextFile(<span class="string">"`UserBehavior.csv`的绝对路径"</span>)</span><br><span class="line">      .map(line =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> arr = line.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">UserBehavior</span>(arr(<span class="number">0</span>).toLong,</span><br><span class="line">          arr(<span class="number">1</span>).toLong, arr(<span class="number">2</span>).toInt, arr(<span class="number">3</span>), arr(<span class="number">4</span>).toLong * <span class="number">1000</span>)</span><br><span class="line">      &#125;)</span><br><span class="line">      .filter(_.behavior == <span class="string">"pv"</span>)</span><br><span class="line">      .assignAscendingTimestamps(_.timestamp)</span><br><span class="line"></span><br><span class="line">    tEnv.createTemporaryView(<span class="string">"t"</span>, stream, <span class="symbol">'itemId</span>, <span class="symbol">'timestamp</span>.rowtime as <span class="symbol">'ts</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result = tEnv.sqlQuery(</span><br><span class="line">      <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        |SELECT *</span></span><br><span class="line"><span class="string">        |FROM (</span></span><br><span class="line"><span class="string">        |    SELECT *,</span></span><br><span class="line"><span class="string">        |        ROW_NUMBER() OVER</span></span><br><span class="line"><span class="string">        |        (PARTITION BY windowEnd ORDER BY icount DESC) as row_num</span></span><br><span class="line"><span class="string">        |    FROM</span></span><br><span class="line"><span class="string">        |    (SELECT count(itemId) as icount,</span></span><br><span class="line"><span class="string">        |     TUMBLE_START(ts, INTERVAL '1' HOUR) as windowEnd</span></span><br><span class="line"><span class="string">        |     FROM t GROUP BY TUMBLE(ts, INTERVAL '1' HOUR), itemId) topn)</span></span><br><span class="line"><span class="string">        |WHERE row_num &lt;= 5</span></span><br><span class="line"><span class="string">        |"</span><span class="string">""</span>.stripMargin</span><br><span class="line">    )</span><br><span class="line">    result.toRetractStream[(<span class="type">Long</span>, <span class="type">Timestamp</span>, <span class="type">Long</span>)].print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Table-API-和-Flink-SQL&quot;&gt;&lt;a href=&quot;#Table-API-和-Flink-SQL&quot; class=&quot;headerlink&quot; title=&quot;Table API 和 Flink SQL&quot;&gt;&lt;/a&gt;Table API 和 Flink SQL&lt;/
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列10Flink CEP简介</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9710Flink-CEP%E7%AE%80%E4%BB%8B/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9710Flink-CEP%E7%AE%80%E4%BB%8B/</id>
    <published>2020-07-02T03:50:56.000Z</published>
    <updated>2020-07-02T03:51:39.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flink-CEP简介"><a href="#Flink-CEP简介" class="headerlink" title="Flink CEP简介"></a>Flink CEP简介</h1><p><em>什么是复杂事件CEP？</em></p><p>一个或多个由简单事件构成的事件流通过一定的规则匹配，然后输出用户想得到的数据，满足规则的复杂事件。</p><p><em>特征：</em></p><ul><li>目标：从有序的简单事件流中发现一些高阶特征</li><li>输入：一个或多个由简单事件构成的事件流</li><li>处理：识别简单事件之间的内在联系，多个符合一定规则的简单事件构成复杂事件</li><li>输出：满足规则的复杂事件</li></ul><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/cep1.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/cep1.jpg" class="lazyload"></a></p><p>CEP用于分析低延迟、频繁产生的不同来源的事件流。CEP可以帮助在复杂的、不相关的事件流中找出有意义的模式和复杂的关系，以接近实时或准实时的获得通知并阻止一些行为。</p><p>CEP支持在流上进行模式匹配，根据模式的条件不同，分为连续的条件或不连续的条件；模式的条件允许有时间的限制，当在条件范围内没有达到满足的条件时，会导致模式匹配超时。</p><p>看起来很简单，但是它有很多不同的功能：</p><ul><li>输入的流数据，尽快产生结果</li><li>在2个event流上，基于时间进行聚合类的计算</li><li>提供实时/准实时的警告和通知</li><li>在多样的数据源中产生关联并分析模式</li><li>高吞吐、低延迟的处理</li></ul><p>市场上有多种CEP的解决方案，例如Spark、Samza、Beam等，但他们都没有提供专门的library支持。但是Flink提供了专门的CEP library。</p><p><em>Flink CEP</em></p><p>Flink为CEP提供了专门的Flink CEP library，它包含如下组件：</p><ul><li>Event Stream</li><li>pattern定义</li><li>pattern检测</li><li>生成Alert</li></ul><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/cep6.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/cep6.png" class="lazyload"></a></p><p>首先，开发人员要在DataStream流上定义出模式条件，之后Flink CEP引擎进行模式检测，必要时生成告警。</p><p>为了使用Flink CEP，我们需要导入依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-cep-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p><em>Event Streams</em></p><p>登录事件流</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginEvent</span>(<span class="params">userId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      ip: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventTime: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">env</span> </span>= <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> loginEventStream = env</span><br><span class="line">  .fromCollection(<span class="type">List</span>(</span><br><span class="line">    <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.1"</span>, <span class="string">"fail"</span>, <span class="string">"1558430842"</span>),</span><br><span class="line">    <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.2"</span>, <span class="string">"fail"</span>, <span class="string">"1558430843"</span>),</span><br><span class="line">    <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.3"</span>, <span class="string">"fail"</span>, <span class="string">"1558430844"</span>),</span><br><span class="line">    <span class="type">LoginEvent</span>(<span class="string">"2"</span>, <span class="string">"192.168.10.10"</span>, <span class="string">"success"</span>, <span class="string">"1558430845"</span>)</span><br><span class="line">  ))</span><br><span class="line">  .assignAscendingTimestamps(_.eventTime.toLong * <span class="number">1000</span>)</span><br></pre></td></tr></table></figure></div><p><em>Pattern API</em></p><p>每个Pattern都应该包含几个步骤，或者叫做state。从一个state到另一个state，通常我们需要定义一些条件，例如下列的代码：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> loginFailPattern = <span class="type">Pattern</span>.begin[<span class="type">LoginEvent</span>](<span class="string">"begin"</span>)</span><br><span class="line">  .where(_.eventType.equals(<span class="string">"fail"</span>))</span><br><span class="line">  .next(<span class="string">"next"</span>)</span><br><span class="line">  .where(_.eventType.equals(<span class="string">"fail"</span>))</span><br><span class="line">  .within(<span class="type">Time</span>.seconds(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></div><p>每个state都应该有一个标示：</p><p>例如: <code>.begin[LoginEvent](&quot;begin&quot;)</code>中的“begin”</p><p>每个state都需要有一个唯一的名字，而且需要一个filter来过滤条件，这个过滤条件定义事件需要符合的条件</p><p>例如: <code>.where(_.eventType.equals(&quot;fail&quot;))</code></p><p>我们也可以通过subtype来限制event的子类型：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start.subtype(<span class="type">SubEvent</span><span class="class">.<span class="keyword">class</span>).<span class="title">where</span>(<span class="params">...</span>)</span>;</span><br></pre></td></tr></table></figure></div><p>事实上，你可以多次调用subtype和where方法；而且如果where条件是不相关的，你可以通过or来指定一个单独的filter函数：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(...).or(...);</span><br></pre></td></tr></table></figure></div><p>之后，我们可以在此条件基础上，通过next或者followedBy方法切换到下一个state，next的意思是说上一步符合条件的元素之后紧挨着的元素；而followedBy并不要求一定是挨着的元素。这两者分别称为严格近邻和非严格近邻。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> strictNext = start.next(<span class="string">"middle"</span>)</span><br><span class="line"><span class="keyword">val</span> nonStrictNext = start.followedBy(<span class="string">"middle"</span>)</span><br></pre></td></tr></table></figure></div><p>最后，我们可以将所有的Pattern的条件限定在一定的时间范围内：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">next.within(<span class="type">Time</span>.seconds(<span class="number">10</span>))</span><br></pre></td></tr></table></figure></div><p>这个时间可以是Processing Time，也可以是Event Time。</p><p><em>Pattern 检测</em></p><p>通过一个input DataStream以及刚刚我们定义的Pattern，我们可以创建一个PatternStream：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> input = ...</span><br><span class="line"><span class="keyword">val</span> pattern = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> patternStream = <span class="type">CEP</span>.pattern(input, pattern)</span><br><span class="line"><span class="keyword">val</span> patternStream = <span class="type">CEP</span></span><br><span class="line">  .pattern(</span><br><span class="line">    loginEventStream.keyBy(_.userId), loginFailPattern</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></div><p>一旦获得PatternStream，我们就可以通过select或flatSelect，从一个Map序列找到我们需要的告警信息。</p><p><em>select</em></p><p>select方法需要实现一个PatternSelectFunction，通过select方法来输出需要的警告。它接受一个Map对，包含string/event，其中key为state的名字，event则为真是的Event。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> loginFailDataStream = patternStream</span><br><span class="line">  .select((pattern: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">LoginEvent</span>]]) =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> first = pattern.getOrElse(<span class="string">"begin"</span>, <span class="literal">null</span>).iterator.next()</span><br><span class="line">    <span class="keyword">val</span> second = pattern.getOrElse(<span class="string">"next"</span>, <span class="literal">null</span>).iterator.next()</span><br><span class="line"></span><br><span class="line">    (second.userId, second.ip, second.eventType)</span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure></div><p>其返回值仅为1条记录。</p><p><em>flatSelect</em></p><p>通过实现PatternFlatSelectFunction，实现与select相似的功能。唯一的区别就是flatSelect方法可以返回多条记录。</p><p><em>超时事件的处理</em></p><p>通过within方法，我们的parttern规则限定在一定的窗口范围内。当有超过窗口时间后还到达的event，我们可以通过在select或flatSelect中，实现PatternTimeoutFunction/PatternFlatTimeoutFunction来处理这种情况。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> complexResult = patternStream.select(orderTimeoutOutput) &#123;</span><br><span class="line">  (pattern: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">OrderEvent</span>]], timestamp: <span class="type">Long</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> createOrder = pattern.get(<span class="string">"begin"</span>)</span><br><span class="line">    <span class="type">OrderTimeoutEvent</span>(createOrder.get.iterator.next().orderId, <span class="string">"timeout"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125; &#123;</span><br><span class="line">  pattern: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">OrderEvent</span>]] =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> payOrder = pattern.get(<span class="string">"next"</span>)</span><br><span class="line">    <span class="type">OrderTimeoutEvent</span>(payOrder.get.iterator.next().orderId, <span class="string">"success"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> timeoutResult = complexResult.getSideOutput(orderTimeoutOutput)</span><br><span class="line"></span><br><span class="line">complexResult.print()</span><br><span class="line">timeoutResult.print()</span><br></pre></td></tr></table></figure></div><p>完整例子:</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.cep.scala.<span class="type">CEP</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.cep.scala.pattern.<span class="type">Pattern</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">Map</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFlinkLoginFail</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> loginEventStream = env.fromCollection(<span class="type">List</span>(</span><br><span class="line">      <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.1"</span>, <span class="string">"fail"</span>, <span class="string">"1558430842"</span>),</span><br><span class="line">      <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.2"</span>, <span class="string">"fail"</span>, <span class="string">"1558430843"</span>),</span><br><span class="line">      <span class="type">LoginEvent</span>(<span class="string">"1"</span>, <span class="string">"192.168.0.3"</span>, <span class="string">"fail"</span>, <span class="string">"1558430844"</span>),</span><br><span class="line">      <span class="type">LoginEvent</span>(<span class="string">"2"</span>, <span class="string">"192.168.10.10"</span>, <span class="string">"success"</span>, <span class="string">"1558430845"</span>)</span><br><span class="line">    )).assignAscendingTimestamps(_.eventTime.toLong)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> loginFailPattern = <span class="type">Pattern</span>.begin[<span class="type">LoginEvent</span>](<span class="string">"begin"</span>)</span><br><span class="line">      .where(_.eventType.equals(<span class="string">"fail"</span>))</span><br><span class="line">      .next(<span class="string">"next"</span>)</span><br><span class="line">      .where(_.eventType.equals(<span class="string">"fail"</span>))</span><br><span class="line">      .within(<span class="type">Time</span>.seconds(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> patternStream = <span class="type">CEP</span>.pattern(</span><br><span class="line">      loginEventStream.keyBy(_.userId), loginFailPattern</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> loginFailDataStream = patternStream</span><br><span class="line">      .select((pattern: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">LoginEvent</span>]]) =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> first = pattern.getOrElse(<span class="string">"begin"</span>, <span class="literal">null</span>).iterator.next()</span><br><span class="line">        <span class="keyword">val</span> second = pattern.getOrElse(<span class="string">"next"</span>, <span class="literal">null</span>).iterator.next()</span><br><span class="line"></span><br><span class="line">        (second.userId, second.ip, second.eventType)</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">    loginFailDataStream.print</span><br><span class="line"></span><br><span class="line">    env.execute</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginEvent</span>(<span class="params">userId: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      ip: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      eventTime: <span class="type">String</span></span>)</span></span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Flink-CEP简介&quot;&gt;&lt;a href=&quot;#Flink-CEP简介&quot; class=&quot;headerlink&quot; title=&quot;Flink CEP简介&quot;&gt;&lt;/a&gt;Flink CEP简介&lt;/h1&gt;&lt;p&gt;&lt;em&gt;什么是复杂事件CEP？&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;一个或多个由
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列09搭建Flink运行流式应用</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9709%E6%90%AD%E5%BB%BAFlink%E8%BF%90%E8%A1%8C%E6%B5%81%E5%BC%8F%E5%BA%94%E7%94%A8/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9709%E6%90%AD%E5%BB%BAFlink%E8%BF%90%E8%A1%8C%E6%B5%81%E5%BC%8F%E5%BA%94%E7%94%A8/</id>
    <published>2020-07-02T03:49:55.000Z</published>
    <updated>2020-07-02T03:50:41.204Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第九章，搭建Flink运行流式应用"><a href="#第九章，搭建Flink运行流式应用" class="headerlink" title="第九章，搭建Flink运行流式应用"></a>第九章，搭建Flink运行流式应用</h1><h2 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h2><h3 id="standalone集群"><a href="#standalone集群" class="headerlink" title="standalone集群"></a>standalone集群</h3><p>standalone集群包含至少一个master进程，以及至少一个TaskManager进程，TaskManager进程运行在一台或者多台机器上。所有的进程都是JVM进程。下图展示了standalone集群的部署。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0901.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0901.png" class="lazyload"></a></p><p>master进程在不同的线程中运行了一个Dispatcher和一个ResourceManager。一旦它们开始运行，所有TaskManager都将在Resourcemanager中进行注册。下图展示了一个任务如何提交到一个standalone集群中去。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0902.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0902.png" class="lazyload"></a></p><p>客户端向Dispatcher提交了一个任务，Dispatcher将会启动一个JobManager线程，并提供执行所需的JobGraph。JobManager向ResourceManager请求必要的task slots。一旦请求的slots分配好，JobManager就会部署job。</p><p>在standalone这种部署方式中，master和worker进程在失败以后，并不会自动重启。如果有足够的slots可供使用，job是可以从一次worker失败中恢复的。只要我们运行多个worker就好了。但如果job想从master失败中恢复的话，则需要进行高可用(HA)的配置了。</p><p><em>部署步骤</em></p><p>下载压缩包</p><p>链接：<a href="http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz</a></p><p>解压缩</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar xvfz flink-1.10.1-bin-scala_2.11.tgz</span><br></pre></td></tr></table></figure></div><p>启动集群</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd flink-1.10.0</span><br><span class="line">$ .&#x2F;bin&#x2F;start-cluster.sh</span><br></pre></td></tr></table></figure></div><p>检查集群状态可以访问：<a href="http://localhost:8081" target="_blank" rel="noopener">http://localhost:8081</a></p><p>部署分布式集群</p><ol><li>所有运行TaskManager的机器的主机名（或者IP地址）都需要写入<code>./conf/slaves</code>文件中。</li><li><code>start-cluster.sh</code>脚本需要所有机器的无密码的SSH登录配置，方便启动TaskManager进程。</li><li>Flink的文件夹在所有的机器上都需要有相同的绝对路径。</li><li>运行master进程的机器的主机名或者IP地址需要写在<code>./conf/flink-conf.yaml</code>文件的<code>jobmanager.rpc.address</code>配置项。</li></ol><p>一旦部署好，我们就可以调用<code>./bin/start-cluster.sh</code>命令启动集群了，脚本会在本地机器启动一个JobManager，然后在每个slave机器上启动一个TaskManager。停止运行，请使用<code>./bin/stop-cluster.sh</code>。</p><h3 id="Apache-Hadoop-Yarn"><a href="#Apache-Hadoop-Yarn" class="headerlink" title="Apache Hadoop Yarn"></a>Apache Hadoop Yarn</h3><p>YARN是Apache Hadoop的资源管理组件。用来计算集群环境所需要的CPU和内存资源，然后提供给应用程序请求的资源。</p><p>Flink在YARN上运行，有两种模式：job模式和session模式。在job模式中，Flink集群用来运行一个单独的job。一旦job结束，Flink集群停止，并释放所有资源。下图展示了Flink的job如何提交到YARN集群。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0903.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0903.png" class="lazyload"></a></p><p>当客户端提交任务时，客户端将建立和YARN ResourceManager的连接，然后启动一个新的YARN应用的master进程，进程中包含一个JobManager线程和一个ResourceManager。JobManager向ResourceManager请求所需要的slots，用来运行Flink的job。接下来，Flink的ResourceManager将向Yarn的ResourceManager请求容器，然后启动TaskManager进程。一旦启动，TaskManager会将slots注册在Flink的ResourceManager中，Flink的ResourceManager将把slots提供给JobManager。最终，JobManager把job的任务提交给TaskManager执行。</p><p>sesison模式将启动一个长期运行的Flink集群，这个集群可以运行多个job，需要手动停止集群。如果以session模式启动，Flink将会连接到YARN的ResourceManager，然后启动一个master进程，包括一个Dispatcher线程和一个Flink的ResourceManager的线程。下图展示了一个Flink YARN session的启动。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0904.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0904.png" class="lazyload"></a></p><p>当一个job被提交运行，Dispatcher将启动一个JobManager线程，这个线程将向Flink的ResourceManager请求所需要的slots。如果没有足够的slots，Flink的ResourceManager将向YARN的ResourceManager请求额外的容器，来启动TaskManager进程，并在Flink的ResourceManager中注册。一旦所需slots可用，Flink的ResourceManager将吧slots分配给JobManager，然后开始执行job。下图展示了job如何在session模式下执行。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0905.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0905.png" class="lazyload"></a></p><p>无论是作业模式还是会话模式，Flink的ResourceManager都会自动对故障的TaskManager进行重启。你可以通过<code>./conf/flink-conf.yaml</code>配置文件来控制Flink在YARN上的故障恢复行为。例如，可以配置有多少容器发生故障后终止应用。</p><p>无论使用job模式还是sesison模式，都需要能够访问Hadoop。</p><p>job模式可以用以下命令来提交任务：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink run -m yarn-cluster .&#x2F;path&#x2F;to&#x2F;job.jar</span><br></pre></td></tr></table></figure></div><p>参数<code>-m</code>用来定义提交作业的目标主机。如果加上关键字<code>&quot;yarn-cluster&quot;</code>，客户端会将作业提交到由Hadoop配置所指定的YARN集群上。Flink的CLI客户端还支持很多参数，例如用于控制TaskManager容器内存大小的参数等。有关它们的详细信息，请参阅文档。Flink集群的Web UI由YARN集群某个节点上的主进程负责提供。你可以通过YARN的Web UI对其进行访问，具体链接位置在“Tracking URL: ApplicationMaster”下的Application Overview页面上。</p><p>session模式则是</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;yarn-session.sh # 启动一个yarn会话</span><br><span class="line">$ .&#x2F;bin&#x2F;flink run .&#x2F;path&#x2F;to&#x2F;job.jar # 向会话提交作业</span><br></pre></td></tr></table></figure></div><blockquote><p>Flink的Web UI链接可以从YARN Web UI的Application Overview页面上找到。</p></blockquote><h2 id="高可用配置-HA"><a href="#高可用配置-HA" class="headerlink" title="高可用配置(HA)"></a>高可用配置(HA)</h2><p>Flink的高可用配置需要Apache ZooKeeper组件，以及一个分布式文件系统，例如HDFS等等。JobManager将会把相关信息都存储在文件系统中，并将指向文件系统中相关信息的指针保存在ZooKeeper中。一旦失败，一个新的JobManager将从ZooKeeper中指向相关信息的指针所指向的文件系统中读取元数据，并恢复运行。</p><p>配置文件编写</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># REQUIRED: enable HA mode via ZooKeeper high-availability: zookeeper</span><br><span class="line"># REQUIRED: provide a list of all ZooKeeper servers of the quorum</span><br><span class="line">high-availability.zookeeper.quorum: address1:2181[,...],addressX:2181</span><br><span class="line"># REQUIRED: set storage location for job metadata in remote storage</span><br><span class="line">high-availability.storageDir: hdfs:&#x2F;&#x2F;&#x2F;flink&#x2F;recovery</span><br><span class="line"># RECOMMENDED: set the base path for all Flink clusters in ZooKeeper.</span><br><span class="line"># Isolates Flink from other frameworks using the ZooKeeper cluster.</span><br><span class="line">high-availability.zookeeper.path.root: &#x2F;flink</span><br></pre></td></tr></table></figure></div><h3 id="standalone集群高可用配置"><a href="#standalone集群高可用配置" class="headerlink" title="standalone集群高可用配置"></a>standalone集群高可用配置</h3><p>需要在配置文件中加一行集群标识符信息，因为可能多个集群共用一个zookeeper服务。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># RECOMMENDED: set the path for the Flink cluster in ZooKeeper.</span><br><span class="line"># Isolates multiple Flink clusters from each other.</span><br><span class="line"># The cluster id is required to look up the metadata of a failed cluster.</span><br><span class="line">high-availability.cluster-id: &#x2F;cluster-1</span><br></pre></td></tr></table></figure></div><h3 id="yarn集群高可用配置"><a href="#yarn集群高可用配置" class="headerlink" title="yarn集群高可用配置"></a>yarn集群高可用配置</h3><p>首先在yarn集群的配置文件<code>yarn-site.xml</code>中加入以下代码</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    The maximum number of application master execution attempts.</span><br><span class="line">    Default value is 2, i.e., an application is restarted at most once.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>然后在<code>./conf/flink-conf.yaml</code>加上</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Restart an application at most 3 times (+ the initial start).</span><br><span class="line"># Must be less or equal to the configured maximum number of attempts.</span><br><span class="line">yarn.application-attempts: 4</span><br></pre></td></tr></table></figure></div><h2 id="与Hadoop集成"><a href="#与Hadoop集成" class="headerlink" title="与Hadoop集成"></a>与Hadoop集成</h2><p>推荐两种方法</p><ol><li>下载包含hadoop的Flink版本。</li><li>使用我们之前下载的Flink，然后配置Hadoop的环境变量。 <code>export HADOOP_CLASSPATH={hadoop classpath}</code></li></ol><p>我们还需要提供Hadoop配置文件的路径。只需设置名为<code>HADOOP_CONF_DIR</code>的环境变量就可以了。这样Flink就能够连上YARN的ResourceManager和HDFS了。</p><h2 id="保存点操作"><a href="#保存点操作" class="headerlink" title="保存点操作"></a>保存点操作</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink savepoint &lt;jobId&gt; [savepointPath]</span><br></pre></td></tr></table></figure></div><p>例如</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink savepoint bc0b2ad61ecd4a615d92ce25390f61ad \</span><br><span class="line">hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints</span><br><span class="line">Triggering savepoint for job bc0b2ad61ecd4a615d92ce25390f61ad.</span><br><span class="line">Waiting for response...</span><br><span class="line">Savepoint completed. </span><br><span class="line">Path: hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints&#x2F;savepoint-bc0b2a-63cf5d5ccef8</span><br><span class="line">You can resume your program from this savepoint with the run command.</span><br></pre></td></tr></table></figure></div><p>删除保存点文件</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink savepoint -d &lt;savepointPath&gt;</span><br></pre></td></tr></table></figure></div><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink savepoint -d \</span><br><span class="line">hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints&#x2F;savepoint-bc0b2a-63cf5d5ccef8</span><br><span class="line">Disposing savepoint &#39;hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints&#x2F;savepoint-bc0b2a-63cf5d5ccef8&#39;.</span><br><span class="line">Waiting for response...</span><br><span class="line">Savepoint &#39;hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints&#x2F;savepoint-bc0b2a-63cf5d5ccef8&#39; disposed.</span><br></pre></td></tr></table></figure></div><h2 id="取消一个应用"><a href="#取消一个应用" class="headerlink" title="取消一个应用"></a>取消一个应用</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink cancel &lt;jobId&gt;</span><br></pre></td></tr></table></figure></div><p>取消的同时做保存点操作</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink cancel -s [savepointPath] &lt;jobId&gt;</span><br></pre></td></tr></table></figure></div><p>例如</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink cancel -s \</span><br><span class="line">hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints d5fdaff43022954f5f02fcd8f25ef855</span><br><span class="line">Cancelling job bc0b2ad61ecd4a615d92ce25390f61ad </span><br><span class="line">with savepoint to hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints.</span><br><span class="line">Cancelled job bc0b2ad61ecd4a615d92ce25390f61ad. </span><br><span class="line">Savepoint stored in hdfs:&#x2F;&#x2F;&#x2F;xxx:50070&#x2F;savepoints&#x2F;savepoint-bc0b2a-d08de07fbb10.</span><br></pre></td></tr></table></figure></div><h2 id="从保存点启动应用程序"><a href="#从保存点启动应用程序" class="headerlink" title="从保存点启动应用程序"></a>从保存点启动应用程序</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink run -s &lt;savepointPath&gt; [options] &lt;jobJar&gt; [arguments]</span><br></pre></td></tr></table></figure></div><h2 id="扩容，改变并行度操作"><a href="#扩容，改变并行度操作" class="headerlink" title="扩容，改变并行度操作"></a>扩容，改变并行度操作</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink modify &lt;jobId&gt; -p &lt;newParallelism&gt;</span><br></pre></td></tr></table></figure></div><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;flink modify bc0b2ad61ecd4a615d92ce25390f61ad -p 16</span><br><span class="line">Modify job bc0b2ad61ecd4a615d92ce25390f61ad.</span><br><span class="line">Rescaled job bc0b2ad61ecd4a615d92ce25390f61ad. Its new parallelism is 16.</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第九章，搭建Flink运行流式应用&quot;&gt;&lt;a href=&quot;#第九章，搭建Flink运行流式应用&quot; class=&quot;headerlink&quot; title=&quot;第九章，搭建Flink运行流式应用&quot;&gt;&lt;/a&gt;第九章，搭建Flink运行流式应用&lt;/h1&gt;&lt;h2 id=&quot;部署方式&quot;
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列08读写外部系统</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9708%E8%AF%BB%E5%86%99%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-07-02T03:48:50.000Z</published>
    <updated>2020-07-02T03:49:41.161Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第八章，读写外部系统"><a href="#第八章，读写外部系统" class="headerlink" title="第八章，读写外部系统"></a>第八章，读写外部系统</h1><p>数据可以存储在不同的系统中，例如：文件系统，对象存储系统（OSS），关系型数据库，Key-Value存储，搜索引擎索引，日志系统，消息队列，等等。每一种系统都是给特定的应用场景设计的，在某一个特定的目标上超越了其他系统。今天的数据架构，往往包含着很多不同的存储系统。在将一个组件加入到我们的系统中时，我们需要问一个问题：“这个组件和架构中的其他组件能多好的一起工作？”</p><p>添加一个像Flink这样的数据处理系统，需要仔细的考虑。因为Flink没有自己的存储层，而是读取数据和持久化数据都需要依赖外部存储。所以，对于Flink，针对外部系统提供良好的读取和写入的连接器就很重要了。尽管如此，仅仅能够读写外部系统对于Flink这样想要提供任务故障情况下一致性保证的流处理器来讲，是不够的。</p><p>在本章中，我们将会讨论source和sink的连接器。这些连接器影响了Flink的一致性保证，也提供了对于最流行的一些外部系统的读写的连接器。我们还将学习如何实现自定义source和sink连接器，以及如何实现可以向外部系统发送异步读写请求的函数。</p><h2 id="应用的一致性保证"><a href="#应用的一致性保证" class="headerlink" title="应用的一致性保证"></a>应用的一致性保证</h2><p>Flink的检查点和恢复机制定期的会保存应用程序状态的一致性检查点。在故障的情况下，应用程序的状态将会从最近一次完成的检查点恢复，并继续处理。尽管如此，可以使用检查点来重置应用程序的状态无法完全达到令人满意的一致性保证。相反，source和sink的连接器需要和Flink的检查点和恢复机制进行集成才能提供有意义的一致性保证。</p><p>为了给应用程序提供恰好处理一次语义的状态一致性保证，应用程序的source连接器需要能够将source的读位置重置到之前保存的检查点位置。当处理一次检查点时，source操作符将会把source的读位置持久化，并在恢复的时候从这些读位置开始重新读取。支持读位置的检查点的source连接器一般来说是基于文件的存储系统，如：文件流或者Kafka source（检查点会持久化某个正在消费的topic的读偏移量）。如果一个应用程序从一个无法存储和重置读位置的source连接器摄入数据，那么当任务出现故障的时候，数据就会丢失。也就是说我们只能提供at-most-once）的一致性保证。</p><p>Fink的检查点和恢复机制和可以重置读位置的source连接器结合使用，可以保证应用程序不会丢失任何数据。尽管如此，应用程序可能会发出两次计算结果，因为从上一次检查点恢复的应用程序所计算的结果将会被重新发送一次（一些结果已经发送出去了，这时任务故障，然后从上一次检查点恢复，这些结果将被重新计算一次然后发送出去）。所以，可重置读位置的source和Flink的恢复机制不足以提供端到端的恰好处理一次语义，即使应用程序的状态是恰好处理一次一致性级别。</p><p>一个志在提供端到端恰好处理一次语义一致性的应用程序需要特殊的sink连接器。sink连接器可以在不同的情况下使用两种技术来达到恰好处理一次一致性语义：幂等性写入和事务性写入。</p><h3 id="幂等性写入"><a href="#幂等性写入" class="headerlink" title="幂等性写入"></a>幂等性写入</h3><p>一个幂等操作无论执行多少次都会返回同样的结果。例如，重复的向hashmap中插入同样的key-value对就是幂等操作，因为头一次插入操作之后所有的插入操作都不会改变这个hashmap，因为hashmap已经包含这个key-value对了。另一方面，append操作就不是幂等操作了，因为多次append同一个元素将会导致列表每次都会添加一个元素。在流处理程序中，幂等写入操作是很有意思的，因为幂等写入操作可以执行多次但不改变结果。所以它们可以在某种程度上缓和Flink检查点机制带来的重播计算结果的效应。</p><p>需要注意的是，依赖于幂等性sink来达到exactly-once语义的应用程序，必须保证在从检查点恢复以后，它将会覆盖之前已经写入的结果。例如，一个包含有sink操作的应用在sink到一个key-value存储时必须保证它能够确定的计算出将要更新的key值。同时，从Flink程序sink到的key-value存储中读取数据的应用，在Flink从检查点恢复的过程中，可能会看到不想看到的结果。当重播开始时，之前已经发出的计算结果可能会被更早的结果所覆盖（因为在恢复过程中）。所以，一个消费Flink程序输出数据的应用，可能会观察到时间回退，例如读到了比之前小的计数。也就是说，当流处理程序处于恢复过程中时，流处理程序的结果将处于不稳定的状态，因为一些结果被覆盖掉，而另一些结果还没有被覆盖。一旦重播完成，也就是说应用程序已经通过了之前出故障的点，结果将会继续保持一致性。</p><h3 id="事务性写入"><a href="#事务性写入" class="headerlink" title="事务性写入"></a>事务性写入</h3><p>第二种实现端到端的恰好处理一次一致性语义的方法基于事务性写入。其思想是只将最近一次成功保存的检查点之前的计算结果写入到外部系统中去。这样就保证了在任务故障的情况下，端到端恰好处理一次语义。应用将被重置到最近一次的检查点，而在这个检查点之后并没有向外部系统发出任何计算结果。通过只有当检查点保存完成以后再写入数据这种方法，事务性的方法将不会遭受幂等性写入所遭受的重播不一致的问题。尽管如此，事务性写入却带来了延迟，因为只有在检查点完成以后，我们才能看到计算结果。</p><p>Flink提供了两种构建模块来实现事务性sink连接器：write-ahead-log（WAL，预写式日志）sink和两阶段提交sink。WAL式sink将会把所有计算结果写入到应用程序的状态中，等接到检查点完成的通知，才会将计算结果发送到sink系统。因为sink操作会把数据都缓存在状态后段，所以WAL可以使用在任何外部sink系统上。尽管如此，WAL还是无法提供刀枪不入的恰好处理一次语义的保证，再加上由于要缓存数据带来的状态后段的状态大小的问题，WAL模型并不十分完美。</p><p>与之形成对比的，2PC sink需要sink系统提供事务的支持或者可以模拟出事务特性的模块。对于每一个检查点，sink开始一个事务，然后将所有的接收到的数据都添加到事务中，并将这些数据写入到sink系统，但并没有提交（commit）它们。当事务接收到检查点完成的通知时，事务将被commit，数据将被真正的写入sink系统。这项机制主要依赖于一次sink可以在检查点完成之前开始事务，并在应用程序从一次故障中恢复以后再commit的能力。</p><p>2PC协议依赖于Flink的检查点机制。检查点屏障是开始一个新的事务的通知，所有操作符自己的检查点成功的通知是它们可以commit的投票，而JobManager通知一个检查点成功的消息是commit事务的指令。于WAL sink形成对比的是，2PC sinks依赖于sink系统和sink本身的实现可以实现恰好处理一次语义。更多的，2PC sink不断的将数据写入到sink系统中，而WAL写模型就会有之前所述的问题。</p><table><thead><tr><th></th><th>不可重置的源</th><th>可重置的源</th></tr></thead><tbody><tr><td>any sink</td><td>at-most-once</td><td>at-least-once</td></tr><tr><td>幂等性sink</td><td>at-most-once</td><td>exactly-once（当从任务失败中恢复时，存在暂时的不一致性）</td></tr><tr><td>预写式日志sink</td><td>at-most-once</td><td>at-least-once</td></tr><tr><td>2PC sink</td><td>at-most-once</td><td>exactly-once</td></tr></tbody></table><h2 id="Flink提供的连接器"><a href="#Flink提供的连接器" class="headerlink" title="Flink提供的连接器"></a>Flink提供的连接器</h2><p>Flink提供了读写很多存储系统的连接器。消息队列，日志系统，例如Apache Kafka, Kinesis, RabbitMQ等等这些是常用的数据源。在批处理环境中，数据流很可能是监听一个文件系统，而当新的数据落盘的时候，读取这些新数据。</p><p>在sink一端，数据流经常写入到消息队列中，以供接下来的流处理程序消费。数据流也可能写入到文件系统中做持久化，或者交给批处理程序来进行分析。数据流还可能被写入到key-value存储或者关系型数据库中，例如Cassandra，ElasticSearch或者MySQL中，这样数据可供查询，还可以在仪表盘中显示出来。</p><p>不幸的是，对于大多数存储系统并没有标准接口，除了针对DBMS的JDBC。相反，每一个存储系统都需要有自己的特定的连接器。所以，Flink需要维护针对不同存储系统（消息队列，日志系统，文件系统，k-v数据库，关系型数据库等等）的连接器实现。</p><p>Flink提供了针对Apache Kafka, Kinesis, RabbitMQ, Apache Nifi, 各种文件系统，Cassandra, Elasticsearch, 还有JDBC的连接器。除此之外，Apache Bahir项目还提供了额外的针对例如ActiveMQ, Akka, Flume, Netty, 和Redis等的连接器。</p><h3 id="Apache-Kafka-Source连接器"><a href="#Apache-Kafka-Source连接器" class="headerlink" title="Apache Kafka Source连接器"></a>Apache Kafka Source连接器</h3><p>Apache Kafka是一个分布式流式平台。它的核心是一个分布式的发布订阅消息系统。</p><p>Kafka将事件流组织为所谓的topics。一个主题就是一个事件日志系统，Kafka可以保证主题中的数据在被读取时和这些数据在被写入时相同的顺序。为了扩大读写的规模，主题可以分裂为多个分区，这些分区分布在一个集群上面。这时，读写顺序的保证就限制到了分区这个粒度， Kafka并没有提供从不同分区读取数据时的顺序保证。Kafka分区的读位置称为偏移量（offset）。</p><p>Kafka的依赖引入如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>Flink Kafka连接器并行的摄入事件流。每一个并行source任务可以从一个或者多个分区中读取数据。任务将会跟踪每一个分区当前的读偏移量，然后将读偏移量写入到检查点数据中。当从任务故障恢复时，读偏移量将被恢复，而source任务将从检查点保存的读偏移量开始重新读取数据。Flink Kafka连接器并不依赖Kafka自己的offset-tracking机制（基于消费者组实现）。下图展示了分区如何分配给source实例。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0801.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0801.png" class="lazyload"></a></p><p>Kafka source连接器使用如下代码创建</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">properties.setProperty(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"test"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.addSource(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](</span><br><span class="line">    <span class="string">"topic"</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),</span><br><span class="line">    properties))</span><br></pre></td></tr></table></figure></div><p>构造器接受三个参数。第一个参数定义了从哪些topic中读取数据，可以是一个topic，也可以是topic列表，还可以是匹配所有想要读取的topic的正则表达式。当从多个topic中读取数据时，Kafka连接器将会处理所有topic的分区，将这些分区的数据放到一条流中去。</p><p>第二个参数是一个DeserializationSchema或者KeyedDeserializationSchema。Kafka消息被存储为原始的字节数据，所以需要反序列化成Java或者Scala对象。上例中使用的SimpleStringSchema，是一个内置的DeserializationSchema，它仅仅是简单的将字节数组反序列化成字符串。DeserializationSchema和KeyedDeserializationSchema是公共的接口，所以我们可以自定义反序列化逻辑。</p><p>第三个参数是一个Properties对象，设置了用来读写的Kafka客户端的一些属性。</p><p>为了抽取事件时间的时间戳然后产生水印，我们可以通过调用</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">FlinkKafkaConsumer</span>.assignTimestampsAndWatermark()</span><br></pre></td></tr></table></figure></div><p>方法为Kafka消费者提供AssignerWithPeriodicWatermark或者AssignerWithPucntuatedWatermark。每一个assigner都将被应用到每个分区，来利用每一个分区的顺序保证特性。source实例将会根据水印的传播协议聚合所有分区的水印。</p><h3 id="Apache-Kafka-Sink连接器"><a href="#Apache-Kafka-Sink连接器" class="headerlink" title="Apache Kafka Sink连接器"></a>Apache Kafka Sink连接器</h3><p>添加依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>下面的例子展示了如何创建一个Kafka sink</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> myProducer = <span class="keyword">new</span> <span class="type">FlinkKafkaProducer</span>[<span class="type">String</span>](</span><br><span class="line">  <span class="string">"localhost:9092"</span>,         <span class="comment">// broker list</span></span><br><span class="line">  <span class="string">"topic"</span>,                  <span class="comment">// target topic</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>)   <span class="comment">// serialization schema</span></span><br><span class="line"></span><br><span class="line">stream.addSink(myProducer)</span><br></pre></td></tr></table></figure></div><h3 id="Kakfa-Sink的at-least-once保证"><a href="#Kakfa-Sink的at-least-once保证" class="headerlink" title="Kakfa Sink的at-least-once保证"></a>Kakfa Sink的at-least-once保证</h3><p>Flink的Kafka sink提供了基于配置的一致性保证。Kafka sink使用下面的条件提供了至少处理一次保证：</p><ul><li>Flink检查点机制开启，所有的数据源都是可重置的。</li><li>当写入失败时，sink连接器将会抛出异常，使得应用程序挂掉然后重启。这是默认行为。应用程序内部的Kafka客户端还可以配置为重试写入，只要提前声明当写入失败时，重试几次这样的属性（retries property）。</li><li>sink连接器在完成它的检查点之前会等待Kafka发送已经将数据写入的通知。</li></ul><h3 id="Kafka-Sink的恰好处理一次语义保证"><a href="#Kafka-Sink的恰好处理一次语义保证" class="headerlink" title="Kafka Sink的恰好处理一次语义保证"></a>Kafka Sink的恰好处理一次语义保证</h3><p>Kafka 0.11版本引入了事务写特性。由于这个新特性，Flink Kafka sink可以为输出结果提供恰好处理一次语义的一致性保证，只要经过合适的配置就行。Flink程序必须开启检查点机制，并从可重置的数据源进行消费。FlinkKafkaProducer还提供了包含Semantic参数的构造器来控制sink提供的一致性保证。可能的取值如下：</p><ul><li>Semantic.NONE，不提供任何一致性保证。数据可能丢失或者被重写多次。</li><li>Semantic.AT_LEAST_ONCE，保证无数据丢失，但可能被处理多次。这个是默认设置。</li><li>Semantic.EXACTLY_ONCE，基于Kafka的事务性写入特性实现，保证每条数据恰好处理一次。</li></ul><h3 id="文件系统source连接器"><a href="#文件系统source连接器" class="headerlink" title="文件系统source连接器"></a>文件系统source连接器</h3><p>Apache Flink针对文件系统实现了一个可重置的source连接器，将文件看作流来读取数据。如下面的例子所示：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lineReader = <span class="keyword">new</span> <span class="type">TextInputFormat</span>(<span class="literal">null</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lineStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readFile[<span class="type">String</span>](</span><br><span class="line">  lineReader,                 <span class="comment">// The FileInputFormat</span></span><br><span class="line">  <span class="string">"hdfs:///path/to/my/data"</span>,  <span class="comment">// The path to read</span></span><br><span class="line">  <span class="type">FileProcessingMode</span></span><br><span class="line">    .<span class="type">PROCESS_CONTINUOUSLY</span>,    <span class="comment">// The processing mode</span></span><br><span class="line">  <span class="number">30000</span>L)                     <span class="comment">// The monitoring interval in ms</span></span><br></pre></td></tr></table></figure></div><p>StreamExecutionEnvironment.readFile()接收如下参数：</p><ul><li>FileInputFormat参数，负责读取文件中的内容。</li><li>文件路径。如果文件路径指向单个文件，那么将会读取这个文件。如果路径指向一个文件夹，FileInputFormat将会扫描文件夹中所有的文件。</li><li>PROCESS_CONTINUOUSLY将会周期性的扫描文件，以便扫描到文件新的改变。</li><li>30000L表示多久扫描一次监听的文件。</li></ul><p>FileInputFormat是一个特定的InputFormat，用来从文件系统中读取文件。FileInputFormat分两步读取文件。首先扫描文件系统的路径，然后为所有匹配到的文件创建所谓的input splits。一个input split将会定义文件上的一个范围，一般通过读取的开始偏移量和读取长度来定义。在将一个大的文件分割成一堆小的splits以后，这些splits可以分发到不同的读任务，这样就可以并行的读取文件了。FileInputFormat的第二步会接收一个input split，读取被split定义的文件范围，然后返回对应的数据。</p><p>DataStream应用中使用的FileInputFormat需要实现CheckpointableInputFormat接口。这个接口定义了方法来做检查点和重置文件片段的当前的读取位置。</p><p>在Flink 1.7中，Flink提供了一些类，这些类继承了FileInputFormat，并实现了CheckpointableInputFormat接口。TextInputFormat一行一行的读取文件，而CsvInputFormat使用逗号分隔符来读取文件。</p><h3 id="文件系统sink连接器"><a href="#文件系统sink连接器" class="headerlink" title="文件系统sink连接器"></a>文件系统sink连接器</h3><p>在将流处理应用配置成exactly-once检查点机制，以及配置成所有源数据都能在故障的情况下可以重置，Flink的StreamingFileSink提供了端到端的恰好处理一次语义保证。下面的例子展示了StreamingFileSink的使用方式。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[<span class="type">String</span>] = …</span><br><span class="line"><span class="keyword">val</span> sink: <span class="type">StreamingFileSink</span>[<span class="type">String</span>] = <span class="type">StreamingFileSink</span></span><br><span class="line">  .forRowFormat(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Path</span>(<span class="string">"/base/path"</span>), </span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringEncoder</span>[<span class="type">String</span>](<span class="string">"UTF-8"</span>))</span><br><span class="line">  .build()</span><br><span class="line"></span><br><span class="line">input.addSink(sink)</span><br></pre></td></tr></table></figure></div><p>当StreamingFileSink接到一条数据，这条数据将被分配到一个桶（bucket）中。一个桶是我们配置的“/base/path”的子目录。</p><p>Flink使用BucketAssigner来分配桶。BucketAssigner是一个公共的接口，为每一条数据返回一个BucketId，BucketId决定了数据被分配到哪个子目录。如果没有指定BucketAssigner，Flink将使用DateTimeBucketAssigner来将每条数据分配到每个一个小时所产生的桶中去，基于数据写入的处理时间（机器时间，墙上时钟）。</p><p>StreamingFileSink提供了exactly-once输出的保证。sink通过一个commit协议来达到恰好处理一次语义的保证。这个commit协议会将文件移动到不同的阶段，有以下状态：in progress，pending，finished。这个协议基于Flink的检查点机制。当Flink决定roll a file时，这个文件将被关闭并移动到pending状态，通过重命名文件来实现。当下一个检查点完成时，pending文件将被移动到finished状态，同样是通过重命名来实现。</p><p>一旦任务故障，sink任务需要将处于in progress状态的文件重置到上一次检查点的写偏移量。这个可以通过关闭当前in progress的文件，并将文件结尾无效的部分丢弃掉来实现。</p><h2 id="实现自定义源函数"><a href="#实现自定义源函数" class="headerlink" title="实现自定义源函数"></a>实现自定义源函数</h2><p>DataStream API提供了两个接口来实现source连接器：</p><ul><li>SourceFunction和RichSourceFunction可以用来定义非并行的source连接器，source跑在单任务上。</li><li>ParallelSourceFunction和RichParallelSourceFunction可以用来定义跑在并行实例上的source连接器。</li></ul><p>除了并行于非并行的区别，这两种接口完全一样。就像process function的rich版本一样，RichSourceFunction和RichParallelSourceFunction的子类可以override open()和close()方法，也可以访问RuntimeContext，RuntimeContext提供了并行任务实例的数量，当前任务实例的索引，以及一些其他信息。</p><p>SourceFunction和ParallelSourceFunction定义了两种方法：</p><ul><li>void run(SourceContext ctx)</li><li>cancel()</li></ul><p>run()方法用来读取或者接收数据然后将数据摄入到Flink应用中。根据接收数据的系统，数据可能是推送的也可能是拉取的。Flink仅仅在特定的线程调用run()方法一次，通常情况下会是一个无限循环来读取或者接收数据并发送数据。任务可以在某个时间点被显式的取消，或者由于流是有限流，当数据被消费完毕时，任务也会停止。</p><p>当应用被取消或者关闭时，cancel()方法会被Flink调用。为了优雅的关闭Flink应用，run()方法需要在cancel()被调用以后，立即终止执行。下面的例子显示了一个简单的源函数的例子：从0数到Long.MaxValue。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountSource</span> <span class="keyword">extends</span> <span class="title">SourceFunction</span>[<span class="type">Long</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> isRunning: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">Long</span>]) = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> cnt: <span class="type">Long</span> = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning &amp;&amp; cnt &lt; <span class="type">Long</span>.<span class="type">MaxValue</span>) &#123;</span><br><span class="line">      cnt += <span class="number">1</span></span><br><span class="line">      ctx.collect(cnt)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>() = isRunning = <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="可重置的源函数"><a href="#可重置的源函数" class="headerlink" title="可重置的源函数"></a>可重置的源函数</h3><p>之前我们讲过，应用程序只有使用可以重播输出数据的数据源时，才能提供令人满意的一致性保证。如果外部系统暴露了获取和重置读偏移量的API，那么source函数就可以重播源数据。这样的例子包括一些能够提供文件流的偏移量的文件系统，或者提供seek方法用来移动到文件的特定位置的文件系统。或者Apache Kafka这种可以为每一个主题的分区提供偏移量并且可以设置分区的读位置的系统。一个反例就是source连接器连接的是socket，socket将会立即丢弃已经发送过的数据。</p><p>支持重播输出的源函数需要和Flink的检查点机制集成起来，还需要在检查点被处理时，持久化当前所有的读取位置。当应用从一个保存点（savepoint）恢复或者从故障恢复时，Flink会从最近一次的检查点或者保存点中获取读偏移量。如果程序开始时并不存在状态，那么读偏移量将会被设置到一个默认值。一个可重置的源函数需要实现CheckpointedFunction接口，还需要能够存储读偏移量和相关的元数据，例如文件的路径，分区的ID。这些数据将被保存在list state或者union list state中。</p><p>下面的例子将CountSource重写为可重置的数据源。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResettableCountSource</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">SourceFunction</span>[<span class="type">Long</span>] <span class="keyword">with</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> isRunning: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">var</span> cnt: <span class="type">Long</span> = _</span><br><span class="line">  <span class="keyword">var</span> offsetState: <span class="type">ListState</span>[<span class="type">Long</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">Long</span>]) = &#123;</span><br><span class="line">    <span class="keyword">while</span> (isRunning &amp;&amp; cnt &lt; <span class="type">Long</span>.<span class="type">MaxValue</span>) &#123;</span><br><span class="line">      <span class="comment">// synchronize data emission and checkpoints</span></span><br><span class="line">      ctx.getCheckpointLock.synchronized &#123;</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        ctx.collect(cnt)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>() = isRunning = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">snapshotState</span></span>(</span><br><span class="line">    snapshotCtx: <span class="type">FunctionSnapshotContext</span></span><br><span class="line">  ): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// remove previous cnt</span></span><br><span class="line">    offsetState.clear()</span><br><span class="line">    <span class="comment">// add current cnt</span></span><br><span class="line">    offsetState.add(cnt)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeState</span></span>(</span><br><span class="line">      initCtx: <span class="type">FunctionInitializationContext</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">val</span> desc = <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[<span class="type">Long</span>](</span><br><span class="line">      <span class="string">"offset"</span>, classOf[<span class="type">Long</span>])</span><br><span class="line">    offsetState = initCtx</span><br><span class="line">      .getOperatorStateStore</span><br><span class="line">      .getListState(desc)</span><br><span class="line">    <span class="comment">// initialize cnt variable</span></span><br><span class="line">    <span class="keyword">val</span> it = offsetState.get()</span><br><span class="line">    cnt = <span class="keyword">if</span> (<span class="literal">null</span> == it || !it.iterator().hasNext) &#123;</span><br><span class="line">      <span class="number">-1</span>L</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      it.iterator().next()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="实现自定义sink函数"><a href="#实现自定义sink函数" class="headerlink" title="实现自定义sink函数"></a>实现自定义sink函数</h2><p>DataStream API中，任何运算符或者函数都可以向外部系统发送数据。DataStream不需要最终流向sink运算符。例如，我们可能实现了一个FlatMapFunction，这个函数将每一个接收到的数据通过HTTP POST请求发送出去，而不使用Collector发送到下一个运算符。DataStream API也提供了SinkFunction接口以及对应的rich版本RichSinkFunction抽象类。SinkFunction接口提供了一个方法：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void invode(<span class="type">IN</span> value, <span class="type">Context</span> ctx)</span><br></pre></td></tr></table></figure></div><p>SinkFunction的Context可以访问当前处理时间，当前水位线，以及数据的时间戳。</p><p>下面的例子展示了一个简单的SinkFunction，可以将传感器读数写入到socket中去。需要注意的是，我们需要在启动Flink程序前启动一个监听相关端口的进程。否则将会抛出ConnectException异常。可以运行“nc -l localhost 9191”命令。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to a socket</span></span><br><span class="line">readings.addSink(<span class="keyword">new</span> <span class="type">SimpleSocketSink</span>(<span class="string">"localhost"</span>, <span class="number">9191</span>))</span><br><span class="line">  <span class="comment">// set parallelism to 1 because only one thread can write to a socket</span></span><br><span class="line">  .setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// -----</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleSocketSink</span>(<span class="params">val host: <span class="type">String</span>, val port: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> socket: <span class="type">Socket</span> = _</span><br><span class="line">  <span class="keyword">var</span> writer: <span class="type">PrintStream</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(config: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// open socket and writer</span></span><br><span class="line">    socket = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="type">InetAddress</span>.getByName(host), port)</span><br><span class="line">    writer = <span class="keyword">new</span> <span class="type">PrintStream</span>(socket.getOutputStream)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(</span><br><span class="line">      value: <span class="type">SensorReading</span>,</span><br><span class="line">      ctx: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// write sensor reading to socket</span></span><br><span class="line">    writer.println(value.toString)</span><br><span class="line">    writer.flush()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// close writer and socket</span></span><br><span class="line">    writer.close()</span><br><span class="line">    socket.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>之前我们讨论过，端到端的一致性保证建立在sink连接器的属性上面。为了达到端到端的恰好处理一次语义的目的，应用程序需要幂等性的sink连接器或者事务性的sink连接器。上面例子中的SinkFunction既不是幂等写入也不是事务性的写入。由于socket具有只能添加（append-only）这样的属性，所以不可能实现幂等性的写入。又因为socket不具备内置的事务支持，所以事务性写入就只能使用Flink的WAL sink特性来实现了。接下来我们将学习如何实现幂等sink连接器和事务sink连接器。</p><h3 id="幂等sink连接器"><a href="#幂等sink连接器" class="headerlink" title="幂等sink连接器"></a>幂等sink连接器</h3><p>对于大多数应用，SinkFunction接口足以实现一个幂等性写入的sink连接器了。需要以下两个条件：</p><ul><li>结果数据必须具有确定性的key，在这个key上面幂等性更新才能实现。例如一个计算每分钟每个传感器的平均温度值的程序，确定性的key值可以是传感器的ID和每分钟的时间戳。确定性的key值，对于在故障恢复的场景下，能够正确的覆盖结果非常的重要。</li><li>外部系统支持针对每个key的更新，例如关系型数据库或者key-value存储。</li></ul><p>下面的例子展示了如何实现一个针对JDBC数据库的幂等写入sink连接器，这里使用的是Apache Derby数据库。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to a Derby table</span></span><br><span class="line">readings.addSink(<span class="keyword">new</span> <span class="type">DerbyUpsertSink</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// -----</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DerbyUpsertSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> conn: <span class="type">Connection</span> = _</span><br><span class="line">  <span class="keyword">var</span> insertStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="keyword">var</span> updateStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// connect to embedded in-memory Derby</span></span><br><span class="line">    conn = <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">       <span class="string">"jdbc:derby:memory:flinkExample"</span>,</span><br><span class="line">       <span class="keyword">new</span> <span class="type">Properties</span>())</span><br><span class="line">    <span class="comment">// prepare insert and update statements</span></span><br><span class="line">    insertStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"INSERT INTO Temperatures (sensor, temp) VALUES (?, ?)"</span>)</span><br><span class="line">    updateStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"UPDATE Temperatures SET temp = ? WHERE sensor = ?"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(r: <span class="type">SensorReading</span>, context: <span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// set parameters for update statement and execute it</span></span><br><span class="line">    updateStmt.setDouble(<span class="number">1</span>, r.temperature)</span><br><span class="line">    updateStmt.setString(<span class="number">2</span>, r.id)</span><br><span class="line">    updateStmt.execute()</span><br><span class="line">    <span class="comment">// execute insert statement</span></span><br><span class="line">    <span class="comment">// if update statement did not update any row</span></span><br><span class="line">    <span class="keyword">if</span> (updateStmt.getUpdateCount == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// set parameters for insert statement</span></span><br><span class="line">      insertStmt.setString(<span class="number">1</span>, r.id)</span><br><span class="line">      insertStmt.setDouble(<span class="number">2</span>, r.temperature)</span><br><span class="line">      <span class="comment">// execute insert statement</span></span><br><span class="line">      insertStmt.execute()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    insertStmt.close()</span><br><span class="line">    updateStmt.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>由于Apache Derby并没有提供内置的UPSERT方法，所以这个sink连接器实现了UPSERT写。具体实现方法是首先去尝试更新一行数据，如果这行数据不存在，则插入新的一行数据。</p><h3 id="事务性sink连接器"><a href="#事务性sink连接器" class="headerlink" title="事务性sink连接器"></a>事务性sink连接器</h3><p>事务写入sink连接器需要和Flink的检查点机制集成，因为只有在检查点成功完成以后，事务写入sink连接器才会向外部系统commit数据。</p><p>为了简化事务性sink的实现，Flink提供了两个模版用来实现自定义sink运算符。这两个模版都实现了CheckpointListener接口。CheckpointListener接口将会从JobManager接收到检查点完成的通知。</p><ul><li>GenericWriteAheadSink模版会收集检查点之前的所有的数据，并将数据存储到sink任务的运算符状态中。状态保存到了检查点中，并在任务故障的情况下恢复。当任务接收到检查点完成的通知时，任务会将所有的数据写入到外部系统中。</li><li>TwoPhaseCommitSinkFunction模版利用了外部系统的事务特性。对于每一个检查点，任务首先开始一个新的事务，并将接下来所有的数据都写到外部系统的当前事务上下文中去。当任务接收到检查点完成的通知时，sink连接器将会commit这个事务。</li></ul><p><em>GENERICWRITEAHEADSINK</em></p><p>GenericWriteAheadSink使得sink运算符可以很方便的实现。这个运算符和Flink的检查点机制集成使用，目标是将每一条数据恰好一次写入到外部系统中去。需要注意的是，在发生故障的情况下，write-ahead log sink可能会不止一次的发送相同的数据。所以GenericWriteAheadSink无法提供完美无缺的恰好处理一次语义的一致性保证，而是仅能提供at-least-once这样的保证。我们接下来详细的讨论这些场景。</p><p>GenericWriteAheadSink的原理是将接收到的所有数据都追加到有检查点分割好的预写式日志中去。每当sink运算符碰到检查点屏障，运算符将会开辟一个新的section，并将接下来的所有数据都追加到新的section中去。WAL（预写式日志）将会保存到运算符状态中。由于log能被恢复，所有不会有数据丢失。</p><p>当GenericWriteAheadSink接收到检查点完成的通知时，将会发送对应检查点的WAL中存储的所有数据。当所有数据发送成功，对应的检查点必须在内部提交。</p><p>检查点的提交分两步。第一步，sink持久化检查点被提交的信息。第二步，删除WAL中所有的数据。我们不能将commit信息保存在Flink应用程序状态中，因为状态不是持久化的，会在故障恢复时重置状态。相反，GenericWriteAheadSink依赖于可插拔的组件在一个外部持久化存储中存储和查找提交信息。这个组件就是CheckpointCommitter。</p><p>继承GenericWriteAheadSink的运算符需要提供三个构造器函数。</p><ul><li>CheckpointCommitter</li><li>TypeSerializer，用来序列化输入数据。</li><li>一个job ID，传给CheckpointCommitter，当应用重启时可以识别commit信息。</li></ul><p>还有，write-ahead运算符需要实现一个单独的方法：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean sendValues(<span class="type">Iterable</span>&lt;<span class="type">IN</span>&gt; values, long chkpntId, long timestamp)</span><br></pre></td></tr></table></figure></div><p>当检查点完成时，GenericWriteAheadSink调用sendValues()方法来将数据写入到外部存储系统中。这个方法接收一个检查点对应的所有数据的迭代器，检查点的ID，检查点被处理时的时间戳。当数据写入成功时，方法必须返回true，写入失败返回false。</p><p>下面的例子展示了如何实现一个写入到标准输出的write-ahead sink。它使用了FileCheckpointCommitter。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ???</span><br><span class="line"></span><br><span class="line"><span class="comment">// write the sensor readings to the standard out via a write-ahead log</span></span><br><span class="line">readings.transform(</span><br><span class="line">  <span class="string">"WriteAheadSink"</span>, <span class="keyword">new</span> <span class="type">SocketWriteAheadSink</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ```-</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StdOutWriteAheadSink</span> <span class="keyword">extends</span> <span class="title">GenericWriteAheadSink</span>[<span class="type">SensorReading</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    // <span class="type">CheckpointCommitter</span> that commits</span></span></span><br><span class="line"><span class="class"><span class="params">    // checkpoints to the local filesystem</span></span></span><br><span class="line"><span class="class"><span class="params">    new <span class="type">FileCheckpointCommitter</span>(<span class="type">System</span>.getProperty("java.io.tmpdir"</span>)),</span></span><br><span class="line"><span class="class">    <span class="title">//</span> <span class="title">Serializer</span> <span class="title">for</span> <span class="title">records</span></span></span><br><span class="line"><span class="class">    <span class="title">createTypeInformation</span>[<span class="type">SensorReading</span>]</span></span><br><span class="line"><span class="class">      .<span class="title">createSerializer</span>(<span class="params">new <span class="type">ExecutionConfig</span></span>),</span></span><br><span class="line"><span class="class">    <span class="title">//</span> <span class="title">Random</span> <span class="title">JobID</span> <span class="title">used</span> <span class="title">by</span> <span class="title">the</span> <span class="title">CheckpointCommitter</span></span></span><br><span class="line"><span class="class">    <span class="title">UUID</span>.<span class="title">randomUUID</span>.<span class="title">toString</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">sendValues</span></span>(</span><br><span class="line">      readings: <span class="type">Iterable</span>[<span class="type">SensorReading</span>],</span><br><span class="line">      checkpointId: <span class="type">Long</span>,</span><br><span class="line">      timestamp: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (r &lt;- readings.asScala) &#123;</span><br><span class="line">      <span class="comment">// write record to standard out</span></span><br><span class="line">      println(r)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>之前我们讲过，GenericWriteAheadSink无法提供完美的exactly-once保证。有两个故障状况会导致数据可能被发送不止一次。</p><ul><li>当任务执行sendValues()方法时，程序挂掉了。如果外部系统无法原子性的写入所有数据（要么都写入要么都不写），一些数据可能会写入，而另一些数据并没有被写入。由于checkpoint还没有commit，所以在任务恢复的过程中一些数据可能会被再次写入。</li><li>所有数据都写入成功了，sendValues()方法也返回true了；但在CheckpointCommitter方法被调用之前程序挂了，或者CheckpointCommitter在commit检查点时失败了。那么在恢复的过程中，所有未被提交的检查点将会被重新写入。</li></ul><p><em>TWOPHASECOMMITSINKFUNCTION</em></p><p>Flink提供了TwoPhaseCommitSinkFunction接口来简化sink函数的实现。这个接口保证了端到端的exactly-once语义。2PC sink函数是否提供这样的一致性保证取决于我们的实现细节。我们需要讨论一个问题：“2PC协议是否开销太大？”</p><p>通常来讲，为了保证分布式系统的一致性，2PC是一个非常昂贵的方法。尽管如此，在Flink的语境下，2PC协议针对每一个检查点只运行一次。TwoPhaseCommitSinkFunction和WAL sink很相似，不同点在于前者不会将数据收集到state中，而是会写入到外部系统事务的上下文中。</p><p>TwoPhaseCommitSinkFunction实现了以下协议。在sink任务发送出第一条数据之前，任务将在外部系统中开始一个事务，所有接下来的数据将被写入这个事务的上下文中。当JobManager初始化检查点并将检查点屏障插入到流中的时候，2PC协议的投票阶段开始。当运算符接收到检查点屏障，运算符将保存它的状态，当保存完成时，运算符将发送一个acknowledgement信息给JobManager。当sink任务接收到检查点屏障时，运算符将会持久化它的状态，并准备提交当前的事务，以及acknowledge JobManager中的检查点。发送给JobManager的acknowledgement信息类似于2PC协议中的commit投票。sink任务还不能提交事务，因为它还没有保证所有的任务都已经完成了它们的检查点操作。sink任务也会为下一个检查点屏障之前的所有数据开始一个新的事务。</p><p>当JobManager成功接收到所有任务实例发出的检查点操作成功的通知时，JobManager将会把检查点完成的通知发送给所有感兴趣的任务。这里的通知对应于2PC协议的提交命令。当sink任务接收到通知时，它将commit所有处于开启状态的事务。一旦sink任务acknowledge了检查点操作，它必须能够commit对应的事务，即使任务发生故障。如果commit失败，数据将会丢失。</p><p>让我们总结一下外部系统需要满足什么样的要求：</p><ul><li>外部系统必须提供事务支持，或者sink的实现能在外部系统上模拟事务功能。</li><li>在检查点操作期间，事务必须处于open状态，并接收这段时间数据的持续写入。</li><li>事务必须等到检查点操作完成的通知到来才可以提交。在恢复周期中，可能需要一段时间等待。如果sink系统关闭了事务（例如超时了），那么未被commit的数据将会丢失。</li><li>sink必须在进程挂掉后能够恢复事务。一些sink系统会提供事务ID，用来commit或者abort一个开始的事务。</li><li>commit一个事务必须是一个幂等性操作。sink系统或者外部系统能够观察到事务已经被提交，或者重复提交并没有副作用。</li></ul><p>下面的例子可能会让上面的一些概念好理解一些。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransactionalFileSink</span>(<span class="params">val targetPath: <span class="type">String</span>, val tempPath: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">TwoPhaseCommitSinkFunction</span>[(<span class="type">String</span>, <span class="type">Double</span>), <span class="type">String</span>, <span class="type">Void</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">      createTypeInformation[<span class="type">String</span>].createSerializer(new <span class="type">ExecutionConfig</span></span>),</span></span><br><span class="line"><span class="class">      <span class="title">createTypeInformation</span>[<span class="type">Void</span>].<span class="title">createSerializer</span>(<span class="params">new <span class="type">ExecutionConfig</span></span>)) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> transactionWriter: <span class="type">BufferedWriter</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Creates a temporary file for a transaction into</span></span><br><span class="line">  <span class="comment">// which the records are written.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">beginTransaction</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="comment">// path of transaction file</span></span><br><span class="line">    <span class="comment">// is built from current time and task index</span></span><br><span class="line">    <span class="keyword">val</span> timeNow = <span class="type">LocalDateTime</span>.now(<span class="type">ZoneId</span>.of(<span class="string">"UTC"</span>))</span><br><span class="line">      .format(<span class="type">DateTimeFormatter</span>.<span class="type">ISO_LOCAL_DATE_TIME</span>)</span><br><span class="line">    <span class="keyword">val</span> taskIdx = <span class="keyword">this</span>.getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line">    <span class="keyword">val</span> transactionFile = <span class="string">s"<span class="subst">$timeNow</span>-<span class="subst">$taskIdx</span>"</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// create transaction file and writer</span></span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transactionFile</span>"</span>)</span><br><span class="line">    <span class="type">Files</span>.createFile(tFilePath)</span><br><span class="line">    <span class="keyword">this</span>.transactionWriter = <span class="type">Files</span>.newBufferedWriter(tFilePath)</span><br><span class="line">    println(<span class="string">s"Creating Transaction File: <span class="subst">$tFilePath</span>"</span>)</span><br><span class="line">    <span class="comment">// name of transaction file is returned to</span></span><br><span class="line">    <span class="comment">// later identify the transaction</span></span><br><span class="line">    transactionFile</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Write record into the current transaction file. */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(</span><br><span class="line">      transaction: <span class="type">String</span>,</span><br><span class="line">      value: (<span class="type">String</span>, <span class="type">Double</span>),</span><br><span class="line">      context: <span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    transactionWriter.write(value.toString)</span><br><span class="line">    transactionWriter.write('\n')</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Flush and close the current transaction file. */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">preCommit</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    transactionWriter.flush()</span><br><span class="line">    transactionWriter.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Commit a transaction by moving</span></span><br><span class="line">  <span class="comment">// the precommitted transaction file</span></span><br><span class="line">  <span class="comment">// to the target directory.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">commit</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">    <span class="comment">// check if the file exists to ensure</span></span><br><span class="line">    <span class="comment">// that the commit is idempotent</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="type">Files</span>.exists(tFilePath)) &#123;</span><br><span class="line">      <span class="keyword">val</span> cFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$targetPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">      <span class="type">Files</span>.move(tFilePath, cFilePath)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Aborts a transaction by deleting the transaction file.</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">abort</span></span>(transaction: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tFilePath = <span class="type">Paths</span>.get(<span class="string">s"<span class="subst">$tempPath</span>/<span class="subst">$transaction</span>"</span>)</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">Files</span>.exists(tFilePath)) &#123;</span><br><span class="line">      <span class="type">Files</span>.delete(tFilePath)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>TwoPhaseCommitSinkFunction[IN, TXN, CONTEXT]包含如下三个范型参数：</p><ul><li>IN表示输入数据的类型。</li><li>TXN定义了一个事务的标识符，可以用来识别和恢复事务。</li><li>CONTEXT定义了自定义的上下文。</li></ul><p>TwoPhaseCommitSinkFunction的构造器需要两个TypeSerializer。一个是TXN的类型，另一个是CONTEXT的类型。</p><p>最后，TwoPhaseCommitSinkFunction定义了五个需要实现的方法：</p><ul><li>beginTransaction(): TXN开始一个事务，并返回事务的标识符。</li><li>invoke(txn: TXN, value: IN, context: Context[_]): Unit将值写入到当前事务中。</li><li>preCommit(txn: TXN): Unit预提交一个事务。一个预提交的事务不会接收新的写入。</li><li>commit(txn: TXN): Unit提交一个事务。这个操作必须是幂等的。</li><li>abort(txn: TXN): Unit终止一个事务。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第八章，读写外部系统&quot;&gt;&lt;a href=&quot;#第八章，读写外部系统&quot; class=&quot;headerlink&quot; title=&quot;第八章，读写外部系统&quot;&gt;&lt;/a&gt;第八章，读写外部系统&lt;/h1&gt;&lt;p&gt;数据可以存储在不同的系统中，例如：文件系统，对象存储系统（OSS），关系型数
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列07有状态算子和应用</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9707%E6%9C%89%E7%8A%B6%E6%80%81%E7%AE%97%E5%AD%90%E5%92%8C%E5%BA%94%E7%94%A8/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9707%E6%9C%89%E7%8A%B6%E6%80%81%E7%AE%97%E5%AD%90%E5%92%8C%E5%BA%94%E7%94%A8/</id>
    <published>2020-07-02T03:47:39.000Z</published>
    <updated>2020-07-02T03:48:27.490Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第七章，有状态算子和应用"><a href="#第七章，有状态算子和应用" class="headerlink" title="第七章，有状态算子和应用"></a>第七章，有状态算子和应用</h1><p>状态操作符和用户自定义函数都是我们在写流处理程序时，常用的工具。事实上，大部分稍微复杂一点的逻辑都需要保存数据或者保存计算结果。很多Flink内置的操作符例如：source操作符，sink操作符等等都是有状态的，也就是说会缓存流数据或者计算结果。例如，窗口操作符将会为ProcessWindowFunction收集输入的数据，或者收集ReduceFunction计算的结果。而ProcessFunction也会保存定时器事件，一些sink方法为了做到exactly-once，会将事务保存下来。除了内置的操作符以及提供的source和sink操作符，Flink的DataStream API还在UDF函数中暴露了可以注册、保存和访问状态的接口。</p><p>本章重点讨论有状态的用户自定义函数的实现，以及讨论有状态应用的性能和健壮性。特别的，我们将解释在用户自定义函数中，如何定义不同类型的状态，以及如何与状态进行交互。我们还讨论了性能方面的问题以及如何控制状态大小的问题。</p><h2 id="实现有状态的用户自定义函数"><a href="#实现有状态的用户自定义函数" class="headerlink" title="实现有状态的用户自定义函数"></a>实现有状态的用户自定义函数</h2><p>我们知道函数有两种状态，键控状态(keyed state)和操作符状态(operator state)。</p><h3 id="在RuntimeContext中定义键控状态-keyed-state"><a href="#在RuntimeContext中定义键控状态-keyed-state" class="headerlink" title="在RuntimeContext中定义键控状态(keyed state)"></a>在RuntimeContext中定义键控状态(keyed state)</h3><p>用户自定义函数可以使用keyed state来存储和访问key对应的状态。对于每一个key，Flink将会维护一个状态实例。一个操作符的状态实例将会被分发到操作符的所有并行任务中去。这表明函数的每一个并行任务只为所有key的某一部分key保存key对应的状态实例。所以keyed state和分布式key-value map数据结构非常类似。</p><p>keyed state仅可用于KeyedStream。Flink支持以下数据类型的状态变量：</p><ul><li>ValueState[T]保存单个的值，值的类型为T。<ul><li>get操作: ValueState.value()</li><li>set操作: ValueState.update(value: T)</li></ul></li><li>ListState[T]保存一个列表，列表里的元素的数据类型为T。基本操作如下：<ul><li>ListState.add(value: T)</li><li>ListState.addAll(values: java.util.List[T])</li><li>ListState.get()返回Iterable[T]</li><li>ListState.update(values: java.util.List[T])</li></ul></li><li>MapState[K, V]保存Key-Value对。<ul><li>MapState.get(key: K)</li><li>MapState.put(key: K, value: V)</li><li>MapState.contains(key: K)</li><li>MapState.remove(key: K)</li></ul></li><li>ReducingState[T]</li><li>AggregatingState[I, O]</li></ul><p>State.clear()是清空操作。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyedData: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = sensorData.keyBy(_.id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> alerts: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] = keyedData</span><br><span class="line">  .flatMap(<span class="keyword">new</span> <span class="type">TemperatureAlertFunction</span>(<span class="number">1.7</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemperatureAlertFunction</span>(<span class="params">val threshold: <span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>[<span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> lastTempState: <span class="type">ValueState</span>[<span class="type">Double</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> lastTempDescriptor = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Double</span>](</span><br><span class="line">      <span class="string">"lastTemp"</span>, classOf[<span class="type">Double</span>])</span><br><span class="line"></span><br><span class="line">    lastTempState = getRuntimeContext.getState[<span class="type">Double</span>](lastTempDescriptor)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(</span><br><span class="line">    reading: <span class="type">SensorReading</span>,</span><br><span class="line">    out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]</span><br><span class="line">  ): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> lastTemp = lastTempState.value()</span><br><span class="line">    <span class="keyword">val</span> tempDiff = (reading.temperature - lastTemp).abs</span><br><span class="line">    <span class="keyword">if</span> (tempDiff &gt; threshold) &#123;</span><br><span class="line">      out.collect((reading.id, reading.temperature, tempDiff))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.lastTempState.update(reading.temperature)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>上面例子中的FlatMapFunction只能访问当前处理的元素所包含的key所对应的状态变量。</p><blockquote><p>不同key对应的keyed state是相互隔离的。</p></blockquote><ul><li>通过RuntimeContext注册StateDescriptor。StateDescriptor以状态state的名字和存储的数据类型为参数。数据类型必须指定，因为Flink需要选择合适的序列化器。</li><li>在open()方法中创建state变量。注意复习之前的RichFunction相关知识。</li></ul><p>当一个函数注册了StateDescriptor描述符，Flink会检查状态后端是否已经存在这个状态。这种情况通常出现在应用挂掉要从检查点或者保存点恢复的时候。在这两种情况下，Flink会将注册的状态连接到已经存在的状态。如果不存在状态，则初始化一个空的状态。</p><p>使用FlatMap with keyed ValueState的快捷方式flatMapWithState也可以实现以上需求。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> alerts: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] = keyedSensorData</span><br><span class="line">  .flatMapWithState[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>), <span class="type">Double</span>] &#123;</span><br><span class="line">    <span class="keyword">case</span> (in: <span class="type">SensorReading</span>, <span class="type">None</span>) =&gt;</span><br><span class="line">      <span class="comment">// no previous temperature defined.</span></span><br><span class="line">      <span class="comment">// Just update the last temperature</span></span><br><span class="line">      (<span class="type">List</span>.empty, <span class="type">Some</span>(in.temperature))</span><br><span class="line">    <span class="keyword">case</span> (r: <span class="type">SensorReading</span>, lastTemp: <span class="type">Some</span>[<span class="type">Double</span>]) =&gt;</span><br><span class="line">      <span class="comment">// compare temperature difference with threshold</span></span><br><span class="line">      <span class="keyword">val</span> tempDiff = (r.temperature - lastTemp.get).abs</span><br><span class="line">      <span class="keyword">if</span> (tempDiff &gt; <span class="number">1.7</span>) &#123;</span><br><span class="line">        <span class="comment">// threshold exceeded.</span></span><br><span class="line">        <span class="comment">// Emit an alert and update the last temperature</span></span><br><span class="line">        (<span class="type">List</span>((r.id, r.temperature, tempDiff)), <span class="type">Some</span>(r.temperature))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// threshold not exceeded. Just update the last temperature</span></span><br><span class="line">        (<span class="type">List</span>.empty, <span class="type">Some</span>(r.temperature))</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></div><h3 id="使用ListCheckpointed接口来实现操作符的列表状态-List-State"><a href="#使用ListCheckpointed接口来实现操作符的列表状态-List-State" class="headerlink" title="使用ListCheckpointed接口来实现操作符的列表状态(List State)"></a>使用ListCheckpointed接口来实现操作符的列表状态(List State)</h3><p>操作符状态会在操作符的每一个并行实例中去维护。一个操作符并行实例上的所有事件都可以访问同一个状态。Flink支持三种操作符状态：list state, list union state, broadcast state。</p><p>一个函数可以实现ListCheckpointed接口来处理操作符的list state。ListCheckpointed接口无法处理ValueState和ListState，因为这些状态是注册在状态后端的。操作符状态类似于成员变量，和状态后端的交互通过ListCheckpointed接口的回调函数实现。接口提供了两个方法：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回函数状态的快照，返回值为列表</span></span><br><span class="line">snapshotState(checkpointId: <span class="type">Long</span>, timestamp: <span class="type">Long</span>): java.util.<span class="type">List</span>[<span class="type">T</span>]</span><br><span class="line"><span class="comment">// 从列表恢复函数状态</span></span><br><span class="line">restoreState(java.util.<span class="type">List</span>[<span class="type">T</span>] state): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></div><p>当Flink触发stateful functon的一次checkpoint时，snapshotState()方法会被调用。方法接收两个参数，checkpointId为唯一的单调递增的检查点Id，timestamp为当master机器开始做检查点操作时的墙上时钟（机器时间）。方法必须返回序列化好的状态对象的列表。</p><p>当宕机程序从检查点或者保存点恢复时会调用restoreState()方法。restoreState使用snapshotState保存的列表来恢复。</p><p>下面的例子展示了如何实现ListCheckpointed接口。业务场景为：一个对每一个并行实例的超过阈值的温度的计数程序。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HighTempCounter</span>(<span class="params">val threshold: <span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>[<span class="type">SensorReading</span>, (<span class="type">Int</span>, <span class="type">Long</span>)]</span></span><br><span class="line"><span class="class">    <span class="keyword">with</span> <span class="title">ListCheckpointed</span>[java.lang.<span class="type">Long</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// index of the subtask</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> subtaskIdx = getRuntimeContext</span><br><span class="line">    .getIndexOfThisSubtask</span><br><span class="line">  <span class="comment">// local count variable</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> highTempCnt = <span class="number">0</span>L</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(</span><br><span class="line">      in: <span class="type">SensorReading</span>, </span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">Int</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (in.temperature &gt; threshold) &#123;</span><br><span class="line">      <span class="comment">// increment counter if threshold is exceeded</span></span><br><span class="line">      highTempCnt += <span class="number">1</span></span><br><span class="line">      <span class="comment">// emit update with subtask index and counter</span></span><br><span class="line">      out.collect((subtaskIdx, highTempCnt))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">restoreState</span></span>(</span><br><span class="line">      state: util.<span class="type">List</span>[java.lang.<span class="type">Long</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    highTempCnt = <span class="number">0</span></span><br><span class="line">    <span class="comment">// restore state by adding all longs of the list</span></span><br><span class="line">    <span class="keyword">for</span> (cnt &lt;- state.asScala) &#123;</span><br><span class="line">      highTempCnt += cnt</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">snapshotState</span></span>(</span><br><span class="line">      chkpntId: <span class="type">Long</span>, </span><br><span class="line">      ts: <span class="type">Long</span>): java.util.<span class="type">List</span>[java.lang.<span class="type">Long</span>] = &#123;</span><br><span class="line">    <span class="comment">// snapshot state as list with a single count</span></span><br><span class="line">    java.util.<span class="type">Collections</span>.singletonList(highTempCnt)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>上面的例子中，每一个并行实例都计数了本实例有多少温度值超过了设定的阈值。例子中使用了操作符状态，并且每一个并行实例都拥有自己的状态变量，这个状态变量将会被检查点操作保存下来，并且可以通过使用ListCheckpointed接口来恢复状态变量。</p><p>看了上面的例子，我们可能会有疑问，那就是为什么操作符状态是状态对象的列表。这是因为列表数据结构支持包含操作符状态的函数的并行度改变的操作。为了增加或者减少包含了操作符状态的函数的并行度，操作符状态需要被重新分区到更多或者更少的并行任务实例中去。而这样的操作需要合并或者分割状态对象。而对于每一个有状态的函数，分割和合并状态对象都是很常见的操作，所以这显然不是任何类型的状态都能自动完成的。</p><p>通过提供一个状态对象的列表，拥有操作符状态的函数可以使用snapshotState()方法和restoreState()方法来实现以上所说的逻辑。snapshotState()方法将操作符状态分割成多个部分，restoreState()方法从所有的部分中将状态对象收集起来。当函数的操作符状态恢复时，状态变量将被分区到函数的所有不同的并行实例中去，并作为参数传递给restoreState()方法。如果并行任务的数量大于状态对象的数量，那么一些并行任务在开始的时候是没有状态的，所以restoreState()函数的参数为空列表。</p><p>再来看一下上面的程序，我们可以看到操作符的每一个并行实例都暴露了一个状态对象的列表。如果我们增加操作符的并行度，那么一些并行任务将会从0开始计数。为了获得更好的状态分区的行为，当HighTempCounter函数扩容时，我们可以按照下面的程序来实现snapshotState()方法，这样就可以把计数值分配到不同的并行计数中去了。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">snapshotState</span></span>(</span><br><span class="line">    chkpntId: <span class="type">Long</span>, </span><br><span class="line">    ts: <span class="type">Long</span>): java.util.<span class="type">List</span>[java.lang.<span class="type">Long</span>] = &#123;</span><br><span class="line">  <span class="comment">// split count into ten partial counts</span></span><br><span class="line">  <span class="keyword">val</span> div = highTempCnt / <span class="number">10</span></span><br><span class="line">  <span class="keyword">val</span> mod = (highTempCnt % <span class="number">10</span>).toInt</span><br><span class="line">  <span class="comment">// return count as ten parts</span></span><br><span class="line">  (<span class="type">List</span>.fill(mod)(<span class="keyword">new</span> java.lang.<span class="type">Long</span>(div + <span class="number">1</span>)) ++</span><br><span class="line">    <span class="type">List</span>.fill(<span class="number">10</span> - mod)(<span class="keyword">new</span> java.lang.<span class="type">Long</span>(div))).asJava</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="使用连接的广播状态-using-connected-broadcast-state"><a href="#使用连接的广播状态-using-connected-broadcast-state" class="headerlink" title="使用连接的广播状态(using connected broadcast state)"></a>使用连接的广播状态(using connected broadcast state)</h3><p>一个常见的需求就是流应用需要将同样的事件分发到操作符的所有的并行实例中，而这样的分发操作还得是可恢复的。</p><p>我们举个例子：一条流是一个规则(比如5秒钟内连续两个超过阈值的温度)，另一条流是待匹配的流。也就是说，规则流和事件流。所以每一个操作符的并行实例都需要把规则流保存在操作符状态中。也就是说，规则流需要被广播到所有的并行实例中去。</p><p>在Flink中，这样的状态叫做广播状态(broadcast state)。广播状态和DataStream或者KeyedStream都可以做连接操作。</p><p>下面的例子实现了一个温度报警应用，应用有可以动态设定的阈值，动态设定通过广播流来实现。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> thresholds: <span class="type">DataStream</span>[<span class="type">ThresholdUpdate</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyedSensorData: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line"></span><br><span class="line"><span class="comment">// the descriptor of the broadcast state</span></span><br><span class="line"><span class="keyword">val</span> broadcastStateDescriptor =</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapStateDescriptor</span>[<span class="type">String</span>, <span class="type">Double</span>](</span><br><span class="line">    <span class="string">"thresholds"</span>, classOf[<span class="type">String</span>], classOf[<span class="type">Double</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> broadcastThresholds: <span class="type">BroadcastStream</span>[<span class="type">ThresholdUpdate</span>] = thresholds</span><br><span class="line">  .broadcast(broadcastStateDescriptor)</span><br><span class="line"></span><br><span class="line"><span class="comment">// connect keyed sensor stream and broadcasted rules stream</span></span><br><span class="line"><span class="keyword">val</span> alerts: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] = keyedSensorData</span><br><span class="line">  .connect(broadcastThresholds)</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">UpdatableTemperatureAlertFunction</span>())</span><br></pre></td></tr></table></figure></div><p>带有广播状态的函数在应用到两条流上时分三个步骤：</p><ul><li>调用DataStream.broadcast()来创建BroadcastStream，定义一个或者多个MapStateDescriptor对象。</li><li>将BroadcastStream和DataStream/KeyedStream做connect操作。</li><li>在connected streams上调用KeyedBroadcastProcessFunction/BroadcastProcessFunction。</li></ul><p>下面的例子实现了动态设定温度阈值的功能。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UpdatableTemperatureAlertFunction</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">KeyedBroadcastProcessFunction</span>[<span class="type">String</span>,</span></span><br><span class="line"><span class="class">      <span class="type">SensorReading</span>, <span class="type">ThresholdUpdate</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// the descriptor of the broadcast state</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> thresholdStateDescriptor =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">MapStateDescriptor</span>[<span class="type">String</span>, <span class="type">Double</span>](</span><br><span class="line">      <span class="string">"thresholds"</span>, classOf[<span class="type">String</span>], classOf[<span class="type">Double</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment">// the keyed state handle</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> lastTempState: <span class="type">ValueState</span>[<span class="type">Double</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// create keyed state descriptor</span></span><br><span class="line">    <span class="keyword">val</span> lastTempDescriptor = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Double</span>](</span><br><span class="line">      <span class="string">"lastTemp"</span>, classOf[<span class="type">Double</span>])</span><br><span class="line">    <span class="comment">// obtain the keyed state handle</span></span><br><span class="line">    lastTempState = getRuntimeContext</span><br><span class="line">      .getState[<span class="type">Double</span>](lastTempDescriptor)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processBroadcastElement</span></span>(</span><br><span class="line">      update: <span class="type">ThresholdUpdate</span>,</span><br><span class="line">      ctx: <span class="type">KeyedBroadcastProcessFunction</span>[<span class="type">String</span>,</span><br><span class="line">        <span class="type">SensorReading</span>, <span class="type">ThresholdUpdate</span>,</span><br><span class="line">        (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// get broadcasted state handle</span></span><br><span class="line">    <span class="keyword">val</span> thresholds = ctx</span><br><span class="line">      .getBroadcastState(thresholdStateDescriptor)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (update.threshold != <span class="number">0.0</span>d) &#123;</span><br><span class="line">      <span class="comment">// configure a new threshold for the sensor</span></span><br><span class="line">      thresholds.put(update.id, update.threshold)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// remove threshold for the sensor</span></span><br><span class="line">      thresholds.remove(update.id)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      reading: <span class="type">SensorReading</span>,</span><br><span class="line">      readOnlyCtx: <span class="type">KeyedBroadcastProcessFunction</span></span><br><span class="line">        [<span class="type">String</span>, <span class="type">SensorReading</span>, <span class="type">ThresholdUpdate</span>, </span><br><span class="line">        (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]#<span class="type">ReadOnlyContext</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// get read-only broadcast state</span></span><br><span class="line">    <span class="keyword">val</span> thresholds = readOnlyCtx</span><br><span class="line">      .getBroadcastState(thresholdStateDescriptor)</span><br><span class="line">    <span class="comment">// check if we have a threshold</span></span><br><span class="line">    <span class="keyword">if</span> (thresholds.contains(reading.id)) &#123;</span><br><span class="line">      <span class="comment">// get threshold for sensor</span></span><br><span class="line">      <span class="keyword">val</span> sensorThreshold: <span class="type">Double</span> = thresholds.get(reading.id)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// fetch the last temperature from state</span></span><br><span class="line">      <span class="keyword">val</span> lastTemp = lastTempState.value()</span><br><span class="line">      <span class="comment">// check if we need to emit an alert</span></span><br><span class="line">      <span class="keyword">val</span> tempDiff = (reading.temperature - lastTemp).abs</span><br><span class="line">      <span class="keyword">if</span> (tempDiff &gt; sensorThreshold) &#123;</span><br><span class="line">        <span class="comment">// temperature increased by more than the threshold</span></span><br><span class="line">        out.collect((reading.id, reading.temperature, tempDiff))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update lastTemp state</span></span><br><span class="line">    <span class="keyword">this</span>.lastTempState.update(reading.temperature)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="配置检查点"><a href="#配置检查点" class="headerlink" title="配置检查点"></a>配置检查点</h2><p>10秒钟保存一次检查点。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// set checkpointing interval to 10 seconds (10000 milliseconds)</span></span><br><span class="line">env.enableCheckpointing(<span class="number">10000</span>L)</span><br></pre></td></tr></table></figure></div><h3 id="将hdfs配置为状态后端"><a href="#将hdfs配置为状态后端" class="headerlink" title="将hdfs配置为状态后端"></a>将hdfs配置为状态后端</h3><p>首先在IDEA的pom文件中添加依赖：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>在<code>hdfs-site.xml</code>添加:</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></div><blockquote><p>别忘了重启hdfs文件系统！</p></blockquote><p>然后添加本地文件夹和hdfs文件的映射：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs getconf -confKey fs.default.name</span><br><span class="line">hdfs dfs -put &#x2F;home&#x2F;parallels&#x2F;flink&#x2F;checkpoint hdfs:&#x2F;&#x2F;localhost:9000&#x2F;flink</span><br></pre></td></tr></table></figure></div><p>然后在代码中添加：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env.enableCheckpointing(5000)</span><br><span class="line">env.setStateBackend(new FsStateBackend(&quot;hdfs:&#x2F;&#x2F;localhost:9000&#x2F;flink&quot;))</span><br></pre></td></tr></table></figure></div><p>检查一下检查点正确保存了没有：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls hdfs:&#x2F;&#x2F;localhost:9000&#x2F;flink</span><br></pre></td></tr></table></figure></div><h2 id="保证有状态应用的可维护性"><a href="#保证有状态应用的可维护性" class="headerlink" title="保证有状态应用的可维护性"></a>保证有状态应用的可维护性</h2><h3 id="指定唯一的操作符标识符-operator-identifiers"><a href="#指定唯一的操作符标识符-operator-identifiers" class="headerlink" title="指定唯一的操作符标识符(operator identifiers)"></a>指定唯一的操作符标识符(operator identifiers)</h3><p>每一个操作符都可以指定唯一的标识符。标识符将会作为操作符的元数据和状态数据一起保存到savepoint中去。当应用从保存点恢复时，标识符可以用来在savepoint中查找标识符对应的操作符的状态数据。标识符必须是唯一的，否则应用不知道从哪一个标识符恢复。</p><p>强烈建议为应用的每一个操作符定义唯一标识符。例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> alerts: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] = keyedSensorData</span><br><span class="line">  .flatMap(<span class="keyword">new</span> <span class="type">TemperatureAlertFunction</span>(<span class="number">1.1</span>))  </span><br><span class="line">  .uid(<span class="string">"TempAlert"</span>)</span><br></pre></td></tr></table></figure></div><h3 id="指定操作符的最大并行度"><a href="#指定操作符的最大并行度" class="headerlink" title="指定操作符的最大并行度"></a>指定操作符的最大并行度</h3><p>操作符的最大并行度定义了操作符的keyed state可以被分到多少个key groups中。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="comment">// set the maximum parallelism for this application</span></span><br><span class="line">env.setMaxParallelism(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> alerts: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] = keyedSensorData</span><br><span class="line">  .flatMap(<span class="keyword">new</span> <span class="type">TemperatureAlertFunction</span>(<span class="number">1.1</span>))</span><br><span class="line">  <span class="comment">// set the maximum parallelism for this operator and</span></span><br><span class="line">  <span class="comment">// override the application-wide value</span></span><br><span class="line">  .setMaxParallelism(<span class="number">1024</span>)</span><br></pre></td></tr></table></figure></div><h2 id="有状态应用的性能和健壮性"><a href="#有状态应用的性能和健壮性" class="headerlink" title="有状态应用的性能和健壮性"></a>有状态应用的性能和健壮性</h2><h3 id="选择一个状态后端"><a href="#选择一个状态后端" class="headerlink" title="选择一个状态后端"></a>选择一个状态后端</h3><ul><li>MemoryStateBackend将状态当作Java的对象(没有序列化操作)存储在TaskManager JVM进程的堆上。</li><li>FsStateBackend将状态存储在本地的文件系统或者远程的文件系统如HDFS。</li><li>RocksDBStateBackend将状态存储在RocksDB 中。</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> checkpointPath: <span class="type">String</span> = ???</span><br><span class="line"><span class="comment">// configure path for checkpoints on the remote filesystem</span></span><br><span class="line"><span class="comment">// env.setStateBackend(new FsStateBackend("file:///tmp/checkpoints"))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> backend = <span class="keyword">new</span> <span class="type">RocksDBStateBackend</span>(checkpointPath)</span><br><span class="line"><span class="comment">// configure the state backend</span></span><br><span class="line">env.setStateBackend(backend)</span><br></pre></td></tr></table></figure></div><h3 id="防止状态泄露"><a href="#防止状态泄露" class="headerlink" title="防止状态泄露"></a>防止状态泄露</h3><p>流应用通常需要运行几个月或者几年。如果state数据不断增长的话，会爆炸。所以控制state数据的大小十分重要。而Flink并不会清理state和gc。所以所有的stateful operator都需要控制他们各自的状态数据大小，保证不爆炸。</p><p>例如我们之前讲过增量聚合函数ReduceFunction/AggregateFunction，就可以提前聚合而不给state太多压力。</p><p>我们来看一个例子，我们实现了一个KeyedProcessFunction，用来计算连续两次的温度的差值，如果差值超过阈值，报警。</p><p>我们之前实现过这个需求，但没有清理掉状态数据。比如一小时内不再产生温度数据的传感器对应的状态数据就可以清理掉了。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SelfCleaningTemperatureAlertFunction</span>(<span class="params">val threshold: <span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">String</span>,</span></span><br><span class="line"><span class="class">      <span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// the keyed state handle for the last temperature</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> lastTempState: <span class="type">ValueState</span>[<span class="type">Double</span>] = _</span><br><span class="line">  <span class="comment">// the keyed state handle for the last registered timer</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> lastTimerState: <span class="type">ValueState</span>[<span class="type">Long</span>] = _</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// register state for last temperature</span></span><br><span class="line">    <span class="keyword">val</span> lastTempDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Double</span>](</span><br><span class="line">      <span class="string">"lastTemp"</span>, classOf[<span class="type">Double</span>])</span><br><span class="line">    lastTempState = getRuntimeContext</span><br><span class="line">      .getState[<span class="type">Double</span>](lastTempDescriptor)</span><br><span class="line">    <span class="comment">// register state for last timer</span></span><br><span class="line">    <span class="keyword">val</span> lastTimerDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Long</span>](</span><br><span class="line">      <span class="string">"lastTimer"</span>, classOf[<span class="type">Long</span>])</span><br><span class="line">    lastTimerState = getRuntimeContext</span><br><span class="line">      .getState(timestampDescriptor)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      reading: <span class="type">SensorReading</span>,</span><br><span class="line">      ctx: <span class="type">KeyedProcessFunction</span></span><br><span class="line">        [<span class="type">String</span>, <span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// compute timestamp of new clean up timer</span></span><br><span class="line">    <span class="comment">// as record timestamp + one hour</span></span><br><span class="line">    <span class="keyword">val</span> newTimer = ctx.timestamp() + (<span class="number">3600</span> * <span class="number">1000</span>)</span><br><span class="line">    <span class="comment">// get timestamp of current timer</span></span><br><span class="line">    <span class="keyword">val</span> curTimer = lastTimerState.value()</span><br><span class="line">    <span class="comment">// delete previous timer and register new timer</span></span><br><span class="line">    ctx.timerService().deleteEventTimeTimer(curTimer)</span><br><span class="line">    ctx.timerService().registerEventTimeTimer(newTimer)</span><br><span class="line">    <span class="comment">// update timer timestamp state</span></span><br><span class="line">    lastTimerState.update(newTimer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fetch the last temperature from state</span></span><br><span class="line">    <span class="keyword">val</span> lastTemp = lastTempState.value()</span><br><span class="line">    <span class="comment">// check if we need to emit an alert</span></span><br><span class="line">    <span class="keyword">val</span> tempDiff = (reading.temperature - lastTemp).abs</span><br><span class="line">    <span class="keyword">if</span> (tempDiff &gt; threshold) &#123;</span><br><span class="line">      <span class="comment">// temperature increased by more than the threshold</span></span><br><span class="line">      out.collect((reading.id, reading.temperature, tempDiff))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update lastTemp state</span></span><br><span class="line">    <span class="keyword">this</span>.lastTempState.update(reading.temperature)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(</span><br><span class="line">      timestamp: <span class="type">Long</span>,</span><br><span class="line">      ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>,</span><br><span class="line">        <span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]#<span class="type">OnTimerContext</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// clear all state for the key</span></span><br><span class="line">    lastTempState.clear()</span><br><span class="line">    lastTimerState.clear()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第七章，有状态算子和应用&quot;&gt;&lt;a href=&quot;#第七章，有状态算子和应用&quot; class=&quot;headerlink&quot; title=&quot;第七章，有状态算子和应用&quot;&gt;&lt;/a&gt;第七章，有状态算子和应用&lt;/h1&gt;&lt;p&gt;状态操作符和用户自定义函数都是我们在写流处理程序时，常用的工
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列06基于时间和窗口的操作符</title>
    <link href="https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9706%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E5%92%8C%E7%AA%97%E5%8F%A3%E7%9A%84%E6%93%8D%E4%BD%9C%E7%AC%A6/"/>
    <id>https://masteryang4.github.io/2020/07/02/flink%E7%B3%BB%E5%88%9706%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E5%92%8C%E7%AA%97%E5%8F%A3%E7%9A%84%E6%93%8D%E4%BD%9C%E7%AC%A6/</id>
    <published>2020-07-02T03:45:19.000Z</published>
    <updated>2020-07-02T03:47:24.167Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第六章，基于时间和窗口的操作符"><a href="#第六章，基于时间和窗口的操作符" class="headerlink" title="第六章，基于时间和窗口的操作符"></a>第六章，基于时间和窗口的操作符</h1><p>在本章，我们将要学习DataStream API中处理时间和基于时间的操作符，例如窗口操作符。</p><p>首先，我们会学习如何定义时间属性，时间戳和水位线。然后我们将会学习底层操作process function，它可以让我们访问时间戳和水位线，以及注册定时器事件。接下来，我们将会使用Flink的window API，它提供了通常使用的各种窗口类型的内置实现。我们将会学到如何进行用户自定义窗口操作符，以及窗口的核心功能：assigners（分配器）、triggers（触发器）和evictors（清理器）。最后，我们将讨论如何基于时间来做流的联结查询，以及处理迟到事件的策略。</p><h2 id="设置时间属性"><a href="#设置时间属性" class="headerlink" title="设置时间属性"></a>设置时间属性</h2><p>如果我们想要在分布式流处理应用程序中定义有关时间的操作，彻底理解时间的语义是非常重要的。当我们指定了一个窗口去收集某1分钟内的数据时，这个长度为1分钟的桶中，到底应该包含哪些数据？在DataStream API中，我们将使用时间属性来告诉Flink：当我们创建窗口时，我们如何定义时间。时间属性是<code>StreamExecutionEnvironment</code>的一个属性，有以下值：</p><p><em>ProcessingTime</em></p><blockquote><p>机器时间在分布式系统中又叫做“墙上时钟”。</p></blockquote><p>当操作符执行时，此操作符看到的时间是操作符所在机器的机器时间。Processing-time window的触发取决于机器时间，窗口包含的元素也是那个机器时间段内到达的元素。通常情况下，窗口操作符使用processing time会导致不确定的结果，因为基于机器时间的窗口中收集的元素取决于元素到达的速度快慢。使用processing time会为程序提供极低的延迟，因为无需等待水位线的到达。</p><blockquote><p>如果要追求极限的低延迟，请使用processing time。</p></blockquote><p><em>EventTime</em></p><p>当操作符执行时，操作符看的当前时间是由流中元素所携带的信息决定的。流中的每一个元素都必须包含时间戳信息。而系统的逻辑时钟由水位线(Watermark)定义。我们之前学习过，时间戳要么在事件进入流处理程序之前已经存在，要么就需要在程序的数据源（source）处进行分配。当水位线宣布特定时间段的数据都已经到达，事件时间窗口将会被触发计算。即使数据到达的顺序是乱序的，事件时间窗口的计算结果也将是确定性的。窗口的计算结果并不取决于元素到达的快与慢。</p><blockquote><p>当水位线超过事件时间窗口的结束时间时，窗口将会闭合，不再接收数据，并触发计算。</p></blockquote><p><em>IngestionTime</em></p><p>当事件进入source操作符时，source操作符所在机器的机器时间，就是此事件的“摄入时间”（IngestionTime），并同时产生水位线。IngestionTime相当于EventTime和ProcessingTime的混合体。一个事件的IngestionTime其实就是它进入流处理器中的时间。</p><blockquote><p>IngestionTime没什么价值，既有EventTime的执行效率（比较低），有没有EventTime计算结果的准确性。</p></blockquote><p>下面的例子展示了如何设置事件时间。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AverageSensorReadings</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env.addSource(...)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>如果要使用processing time，将<code>TimeCharacteristic.EventTime</code>替换为<code>TimeCharacteristic.ProcessingTIme</code>就可以了。</p><h3 id="指定时间戳和产生水位线"><a href="#指定时间戳和产生水位线" class="headerlink" title="指定时间戳和产生水位线"></a>指定时间戳和产生水位线</h3><p>如果使用事件时间，那么流中的事件必须包含这个事件真正发生的时间。使用了事件时间的流必须携带水位线。</p><p>时间戳和水位线的单位是毫秒，记时从<code>1970-01-01T00:00:00Z</code>开始。到达某个操作符的水位线就会告知这个操作符：小于等于水位线中携带的时间戳的事件都已经到达这个操作符了。时间戳和水位线可以由<code>SourceFunction</code>产生，或者由用户自定义的时间戳分配器和水位线产生器来生成。</p><p>Flink暴露了TimestampAssigner接口供我们实现，使我们可以自定义如何从事件数据中抽取时间戳。一般来说，时间戳分配器需要在source操作符后马上进行调用。</p><blockquote><p>因为时间戳分配器看到的元素的顺序应该和source操作符产生数据的顺序是一样的，否则就乱了。这就是为什么我们经常将source操作符的并行度设置为1的原因。</p></blockquote><p>也就是说，任何分区操作都会将元素的顺序打乱，例如：并行度改变，keyBy()操作等等。</p><p>所以最佳实践是：在尽量接近数据源source操作符的地方分配时间戳和产生水位线，甚至最好在SourceFunction中分配时间戳和产生水位线。当然在分配时间戳和产生水位线之前可以对流进行map和filter操作是没问题的，也就是说必须是窄依赖。</p><p>以下这种写法是可以的。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  .addSource(...)</span><br><span class="line">  .map(...)</span><br><span class="line">  .filter(...)</span><br><span class="line">  .assignTimestampsAndWatermarks(...)</span><br></pre></td></tr></table></figure></div><p>下面的例子展示了首先filter流，然后再分配时间戳和水位线。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 从调用时刻开始给env创建的每一个stream追加时间特征</span></span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">  .filter(r =&gt; r.temperature &gt; <span class="number">25</span>)</span><br><span class="line">  .assignTimestampsAndWatermarks(<span class="keyword">new</span> <span class="type">MyAssigner</span>())</span><br></pre></td></tr></table></figure></div><p>MyAssigner有两种类型</p><ul><li>AssignerWithPeriodicWatermarks</li><li>AssignerWithPunctuatedWatermarks</li></ul><p>以上两个接口都继承自TimestampAssigner。</p><h3 id="周期性的生成水位线"><a href="#周期性的生成水位线" class="headerlink" title="周期性的生成水位线"></a>周期性的生成水位线</h3><p>周期性的生成水位线：系统会周期性的将水位线插入到流中（水位线也是一种特殊的事件!）。默认周期是200毫秒，也就是说，系统会每隔200毫秒就往流中插入一次水位线。</p><blockquote><p>这里的200毫秒是机器时间！</p></blockquote><p>可以使用<code>ExecutionConfig.setAutoWatermarkInterval()</code>方法进行设置。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"><span class="comment">// 每隔5秒产生一个水位线</span></span><br><span class="line">env.getConfig.setAutoWatermarkInterval(<span class="number">5000</span>)</span><br></pre></td></tr></table></figure></div><p>上面的例子产生水位线的逻辑：每隔5秒钟，Flink会调用AssignerWithPeriodicWatermarks中的getCurrentWatermark()方法。如果方法返回的时间戳大于之前水位线的时间戳，新的水位线会被插入到流中。这个检查保证了水位线是单调递增的。如果方法返回的时间戳小于等于之前水位线的时间戳，则不会产生新的水位线。</p><p>例子，自定义一个周期性的时间戳抽取</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PeriodicAssigner</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AssignerWithPeriodicWatermarks</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> bound: <span class="type">Long</span> = <span class="number">60</span> * <span class="number">1000</span> <span class="comment">// 延时为1分钟</span></span><br><span class="line">  <span class="keyword">var</span> maxTs: <span class="type">Long</span> = <span class="type">Long</span>.<span class="type">MinValue</span> + bound <span class="comment">// 观察到的最大时间戳</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getCurrentWatermark</span></span>: <span class="type">Watermark</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Watermark</span>(maxTs - bound)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(r: <span class="type">SensorReading</span>, previousTS: <span class="type">Long</span>) = &#123;</span><br><span class="line">    maxTs = maxTs.max(r.timestamp)</span><br><span class="line">    r.timestamp</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>如果我们事先得知数据流的时间戳是单调递增的，也就是说没有乱序。我们可以使用assignAscendingTimestamps，方法会直接使用数据的时间戳生成水位线。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val stream: DataStream[SensorReading] &#x3D; ...</span><br><span class="line">val withTimestampsAndWatermarks &#x3D; stream</span><br><span class="line">  .assignAscendingTimestamps(e &#x3D;&gt; e.timestamp)</span><br></pre></td></tr></table></figure></div><p>如果我们能大致估算出数据流中的事件的最大延迟时间，可以使用如下代码：</p><blockquote><p>最大延迟时间就是当前到达的事件的事件时间和之前所有到达的事件中最大时间戳的差。</p></blockquote><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> withTimestampsAndWatermarks = stream.assignTimestampsAndWatermarks(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">SensorTimeAssigner</span> </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SensorTimeAssigner</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">SensorReading</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    <span class="type">Time</span>.seconds(5</span>)</span></span><br><span class="line"><span class="class">  ) </span>&#123;</span><br><span class="line">    <span class="comment">// 抽取时间戳</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(r: <span class="type">SensorReading</span>): <span class="type">Long</span> = r.timestamp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>以上代码设置了最大延迟时间为5秒。</p><h3 id="如何产生不规则的水位线"><a href="#如何产生不规则的水位线" class="headerlink" title="如何产生不规则的水位线"></a>如何产生不规则的水位线</h3><p>有时候输入流中会包含一些用于指示系统进度的特殊元组或标记。Flink为此类情形以及可根据输入元素生成水位线的情形提供了<code>AssignerWithPunctuatedWatermarks</code>接口。该接口中的<code>checkAndGetNextWatermark()</code>方法会在针对每个事件的<code>extractTimestamp()</code>方法后立即调用。它可以决定是否生成一个新的水位线。如果该方法返回一个非空、且大于之前值的水位线，算子就会将这个新水位线发出。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PunctuatedAssigner</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AssignerWithPunctuatedWatermarks</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> bound: <span class="type">Long</span> = <span class="number">60</span> * <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 每来一条数据就调用一次</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">checkAndGetNextWatermark</span></span>(r: <span class="type">SensorReading</span>,</span><br><span class="line">                                        extractedTS: <span class="type">Long</span>): <span class="type">Watermark</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (r.id == <span class="string">"sensor_1"</span>) &#123;</span><br><span class="line">      <span class="comment">// 抽取的时间戳 - 最大延迟时间</span></span><br><span class="line">      <span class="keyword">new</span> <span class="type">Watermark</span>(extractedTS - bound)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 每来一条数据就调用一次</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(r: <span class="type">SensorReading</span>,</span><br><span class="line">                                previousTS: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">    r.timestamp</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>现在我们已经知道如何使用 <code>TimestampAssigner</code> 来产生水位线了。现在我们要讨论一下水位线会对我们的程序产生什么样的影响。</p><p>水位线用来平衡延迟和计算结果的正确性。水位线告诉我们，在触发计算（例如关闭窗口并触发窗口计算）之前，我们需要等待事件多长时间。基于事件时间的操作符根据水位线来衡量系统的逻辑时间的进度。</p><p>完美的水位线永远不会错：时间戳小于水位线的事件不会再出现。在特殊情况下(例如非乱序事件流)，最近一次事件的时间戳就可能是完美的水位线。启发式水位线则相反，它只估计时间，因此有可能出错，即迟到的事件(其时间戳小于水位线标记时间)晚于水位线出现。针对启发式水位线，Flink提供了处理迟到元素的机制。</p><p>设定水位线通常需要用到领域知识。举例来说，如果知道事件的迟到时间不会超过5秒，就可以将水位线标记时间设为收到的最大时间戳减去5秒。另一种做法是，采用一个Flink作业监控事件流，学习事件的迟到规律，并以此构建水位线生成模型。</p><p>如果最大延迟时间设置的很大，计算出的结果会更精确，但收到计算结果的速度会很慢，同时系统会缓存大量的数据，并对系统造成比较大的压力。如果最大延迟时间设置的很小，那么收到计算结果的速度会很快，但可能收到错误的计算结果。不过Flink处理迟到数据的机制可以解决这个问题。上述问题看起来很复杂，但是恰恰符合现实世界的规律：大部分真实的事件流都是乱序的，并且通常无法了解它们的乱序程度(因为理论上不能预见未来)。水位线是唯一让我们直面乱序事件流并保证正确性的机制; 否则只能选择忽视事实，假装错误的结果是正确的。</p><blockquote><p>思考题一：实时程序，要求实时性非常高，并且结果并不一定要求非常准确，那么应该怎么办？ 直接使用处理时间。 思考题二：如果要进行时间旅行，也就是要还原以前的数据集当时的流的状态，应该怎么办？ 使用事件时间。使用Hive将数据集先按照时间戳升序排列，再将最大延迟时间设置为0。</p></blockquote><h2 id="Process-Function-Low-Level-API"><a href="#Process-Function-Low-Level-API" class="headerlink" title="Process Function(Low-Level API)"></a>Process Function(Low-Level API)</h2><p>我们之前学习的转换算子是无法访问事件的时间戳信息和水位线信息的。而这在一些应用场景下，极为重要。例如MapFunction这样的map转换算子就无法访问时间戳或者当前事件的事件时间。</p><p>基于此，DataStream API提供了一系列的Low-Level转换算子。可以访问时间戳、水位线以及注册定时事件。还可以输出特定的一些事件，例如超时事件等。Process Function用来构建事件驱动的应用以及实现自定义的业务逻辑(使用之前的window函数和转换算子无法实现)。例如，Flink-SQL就是使用Process Function实现的。</p><p>Flink提供了8个Process Function：</p><ul><li>ProcessFunction</li><li>KeyedProcessFunction</li><li>CoProcessFunction</li><li>ProcessJoinFunction</li><li>BroadcastProcessFunction</li><li>KeyedBroadcastProcessFunction</li><li>ProcessWindowFunction</li><li>ProcessAllWindowFunction</li></ul><p>我们这里详细介绍一下KeyedProcessFunction。</p><p>KeyedProcessFunction用来操作KeyedStream。KeyedProcessFunction会处理流的每一个元素，输出为0个、1个或者多个元素。所有的Process Function都继承自RichFunction接口，所以都有open()、close()和getRuntimeContext()等方法。而KeyedProcessFunction[KEY, IN, OUT]还额外提供了两个方法:</p><ul><li>processElement(v: IN, ctx: Context, out: Collector[OUT]), 流中的每一个元素都会调用这个方法，调用结果将会放在Collector数据类型中输出。Context可以访问元素的时间戳，元素的key，以及TimerService时间服务。Context还可以将结果输出到别的流(side outputs)。</li><li>onTimer(timestamp: Long, ctx: OnTimerContext, out: Collector[OUT])是一个回调函数。当之前注册的定时器触发时调用。参数timestamp为定时器所设定的触发的时间戳。Collector为输出结果的集合。OnTimerContext和processElement的Context参数一样，提供了上下文的一些信息，例如firing trigger的时间信息(事件时间或者处理时间)。</li></ul><h3 id="TimerService-and-Timers"><a href="#TimerService-and-Timers" class="headerlink" title="TimerService and Timers"></a>TimerService and Timers</h3><p>Context和OnTimerContext所持有的TimerService对象拥有以下方法:</p><ul><li><code>currentProcessingTime(): Long</code> 返回当前处理时间</li><li><code>currentWatermark(): Long</code> 返回当前水位线的时间戳</li><li><code>registerProcessingTimeTimer(timestamp: Long): Unit</code> 会注册当前key的processing time的timer。当processing time到达定时时间时，触发timer。</li><li><code>registerEventTimeTimer(timestamp: Long): Unit</code> 会注册当前key的event time timer。当水位线大于等于定时器注册的时间时，触发定时器执行回调函数。</li><li><code>deleteProcessingTimeTimer(timestamp: Long): Unit</code> 删除之前注册处理时间定时器。如果没有这个时间戳的定时器，则不执行。</li><li><code>deleteEventTimeTimer(timestamp: Long): Unit</code> 删除之前注册的事件时间定时器，如果没有此时间戳的定时器，则不执行。</li></ul><p>当定时器timer触发时，执行回调函数onTimer()。processElement()方法和onTimer()方法是同步（不是异步）方法，这样可以避免并发访问和操作状态。</p><blockquote><p>定时器timer只能在KeyedStream上面使用。</p></blockquote><p>针对每一个key和timestamp，只能注册一个定期器。也就是说，每一个key可以注册多个定时器，但在每一个时间戳只能注册一个定时器。KeyedProcessFunction默认将所有定时器的时间戳放在一个优先队列中。在Flink做检查点操作时，定时器也会被保存到状态后端中。</p><p>举个例子说明KeyedProcessFunction如何操作KeyedStream。</p><p>下面的程序展示了如何监控温度传感器的温度值，如果温度值在一秒钟之内(processing time)连续上升，报警。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> warnings = readings</span><br><span class="line">  <span class="comment">// key by sensor id</span></span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  <span class="comment">// apply ProcessFunction to monitor temperatures</span></span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TempIncreaseAlertFunction</span>)</span><br></pre></td></tr></table></figure></div><p>看一下TempIncreaseAlertFunction如何实现, 程序中使用了ValueState这样一个状态变量, 后面会详细讲解。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TempIncreaseAlertFunction</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>[<span class="type">String</span>, <span class="type">SensorReading</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="comment">// 保存上一个传感器温度值</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> lastTemp: <span class="type">ValueState</span>[<span class="type">Double</span>] = getRuntimeContext.getState(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Double</span>](<span class="string">"lastTemp"</span>, <span class="type">Types</span>.of[<span class="type">Double</span>])</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 保存注册的定时器的时间戳</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> currentTimer: <span class="type">ValueState</span>[<span class="type">Long</span>] = getRuntimeContext.getState(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Long</span>](<span class="string">"timer"</span>, <span class="type">Types</span>.of[<span class="type">Long</span>])</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(r: <span class="type">SensorReading</span>,</span><br><span class="line">                              ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>,</span><br><span class="line">                                <span class="type">SensorReading</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">                              out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// get previous temperature</span></span><br><span class="line">    <span class="comment">// 取出上一次的温度</span></span><br><span class="line">    <span class="keyword">val</span> prevTemp = lastTemp.value()</span><br><span class="line">    <span class="comment">// update last temperature</span></span><br><span class="line">    <span class="comment">// 将当前温度更新到上一次的温度这个变量中</span></span><br><span class="line">    lastTemp.update(r.temperature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> curTimerTimestamp = currentTimer.value()</span><br><span class="line">    <span class="keyword">if</span> (prevTemp == <span class="number">0.0</span> || r.temperature &lt; prevTemp) &#123;</span><br><span class="line">      <span class="comment">// temperature decreased; delete current timer</span></span><br><span class="line">      <span class="comment">// 温度下降或者是第一个温度值，删除定时器</span></span><br><span class="line">      ctx.timerService().deleteProcessingTimeTimer(curTimerTimestamp)</span><br><span class="line">      <span class="comment">// 清空状态变量</span></span><br><span class="line">      currentTimer.clear()</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (r.temperature &gt; prevTemp &amp;&amp; curTimerTimestamp == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// temperature increased and we have not set a timer yet</span></span><br><span class="line">      <span class="comment">// set processing time timer for now + 1 second</span></span><br><span class="line">      <span class="comment">// 温度上升且我们并没有设置定时器</span></span><br><span class="line">      <span class="keyword">val</span> timerTs = ctx.timerService().currentProcessingTime() + <span class="number">1000</span></span><br><span class="line">      ctx.timerService().registerProcessingTimeTimer(timerTs)</span><br><span class="line">      <span class="comment">// remember current timer</span></span><br><span class="line">      currentTimer.update(timerTs)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(ts: <span class="type">Long</span>,</span><br><span class="line">                       ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>,</span><br><span class="line">                        <span class="type">SensorReading</span>, <span class="type">String</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">                       out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    out.collect(<span class="string">"传感器id为: "</span></span><br><span class="line">      + ctx.getCurrentKey</span><br><span class="line">      + <span class="string">"的传感器温度值已经连续1s上升了。"</span>)</span><br><span class="line">    currentTimer.clear()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="将事件发送到侧输出-Emitting-to-Side-Outputs"><a href="#将事件发送到侧输出-Emitting-to-Side-Outputs" class="headerlink" title="将事件发送到侧输出(Emitting to Side Outputs)"></a>将事件发送到侧输出(Emitting to Side Outputs)</h3><p>大部分的DataStream API的算子的输出是单一输出，也就是某种数据类型的流。除了split算子，可以将一条流分成多条流，这些流的数据类型也都相同。process function的side outputs功能可以产生多条流，并且这些流的数据类型可以不一样。一个side output可以定义为OutputTag[X]对象，X是输出流的数据类型。process function可以通过Context对象发射一个事件到一个或者多个side outputs。</p><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> monitoredReadings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = readings</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">FreezingMonitor</span>)</span><br><span class="line"></span><br><span class="line">monitoredReadings</span><br><span class="line">  .getSideOutput(<span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">String</span>](<span class="string">"freezing-alarms"</span>))</span><br><span class="line">  .print()</span><br><span class="line"></span><br><span class="line">readings.print()</span><br></pre></td></tr></table></figure></div><p>接下来我们实现FreezingMonitor函数，用来监控传感器温度值，将温度值低于32F的温度输出到side output。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FreezingMonitor</span> <span class="keyword">extends</span> <span class="title">ProcessFunction</span>[<span class="type">SensorReading</span>, <span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="comment">// define a side output tag</span></span><br><span class="line">  <span class="comment">// 定义一个侧输出标签</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> freezingAlarmOutput: <span class="type">OutputTag</span>[<span class="type">String</span>] =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">String</span>](<span class="string">"freezing-alarms"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(r: <span class="type">SensorReading</span>,</span><br><span class="line">                              ctx: <span class="type">ProcessFunction</span>[<span class="type">SensorReading</span>,</span><br><span class="line">                                <span class="type">SensorReading</span>]#<span class="type">Context</span>,</span><br><span class="line">                              out: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// emit freezing alarm if temperature is below 32F</span></span><br><span class="line">    <span class="keyword">if</span> (r.temperature &lt; <span class="number">32.0</span>) &#123;</span><br><span class="line">      ctx.output(freezingAlarmOutput, <span class="string">s"Freezing Alarm for <span class="subst">$&#123;r.id&#125;</span>"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// forward all readings to the regular output</span></span><br><span class="line">    out.collect(r)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="CoProcessFunction"><a href="#CoProcessFunction" class="headerlink" title="CoProcessFunction"></a>CoProcessFunction</h3><p>对于两条输入流，DataStream API提供了CoProcessFunction这样的low-level操作。CoProcessFunction提供了操作每一个输入流的方法: processElement1()和processElement2()。类似于ProcessFunction，这两种方法都通过Context对象来调用。这个Context对象可以访问事件数据，定时器时间戳，TimerService，以及side outputs。CoProcessFunction也提供了onTimer()回调函数。下面的例子展示了如何使用CoProcessFunction来合并两条流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ingest sensor stream</span></span><br><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// filter switches enable forwarding of readings</span></span><br><span class="line"><span class="keyword">val</span> filterSwitches: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = env</span><br><span class="line">  .fromCollection(<span class="type">Seq</span>(</span><br><span class="line">    (<span class="string">"sensor_2"</span>, <span class="number">10</span> * <span class="number">1000</span>L),</span><br><span class="line">    (<span class="string">"sensor_7"</span>, <span class="number">60</span> * <span class="number">1000</span>L)</span><br><span class="line">  ))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> forwardedReadings = readings</span><br><span class="line">  <span class="comment">// connect readings and switches</span></span><br><span class="line">  .connect(filterSwitches)</span><br><span class="line">  <span class="comment">// key by sensor ids</span></span><br><span class="line">  .keyBy(_.id, _._1)</span><br><span class="line">  <span class="comment">// apply filtering CoProcessFunction</span></span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">ReadingFilter</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadingFilter</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">CoProcessFunction</span>[<span class="type">SensorReading</span>,</span></span><br><span class="line"><span class="class">    (<span class="type">String</span>, <span class="type">Long</span>), <span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="comment">// switch to enable forwarding</span></span><br><span class="line">  <span class="comment">// 传送数据的开关</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> forwardingEnabled: <span class="type">ValueState</span>[<span class="type">Boolean</span>] = getRuntimeContext</span><br><span class="line">    .getState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Boolean</span>](<span class="string">"filterSwitch"</span>, <span class="type">Types</span>.of[<span class="type">Boolean</span>])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">  <span class="comment">// hold timestamp of currently active disable timer</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> disableTimer: <span class="type">ValueState</span>[<span class="type">Long</span>] = getRuntimeContext</span><br><span class="line">    .getState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Long</span>](<span class="string">"timer"</span>, <span class="type">Types</span>.of[<span class="type">Long</span>])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement1</span></span>(reading: <span class="type">SensorReading</span>,</span><br><span class="line">                               ctx: <span class="type">CoProcessFunction</span>[<span class="type">SensorReading</span>,</span><br><span class="line">                                (<span class="type">String</span>, <span class="type">Long</span>), <span class="type">SensorReading</span>]#<span class="type">Context</span>,</span><br><span class="line">                               out: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// check if we may forward the reading</span></span><br><span class="line">    <span class="comment">// 决定我们是否要将数据继续传下去</span></span><br><span class="line">    <span class="keyword">if</span> (forwardingEnabled.value()) &#123;</span><br><span class="line">      out.collect(reading)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement2</span></span>(switch: (<span class="type">String</span>, <span class="type">Long</span>),</span><br><span class="line">                               ctx: <span class="type">CoProcessFunction</span>[<span class="type">SensorReading</span>,</span><br><span class="line">                                (<span class="type">String</span>, <span class="type">Long</span>), <span class="type">SensorReading</span>]#<span class="type">Context</span>,</span><br><span class="line">                               out: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// enable reading forwarding</span></span><br><span class="line">    <span class="comment">// 允许继续传输数据</span></span><br><span class="line">    forwardingEnabled.update(<span class="literal">true</span>)</span><br><span class="line">    <span class="comment">// set disable forward timer</span></span><br><span class="line">    <span class="keyword">val</span> timerTimestamp = ctx.timerService().currentProcessingTime()</span><br><span class="line">     + switch._2</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">val</span> curTimerTimestamp = disableTimer.value()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (timerTimestamp &gt; curTimerTimestamp) &#123;</span><br><span class="line">      <span class="comment">// remove current timer and register new timer</span></span><br><span class="line">      ctx.timerService().deleteProcessingTimeTimer(curTimerTimestamp)</span><br><span class="line">      ctx.timerService().registerProcessingTimeTimer(timerTimestamp)</span><br><span class="line">      disableTimer.update(timerTimestamp)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onTimer</span></span>(ts: <span class="type">Long</span>,</span><br><span class="line">                       ctx: <span class="type">CoProcessFunction</span>[<span class="type">SensorReading</span>,</span><br><span class="line">                        (<span class="type">String</span>, <span class="type">Long</span>), <span class="type">SensorReading</span>]#<span class="type">OnTimerContext</span>,</span><br><span class="line">                       out: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">     <span class="comment">// remove all state; forward switch will be false by default</span></span><br><span class="line">     forwardingEnabled.clear()</span><br><span class="line">     disableTimer.clear()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="窗口操作符-Window-Operators"><a href="#窗口操作符-Window-Operators" class="headerlink" title="窗口操作符(Window Operators)"></a>窗口操作符(Window Operators)</h2><p>窗口操作是流处理程序中很常见的操作。窗口操作允许我们在无限流上的一段有界区间上面做聚合之类的操作。而我们使用基于时间的逻辑来定义区间。窗口操作符提供了一种将数据放进一个桶，并根据桶中的数据做计算的方法。例如，我们可以将事件放进5分钟的滚动窗口中，然后计数。</p><blockquote><p>无限流转化成有限数据的方法：使用窗口。</p></blockquote><h3 id="定义窗口操作符"><a href="#定义窗口操作符" class="headerlink" title="定义窗口操作符"></a>定义窗口操作符</h3><p>Window算子可以在keyed stream或者nokeyed stream上面使用。</p><p>创建一个Window算子，需要指定两个部分：</p><ol><li><code>window assigner</code>定义了流的元素如何分配到window中。window assigner将会产生一条WindowedStream(或者AllWindowedStream，如果是nonkeyed DataStream的话)</li><li>window function用来处理WindowedStream(AllWindowedStream)中的元素。</li></ol><p>下面的代码说明了如何使用窗口操作符。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">  .keyBy(...)</span><br><span class="line">  .window(...)  <span class="comment">// 指定window assigner</span></span><br><span class="line">  .reduce/aggregate/process(...) <span class="comment">// 指定window function</span></span><br><span class="line"></span><br><span class="line">stream</span><br><span class="line">  .windowAll(...) <span class="comment">// 指定window assigner</span></span><br><span class="line">  .reduce/aggregate/process(...) <span class="comment">// 指定window function</span></span><br></pre></td></tr></table></figure></div><blockquote><p>我们的学习重点是Keyed WindowedStream。</p></blockquote><h3 id="内置的窗口分配器-built-in-window-assigner"><a href="#内置的窗口分配器-built-in-window-assigner" class="headerlink" title="内置的窗口分配器(built-in window assigner)"></a>内置的窗口分配器(built-in window assigner)</h3><p>窗口分配器将会根据事件的事件时间或者处理时间来将事件分配到对应的窗口中去。窗口包含开始时间和结束时间这两个时间戳。</p><p>所有的窗口分配器都包含一个默认的触发器：</p><ul><li>对于事件时间：当水位线超过窗口结束时间，触发窗口的求值操作。</li><li>对于处理时间：当机器时间超过窗口结束时间，触发窗口的求值操作。</li></ul><blockquote><p>需要注意的是：当处于某个窗口的第一个事件到达的时候，这个窗口才会被创建。Flink不会对空窗口求值。</p></blockquote><p>Flink创建的窗口类型是<code>TimeWindow</code>，包含开始时间和结束时间，区间是左闭右开的，也就是说包含开始时间戳，不包含结束时间戳。</p><p><em>滚动窗口(tumbling windows)</em></p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0601.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0601.png" class="lazyload"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> avgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  <span class="comment">// group readings in 1s event-time windows</span></span><br><span class="line">  .window(<span class="type">TumblingEventTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">1</span>)))</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> avgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  <span class="comment">// group readings in 1s processing-time windows</span></span><br><span class="line">  .window(<span class="type">TumblingProcessingTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">1</span>)))</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 其实就是之前的</span></span><br><span class="line"><span class="comment">// shortcut for window.(TumblingEventTimeWindows.of(size))</span></span><br><span class="line"><span class="keyword">val</span> avgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">1</span>))</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br></pre></td></tr></table></figure></div><p>默认情况下，滚动窗口会和<code>1970-01-01-00:00:00.000</code>对齐，例如一个1小时的滚动窗口将会定义以下开始时间的窗口：00:00:00，01:00:00，02:00:00，等等。</p><p><em>滑动窗口(sliding window)</em></p><p>对于滑动窗口，我们需要指定窗口的大小和滑动的步长。当滑动步长小于窗口大小时，窗口将会出现重叠，而元素会被分配到不止一个窗口中去。当滑动步长大于窗口大小时，一些元素可能不会被分配到任何窗口中去，会被直接丢弃。</p><p>下面的代码定义了窗口大小为1小时，滑动步长为15分钟的窗口。每一个元素将被分配到4个窗口中去。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0602.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0602.png" class="lazyload"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> slidingAvgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .window(</span><br><span class="line">    <span class="type">SlidingEventTimeWindows</span>.of(<span class="type">Time</span>.hours(<span class="number">1</span>), <span class="type">Time</span>.minutes(<span class="number">15</span>))</span><br><span class="line">  )</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> slidingAvgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .window(</span><br><span class="line">    <span class="type">SlidingProcessingTimeWindows</span>.of(<span class="type">Time</span>.hours(<span class="number">1</span>), <span class="type">Time</span>.minutes(<span class="number">15</span>))</span><br><span class="line">  )</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> slidingAvgTemp = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.hours(<span class="number">1</span>), <span class="type">Time</span>.minutes(<span class="number">15</span>))</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br></pre></td></tr></table></figure></div><p><em>会话窗口(session windows)</em></p><p>会话窗口不可能重叠，并且会话窗口的大小也不是固定的。不活跃的时间长度定义了会话窗口的界限。不活跃的时间是指这段时间没有元素到达。下图展示了元素如何被分配到会话窗口。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0603.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0603.png" class="lazyload"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sessionWindows = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .window(<span class="type">EventTimeSessionWindows</span>.withGap(<span class="type">Time</span>.minutes(<span class="number">15</span>)))</span><br><span class="line">  .process(...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sessionWindows = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .window(<span class="type">ProcessingTimeSessionWindows</span>.withGap(<span class="type">Time</span>.minutes(<span class="number">15</span>)))</span><br><span class="line">  .process(...)</span><br></pre></td></tr></table></figure></div><p>由于会话窗口的开始时间和结束时间取决于接收到的元素，所以窗口分配器无法立即将所有的元素分配到正确的窗口中去。相反，会话窗口分配器最开始时先将每一个元素分配到它自己独有的窗口中去，窗口开始时间是这个元素的时间戳，窗口大小是session gap的大小。接下来，会话窗口分配器会将出现重叠的窗口合并成一个窗口。</p><h3 id="调用窗口计算函数"><a href="#调用窗口计算函数" class="headerlink" title="调用窗口计算函数"></a>调用窗口计算函数</h3><p>window functions定义了窗口中数据的计算逻辑。有两种计算逻辑：</p><ol><li>增量聚合函数(Incremental aggregation functions)：当一个事件被添加到窗口时，触发函数计算，并且更新window的状态(单个值)。最终聚合的结果将作为输出。ReduceFunction和AggregateFunction是增量聚合函数。</li><li>全窗口函数(Full window functions)：这个函数将会收集窗口中所有的元素，可以做一些复杂计算。ProcessWindowFunction是window function。</li></ol><p><em>ReduceFunction</em></p><p>例子: 计算每个传感器15s窗口中的温度最小值</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> minTempPerWindow: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = sensorData</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">15</span>))</span><br><span class="line">  .reduce((r1, r2) =&gt; (r1._1, r1._2.min(r2._2)))</span><br></pre></td></tr></table></figure></div><p><em>AggregateFunction</em></p><p>先来看接口定义</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public interface <span class="type">AggregateFunction</span>&lt;<span class="type">IN</span>, <span class="type">ACC</span>, <span class="type">OUT</span>&gt;</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Function</span>, <span class="type">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// create a new accumulator to start a new aggregate</span></span><br><span class="line">  <span class="type">ACC</span> createAccumulator();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// add an input element to the accumulator and return the accumulator</span></span><br><span class="line">  <span class="type">ACC</span> add(<span class="type">IN</span> value, <span class="type">ACC</span> accumulator);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// compute the result from the accumulator and return it.</span></span><br><span class="line">  <span class="type">OUT</span> getResult(<span class="type">ACC</span> accumulator);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// merge two accumulators and return the result.</span></span><br><span class="line">  <span class="type">ACC</span> merge(<span class="type">ACC</span> a, <span class="type">ACC</span> b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>IN是输入元素的类型，ACC是累加器的类型，OUT是输出元素的类型。</p><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> avgTempPerWindow: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = sensorData</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">15</span>))</span><br><span class="line">  .aggregate(<span class="keyword">new</span> <span class="type">AvgTempFunction</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// An AggregateFunction to compute the average temperature per sensor.</span></span><br><span class="line"><span class="comment">// The accumulator holds the sum of temperatures and an event count.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTempFunction</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[(<span class="type">String</span>, <span class="type">Double</span>),</span></span><br><span class="line"><span class="class">    (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>() = &#123;</span><br><span class="line">    (<span class="string">""</span>, <span class="number">0.0</span>, <span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(in: (<span class="type">String</span>, <span class="type">Double</span>), acc: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)) = &#123;</span><br><span class="line">    (in._1, in._2 + acc._2, <span class="number">1</span> + acc._3)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)) = &#123;</span><br><span class="line">    (acc._1, acc._2 / acc._3)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc1: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>),</span><br><span class="line">    acc2: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)) = &#123;</span><br><span class="line">    (acc1._1, acc1._2 + acc2._2, acc1._3 + acc2._3)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p><em>ProcessWindowFunction</em></p><p>一些业务场景，我们需要收集窗口内所有的数据进行计算，例如计算窗口数据的中位数，或者计算窗口数据中出现频率最高的值。这样的需求，使用ReduceFunction和AggregateFunction就无法实现了。这个时候就需要ProcessWindowFunction了。</p><p>先来看接口定义</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ProcessWindowFunction&lt;IN</span>, <span class="title">OUT</span>, <span class="title">KEY</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window&gt;</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AbstractRichFunction</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Evaluates the window</span></span><br><span class="line">  void process(<span class="type">KEY</span> key, <span class="type">Context</span> ctx, <span class="type">Iterable</span>&lt;<span class="type">IN</span>&gt; vals, <span class="type">Collector</span>&lt;<span class="type">OUT</span>&gt; out)</span><br><span class="line">    <span class="keyword">throws</span> <span class="type">Exception</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Deletes any custom per-window state when the window is purged</span></span><br><span class="line">  public void clear(<span class="type">Context</span> ctx) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The context holding window metadata</span></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> <span class="title">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Returns the metadata of the window</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">W</span> window();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Returns the current processing time</span></span><br><span class="line">    public <span class="keyword">abstract</span> long currentProcessingTime();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Returns the current event-time watermark</span></span><br><span class="line">    public <span class="keyword">abstract</span> long currentWatermark();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// State accessor for per-window state</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">KeyedStateStore</span> windowState();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// State accessor for per-key global state</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">KeyedStateStore</span> globalState();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Emits a record to the side output identified by the OutputTag.</span></span><br><span class="line">    public <span class="keyword">abstract</span> &lt;<span class="type">X</span>&gt; void output(<span class="type">OutputTag</span>&lt;<span class="type">X</span>&gt; outputTag, <span class="type">X</span> value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>process()方法接受的参数为：window的key，Iterable迭代器包含窗口的所有元素，Collector用于输出结果流。Context参数和别的process方法一样。而ProcessWindowFunction的Context对象还可以访问window的元数据(窗口开始和结束时间)，当前处理时间和水位线，per-window state和per-key global state，side outputs。</p><ul><li>per-window state: 用于保存一些信息，这些信息可以被process()访问，只要process所处理的元素属于这个窗口。</li><li>per-key global state: 同一个key，也就是在一条KeyedStream上，不同的window可以访问per-key global state保存的值。</li></ul><p>例子：计算5s滚动窗口中的最低和最高的温度。输出的元素包含了(流的Key, 最低温度, 最高温度, 窗口结束时间)。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> minMaxTempPerWindow: <span class="type">DataStream</span>[<span class="type">MinMaxTemp</span>] = sensorData</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">HighAndLowTempProcessFunction</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">MinMaxTemp</span>(<span class="params">id: <span class="type">String</span>, min: <span class="type">Double</span>, max: <span class="type">Double</span>, endTs: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">HighAndLowTempProcessFunction</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[<span class="type">SensorReading</span>,</span></span><br><span class="line"><span class="class">    <span class="type">MinMaxTemp</span>, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                       ctx: <span class="type">Context</span>,</span><br><span class="line">                       vals: <span class="type">Iterable</span>[<span class="type">SensorReading</span>],</span><br><span class="line">                       out: <span class="type">Collector</span>[<span class="type">MinMaxTemp</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> temps = vals.map(_.temperature)</span><br><span class="line">    <span class="keyword">val</span> windowEnd = ctx.window.getEnd</span><br><span class="line"></span><br><span class="line">    out.collect(<span class="type">MinMaxTemp</span>(key, temps.min, temps.max, windowEnd))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>我们还可以将ReduceFunction/AggregateFunction和ProcessWindowFunction结合起来使用。ReduceFunction/AggregateFunction做增量聚合，ProcessWindowFunction提供更多的对数据流的访问权限。如果只使用ProcessWindowFunction(底层的实现为将事件都保存在ListState中)，将会非常占用空间。分配到某个窗口的元素将被提前聚合，而当窗口的trigger触发时，也就是窗口收集完数据关闭时，将会把聚合结果发送到ProcessWindowFunction中，这时Iterable参数将会只有一个值，就是前面聚合的值。</p><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">input</span><br><span class="line">  .keyBy(...)</span><br><span class="line">  .timeWindow(...)</span><br><span class="line">  .reduce(</span><br><span class="line">    incrAggregator: <span class="type">ReduceFunction</span>[<span class="type">IN</span>],</span><br><span class="line">    function: <span class="type">ProcessWindowFunction</span>[<span class="type">IN</span>, <span class="type">OUT</span>, <span class="type">K</span>, <span class="type">W</span>])</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">  .keyBy(...)</span><br><span class="line">  .timeWindow(...)</span><br><span class="line">  .aggregate(</span><br><span class="line">    incrAggregator: <span class="type">AggregateFunction</span>[<span class="type">IN</span>, <span class="type">ACC</span>, <span class="type">V</span>],</span><br><span class="line">    windowFunction: <span class="type">ProcessWindowFunction</span>[<span class="type">V</span>, <span class="type">OUT</span>, <span class="type">K</span>, <span class="type">W</span>])</span><br></pre></td></tr></table></figure></div><p>我们把之前的需求重新使用以上两种方法实现一下。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">MinMaxTemp</span>(<span class="params">id: <span class="type">String</span>, min: <span class="type">Double</span>, max: <span class="type">Double</span>, endTs: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">minMaxTempPerWindow2</span></span>: <span class="type">DataStream</span>[<span class="type">MinMaxTemp</span>] = sensorData</span><br><span class="line">  .map(r =&gt; (r.id, r.temperature, r.temperature))</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">  .reduce(</span><br><span class="line">    (r1: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>), r2: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)) =&gt; &#123;</span><br><span class="line">      (r1._1, r1._2.min(r2._2), r1._3.max(r2._3))</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">AssignWindowEndProcessFunction</span>()</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AssignWindowEndProcessFunction</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>),</span></span><br><span class="line"><span class="class">    <span class="type">MinMaxTemp</span>, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                       ctx: <span class="type">Context</span>,</span><br><span class="line">                       minMaxIt: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)],</span><br><span class="line">                       out: <span class="type">Collector</span>[<span class="type">MinMaxTemp</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> minMax = minMaxIt.head</span><br><span class="line">    <span class="keyword">val</span> windowEnd = ctx.window.getEnd</span><br><span class="line">    out.collect(<span class="type">MinMaxTemp</span>(key, minMax._2, minMax._3, windowEnd))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="自定义窗口操作符-windows-operators"><a href="#自定义窗口操作符-windows-operators" class="headerlink" title="自定义窗口操作符(windows operators)"></a>自定义窗口操作符(windows operators)</h3><p>Flink内置的window operators分配器已经已经足够应付大多数应用场景。尽管如此，如果我们需要实现一些复杂的窗口逻辑，例如：可以发射早到的事件或者碰到迟到的事件就更新窗口的结果，或者窗口的开始和结束决定于特定事件的接收。</p><p>DataStream API暴露了接口和方法来自定义窗口操作符。</p><ul><li>自定义窗口分配器</li><li>自定义窗口计算触发器(trigger)</li><li>自定义窗口数据清理功能(evictor)</li></ul><p>当一个事件来到窗口操作符，首先将会传给WindowAssigner来处理。WindowAssigner决定了事件将被分配到哪些窗口。如果窗口不存在，WindowAssigner将会创建一个新的窗口。</p><p>如果一个window operator接受了一个增量聚合函数作为参数，例如ReduceFunction或者AggregateFunction，新到的元素将会立即被聚合，而聚合结果result将存储在window中。如果window operator没有使用增量聚合函数，那么新元素将被添加到ListState中，ListState中保存了所有分配给窗口的元素。</p><p>新元素被添加到窗口时，这个新元素同时也被传给了window的trigger。trigger定义了window何时准备好求值，何时window被清空。trigger可以基于window被分配的元素和注册的定时器来对窗口的所有元素求值或者在特定事件清空window中所有的元素。</p><p>当window operator只接收一个增量聚合函数作为参数时：</p><p>当window operator只接收一个全窗口函数作为参数时：</p><p>当window operator接收一个增量聚合函数和一个全窗口函数作为参数时：</p><p>evictor是一个可选的组件，可以被注入到ProcessWindowFunction之前或者之后调用。evictor可以清除掉window中收集的元素。由于evictor需要迭代所有的元素，所以evictor只能使用在没有增量聚合函数作为参数的情况下。</p><p>下面的代码说明了如果使用自定义的trigger和evictor定义一个window operator：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">  .keyBy(...)</span><br><span class="line">  .window(...)</span><br><span class="line"> [.trigger(...)]</span><br><span class="line"> [.evictor(...)]</span><br><span class="line">  .reduce/aggregate/process(...)</span><br></pre></td></tr></table></figure></div><p>注意：每个WindowAssigner都有一个默认的trigger。</p><p><em>窗口生命周期</em></p><p>当WindowAssigner分配某个窗口的第一个元素时，这个窗口才会被创建。所以不存在没有元素的窗口。</p><p>一个窗口包含了如下状态：</p><ul><li>Window content<ul><li>分配到这个窗口的元素</li><li>增量聚合的结果(如果window operator接收了ReduceFunction或者AggregateFunction作为参数)。</li></ul></li><li>Window object<ul><li>WindowAssigner返回0个，1个或者多个window object。</li><li>window operator根据返回的window object来聚合元素。</li><li>每一个window object包含一个windowEnd时间戳，来区别于其他窗口。</li></ul></li><li>触发器的定时器：一个触发器可以注册定时事件，到了定时的时间可以执行相应的回调函数，例如：对窗口进行求值或者清空窗口。</li><li>触发器中的自定义状态：触发器可以定义和使用自定义的、per-window或者per-key状态。这个状态完全被触发器所控制。而不是被window operator控制。</li></ul><p>当窗口结束时间来到，window operator将删掉这个窗口。窗口结束时间是由window object的end timestamp所定义的。无论是使用processing time还是event time，窗口结束时间是什么类型可以调用WindowAssigner.isEventTime()方法获得。</p><p><em>窗口分配器(window assigners)</em></p><p>WindowAssigner将会把元素分配到0个，1个或者多个窗口中去。我们看一下WindowAssigner接口：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowAssigner&lt;T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window&gt;</span></span></span><br><span class="line"><span class="class">    <span class="title">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="type">Collection</span>&lt;<span class="type">W</span>&gt; assignWindows(</span><br><span class="line">    <span class="type">T</span> element,</span><br><span class="line">    long timestamp,</span><br><span class="line">    <span class="type">WindowAssignerContext</span> context);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="type">Trigger</span>&lt;<span class="type">T</span>, <span class="type">W</span>&gt; getDefaultTriger(</span><br><span class="line">    <span class="type">StreamExecutionEnvironment</span> env);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="type">TypeSerializer</span>&lt;<span class="type">W</span>&gt; getWindowSerializer(</span><br><span class="line">    <span class="type">ExecutionConfig</span> executionConfig);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> boolean isEventTime();</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> static <span class="class"><span class="keyword">class</span> <span class="title">WindowAssignerContext</span> </span>&#123;</span><br><span class="line">    public <span class="keyword">abstract</span> long getCurrentProcessingTime();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>WindowAssigner有两个泛型参数：</p><ul><li>T: 事件的数据类型</li><li>W: 窗口的类型</li></ul><p>下面的代码创建了一个自定义窗口分配器，是一个30秒的滚动事件时间窗口。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThirtySecondsWindows</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">WindowAssigner</span>[<span class="type">Object</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> windowSize: <span class="type">Long</span> = <span class="number">30</span> * <span class="number">1000</span>L</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">assignWindows</span></span>(</span><br><span class="line">    o: <span class="type">Object</span>,</span><br><span class="line">    ts: <span class="type">Long</span>,</span><br><span class="line">    ctx: <span class="type">WindowAssigner</span>.<span class="type">WindowAssignerContext</span></span><br><span class="line">  ): java.util.<span class="type">List</span>[<span class="type">TimeWindow</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> startTime = ts - (ts % windowSize)</span><br><span class="line">    <span class="keyword">val</span> endTime = startTime + windowSize</span><br><span class="line">    <span class="type">Collections</span>.singletonList(<span class="keyword">new</span> <span class="type">TimeWindow</span>(startTime, endTime))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getDefaultTrigger</span></span>(</span><br><span class="line">    env: environment.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  ): <span class="type">Trigger</span>[<span class="type">Object</span>, <span class="type">TimeWindow</span>] = &#123;</span><br><span class="line">      <span class="type">EventTimeTrigger</span>.create()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getWindowSerializer</span></span>(</span><br><span class="line">    executionConfig: <span class="type">ExecutionConfig</span></span><br><span class="line">  ): <span class="type">TypeSerializer</span>[<span class="type">TimeWindow</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">TimeWindow</span>.<span class="type">Serializer</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isEventTime</span> </span>= <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>增量聚合示意图</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0604.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0604.png" class="lazyload"></a></p><p>全窗口聚合示意图</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0605.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0605.png" class="lazyload"></a></p><p>增量聚合和全窗口聚合结合使用的示意图</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0606.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0606.png" class="lazyload"></a></p><p><em>触发器(Triggers)</em></p><p>触发器定义了window何时会被求值以及何时发送求值结果。触发器可以到了特定的时间触发也可以碰到特定的事件触发。例如：观察到事件数量符合一定条件或者观察到了特定的事件。</p><p>默认的触发器将会在两种情况下触发</p><ul><li>处理时间：机器时间到达处理时间</li><li>事件时间：水位线超过了窗口的结束时间</li></ul><p>触发器可以访问流的时间属性以及定时器，还可以对state状态编程。所以触发器和process function一样强大。例如我们可以实现一个触发逻辑：当窗口接收到一定数量的元素时，触发器触发。再比如当窗口接收到一个特定元素时，触发器触发。还有就是当窗口接收到的元素里面包含特定模式(5秒钟内接收到了两个同样类型的事件)，触发器也可以触发。在一个事件时间的窗口中，一个自定义的触发器可以提前(在水位线没过窗口结束时间之前)计算和发射计算结果。这是一个常见的低延迟计算策略，尽管计算不完全，但不像默认的那样需要等待水位线没过窗口结束时间。</p><p>每次调用触发器都会产生一个TriggerResult来决定窗口接下来发生什么。TriggerResult可以取以下结果：</p><ul><li>CONTINUE：什么都不做</li><li>FIRE：如果window operator有ProcessWindowFunction这个参数，将会调用这个ProcessWindowFunction。如果窗口仅有增量聚合函数(ReduceFunction或者AggregateFunction)作为参数，那么当前的聚合结果将会被发送。窗口的state不变。</li><li>PURGE：窗口所有内容包括窗口的元数据都将被丢弃。</li><li>FIRE_AND_PURGE：先对窗口进行求值，再将窗口中的内容丢弃。</li></ul><p>TriggerResult可能的取值使得我们可以实现很复杂的窗口逻辑。一个自定义触发器可以触发多次，可以计算或者更新结果，可以在发送结果之前清空窗口。</p><p>接下来我们看一下Trigger API：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Trigger&lt;T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window&gt;</span></span></span><br><span class="line"><span class="class">    <span class="title">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">TriggerResult</span> onElement(</span><br><span class="line">    long timestamp,</span><br><span class="line">    <span class="type">W</span> window,</span><br><span class="line">    <span class="type">TriggerContext</span> ctx);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="type">TriggerResult</span> onProcessingTime(</span><br><span class="line">    long timestamp,</span><br><span class="line">    <span class="type">W</span> window,</span><br><span class="line">    <span class="type">TriggerContext</span> ctx);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="type">TriggerResult</span> onEventTime(</span><br><span class="line">    long timestamp,</span><br><span class="line">    <span class="type">W</span> window,</span><br><span class="line">    <span class="type">TriggerContext</span> ctx);</span><br><span class="line">  </span><br><span class="line">  public boolean canMerge();</span><br><span class="line"></span><br><span class="line">  public void onMerge(<span class="type">W</span> window, <span class="type">OnMergeContext</span> ctx);</span><br><span class="line"></span><br><span class="line">  public <span class="keyword">abstract</span> void clear(<span class="type">W</span> window, <span class="type">TriggerContext</span> ctx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface <span class="type">TriggerContext</span> &#123;</span><br><span class="line"></span><br><span class="line">  long getCurrentProcessingTime();</span><br><span class="line"></span><br><span class="line">  long getCurrentWatermark();</span><br><span class="line"></span><br><span class="line">  void registerProcessingTimeTimer(long time);</span><br><span class="line"></span><br><span class="line">  void registerEventTimeTimer(long time);</span><br><span class="line"></span><br><span class="line">  void deleteProcessingTimeTimer(long time);</span><br><span class="line"></span><br><span class="line">  void deleteEventTimeTimer(long time);</span><br><span class="line"></span><br><span class="line">  &lt;<span class="type">S</span> <span class="keyword">extends</span> <span class="type">State</span>&gt; <span class="type">S</span> getPartitionedState(</span><br><span class="line">    <span class="type">StateDescriptor</span>&lt;<span class="type">S</span>, ?&gt; stateDescriptor);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface <span class="type">OnMergeContext</span> <span class="keyword">extends</span> <span class="type">TriggerContext</span> &#123;</span><br><span class="line"></span><br><span class="line">  void mergePartitionedState(</span><br><span class="line">    <span class="type">StateDescriptor</span>&lt;<span class="type">S</span>, ?&gt; stateDescriptor</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>这里要注意两个地方：清空state和merging合并触发器。</p><p>当在触发器中使用per-window state时，这里我们需要保证当窗口被删除时state也要被删除，否则随着时间的推移，window operator将会积累越来越多的数据，最终可能使应用崩溃。</p><p>当窗口被删除时，为了清空所有状态，触发器的clear()方法需要需要删掉所有的自定义per-window state，以及使用TriggerContext对象将处理时间和事件时间的定时器都删除。</p><p>下面的例子展示了一个触发器在窗口结束时间之前触发。当第一个事件被分配到窗口时，这个触发器注册了一个定时器，定时时间为水位线之前一秒钟。当定时事件执行，将会注册一个新的定时事件，这样，这个触发器每秒钟最多触发一次。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OneSecondIntervalTrigger</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">Trigger</span>[<span class="type">SensorReading</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onElement</span></span>(</span><br><span class="line">    r: <span class="type">SensorReading</span>,</span><br><span class="line">    timestamp: <span class="type">Long</span>,</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    ctx: <span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line">  ): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> firstSeen: <span class="type">ValueState</span>[<span class="type">Boolean</span>] = ctx</span><br><span class="line">      .getPartitionedState(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Boolean</span>](</span><br><span class="line">          <span class="string">"firstSeen"</span>, classOf[<span class="type">Boolean</span>]</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!firstSeen.value()) &#123;</span><br><span class="line">      <span class="keyword">val</span> t = ctx.getCurrentWatermark</span><br><span class="line">       + (<span class="number">1000</span> - (ctx.getCurrentWatermark % <span class="number">1000</span>))</span><br><span class="line">      ctx.registerEventTimeTimer(t)</span><br><span class="line">      ctx.registerEventTimeTimer(window.getEnd)</span><br><span class="line">      firstSeen.update(<span class="literal">true</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">TriggerResult</span>.<span class="type">CONTINUE</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onEventTime</span></span>(</span><br><span class="line">    timestamp: <span class="type">Long</span>,</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    ctx: <span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line">  ): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (timestamp == window.getEnd) &#123;</span><br><span class="line">      <span class="type">TriggerResult</span>.<span class="type">FIRE_AND_PURGE</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> t = ctx.getCurrentWatermark</span><br><span class="line">       + (<span class="number">1000</span> - (ctx.getCurrentWatermark % <span class="number">1000</span>))</span><br><span class="line">      <span class="keyword">if</span> (t &lt; window.getEnd) &#123;</span><br><span class="line">        ctx.registerEventTimeTimer(t)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">TriggerResult</span>.<span class="type">FIRE</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onProcessingTime</span></span>(</span><br><span class="line">    timestamp: <span class="type">Long</span>,</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    ctx: <span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line">  ): <span class="type">TriggerResult</span> = &#123;</span><br><span class="line">    <span class="type">TriggerResult</span>.<span class="type">CONTINUE</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">clear</span></span>(</span><br><span class="line">    window: <span class="type">TimeWindow</span>,</span><br><span class="line">    ctx: <span class="type">Trigger</span>.<span class="type">TriggerContext</span></span><br><span class="line">  ): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> firstSeen: <span class="type">ValueState</span>[<span class="type">Boolean</span>] = ctx</span><br><span class="line">      .getPartitionedState(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Boolean</span>](</span><br><span class="line">          <span class="string">"firstSeen"</span>, classOf[<span class="type">Boolean</span>]</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    firstSeen.clear()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p><em>清理器(EVICTORS)</em></p><p>evictor可以在window function求值之前或者之后移除窗口中的元素。</p><p>我们看一下Evictor的接口定义：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public interface <span class="type">Evictor</span>&lt;<span class="type">T</span>, <span class="type">W</span> <span class="keyword">extends</span> <span class="type">Window</span>&gt;</span><br><span class="line">    <span class="keyword">extends</span> <span class="type">Serializable</span> &#123;</span><br><span class="line">  void evictBefore(</span><br><span class="line">    <span class="type">Iterable</span>&lt;<span class="type">TimestampedValue</span>&lt;<span class="type">T</span>&gt;&gt; elements,</span><br><span class="line">    int size,</span><br><span class="line">    <span class="type">W</span> window,</span><br><span class="line">    <span class="type">EvictorContext</span> evictorContext);</span><br><span class="line"></span><br><span class="line">  void evictAfter(</span><br><span class="line">    <span class="type">Iterable</span>&lt;<span class="type">TimestampedValue</span>&lt;<span class="type">T</span>&gt;&gt; elements,</span><br><span class="line">    int size,</span><br><span class="line">    <span class="type">W</span> window,</span><br><span class="line">    <span class="type">EvictorContext</span> evictorContext);</span><br><span class="line"></span><br><span class="line">  interface <span class="type">EvictorContext</span> &#123;</span><br><span class="line"></span><br><span class="line">    long getCurrentProcessingTime();</span><br><span class="line"></span><br><span class="line">    long getCurrentWatermark();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>evictBefore()和evictAfter()分别在window function计算之前或者之后调用。Iterable迭代器包含了窗口所有的元素，size为窗口中元素的数量，window object和EvictorContext可以访问当前处理时间和水位线。可以对Iterator调用remove()方法来移除窗口中的元素。</p><p>evictor也经常被用在GlobalWindow上，用来清除部分元素，而不是将窗口中的元素全部清空。</p><h2 id="基于时间的双流Join"><a href="#基于时间的双流Join" class="headerlink" title="基于时间的双流Join"></a>基于时间的双流Join</h2><p>数据流操作的另一个常见需求是对两条数据流中的事件进行联结（connect）或Join。Flink DataStream API中内置有两个可以根据时间条件对数据流进行Join的算子：基于间隔的Join和基于窗口的Join。本节我们会对它们进行介绍。</p><p>如果Flink内置的Join算子无法表达所需的Join语义，那么你可以通过CoProcessFunction、BroadcastProcessFunction或KeyedBroadcastProcessFunction实现自定义的Join逻辑。</p><blockquote><p>注意，你要设计的Join算子需要具备高效的状态访问模式及有效的状态清理策略。</p></blockquote><h3 id="基于间隔的Join"><a href="#基于间隔的Join" class="headerlink" title="基于间隔的Join"></a>基于间隔的Join</h3><p>基于间隔的Join会对两条流中拥有相同键值以及彼此之间时间戳不超过某一指定间隔的事件进行Join。</p><p>下图展示了两条流（A和B）上基于间隔的Join，如果B中事件的时间戳相较于A中事件的时间戳不早于1小时且不晚于15分钟，则会将两个事件Join起来。Join间隔具有对称性，因此上面的条件也可以表示为A中事件的时间戳相较B中事件的时间戳不早于15分钟且不晚于1小时。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0607.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0607.png" class="lazyload"></a></p><p>基于间隔的Join目前只支持事件时间以及INNER JOIN语义（无法发出未匹配成功的事件）。下面的例子定义了一个基于间隔的Join。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input1</span><br><span class="line">  .keyBy(...)</span><br><span class="line">  .between(&lt;lower-bound&gt;, &lt;upper-bound&gt;) <span class="comment">// 相对于input1的上下界</span></span><br><span class="line">  .process(<span class="type">ProcessJoinFunction</span>) <span class="comment">// 处理匹配的事件对</span></span><br></pre></td></tr></table></figure></div><p>Join成功的事件对会发送给ProcessJoinFunction。下界和上界分别由负时间间隔和正时间间隔来定义，例如between(Time.hour(-1), Time.minute(15))。在满足下界值小于上界值的前提下，你可以任意对它们赋值。例如，允许出现B中事件的时间戳相较A中事件的时间戳早1～2小时这样的条件。</p><p>基于间隔的Join需要同时对双流的记录进行缓冲。对第一个输入而言，所有时间戳大于当前水位线减去间隔上界的数据都会被缓冲起来；对第二个输入而言，所有时间戳大于当前水位线加上间隔下界的数据都会被缓冲起来。注意，两侧边界值都有可能为负。上图中的Join需要存储数据流A中所有时间戳大于当前水位线减去15分钟的记录，以及数据流B中所有时间戳大于当前水位线减去1小时的记录。不难想象，如果两条流的事件时间不同步，那么Join所需的存储就会显著增加，因为水位线总是由“较慢”的那条流来决定。</p><p>例子：每个用户的点击Join这个用户最近10分钟内的浏览</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.co.<span class="type">ProcessJoinFunction</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions</span><br><span class="line">.timestamps.<span class="type">BoundedOutOfOrdernessTimestampExtractor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"><span class="keyword">import</span> org.joda.time.<span class="type">DateTime</span></span><br><span class="line"><span class="keyword">import</span> org.joda.time.format.<span class="type">DateTimeFormat</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 需求：每个用户的点击Join这个用户最近10分钟内的浏览</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据流clickStream</span></span><br><span class="line"><span class="comment">// 某个用户在某个时刻点击了某个页面</span></span><br><span class="line"><span class="comment">// &#123;"userID": "user_2", "eventTime": "2019-11-16 17:30:02", "eventType": "click", "pageID": "page_1"&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据流browseStream</span></span><br><span class="line"><span class="comment">// 某个用户在某个时刻浏览了某个商品，以及商品的价值</span></span><br><span class="line"><span class="comment">// &#123;"userID": "user_2", "eventTime": "2019-11-16 17:30:01", "eventType": "browse", "productID": "product_1", "productPrice": 10&#125;</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">IntervalJoinExample</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserClickLog</span>(<span class="params">userID: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          eventTime: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          pageID: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">case</span> <span class="title">class</span> <span class="title">UserBrowseLog</span>(<span class="params">userID: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                           eventTime: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                           eventType: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                           productID: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                           productPrice: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">def</span> <span class="title">main</span>(<span class="params">args: <span class="type">Array</span>[<span class="type">String</span>]</span>)</span>: <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> clickStream = env</span><br><span class="line">      .fromElements(</span><br><span class="line">        <span class="type">UserClickLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:30:00"</span>, <span class="string">"click"</span>, <span class="string">"page_1"</span>)</span><br><span class="line">      )</span><br><span class="line">      .assignTimestampsAndWatermarks(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">UserClickLog</span>](<span class="type">Time</span>.seconds(<span class="number">0</span>)) &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(t: <span class="type">UserClickLog</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            <span class="keyword">val</span> dateTimeFormatter = <span class="type">DateTimeFormat</span>.forPattern(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line">            <span class="keyword">val</span> dateTime = <span class="type">DateTime</span>.parse(t.eventTime, dateTimeFormatter)</span><br><span class="line">            dateTime.getMillis</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> browseStream = env</span><br><span class="line">      .fromElements(</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:19:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>),</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:20:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>),</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:22:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>),</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:26:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>),</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:30:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>),</span><br><span class="line">        <span class="type">UserBrowseLog</span>(<span class="string">"user_2"</span>, <span class="string">"2019-11-16 17:31:00"</span>, <span class="string">"browse"</span>, <span class="string">"product_1"</span>, <span class="string">"10"</span>)</span><br><span class="line">      )</span><br><span class="line">      .assignTimestampsAndWatermarks(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">UserBrowseLog</span>](<span class="type">Time</span>.seconds(<span class="number">0</span>)) &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(t: <span class="type">UserBrowseLog</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            <span class="keyword">val</span> dateTimeFormatter = <span class="type">DateTimeFormat</span>.forPattern(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line">            <span class="keyword">val</span> dateTime = <span class="type">DateTime</span>.parse(t.eventTime, dateTimeFormatter)</span><br><span class="line">            dateTime.getMillis</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    clickStream</span><br><span class="line">      .keyBy(<span class="string">"userID"</span>)</span><br><span class="line">      .intervalJoin(browseStream.keyBy(<span class="string">"userID"</span>))</span><br><span class="line">      .between(<span class="type">Time</span>.minutes(<span class="number">-10</span>),<span class="type">Time</span>.seconds(<span class="number">0</span>))</span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">MyIntervalJoin</span>)</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyIntervalJoin</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessJoinFunction</span>[<span class="type">UserClickLog</span>, <span class="type">UserBrowseLog</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      left: <span class="type">UserClickLog</span>,</span><br><span class="line">      right: <span class="type">UserBrowseLog</span>,</span><br><span class="line">      context: <span class="type">ProcessJoinFunction</span>[<span class="type">UserClickLog</span>, <span class="type">UserBrowseLog</span>, <span class="type">String</span>]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">String</span>]</span><br><span class="line">    ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      out.collect(left +<span class="string">" =Interval Join=&gt; "</span>+right)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="基于窗口的Join"><a href="#基于窗口的Join" class="headerlink" title="基于窗口的Join"></a>基于窗口的Join</h3><p>顾名思义，基于窗口的Join需要用到Flink中的窗口机制。其原理是将两条输入流中的元素分配到公共窗口中并在窗口完成时进行Join（或Cogroup）。</p><p>下面的例子展示了如何定义基于窗口的Join。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">input1.join(input2)</span><br><span class="line">  .where(...)       <span class="comment">// 为input1指定键值属性</span></span><br><span class="line">  .equalTo(...)     <span class="comment">// 为input2指定键值属性</span></span><br><span class="line">  .window(...)      <span class="comment">// 指定WindowAssigner</span></span><br><span class="line">  [.trigger(...)]   <span class="comment">// 选择性的指定Trigger</span></span><br><span class="line">  [.evictor(...)]   <span class="comment">// 选择性的指定Evictor</span></span><br><span class="line">  .apply(...)       <span class="comment">// 指定JoinFunction</span></span><br></pre></td></tr></table></figure></div><p>下图展示了DataStream API中基于窗口的Join是如何工作的。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0608.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0608.png" class="lazyload"></a></p><p>两条输入流都会根据各自的键值属性进行分区，公共窗口分配器会将二者的事件映射到公共窗口内（其中同时存储了两条流中的数据）。当窗口的计时器触发时，算子会遍历两个输入中元素的每个组合（叉乘积）去调用JoinFunction。同时你也可以自定义触发器或移除器。由于两条流中的事件会被映射到同一个窗口中，因此该过程中的触发器和移除器与常规窗口算子中的完全相同。</p><p>除了对窗口中的两条流进行Join，你还可以对它们进行Cogroup，只需将算子定义开始位置的join改为coGroup()即可。Join和Cogroup的总体逻辑相同，二者的唯一区别是：Join会为两侧输入中的每个事件对调用JoinFunction；而Cogroup中用到的CoGroupFunction会以两个输入的元素遍历器为参数，只在每个窗口中被调用一次。</p><blockquote><p>注意，对划分窗口后的数据流进行Join可能会产生意想不到的语义。例如，假设你为执行Join操作的算子配置了1小时的滚动窗口，那么一旦来自两个输入的元素没有被划分到同一窗口，它们就无法Join在一起，即使二者彼此仅相差1秒钟。</p></blockquote><h2 id="处理迟到的元素-Handling-Late-Data"><a href="#处理迟到的元素-Handling-Late-Data" class="headerlink" title="处理迟到的元素(Handling Late Data)"></a>处理迟到的元素(Handling Late Data)</h2><p>水位线可以用来平衡计算的完整性和延迟两方面。除非我们选择一种非常保守的水位线策略(最大延时设置的非常大，以至于包含了所有的元素，但结果是非常大的延迟)，否则我们总需要处理迟到的元素。</p><p>迟到的元素是指当这个元素来到时，这个元素所对应的窗口已经计算完毕了(也就是说水位线已经没过窗口结束时间了)。这说明迟到这个特性只针对事件时间。</p><p>DataStream API提供了三种策略来处理迟到元素</p><ul><li>直接抛弃迟到的元素</li><li>将迟到的元素发送到另一条流中去</li><li>可以更新窗口已经计算完的结果，并发出计算结果。</li></ul><h3 id="抛弃迟到元素"><a href="#抛弃迟到元素" class="headerlink" title="抛弃迟到元素"></a>抛弃迟到元素</h3><p>抛弃迟到的元素是event time window operator的默认行为。也就是说一个迟到的元素不会创建一个新的窗口。</p><p>process function可以通过比较迟到元素的时间戳和当前水位线的大小来很轻易的过滤掉迟到元素。</p><h3 id="重定向迟到元素"><a href="#重定向迟到元素" class="headerlink" title="重定向迟到元素"></a>重定向迟到元素</h3><p>迟到的元素也可以使用侧输出(side output)特性被重定向到另外的一条流中去。迟到元素所组成的侧输出流可以继续处理或者sink到持久化设施中去。</p><p>例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings = env</span><br><span class="line">  .socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>, '\n')</span><br><span class="line">  .map(line =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> arr = line.split(<span class="string">" "</span>)</span><br><span class="line">    (arr(<span class="number">0</span>), arr(<span class="number">1</span>).toLong * <span class="number">1000</span>)</span><br><span class="line">  &#125;)</span><br><span class="line">  .assignAscendingTimestamps(_._2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> countPer10Secs = readings</span><br><span class="line">  .keyBy(_._1)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">10</span>))</span><br><span class="line">  .sideOutputLateData(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">OutputTag</span>[(<span class="type">String</span>, <span class="type">Long</span>)](<span class="string">"late-readings"</span>)</span><br><span class="line">  )</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">CountFunction</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lateStream = countPer10Secs</span><br><span class="line">  .getSideOutput(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">OutputTag</span>[(<span class="type">String</span>, <span class="type">Long</span>)](<span class="string">"late-readings"</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">lateStream.print()</span><br></pre></td></tr></table></figure></div><p>实现<code>CountFunction</code>:</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountFunction</span> <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[(<span class="type">String</span>, <span class="type">Long</span>),</span></span><br><span class="line"><span class="class">  <span class="type">String</span>, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>,</span><br><span class="line">                       context: <span class="type">Context</span>,</span><br><span class="line">                       elements: <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Long</span>)],</span><br><span class="line">                       out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    out.collect(<span class="string">"窗口共有"</span> + elements.size + <span class="string">"条数据"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>下面这个例子展示了ProcessFunction如何过滤掉迟到的元素然后将迟到的元素发送到侧输出流中去。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ???</span><br><span class="line"><span class="keyword">val</span> filteredReadings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = readings</span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">LateReadingsFilter</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// retrieve late readings</span></span><br><span class="line"><span class="keyword">val</span> lateReadings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = filteredReadings</span><br><span class="line">  .getSideOutput(<span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">SensorReading</span>](<span class="string">"late-readings"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/** A ProcessFunction that filters out late sensor readings and </span></span><br><span class="line"><span class="comment">  * re-directs them to a side output */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LateReadingsFilter</span> </span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessFunction</span>[<span class="type">SensorReading</span>, <span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lateReadingsOut = <span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">SensorReading</span>](<span class="string">"late-readings"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(</span><br><span class="line">      r: <span class="type">SensorReading</span>,</span><br><span class="line">      ctx: <span class="type">ProcessFunction</span>[<span class="type">SensorReading</span>, <span class="type">SensorReading</span>]#<span class="type">Context</span>,</span><br><span class="line">      out: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// compare record timestamp with current watermark</span></span><br><span class="line">    <span class="keyword">if</span> (r.timestamp &lt; ctx.timerService().currentWatermark()) &#123;</span><br><span class="line">      <span class="comment">// this is a late reading =&gt; redirect it to the side output</span></span><br><span class="line">      ctx.output(lateReadingsOut, r)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      out.collect(r)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="使用迟到元素更新窗口计算结果-Updating-Results-by-Including-Late-Events"><a href="#使用迟到元素更新窗口计算结果-Updating-Results-by-Including-Late-Events" class="headerlink" title="使用迟到元素更新窗口计算结果(Updating Results by Including Late Events)"></a>使用迟到元素更新窗口计算结果(Updating Results by Including Late Events)</h3><p>由于存在迟到的元素，所以已经计算出的窗口结果是不准确和不完全的。我们可以使用迟到元素更新已经计算完的窗口结果。</p><p>如果我们要求一个operator支持重新计算和更新已经发出的结果，就需要在第一次发出结果以后也要保存之前所有的状态。但显然我们不能一直保存所有的状态，肯定会在某一个时间点将状态清空，而一旦状态被清空，结果就再也不能重新计算或者更新了。而迟到的元素只能被抛弃或者发送到侧输出流。</p><p>window operator API提供了方法来明确声明我们要等待迟到元素。当使用event-time window，我们可以指定一个时间段叫做allowed lateness。window operator如果设置了allowed lateness，这个window operator在水位线没过窗口结束时间时也将不会删除窗口和窗口中的状态。窗口会在一段时间内(allowed lateness设置的)保留所有的元素。</p><p>当迟到元素在allowed lateness时间内到达时，这个迟到元素会被实时处理并发送到触发器(trigger)。当水位线没过了窗口结束时间+allowed lateness时间时，窗口会被删除，并且所有后来的迟到的元素都会被丢弃。</p><p>Allowed lateness可以使用allowedLateness()方法来指定，如下所示：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> countPer10Secs: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Int</span>, <span class="type">String</span>)] = readings</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">10</span>))</span><br><span class="line">  <span class="comment">// process late readings for 5 additional seconds</span></span><br><span class="line">  .allowedLateness(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">  <span class="comment">// count readings and update results if late readings arrive</span></span><br><span class="line">  .process(<span class="keyword">new</span> <span class="type">UpdatingWindowCountFunction</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** A counting WindowProcessFunction that distinguishes between </span></span><br><span class="line"><span class="comment">  * first results and updates. */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UpdatingWindowCountFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[<span class="type">SensorReading</span>,</span></span><br><span class="line"><span class="class">      (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Int</span>, <span class="type">String</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(</span><br><span class="line">      id: <span class="type">String</span>,</span><br><span class="line">      ctx: <span class="type">Context</span>,</span><br><span class="line">      elements: <span class="type">Iterable</span>[<span class="type">SensorReading</span>],</span><br><span class="line">      out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Int</span>, <span class="type">String</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// count the number of readings</span></span><br><span class="line">    <span class="keyword">val</span> cnt = elements.count(_ =&gt; <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// state to check if this is</span></span><br><span class="line">    <span class="comment">// the first evaluation of the window or not</span></span><br><span class="line">    <span class="keyword">val</span> isUpdate = ctx.windowState.getState(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Boolean</span>](</span><br><span class="line">        <span class="string">"isUpdate"</span>,</span><br><span class="line">        <span class="type">Types</span>.of[<span class="type">Boolean</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!isUpdate.value()) &#123;</span><br><span class="line">      <span class="comment">// first evaluation, emit first result</span></span><br><span class="line">      out.collect((id, ctx.window.getEnd, cnt, <span class="string">"first"</span>))</span><br><span class="line">      isUpdate.update(<span class="literal">true</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// not the first evaluation, emit an update</span></span><br><span class="line">      out.collect((id, ctx.window.getEnd, cnt, <span class="string">"update"</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第六章，基于时间和窗口的操作符&quot;&gt;&lt;a href=&quot;#第六章，基于时间和窗口的操作符&quot; class=&quot;headerlink&quot; title=&quot;第六章，基于时间和窗口的操作符&quot;&gt;&lt;/a&gt;第六章，基于时间和窗口的操作符&lt;/h1&gt;&lt;p&gt;在本章，我们将要学习DataStre
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flume源码修改之flumeTailDirSource兼容log4j</title>
    <link href="https://masteryang4.github.io/2020/06/30/flume%E6%BA%90%E7%A0%81%E4%BF%AE%E6%94%B9%E4%B9%8BflumeTailDirSource%E5%85%BC%E5%AE%B9log4j/"/>
    <id>https://masteryang4.github.io/2020/06/30/flume%E6%BA%90%E7%A0%81%E4%BF%AE%E6%94%B9%E4%B9%8BflumeTailDirSource%E5%85%BC%E5%AE%B9log4j/</id>
    <published>2020-06-30T13:41:57.000Z</published>
    <updated>2020-06-30T14:49:36.440Z</updated>
    
    <content type="html"><![CDATA[<h1 id="tailDir-Source"><a href="#tailDir-Source" class="headerlink" title="tailDir Source"></a>tailDir Source</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>1）断点续传</p><p>2）同时监控多目录</p><h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>1）说明：使用<strong>正则表达式</strong>监控文件名时，当修改文件名称之后，会重复读取数据。</p><p>2）示例：</p><p>配置信息 test.conf</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line"></span><br><span class="line"># Describe&#x2F;configure the source</span><br><span class="line">a1.sources.r1.type &#x3D; TAILDIR</span><br><span class="line">a1.sources.r1.filegroups &#x3D; f1</span><br><span class="line">a1.sources.r1.filegroups.f1 &#x3D; &#x2F;opt&#x2F;module&#x2F;data&#x2F;flume.*</span><br><span class="line">a1.sources.r1.positionFile &#x3D; &#x2F;opt&#x2F;module&#x2F;flume&#x2F;taildir&#x2F;taildir_flume.json</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure></div><p>3）启动任务</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop102 flume]$ bin/flume-ng agent -n a1 -c conf -f conf/test.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure></div><p>4）测试</p><p>（1）在/opt/module/data目录下创建flume.log</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop102 data]$ pwd</span><br><span class="line">/opt/module/data</span><br><span class="line">[ysss@hadoop102 data]$ touch flume.log</span><br></pre></td></tr></table></figure></div><p>（2）向flume.log文件中添加数据</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop102 data]$ echo hello &gt;&gt; flume.log </span><br><span class="line">[ysss@hadoop102 data]$ echo ysss &gt;&gt; flume.log</span><br></pre></td></tr></table></figure></div><p>（3）查看监控Flume控制台</p><p>（4）修改flume.log为flume.2020-06-09.log</p><p>（5）再次查看监控Flume控制台</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>1）方案一</p><p>跟公司后台人员协商；</p><p>让他们使用类似<code>logback</code>不更名打印日志框架，不要使用<code>log4j</code>会更名的打印日志框架。对于不想协商、项目经理或组长偏向JAVA组的，只能使用方案二了。</p><p>2）方案二</p><p>修改TailDirSource源码:</p><p>1、flume-taildir-source\src\main\java\org\apache\flume\source\taildir\TailFile.java</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">updatePos</span><span class="params">(String path, <span class="keyword">long</span> inode, <span class="keyword">long</span> pos)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//    if (this.inode == inode &amp;&amp; this.path.equals(path)) &#123;</span></span><br><span class="line">        <span class="comment">//    ysss</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.inode == inode) &#123;</span><br><span class="line">            setPos(pos);</span><br><span class="line">            updateFilePos(pos);</span><br><span class="line">            logger.info(<span class="string">"Updated position, file: "</span> + path + <span class="string">", inode: "</span> + inode + <span class="string">", pos: "</span> + pos);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div><p>2、\src\main\java\org\apache\flume\source\taildir\ReliableTaildirEventReader.java</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">**</span><br><span class="line">     * Update tailFiles mapping <span class="keyword">if</span> a <span class="keyword">new</span> file is created or appends are detected</span><br><span class="line">     * to the existing file.</span><br><span class="line">     */</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Long&gt; <span class="title">updateTailFiles</span><span class="params">(<span class="keyword">boolean</span> skipToEnd)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        updateTime = System.currentTimeMillis();</span><br><span class="line">        List&lt;Long&gt; updatedInodes = Lists.newArrayList();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (TaildirMatcher taildir : taildirCache) &#123;</span><br><span class="line">            Map&lt;String, String&gt; headers = headerTable.row(taildir.getFileGroup());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (File f : taildir.getMatchingFiles()) &#123;</span><br><span class="line">                <span class="keyword">long</span> inode;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    inode = getInode(f);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (NoSuchFileException e) &#123;</span><br><span class="line">                    logger.info(<span class="string">"File has been deleted in the meantime: "</span> + e.getMessage());</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                TailFile tf = tailFiles.get(inode);</span><br><span class="line">                <span class="comment">//if (tf == null || !tf.getPath().equals(f.getAbsolutePath())) &#123;</span></span><br><span class="line">                <span class="comment">//ysss</span></span><br><span class="line">                <span class="keyword">if</span> (tf == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">long</span> startPos = skipToEnd ? f.length() : <span class="number">0</span>;</span><br><span class="line">                    tf = openFile(f, headers, inode, startPos);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">boolean</span> updated = tf.getLastUpdated() &lt; f.lastModified() || tf.getPos() != f.length();</span><br><span class="line">                    <span class="keyword">if</span> (updated) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (tf.getRaf() == <span class="keyword">null</span>) &#123;</span><br><span class="line">                            tf = openFile(f, headers, inode, tf.getPos());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (f.length() &lt; tf.getPos()) &#123;</span><br><span class="line">                            logger.info(<span class="string">"Pos "</span> + tf.getPos() + <span class="string">" is larger than file size! "</span></span><br><span class="line">                                    + <span class="string">"Restarting from pos 0, file: "</span> + tf.getPath() + <span class="string">", inode: "</span> + inode);</span><br><span class="line">                            tf.updatePos(tf.getPath(), inode, <span class="number">0</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    tf.setNeedTail(updated);</span><br><span class="line">                &#125;</span><br><span class="line">                tailFiles.put(inode, tf);</span><br><span class="line">                updatedInodes.add(inode);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> updatedInodes;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><blockquote><p>taildir和logback配合使用，为什么不是log4j？</p><p>logback的日志：ysss.2020-05-18.log，ysss.2020-05-19.log</p><p>Log4j的日志：ysss.log -&gt; ysss.2020-05-18.log，在一天过去之后，改名为后者存盘</p><p>Linux对于文件而言</p><p>​        (1) 全路径</p><p>​        (2) Inode(Linux文件的唯一标识,修改名称不会改动INode值)</p><p>但是tailDirSource的工作机制：文件更名或者INode改变都会被识别为一个新文件！也就是说，如果使用log4j，日志会更名，被tailDirSource识别为一个新文件，重复读取。</p><p>如果非要使用log4j怎么办呢？</p><p>改flume源码！只有INode改变才会是被为一个新文件！</p></blockquote><ul><li><p><code>source\taildir\TailFile.java</code> 的 <code>updatePos</code> 方法</p></li><li><p><code>source\taildir\ReliableTaildirEventReader.java</code> 的 <code>updateTailFiles</code> 方法</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;tailDir-Source&quot;&gt;&lt;a href=&quot;#tailDir-Source&quot; class=&quot;headerlink&quot; title=&quot;tailDir Source&quot;&gt;&lt;/a&gt;tailDir Source&lt;/h1&gt;&lt;h2 id=&quot;优点&quot;&gt;&lt;a href=&quot;#优点&quot;
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flume" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flume/"/>
    
    
      <category term="源码" scheme="https://masteryang4.github.io/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flume" scheme="https://masteryang4.github.io/tags/flume/"/>
    
  </entry>
  
  <entry>
    <title>flume拦截器之flumeHDFS_Sink时间问题</title>
    <link href="https://masteryang4.github.io/2020/06/30/flume%E6%8B%A6%E6%88%AA%E5%99%A8%E4%B9%8BflumeHDFS-Sink%E6%97%B6%E9%97%B4%E9%97%AE%E9%A2%98/"/>
    <id>https://masteryang4.github.io/2020/06/30/flume%E6%8B%A6%E6%88%AA%E5%99%A8%E4%B9%8BflumeHDFS-Sink%E6%97%B6%E9%97%B4%E9%97%AE%E9%A2%98/</id>
    <published>2020-06-30T13:38:37.000Z</published>
    <updated>2020-06-30T13:43:23.484Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HDFS-Sink存在的问题"><a href="#HDFS-Sink存在的问题" class="headerlink" title="HDFS Sink存在的问题"></a>HDFS Sink存在的问题</h1><p><code>hdfs.useLocalTimeStamp</code>设置为<code>true</code>，也会在Event头信息中添加”timestamp”的key</p><p>我们一般设置为false，因为我们目前使用的是KafkaSource，会根据<strong>当前系统时间</strong>添加该头信息。</p><p><a href="https://pic.downk.cc/item/5efb3b1414195aa5949f15ae.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5efb3b1414195aa5949f15ae.png" class="lazyload"></a></p><blockquote><p>说明：HDFS Sink要想根据时间滚动文件夹，必须在Event头信息中添加”timestamp”的key用于提供给HDFS Sink使用。</p><p>我们目前使用的是KafkaSource，会根据当前系统时间添加该头信息。</p></blockquote><p><strong>问题：我们使用的是按照每天的具体时间来创建新的目录，假如我们Flume任务在夜间11点多挂了，零点以后任务才被重新启动，那么昨天的挂掉之后的数据就会被算作第二天的数据了。</strong></p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p><strong>我们需要根据事件内部时间来控制HDFS目录时间的创建，</strong></p><p>思路为<strong>自定义拦截器</strong>来修改KafkaSource自动添加的时间戳。</p><blockquote><p>使用事件内部时间【替换】KafkaSource自动添加的时间戳</p></blockquote><p>1）创建Maven工程flume-interceptor</p><p>2）创建包名：com.ysss.flume.interceptor</p><p>3）在pom.xml文件中添加如下配置</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.62<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>4）在com.ysss.flume.interceptor包下创建TimeStampInterceptor类</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ysss.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeStampInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;Event&gt; events = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line">        String log = <span class="keyword">new</span> String(event.getBody(), StandardCharsets.UTF_8);</span><br><span class="line"></span><br><span class="line">        JSONObject jsonObject = JSONObject.parseObject(log);</span><br><span class="line"></span><br><span class="line">        String ts = jsonObject.getString(<span class="string">"ts"</span>);</span><br><span class="line">        headers.put(<span class="string">"timestamp"</span>, ts);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;</span><br><span class="line">        events.clear();</span><br><span class="line">        <span class="keyword">for</span> (Event event : list) &#123;</span><br><span class="line">            events.add(intercept(event));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> events;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span> </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> TimeStampInterceptor();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>5）打包</p><p>flume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar</p><p>6）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop102 lib]$ ls | grep interceptor</span><br><span class="line">flume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br></pre></td></tr></table></figure></div><p>7）分发Flume到hadoop103、hadoop104</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop102 module]$ xsync flume/</span><br></pre></td></tr></table></figure></div><h1 id="调整消费Flume配置文件"><a href="#调整消费Flume配置文件" class="headerlink" title="调整消费Flume配置文件"></a>调整消费Flume配置文件</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ysss@hadoop104 conf]$ pwd</span><br><span class="line">/opt/module/flume/conf</span><br></pre></td></tr></table></figure></div><p>修改配置文件kafka-flume-hdfs.conf</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#组件</span><br><span class="line">a1.sources&#x3D;r1</span><br><span class="line">a1.channels&#x3D;c1</span><br><span class="line">a1.sinks&#x3D;k1</span><br><span class="line"></span><br><span class="line">#source</span><br><span class="line">a1.sources.r1.type &#x3D; org.apache.flume.source.kafka.KafkaSource</span><br><span class="line">a1.sources.r1.batchSize &#x3D; 5000</span><br><span class="line">a1.sources.r1.batchDurationMillis &#x3D; 2000</span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers &#x3D; hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">a1.sources.r1.kafka.topics&#x3D;topic_log</span><br><span class="line">a1.sources.r1.interceptors &#x3D; i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type &#x3D; com.ysss.interceptor.TimeStampInterceptor$Builder  #【注意】</span><br><span class="line"></span><br><span class="line">#channel</span><br><span class="line">a1.channels.c1.type &#x3D; file</span><br><span class="line">a1.channels.c1.checkpointDir &#x3D; &#x2F;opt&#x2F;module&#x2F;flume&#x2F;checkpoint&#x2F;behavior1</span><br><span class="line">a1.channels.c1.dataDirs &#x3D; &#x2F;opt&#x2F;module&#x2F;flume&#x2F;data&#x2F;behavior1&#x2F;</span><br><span class="line">a1.channels.c1.maxFileSize &#x3D; 2146435071</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000000</span><br><span class="line">a1.channels.c1.keep-alive &#x3D; 6</span><br><span class="line"></span><br><span class="line">#sink</span><br><span class="line">a1.sinks.k1.type &#x3D; hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path &#x3D; &#x2F;origin_data&#x2F;gmall&#x2F;log&#x2F;topic_log&#x2F;%Y-%m-%d</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix &#x3D; log-</span><br><span class="line">a1.sinks.k1.hdfs.round &#x3D; false</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval &#x3D; 10</span><br><span class="line">a1.sinks.k1.hdfs.rollSize &#x3D; 134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollCount &#x3D; 0</span><br><span class="line"></span><br><span class="line">#控制输出文件是原生文件。</span><br><span class="line">a1.sinks.k1.hdfs.fileType &#x3D; CompressedStream</span><br><span class="line">a1.sinks.k1.hdfs.codeC &#x3D; lzop</span><br><span class="line"></span><br><span class="line">#拼装</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel&#x3D; c1</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HDFS-Sink存在的问题&quot;&gt;&lt;a href=&quot;#HDFS-Sink存在的问题&quot; class=&quot;headerlink&quot; title=&quot;HDFS Sink存在的问题&quot;&gt;&lt;/a&gt;HDFS Sink存在的问题&lt;/h1&gt;&lt;p&gt;&lt;code&gt;hdfs.useLocalTim
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flume" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flume/"/>
    
    
      <category term="源码" scheme="https://masteryang4.github.io/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flume" scheme="https://masteryang4.github.io/tags/flume/"/>
    
  </entry>
  
  <entry>
    <title>OLAP和OLTP的区别</title>
    <link href="https://masteryang4.github.io/2020/06/29/OLAP%E5%92%8COLTP%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://masteryang4.github.io/2020/06/29/OLAP%E5%92%8COLTP%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-06-28T17:12:12.000Z</published>
    <updated>2020-06-28T17:14:10.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OLAP和OLTP的区别"><a href="#OLAP和OLTP的区别" class="headerlink" title="OLAP和OLTP的区别"></a>OLAP和OLTP的区别</h1><p>OLAP（On-Line Analytical Processing）联机分析处理，也称为面向交易的处理过程，其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作快速响应的方式之一。应用在数据仓库，使用对象是决策者。OLAP系统强调的是数据分析，响应速度要求没那么高。</p><p>OLTP（On-Line Transaction Processing）联机事务处理，它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的。它具有FASMI(Fast Analysis of Shared Multidimensional Information)，即共享多维信息的快速分析的特征。主要应用是传统关系型数据库。OLTP系统强调的是内存效率，实时性比较高。</p><p> 以下是OLAP和OLTP的比较图1： </p><p><a href="https://pic.downk.cc/item/5ef8ce0514195aa594e85521.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5ef8ce0514195aa594e85521.png" class="lazyload"></a></p><p>图2：</p><p><a href="https://pic.downk.cc/item/5ef8ce1d14195aa594e86d3b.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://pic.downk.cc/item/5ef8ce1d14195aa594e86d3b.png" class="lazyload"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;OLAP和OLTP的区别&quot;&gt;&lt;a href=&quot;#OLAP和OLTP的区别&quot; class=&quot;headerlink&quot; title=&quot;OLAP和OLTP的区别&quot;&gt;&lt;/a&gt;OLAP和OLTP的区别&lt;/h1&gt;&lt;p&gt;OLAP（On-Line Analytical Proces
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="数据库" scheme="https://masteryang4.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>flink系列05Flink DataStream API</title>
    <link href="https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9705Flink-DataStream-API/"/>
    <id>https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9705Flink-DataStream-API/</id>
    <published>2020-06-27T15:28:18.000Z</published>
    <updated>2020-06-27T15:29:00.972Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第五章，Flink-DataStream-API"><a href="#第五章，Flink-DataStream-API" class="headerlink" title="第五章，Flink DataStream API"></a>第五章，Flink DataStream API</h1><p>本章介绍了Flink DataStream API的基本知识。我们展示了典型的Flink流处理程序的结构和组成部分，还讨论了Flink的类型系统以及支持的数据类型，还展示了数据和分区转换操作。窗口操作符，基于时间语义的转换操作，有状态的操作符，以及和外部系统的连接器将在接下来的章节进行介绍。阅读完这一章后，我们将会知道如何去实现一个具有基本功能的流处理程序。我们的示例程序采用Scala语言，因为Scala语言相对比较简洁。但Java API也是十分类似的（特殊情况，我们将会指出）。在我们的Github仓库里，我们所写的应用程序具有Scala和Java两种版本。</p><h2 id="你好，Flink！"><a href="#你好，Flink！" class="headerlink" title="你好，Flink！"></a>你好，Flink！</h2><p>让我们写一个简单的例子来获得使用DataStream API编写流处理应用程序的粗浅印象。我们将使用这个简单的示例来展示一个Flink程序的基本结构，以及介绍一些DataStream API的重要特性。我们的示例程序摄取了一条（来自多个传感器的）温度测量数据流。</p><p>首先让我们看一下表示传感器读数的数据结构：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  timestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  temperature: <span class="type">Double</span></span>)</span></span><br></pre></td></tr></table></figure></div><p>示例程序5-1将温度从华氏温度读数转换成摄氏温度读数，然后针对每一个传感器，每5秒钟计算一次平均温度纸。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Scala object that defines</span></span><br><span class="line"><span class="comment">// the DataStream program in the main() method.</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AverageSensorReadings</span> </span>&#123;</span><br><span class="line">  <span class="comment">// main() defines and executes the DataStream program</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">// set up the streaming execution environment</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="comment">// use event time for the application</span></span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    <span class="comment">// create a DataStream[SensorReading] from a stream source</span></span><br><span class="line">    <span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">      <span class="comment">// ingest sensor readings with a SensorSource SourceFunction</span></span><br><span class="line">      .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">      <span class="comment">// assign timestamps and watermarks (required for event time)</span></span><br><span class="line">    <span class="keyword">val</span> avgTemp: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = sensorData</span><br><span class="line">      <span class="comment">// convert Fahrenheit to Celsius with an inline lambda function</span></span><br><span class="line">      .map( r =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> celsius = (r.temperature - <span class="number">32</span>) * (<span class="number">5.0</span> / <span class="number">9.0</span>)</span><br><span class="line">        <span class="type">SensorReading</span>(r.id, r.timestamp, celsius)</span><br><span class="line">      &#125;)</span><br><span class="line">      <span class="comment">// organize readings by sensor id</span></span><br><span class="line">      .keyBy(_.id)</span><br><span class="line">      <span class="comment">// group readings in 5 second tumbling windows</span></span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">      <span class="comment">// compute average temperature using a user-defined function</span></span><br><span class="line">      .apply(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br><span class="line">      <span class="comment">// print result stream to standard out</span></span><br><span class="line">      avgTemp.print()</span><br><span class="line">    <span class="comment">// execute application</span></span><br><span class="line">    env.execute(<span class="string">"Compute average sensor temperature"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>你可能已经注意到Flink程序的定义和提交执行使用的就是正常的Scala或者Java的方法。大多数情况下，这些代码都写在一个静态main方法中。在我们的例子中，我们定义了AverageSensorReadings对象，然后将大多数的应用程序逻辑放在了main()中。</p><p>Flink流处理程序的结构如下：</p><ol><li>创建Flink程序执行环境。</li><li>从数据源读取一条或者多条流数据</li><li>使用流转换算子实现业务逻辑</li><li>将计算结果输出到一个或者多个外部设备（可选）</li><li>执行程序</li></ol><p>接下来我们详细的学习一下这些部分。</p><h2 id="搭建执行环境"><a href="#搭建执行环境" class="headerlink" title="搭建执行环境"></a>搭建执行环境</h2><p>编写Flink程序的第一件事情就是搭建执行环境。执行环境决定了程序是运行在单机上还是集群上。在DataStream API中，程序的执行环境是由StreamExecutionEnvironment设置的。在我们的例子中，我们通过调用静态getExecutionEnvironment()方法来获取执行环境。这个方法根据调用方法的上下文，返回一个本地的或者远程的环境。如果这个方法是一个客户端提交到远程集群的代码调用的，那么这个方法将会返回一个远程的执行环境。否则，将返回本地执行环境。</p><p>也可以用下面的方法来显式的创建本地或者远程执行环境：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create a local stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> localEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createLocalEnvironment()</span><br><span class="line"><span class="comment">// create a remote stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> remoteEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createRemoteEnvironment(</span><br><span class="line">    <span class="string">"host"</span>, <span class="comment">// hostname of JobManager</span></span><br><span class="line">    <span class="number">1234</span>, <span class="comment">// port of JobManager process</span></span><br><span class="line">    <span class="string">"path/to/jarFile.jar"</span></span><br><span class="line">  ) <span class="comment">// JAR file to ship to the JobManager</span></span><br></pre></td></tr></table></figure></div><p>接下来，我们使用<code>env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>来将我们程序的时间语义设置为事件时间。执行环境提供了很多配置选项，例如：设置程序的并行度和程序是否开启容错机制。</p><h2 id="读取输入流"><a href="#读取输入流" class="headerlink" title="读取输入流"></a>读取输入流</h2><p>一旦执行环境设置好，就该写业务逻辑了。<code>StreamExecutionEnvironment</code>提供了创建数据源的方法，这些方法可以从数据流中将数据摄取到程序中。数据流可以来自消息队列或者文件系统，也可能是实时产生的（例如socket）。</p><p>在我们的例子里面，我们这样写：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br></pre></td></tr></table></figure></div><p>这样就可以连接到传感器测量数据的数据源并创建一个类型为<code>SensorReading</code>的<code>DataStream</code>了。Flink支持很多数据类型，我们将在接下来的章节里面讲解。在我们的例子里面，我们的数据类型是一个定义好的Scala样例类。<code>SensorReading</code>样例类包含了传感器ID，数据的测量时间戳，以及测量温度值。<code>assignTimestampsAndWatermarks(new SensorTimeAssigner)</code>方法指定了如何设置事件时间语义的时间戳和水位线。有关<code>SensorTimeAssigner</code>我们后面再讲。</p><h2 id="转换算子的使用"><a href="#转换算子的使用" class="headerlink" title="转换算子的使用"></a>转换算子的使用</h2><p>一旦我们有一条DataStream，我们就可以在这条数据流上面使用转换算子了。转换算子有很多种。一些转换算子可以产生一条新的DataStream，当然这个DataStream的类型可能是新类型。还有一些转换算子不会改变原有DataStream的数据，但会将数据流分区或者分组。业务逻辑就是由转换算子串起来组合而成的。</p><p>在我们的例子中，我们首先使用<code>map()</code>转换算子将传感器的温度值转换成了摄氏温度单位。然后，我们使用<code>keyBy()</code>转换算子将传感器读数流按照传感器ID进行分区。接下来，我们定义了一个<code>timeWindow()</code>转换算子，这个算子将每个传感器ID所对应的分区的传感器读数分配到了5秒钟的滚动窗口中。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> avgTemp: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = sensorData</span><br><span class="line">  .map(r =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> celsius = (r.temperature - <span class="number">32</span>) * (<span class="number">5.0</span> / <span class="number">9.0</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(r.id, r.timestamp, celsius)</span><br><span class="line">  &#125;)</span><br><span class="line">  .keyBy(_.id)</span><br><span class="line">  .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">  .apply(<span class="keyword">new</span> <span class="type">TemperatureAverager</span>)</span><br></pre></td></tr></table></figure></div><p>窗口转换算子将在“窗口操作符”一章中讲解。最后，我们使用了一个UDF函数来计算每个窗口的温度的平均值。我们稍后将会讨论UDF函数的实现。</p><h2 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h2><p>流处理程序经常将它们的计算结果发送到一些外部系统中去，例如：Apache Kafka，文件系统，或者数据库中。Flink提供了一个维护的很好的sink算子的集合，这些sink算子可以用来将数据写入到不同的系统中去。我们也可以实现自己的sink算子。也有一些Flink程序并不会向第三方外部系统发送数据，而是将数据存储到Flink系统内部，然后可以使用Flink的可查询状态的特性来查询数据。</p><p>在我们的例子中，计算结果是一个<code>DataStream[SensorReading]</code>数据记录。每一条数据记录包含了一个传感器在5秒钟的周期里面的平均温度。计算结果组成的数据流将会调用<code>print()</code>将计算结果写到标准输出。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">avgTemp.print()</span><br></pre></td></tr></table></figure></div><blockquote><p>要注意一点，流的Sink算子的选择将会影响应用程序端到端(<code>end-to-end</code>)的一致性，具体就是应用程序的计算提供的到底是<code>at-least-once</code>还是<code>exactly-once</code>的一致性语义。应用程序端到端的一致性依赖于所选择的流的Sink算子和Flink的检查点算法的集成使用。</p></blockquote><h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><p>当应用程序完全写好时，我们可以调用<code>StreamExecutionEnvironment.execute()</code>来执行应用程序。在我们的例子中就是我们的最后一行调用：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.execute(<span class="string">"Compute average sensor temperature"</span>)</span><br></pre></td></tr></table></figure></div><p>Flink程序是惰性执行的。也就是说创建数据源和转换算子的API调用并不会立刻触发任何数据处理逻辑。API调用仅仅是在执行环境中构建了一个执行计划，这个执行计划包含了执行环境创建的数据源和所有的将要用在数据源上的转换算子。只有当<code>execute()</code>被调用时，系统才会触发程序的执行。</p><p>构建好的执行计划将被翻译成一个<code>JobGraph</code>并提交到<code>JobManager</code>上面去执行。根据执行环境的种类，一个<code>JobManager</code>将会运行在一个本地线程中（如果是本地执行环境的化）或者<code>JobGraph</code>将会被发送到一个远程的<code>JobManager</code>上面去。如果<code>JobManager</code>远程运行，那么<code>JobGraph</code>必须和一个包含有所有类和应用程序的依赖的JAR包一起发送到远程<code>JobManager</code>。</p><h2 id="产生传感器读数代码编写"><a href="#产生传感器读数代码编写" class="headerlink" title="产生传感器读数代码编写"></a>产生传感器读数代码编写</h2><h3 id="从批读取数据"><a href="#从批读取数据" class="headerlink" title="从批读取数据"></a>从批读取数据</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  .fromCollection(<span class="type">List</span>(</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_1"</span>, <span class="number">1547718199</span>, <span class="number">35.80018327300259</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_6"</span>, <span class="number">1547718199</span>, <span class="number">15.402984393403084</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_7"</span>, <span class="number">1547718199</span>, <span class="number">6.720945201171228</span>),</span><br><span class="line">    <span class="type">SensorReading</span>(<span class="string">"sensor_10"</span>, <span class="number">1547718199</span>, <span class="number">38.101067604893444</span>)</span><br><span class="line">  ))</span><br></pre></td></tr></table></figure></div><h3 id="从文件读取数据"><a href="#从文件读取数据" class="headerlink" title="从文件读取数据"></a>从文件读取数据</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = env.readTextFile(filePath)</span><br></pre></td></tr></table></figure></div><h3 id="以Kafka消息队列的数据为数据来源"><a href="#以Kafka消息队列的数据为数据来源" class="headerlink" title="以Kafka消息队列的数据为数据来源"></a>以Kafka消息队列的数据为数据来源</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">properties.setProperty(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"consumer-group"</span>)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"key.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(</span><br><span class="line">  <span class="string">"value.deserializer"</span>,</span><br><span class="line">  <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span></span><br><span class="line">)</span><br><span class="line">properties.setProperty(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>)</span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">env.setParallelism(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> stream = env</span><br><span class="line">  <span class="comment">// source为来自Kafka的数据，这里我们实例化一个消费者，topic为hotitems</span></span><br><span class="line">  .addSource(</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](</span><br><span class="line">      <span class="string">"hotitems"</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),</span><br><span class="line">      properties</span><br><span class="line">    )</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></div><blockquote><p>注意，Kafka的版本为<code>2.2</code>。</p></blockquote><h3 id="自定义数据源"><a href="#自定义数据源" class="headerlink" title="自定义数据源"></a>自定义数据源</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Calendar</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">RichParallelSourceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">SourceFunction</span>.<span class="type">SourceContext</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 传感器id，时间戳，温度</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params">id: <span class="type">String</span>, timestamp: <span class="type">Long</span>, temperature: <span class="type">Double</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">需要extends</span> <span class="title">RichParallelSourceFunction</span>, <span class="title">泛型为SensorReading</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">SensorSource</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// flag indicating whether source is still running.</span></span><br><span class="line">  <span class="comment">// flag: 表示数据源是否还在正常运行</span></span><br><span class="line">  <span class="keyword">var</span> running: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// run()函数连续的发送SensorReading数据，使用SourceContext</span></span><br><span class="line">  <span class="comment">// 需要override</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(srcCtx: <span class="type">SourceContext</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialize random number generator</span></span><br><span class="line">    <span class="comment">// 初始化随机数发生器</span></span><br><span class="line">    <span class="keyword">val</span> rand = <span class="keyword">new</span> <span class="type">Random</span>()</span><br><span class="line">    <span class="comment">// look up index of this parallel task</span></span><br><span class="line">    <span class="comment">// 查找当前运行时上下文的任务的索引</span></span><br><span class="line">    <span class="keyword">val</span> taskIdx = <span class="keyword">this</span>.getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialize sensor ids and temperatures</span></span><br><span class="line">    <span class="comment">// 初始化10个(温度传感器的id, 温度值)元组</span></span><br><span class="line">    <span class="keyword">var</span> curFTemp = (<span class="number">1</span> to <span class="number">10</span>).map &#123;</span><br><span class="line">      <span class="comment">// nextGaussian产生高斯随机数</span></span><br><span class="line">      i =&gt; (<span class="string">"sensor_"</span> + (taskIdx * <span class="number">10</span> + i), <span class="number">65</span> + (rand.nextGaussian() * <span class="number">20</span>))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// emit data until being canceled</span></span><br><span class="line">    <span class="comment">// 无限循环，产生数据流</span></span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// update temperature</span></span><br><span class="line">      <span class="comment">// 更新温度</span></span><br><span class="line">      curFTemp = curFTemp.map(t =&gt; (t._1, t._2 + (rand.nextGaussian() * <span class="number">0.5</span>)) )</span><br><span class="line">      <span class="comment">// get current time</span></span><br><span class="line">      <span class="comment">// 获取当前时间戳</span></span><br><span class="line">      <span class="keyword">val</span> curTime = <span class="type">Calendar</span>.getInstance.getTimeInMillis</span><br><span class="line"></span><br><span class="line">      <span class="comment">// emit new SensorReading</span></span><br><span class="line">      <span class="comment">// 发射新的传感器数据, 注意这里srcCtx.collect</span></span><br><span class="line">      curFTemp.foreach(t =&gt; srcCtx.collect(<span class="type">SensorReading</span>(t._1, curTime, t._2)))</span><br><span class="line"></span><br><span class="line">      <span class="comment">// wait for 100 ms</span></span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">100</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// override cancel函数</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    running = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>使用方法</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ingest sensor stream</span></span><br><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env</span><br><span class="line">  <span class="comment">// SensorSource generates random temperature readings</span></span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br></pre></td></tr></table></figure></div><blockquote><p>注意，在我们本教程中，我们一直会使用这个自定义的数据源。</p></blockquote><h2 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a>转换算子</h2><p>在这一小节我们将大概看一下DataStream API的基本转换算子。与时间有关的操作符（例如窗口操作符和其他特殊的转换算子）将会在后面的章节叙述。一个流的转换操作将会应用在一个或者多个流上面，这些转换操作将流转换成一个或者多个输出流。编写一个DataStream API简单来说就是将这些转换算子组合在一起来构建一个数据流图，这个数据流图就实现了我们的业务逻辑。</p><p>大部分的流转换操作都基于用户自定义函数UDF。UDF函数打包了一些业务逻辑并定义了输入流的元素如何转换成输出流的元素。像<code>MapFunction</code>这样的函数，将会被定义为类，这个类实现了Flink针对特定的转换操作暴露出来的接口。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMapFunction</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">Int</span>, <span class="type">Int</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">Int</span>): <span class="type">Int</span> = value + <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>函数接口定义了需要由用户实现的转换方法，例如上面例子中的<code>map()</code>方法。</p><p>大部分函数接口被设计为<code>Single Abstract Method</code>（单独抽象方法）接口，并且接口可以使用Java 8匿名函数来实现。Scala DataStream API也内置了对匿名函数的支持。当讲解DataStream API的转换算子时，我们展示了针对所有函数类的接口，但为了简洁，大部分接口的实现使用匿名函数而不是函数类的方式。</p><p>DataStream API针对大多数数据转换操作提供了转换算子。如果你很熟悉批处理API、函数式编程语言或者SQL，那么你将会发现这些API很容易学习。我们会将DataStream API的转换算子分成四类：</p><ul><li>基本转换算子：将会作用在数据流中的每一条单独的数据上。</li><li>KeyedStream转换算子：在数据有key的情况下，对数据应用转换算子。</li><li>多流转换算子：合并多条流为一条流或者将一条流分割为多条流。</li><li>分布式转换算子：将重新组织流里面的事件。</li></ul><h3 id="基本转换算子"><a href="#基本转换算子" class="headerlink" title="基本转换算子"></a>基本转换算子</h3><p>基本转换算子会针对流中的每一个单独的事件做处理，也就是说每一个输入数据会产生一个输出数据。单值转换，数据的分割，数据的过滤，都是基本转换操作的典型例子。我们将解释这些算子的语义并提供示例代码。</p><p><em>MAP</em></p><p><code>map</code>算子通过调用<code>DataStream.map()</code>来指定。<code>map</code>算子的使用将会产生一条新的数据流。它会将每一个输入的事件传送到一个用户自定义的mapper，这个mapper只返回一个输出事件，这个输出事件和输入事件的类型可能不一样。图5-1展示了一个map算子，这个map将每一个正方形转化成了圆形。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0501.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0501.png" class="lazyload"></a></p><p><code>MapFunction</code>的类型与输入事件和输出事件的类型相关，可以通过实现<code>MapFunction</code>接口来定义。接口包含<code>map()</code>函数，这个函数将一个输入事件恰好转换为一个输出事件。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// T: the type of input elements</span></span><br><span class="line"><span class="comment">// O: the type of output elements</span></span><br><span class="line"><span class="type">MapFunction</span>[<span class="type">T</span>, <span class="type">O</span>]</span><br><span class="line">    &gt; map(<span class="type">T</span>): <span class="type">O</span></span><br></pre></td></tr></table></figure></div><p>下面的代码实现了将SensorReading中的id字段抽取出来的功能。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = readings.map(<span class="keyword">new</span> <span class="type">MyMapFunction</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMapFunction</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(r: <span class="type">SensorReading</span>): <span class="type">String</span> = r.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>当然我们更推荐匿名函数的写法。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = readings.map(r =&gt; r.id)</span><br></pre></td></tr></table></figure></div><p><em>FILTER</em></p><p><code>filter</code>转换算子通过在每个输入事件上对一个布尔条件进行求值来过滤掉一些元素，然后将剩下的元素继续发送。一个<code>true</code>的求值结果将会把输入事件保留下来并发送到输出，而如果求值结果为<code>false</code>，则输入事件会被抛弃掉。我们通过调用<code>DataStream.filter()</code>来指定流的<code>filter</code>算子，<code>filter</code>操作将产生一条新的流，其类型和输入流中的事件类型是一样的。图5-2展示了只产生白色方框的<code>filter</code>操作。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0502.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0502.png" class="lazyload"></a></p><p>布尔条件可以使用函数、FilterFunction接口或者匿名函数来实现。FilterFunction中的泛型是输入事件的类型。定义的<code>filter()</code>方法会作用在每一个输入元素上面，并返回一个布尔值。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// T: the type of elements</span></span><br><span class="line"><span class="type">FilterFunction</span>[<span class="type">T</span>]</span><br><span class="line">    &gt; filter(<span class="type">T</span>): <span class="type">Boolean</span></span><br></pre></td></tr></table></figure></div><p>下面的例子展示了如何使用filter来从传感器数据中过滤掉温度值小于25华氏温度的读数。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> filteredSensors = readings.filter(r =&gt; r.temperature &gt;= <span class="number">25</span>)</span><br></pre></td></tr></table></figure></div><p><em>FLATMAP</em></p><p><code>flatMap</code>算子和<code>map</code>算子很类似，不同之处在于针对每一个输入事件<code>flatMap</code>可以生成0个、1个或者多个输出元素。事实上，<code>flatMap</code>转换算子是<code>filter</code>和<code>map</code>的泛化。所以<code>flatMap</code>可以实现<code>map</code>和<code>filter</code>算子的功能。图5-3展示了<code>flatMap</code>如何根据输入事件的颜色来做不同的处理。如果输入事件是白色方框，则直接输出。输入元素是黑框，则复制输入。灰色方框会被过滤掉。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0503.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0503.png" class="lazyload"></a></p><p>flatMap算子将会应用在每一个输入事件上面。对应的<code>FlatMapFunction</code>定义了<code>flatMap()</code>方法，这个方法返回0个、1个或者多个事件到一个<code>Collector</code>集合中，作为输出结果。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// T: the type of input elements</span></span><br><span class="line"><span class="comment">// O: the type of output elements</span></span><br><span class="line"><span class="type">FlatMapFunction</span>[<span class="type">T</span>, <span class="type">O</span>]</span><br><span class="line">    &gt; flatMap(<span class="type">T</span>, <span class="type">Collector</span>[<span class="type">O</span>]): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></div><p>下面的例子展示了在数据分析教程中经常用到的例子，我们用<code>flatMap</code>来实现。这个函数应用在一个语句流上面，将每个句子用空格切分，然后把切分出来的单词作为单独的事件发送出去。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sentences: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> words: <span class="type">DataStream</span>[<span class="type">String</span>] = sentences</span><br><span class="line">  .flatMap(id =&gt; id.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure></div><h3 id="键控流转换算子"><a href="#键控流转换算子" class="headerlink" title="键控流转换算子"></a>键控流转换算子</h3><p>很多流处理程序的一个基本要求就是要能对数据进行分组，分组后的数据共享某一个相同的属性。DataStream API提供了一个叫做<code>KeyedStream</code>的抽象，此抽象会从逻辑上对DataStream进行分区，分区后的数据拥有同样的<code>Key</code>值，分区后的流互不相关。</p><p>针对KeyedStream的状态转换操作可以读取数据或者写入数据到当前事件Key所对应的状态中。这表明拥有同样Key的所有事件都可以访问同样的状态，也就是说所以这些事件可以一起处理。</p><blockquote><p>要小心使用状态转换操作和基于Key的聚合操作。如果Key的值越来越多，例如：Key是订单ID，我们必须及时清空Key所对应的状态，以免引起内存方面的问题。稍后我们会详细讲解。</p></blockquote><p>KeyedStream可以使用map，flatMap和filter算子来处理。接下来我们会使用keyBy算子来将DataStream转换成KeyedStream，并讲解基于key的转换操作：滚动聚合和reduce算子。</p><p><em>KEYBY</em></p><p>keyBy通过指定key来将DataStream转换成KeyedStream。基于不同的key，流中的事件将被分配到不同的分区中去。所有具有相同key的事件将会在接下来的操作符的同一个子任务槽中进行处理。拥有不同key的事件可以在同一个任务中处理。但是算子只能访问当前事件的key所对应的状态。</p><p>如图5-4所示，把输入事件的颜色作为key，黑色的事件输出到了一个分区，其他颜色输出到了另一个分区。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0504.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0504.png" class="lazyload"></a></p><p><code>keyBy()</code>方法接收一个参数，这个参数指定了key或者keys，有很多不同的方法来指定key。我们将在后面讲解。下面的代码声明了<code>id</code>这个字段为SensorReading流的key。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyed: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = readings</span><br><span class="line">  .keyBy(r =&gt; r.id)</span><br></pre></td></tr></table></figure></div><p>匿名函数<code>r =&gt; r.id</code>抽取了传感器读数SensorReading的id值。</p><p><em>滚动聚合</em></p><p>滚动聚合算子由<code>KeyedStream</code>调用，并生成一个聚合以后的DataStream，例如：sum，minimum，maximum。一个滚动聚合算子会为每一个观察到的key保存一个聚合的值。针对每一个输入事件，算子将会更新保存的聚合结果，并发送一个带有更新后的值的事件到下游算子。滚动聚合不需要用户自定义函数，但需要接受一个参数，这个参数指定了在哪一个字段上面做聚合操作。DataStream API提供了以下滚动聚合方法。</p><blockquote><p>滚动聚合算子只能用在滚动窗口，不能用在滑动窗口。</p></blockquote><ul><li>sum()：在输入流上对指定的字段做滚动相加操作。</li><li>min()：在输入流上对指定的字段求最小值。</li><li>max()：在输入流上对指定的字段求最大值。</li><li>minBy()：在输入流上针对指定字段求最小值，并返回包含当前观察到的最小值的事件。</li><li>maxBy()：在输入流上针对指定字段求最大值，并返回包含当前观察到的最大值的事件。</li></ul><p>滚动聚合算子无法组合起来使用，每次计算只能使用一个单独的滚动聚合算子。</p><p>下面的例子根据第一个字段来对类型为<code>Tuple3[Int, Int, Int]</code>的流做分流操作，然后针对第二个字段做滚动求和操作。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>)] = env.fromElements(</span><br><span class="line">  (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>)] = inputStream</span><br><span class="line">  .keyBy(<span class="number">0</span>) <span class="comment">// key on first field of the tuple</span></span><br><span class="line">  .sum(<span class="number">1</span>)   <span class="comment">// sum the second field of the tuple in place</span></span><br></pre></td></tr></table></figure></div><p>在这个例子里面，输入流根据第一个字段来分流，然后在第二个字段上做计算。对于key 1，输出结果是(1,2,2),(1,7,2)。对于key 2，输出结果是(2,3,1),(2,5,1)。第一个字段是key，第二个字段是求和的数值，第三个字段未定义。</p><blockquote><p>滚动聚合操作会对每一个key都保存一个状态。因为状态从来不会被清空，所以我们在使用滚动聚合算子时只能使用在含有有限个key的流上面。</p></blockquote><p><em>REDUCE</em></p><p>reduce算子是滚动聚合的泛化实现。它将一个ReduceFunction应用到了一个KeyedStream上面去。reduce算子将会把每一个输入事件和当前已经reduce出来的值做聚合计算。reduce操作不会改变流的事件类型。输出流数据类型和输入流数据类型是一样的。</p><p>reduce函数可以通过实现接口ReduceFunction来创建一个类。ReduceFunction接口定义了<code>reduce()</code>方法，此方法接收两个输入事件，输入一个相同类型的事件。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// T: the element type</span></span><br><span class="line"><span class="type">ReduceFunction</span>[<span class="type">T</span>]</span><br><span class="line">    &gt; reduce(<span class="type">T</span>, <span class="type">T</span>): <span class="type">T</span></span><br></pre></td></tr></table></figure></div><p>下面的例子，流根据语言这个key来分区，输出结果为针对每一种语言都实时更新的单词列表。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])] = env.fromElements(</span><br><span class="line">  (<span class="string">"en"</span>, <span class="type">List</span>(<span class="string">"tea"</span>)), (<span class="string">"fr"</span>, <span class="type">List</span>(<span class="string">"vin"</span>)), (<span class="string">"en"</span>, <span class="type">List</span>(<span class="string">"cake"</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])] = inputStream</span><br><span class="line">  .keyBy(<span class="number">0</span>)</span><br><span class="line">  .reduce((x, y) =&gt; (x._1, x._2 ::: y._2))</span><br></pre></td></tr></table></figure></div><p>reduce匿名函数将连续两个tuple的第一个字段(key字段)继续发送出去，然后将两个tuple的第二个字段List[String]连接。</p><blockquote><p>reduce作为滚动聚合的泛化实现，同样也要针对每一个key保存状态。因为状态从来不会清空，所以我们需要将reduce算子应用在一个有限key的流上。</p></blockquote><h3 id="多流转换算子"><a href="#多流转换算子" class="headerlink" title="多流转换算子"></a>多流转换算子</h3><p>许多应用需要摄入多个流并将流合并处理，还可能需要将一条流分割成多条流然后针对每一条流应用不同的业务逻辑。接下来，我们将讨论DataStream API中提供的能够处理多条输入流或者发送多条输出流的操作算子。</p><p><em>UNION</em></p><p>DataStream.union()方法将两条或者多条DataStream合并成一条具有与输入流相同类型的输出DataStream。接下来的转换算子将会处理输入流中的所有元素。图5-5展示了union操作符如何将黑色和白色的事件流合并成一个单一输出流。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0505.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0505.png" class="lazyload"></a></p><p>事件合流的方式为FIFO方式。操作符并不会产生一个特定顺序的事件流。union操作符也不会进行去重。每一个输入事件都被发送到了下一个操作符。</p><p>下面的例子展示了如何将三条类型为SensorReading的数据流合并成一条流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> parisStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> tokyoStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> rioStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> allCities: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = parisStream</span><br><span class="line">  .union(tokyoStream, rioStream)</span><br></pre></td></tr></table></figure></div><p><em>CONNECT, COMAP和COFLATMAP</em></p><p>联合两条流的事件是非常常见的流处理需求。例如监控一片森林然后发出高危的火警警报。报警的Application接收两条流，一条是温度传感器传回来的数据，一条是烟雾传感器传回来的数据。当两条流都超过各自的阈值时，报警。</p><p>DataStream API提供了<code>connect</code>操作来支持以上的应用场景。<code>DataStream.connect()</code>方法接收一条<code>DataStream</code>，然后返回一个<code>ConnectedStreams</code>类型的对象，这个对象表示了两条连接的流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// first stream</span></span><br><span class="line"><span class="keyword">val</span> first: <span class="type">DataStream</span>[<span class="type">Int</span>] = ...</span><br><span class="line"><span class="comment">// second stream</span></span><br><span class="line"><span class="keyword">val</span> second: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// connect streams</span></span><br><span class="line"><span class="keyword">val</span> connected: <span class="type">ConnectedStreams</span>[<span class="type">Int</span>, <span class="type">String</span>] = first.connect(second)</span><br></pre></td></tr></table></figure></div><p>ConnectedStreams提供了<code>map()</code>和<code>flatMap()</code>方法，分别需要接收类型为<code>CoMapFunction</code>和<code>CoFlatMapFunction</code>的参数。</p><p>以上两个函数里面的泛型是第一条流的事件类型和第二条流的事件类型，以及输出流的事件类型。还定义了两个方法，每一个方法针对一条流来调用。<code>map1()</code>和<code>flatMap1()</code>会调用在第一条流的元素上面，<code>map2()</code>和<code>flatMap2()</code>会调用在第二条流的元素上面。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// IN1: 第一条流的事件类型</span></span><br><span class="line"><span class="comment">// IN2: 第二条流的事件类型</span></span><br><span class="line"><span class="comment">// OUT: 输出流的事件类型</span></span><br><span class="line"><span class="type">CoMapFunction</span>[<span class="type">IN1</span>, <span class="type">IN2</span>, <span class="type">OUT</span>]</span><br><span class="line">    &gt; map1(<span class="type">IN1</span>): <span class="type">OUT</span></span><br><span class="line">    &gt; map2(<span class="type">IN2</span>): <span class="type">OUT</span></span><br><span class="line"></span><br><span class="line"><span class="type">CoFlatMapFunction</span>[<span class="type">IN1</span>, <span class="type">IN2</span>, <span class="type">OUT</span>]</span><br><span class="line">    &gt; flatMap1(<span class="type">IN1</span>, <span class="type">Collector</span>[<span class="type">OUT</span>]): <span class="type">Unit</span></span><br><span class="line">    &gt; flatMap2(<span class="type">IN2</span>, <span class="type">Collector</span>[<span class="type">OUT</span>]): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></div><blockquote><p>函数无法选择读某一条流。我们是无法控制函数中的两个方法的调用顺序的。当一条流中的元素到来时，将会调用相对应的方法。</p></blockquote><p>对两条流做连接查询通常需要这两条流基于某些条件被确定性的路由到操作符中相同的并行实例里面去。在默认情况下，connect()操作将不会对两条流的事件建立任何关系，所以两条流的事件将会随机的被发送到下游的算子实例里面去。这样的行为会产生不确定性的计算结果，显然不是我们想要的。为了针对ConnectedStreams进行确定性的转换操作，connect()方法可以和keyBy()或者broadcast()组合起来使用。我们首先看一下keyBy()的示例。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> one: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> two: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// keyBy two connected streams</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect1: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = one</span><br><span class="line">  .connect(two)</span><br><span class="line">  .keyBy(<span class="number">0</span>, <span class="number">0</span>) <span class="comment">// key both input streams on first attribute</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// alternative: connect two keyed streams</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect2: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = one</span><br><span class="line">  .keyBy(<span class="number">0</span>)</span><br><span class="line">  .connect(two.keyBy(<span class="number">0</span>))</span><br></pre></td></tr></table></figure></div><p>无论使用keyBy()算子操作ConnectedStreams还是使用connect()算子连接两条KeyedStreams，connect()算子会将两条流的含有相同Key的所有事件都发送到相同的算子实例。两条流的key必须是一样的类型和值，就像SQL中的JOIN。在connected和keyed stream上面执行的算子有访问keyed state的权限。</p><p>下面的例子展示了如何连接一条DataStream和广播过的流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> first: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> second: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// connect streams with broadcast</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">Long</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = first</span><br><span class="line">  <span class="comment">// broadcast second input stream</span></span><br><span class="line">  .connect(second.broadcast())</span><br></pre></td></tr></table></figure></div><p>一条被广播过的流中的所有元素将会被复制然后发送到下游算子的所有并行实例中去。未被广播过的流仅仅向前发送。所以两条流的元素显然会被连接处理。</p><p><em>SPLIT和SELECT</em></p><p>Split是Union的反函数。Split将输入的流分成两条或者多条流。每一个输入的元素都可以被路由到0、1或者多条流中去。所以，split可以用来过滤或者复制元素。图5-6展示了split操作符将所有的白色事件都路由到同一条流中去了，剩下的元素去往另一条流。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0506.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0506.png" class="lazyload"></a></p><p>DataStream.split()方法接受<code>OutputSelector</code>类型，此类型定义了输入流中的元素被分配到哪个名字的流中去。<code>OutputSelector</code>定义了<code>select()</code>方法，此方法将被每一个元素调用，并返回<code>java.lang.Iterable[String]</code>类型的数据。返回的<code>String</code>类型的值将指定元素将被路由到哪一条流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; IN: the type of the split elements</span><br><span class="line">OutputSelector[IN]</span><br><span class="line">    &gt; select(IN): Iterable[String]</span><br></pre></td></tr></table></figure></div><p>DataStream.split()方法返回<code>SplitStream</code>类型，此类型提供<code>select()</code>方法，可以根据分流后不同流的名字，将某个名字对应的流提取出来。</p><p>例5-2将一条整数流分成了不同的流，大的整数一条流，小的整数一条流。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> splitted: <span class="type">SplitStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = inputStream</span><br><span class="line">  .split(t =&gt; <span class="keyword">if</span> (t._1 &gt; <span class="number">1000</span>) <span class="type">Seq</span>(<span class="string">"large"</span>) <span class="keyword">else</span> <span class="type">Seq</span>(<span class="string">"small"</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> large: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"large"</span>)</span><br><span class="line"><span class="keyword">val</span> small: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"small"</span>)</span><br><span class="line"><span class="keyword">val</span> all: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = splitted.select(<span class="string">"small"</span>, <span class="string">"large"</span>)</span><br></pre></td></tr></table></figure></div><blockquote><p>不推荐使用split方法，推荐使用Flink的侧输出（side-output）特性。</p></blockquote><h3 id="分布式转换算子"><a href="#分布式转换算子" class="headerlink" title="分布式转换算子"></a>分布式转换算子</h3><p>分区操作对应于我们之前讲过的“数据交换策略”这一节。这些操作定义了事件如何分配到不同的任务中去。当我们使用DataStream API来编写程序时，系统将自动的选择数据分区策略，然后根据操作符的语义和设置的并行度将数据路由到正确的地方去。有些时候，我们需要在应用程序的层面控制分区策略，或者自定义分区策略。例如，如果我们知道会发生数据倾斜，那么我们想要针对数据流做负载均衡，将数据流平均发送到接下来的操作符中去。又或者，应用程序的业务逻辑可能需要一个算子所有的并行任务都需要接收同样的数据。再或者，我们需要自定义分区策略的时候。在这一小节，我们将展示DataStream的一些方法，可以使我们来控制或者自定义数据分区策略。</p><blockquote><p>keyBy()方法不同于分布式转换算子。所有的分布式转换算子将产生DataStream数据类型。而keyBy()产生的类型是KeyedStream，它拥有自己的keyed state。</p></blockquote><p><em>Random</em></p><p>随机数据交换由<code>DataStream.shuffle()</code>方法实现。shuffle方法将数据随机的分配到下游算子的并行任务中去。</p><p><em>Round-Robin</em></p><p><code>rebalance()</code>方法使用Round-Robin负载均衡算法将输入流平均分配到随后的并行运行的任务中去。图5-7为round-robin分布式转换算子的示意图。</p><p><em>Rescale</em></p><p><code>rescale()</code>方法使用的也是round-robin算法，但只会将数据发送到接下来的并行运行的任务中的一部分任务中。本质上，当发送者任务数量和接收者任务数量不一样时，rescale分区策略提供了一种轻量级的负载均衡策略。如果接收者任务的数量是发送者任务的数量的倍数时，rescale操作将会效率更高。</p><p><code>rebalance()</code>和<code>rescale()</code>的根本区别在于任务之间连接的机制不同。 <code>rebalance()</code>将会针对所有发送者任务和所有接收者任务之间建立通信通道，而<code>rescale()</code>仅仅针对每一个任务和下游算子的一部分子并行任务之间建立通信通道。rescale的示意图为图5-7。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0507.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0507.png" class="lazyload"></a></p><p><em>Broadcast</em></p><p><code>broadcast()</code>方法将输入流的所有数据复制并发送到下游算子的所有并行任务中去。</p><p><em>Global</em></p><p><code>global()</code>方法将所有的输入流数据都发送到下游算子的第一个并行任务中去。这个操作需要很谨慎，因为将所有数据发送到同一个task，将会对应用程序造成很大的压力。</p><p><em>Custom</em></p><p>当Flink提供的分区策略都不适用时，我们可以使用<code>partitionCustom()</code>方法来自定义分区策略。这个方法接收一个<code>Partitioner</code>对象，这个对象需要实现分区逻辑以及定义针对流的哪一个字段或者key来进行分区。下面的例子将一条整数流做partition，使得所有的负整数都发送到第一个任务中，剩下的数随机分配。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers: <span class="type">DataStream</span>[(<span class="type">Int</span>)] = ...</span><br><span class="line">numbers.partitionCustom(myPartitioner, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">myPartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>[<span class="type">Int</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> r = scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">partition</span></span>(key: <span class="type">Int</span>, numPartitions: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (key &lt; <span class="number">0</span>) <span class="number">0</span> <span class="keyword">else</span> r.nextInt(numPartitions)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="设置并行度"><a href="#设置并行度" class="headerlink" title="设置并行度"></a>设置并行度</h2><p>Flink应用程序在一个像集群这样的分布式环境中并行执行。当一个数据流程序提交到JobManager执行时，系统将会创建一个数据流图，然后准备执行需要的操作符。每一个操作符将会并行化到一个或者多个任务中去。每个算子的并行任务都会处理这个算子的输入流中的一份子集。一个算子并行任务的个数叫做算子的并行度。它决定了算子执行的并行化程度，以及这个算子能处理多少数据量。</p><p>算子的并行度可以在执行环境这个层级来控制，也可以针对每个不同的算子设置不同的并行度。默认情况下，应用程序中所有算子的并行度都将设置为执行环境的并行度。执行环境的并行度（也就是所有算子的默认并行度）将在程序开始运行时自动初始化。如果应用程序在本地执行环境中运行，并行度将被设置为CPU的核数。当我们把应用程序提交到一个处于运行中的Flink集群时，执行环境的并行度将被设置为集群默认的并行度，除非我们在客户端提交应用程序时显式的设置好并行度。</p><p>通常情况下，将算子的并行度定义为和执行环境并行度相关的数值会是个好主意。这允许我们通过在客户端调整应用程序的并行度就可以将程序水平扩展了。我们可以使用以下代码来访问执行环境的默认并行度。</p><p>我们还可以重写执行环境的默认并行度，但这样的话我们将再也不能通过客户端来控制应用程序的并行度了。</p><p>算子默认的并行度也可以通过重写来明确指定。在下面的例子里面，数据源的操作符将会按照环境默认的并行度来并行执行，map操作符的并行度将会是默认并行度的2倍，sink操作符的并行度为2。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> defaultP = env.getParallelism</span><br><span class="line"><span class="keyword">val</span> result = env.addSource(<span class="keyword">new</span> <span class="type">CustomSource</span>)</span><br><span class="line">  .map(<span class="keyword">new</span> <span class="type">MyMapper</span>).setParallelism(defaultP * <span class="number">2</span>)</span><br><span class="line">  .print().setParallelism(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></div><p>当我们通过客户端将应用程序的并行度设置为16并提交执行时，source操作符的并行度为16，mapper并行度为32，sink并行度为2。如果我们在本地环境运行应用程序的话，例如在IDE中运行，机器是8核，那么source任务将会并行执行在8个任务上面，mapper运行在16个任务上面，sink运行在2个任务上面。</p><blockquote><p>并行度是动态概念，任务槽数量是静态概念。并行度&lt;=任务槽数量。一个任务槽最多运行一个并行度。</p></blockquote><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><p>Flink程序所处理的流中的事件一般是对象类型。操作符接收对象输出对象。所以Flink的内部机制需要能够处理事件的类型。在网络中传输数据，或者将数据写入到状态后端、检查点和保存点中，都需要我们对数据进行序列化和反序列化。为了高效的进行此类操作，Flink需要流中事件类型的详细信息。Flink使用了<code>Type Information</code>的概念来表达数据类型，这样就能针对不同的数据类型产生特定的序列化器，反序列化器和比较操作符。</p><blockquote><p>有点像泛型。</p></blockquote><p>Flink也能够通过分析输入数据和输出数据来自动获取数据的类型信息以及序列化器和反序列化器。尽管如此，在一些特定的情况下，例如匿名函数或者使用泛型的情况下，我们需要明确的提供数据的类型信息，来提高我们程序的性能。</p><p>在这一节中，我们将讨论Flink支持的类型，以及如何为数据类型创建相应的类型信息，还有就是在Flink无法推断函数返回类型的情况下，如何帮助Flink的类型系统去做类型推断。</p><h3 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h3><p>Flink支持Java和Scala提供的所有普通数据类型。最常用的数据类型可以做以下分类：</p><ul><li>Primitives（原始数据类型）</li><li>Java和Scala的Tuples（元组）</li><li>Scala的样例类</li><li>POJO类型</li><li>一些特殊的类型</li></ul><p>接下来让我们一探究竟。</p><p><em>Primitives</em></p><p>Java和Scala提供的所有原始数据类型都支持，例如<code>Int</code>(Java的<code>Integer</code>)，String，Double等等。下面举一个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers: <span class="type">DataStream</span>[<span class="type">Long</span>] = env.fromElements(<span class="number">1</span>L, <span class="number">2</span>L, <span class="number">3</span>L, <span class="number">4</span>L)</span><br><span class="line">numbers.map(n =&gt; n + <span class="number">1</span>)</span><br></pre></td></tr></table></figure></div><p><em>Tuples</em></p><p>元组是一种组合数据类型，由固定数量的元素组成。</p><p>DataStream的Scala API直接使用Scala内置的Tuple。举个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> persons: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Integer</span>)] =</span><br><span class="line">env.fromElements(</span><br><span class="line">  (<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">  (<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">persons.filter(p =&gt; p._2 &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure></div><p>Flink为Java的Tuple同样提供了高效的实现。Flink实现的Java Tuple最多可以有25个元素，根据元素数量的不同，Tuple都被实现成了不同的类：Tuple1，Tuple2，一直到Tuple25。Tuple类是强类型。</p><p>我们可以将上面的例子用Java的DataStream API重写：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt; persons = env</span><br><span class="line">  .fromElements(</span><br><span class="line">    <span class="type">Tuple2</span>.of(<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">    <span class="type">Tuple2</span>.of(<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">persons.filter(p -&gt; p.f1 &gt; <span class="number">18</span>);</span><br></pre></td></tr></table></figure></div><p>Tuple的元素可以通过它们的public属性访问–f0，f1，f2等等。或者使用<code>getField(int pos)</code>方法来访问，元素下标从0开始：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.<span class="type">Tuple2</span></span><br><span class="line"></span><br><span class="line"><span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt; personTuple = <span class="type">Tuple2</span>.of(<span class="string">"Alex"</span>, <span class="number">42</span>);</span><br><span class="line"><span class="type">Integer</span> age = personTuple.getField(<span class="number">1</span>); <span class="comment">// age = 42</span></span><br></pre></td></tr></table></figure></div><p>不同于Scala的Tuple，Java的Tuple是可变数据结构，所以Tuple中的元素可以重新进行赋值。重复利用Java的Tuple可以减轻垃圾收集的压力。举个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">personTuple.f1 = <span class="number">42</span>; <span class="comment">// set the 2nd field to 42</span></span><br><span class="line">personTuple.setField(<span class="number">43</span>, <span class="number">1</span>); <span class="comment">// set the 2nd field to 43</span></span><br></pre></td></tr></table></figure></div><p><em>Scala case classes</em></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">persons</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = env.fromElements(</span><br><span class="line">  <span class="type">Person</span>(<span class="string">"Adam"</span>, <span class="number">17</span>),</span><br><span class="line">  <span class="type">Person</span>(<span class="string">"Sarah"</span>, <span class="number">23</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">persons.filter(p =&gt; p.age &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure></div><p><em>POJO</em></p><p>POJO类的定义：</p><ul><li>公有类</li><li>无参数的公有构造器</li><li>所有的字段都是公有的，可以通过getters和setters访问。</li><li>所有字段的数据类型都必须是Flink支持的数据类型。</li></ul><p>举个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">  public <span class="type">String</span> name;</span><br><span class="line">  public int age;</span><br><span class="line"></span><br><span class="line">  public <span class="type">Person</span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  public <span class="type">Person</span>(<span class="type">String</span> name, int age) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Person</span>&gt; persons = env.fromElements(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">"Alex"</span>, <span class="number">42</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Person</span>(<span class="string">"Wendy"</span>, <span class="number">23</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></div><p><em>其他数据类型</em></p><ul><li>Array, ArrayList, HashMap, Enum</li><li>Hadoop Writable types</li><li>Either, Option, Try</li></ul><h3 id="为数据类型创建类型信息"><a href="#为数据类型创建类型信息" class="headerlink" title="为数据类型创建类型信息"></a>为数据类型创建类型信息</h3><p>Flink类型系统的核心类是<code>TypeInformation</code>。它为系统在产生序列化器和比较操作符时，提供了必要的类型信息。例如，如果我们想使用某个key来做联结查询或者分组操作，<code>TypeInformation</code>可以让Flink做更严格的类型检查。</p><p>Flink针对Java和Scala分别提供了类来产生类型信息。在Java中，类是</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.flink.api.common.typeinfo.<span class="type">Types</span></span><br></pre></td></tr></table></figure></div><p>举个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Integer</span>&gt; intType = <span class="type">Types</span>.<span class="type">INT</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Long</span>, <span class="type">String</span>&gt;&gt; tupleType = <span class="type">Types</span></span><br><span class="line">  .<span class="type">TUPLE</span>(<span class="type">Types</span>.<span class="type">LONG</span>, <span class="type">Types</span>.<span class="type">STRING</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">TypeInformation</span>&lt;<span class="type">Person</span>&gt; personType = <span class="type">Types</span></span><br><span class="line">  .<span class="type">POJO</span>(<span class="type">Person</span><span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure></div><p>在Scala中，类是 <code>org.apache.flink.api.scala.typeutils.Types</code> ，举个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TypeInformation for primitive types</span></span><br><span class="line"><span class="keyword">val</span> stringType: <span class="type">TypeInformation</span>[<span class="type">String</span>] = <span class="type">Types</span>.<span class="type">STRING</span></span><br><span class="line"><span class="comment">// TypeInformation for Scala Tuples</span></span><br><span class="line"><span class="keyword">val</span> tupleType: <span class="type">TypeInformation</span>[(<span class="type">Int</span>, <span class="type">Long</span>)] = <span class="type">Types</span>.<span class="type">TUPLE</span>[(<span class="type">Int</span>, <span class="type">Long</span>)]</span><br><span class="line"><span class="comment">// TypeInformation for case classes</span></span><br><span class="line"><span class="keyword">val</span> caseClassType: <span class="type">TypeInformation</span>[<span class="type">Person</span>] = <span class="type">Types</span>.<span class="type">CASE_CLASS</span>[<span class="type">Person</span>]</span><br></pre></td></tr></table></figure></div><blockquote><p>别忘了导入<code>import org.apache.flink.streaming.api.scala._</code></p></blockquote><h2 id="定义Key以及引用字段"><a href="#定义Key以及引用字段" class="headerlink" title="定义Key以及引用字段"></a>定义Key以及引用字段</h2><p>在Flink中，我们必须明确指定输入流中的元素中的哪一个字段是key。</p><h3 id="使用字段位置进行keyBy"><a href="#使用字段位置进行keyBy" class="headerlink" title="使用字段位置进行keyBy"></a>使用字段位置进行keyBy</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyed = input.keyBy(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></div><blockquote><p>注意，要么明确写清楚类型注释，要么让Scala去做类型推断，不要用IDEA的类型推断功能。</p></blockquote><p>如果我们想要用元组的第2个字段和第3个字段做keyBy，可以看下面的例子。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> keyed2 = input.keyBy(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div><h3 id="使用字段表达式来进行keyBy"><a href="#使用字段表达式来进行keyBy" class="headerlink" title="使用字段表达式来进行keyBy"></a>使用字段表达式来进行keyBy</h3><p>对于样例类：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  timestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  temperature: <span class="type">Double</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">sensorStream</span></span>: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> keyedSensors = sensorStream.keyBy(<span class="string">"id"</span>)</span><br></pre></td></tr></table></figure></div><p>对于元组：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Long</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyed1 = input.keyBy(<span class="string">"2"</span>) <span class="comment">// key by 3rd field</span></span><br><span class="line"><span class="keyword">val</span> keyed2 = input.keyBy(<span class="string">"_1"</span>) <span class="comment">// key by 1st field</span></span><br><span class="line"></span><br><span class="line"><span class="type">DataStream</span>&lt;<span class="type">Tuple3</span>&lt;<span class="type">Integer</span>, <span class="type">String</span>, <span class="type">Long</span>&gt;&gt; javaInput = ...</span><br><span class="line">javaInput.keyBy(<span class="string">"f2"</span>) <span class="comment">// key Java tuple by 3rd field</span></span><br></pre></td></tr></table></figure></div><p>对于存在嵌套的样例类：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Address</span> (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  address: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  zip: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  country: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Person</span> (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  birthday: (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span></span>), <span class="title">//</span> <span class="title">year</span>, <span class="title">month</span>, <span class="title">day</span></span></span><br><span class="line"><span class="class">  <span class="title">address</span></span>: <span class="type">Address</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> persons: <span class="type">DataStream</span>[<span class="type">Person</span>] = ...</span><br><span class="line">persons.keyBy(<span class="string">"address.zip"</span>) <span class="comment">// key by nested POJO field</span></span><br><span class="line">persons.keyBy(<span class="string">"birthday._1"</span>) <span class="comment">// key by field of nested tuple</span></span><br><span class="line">persons.keyBy(<span class="string">"birthday._"</span>) <span class="comment">// key by all fields of nested tuple</span></span><br></pre></td></tr></table></figure></div><h3 id="Key选择器"><a href="#Key选择器" class="headerlink" title="Key选择器"></a>Key选择器</h3><p>方法类型</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KeySelector[IN, KEY]</span><br><span class="line">  &gt; getKey(IN): KEY</span><br></pre></td></tr></table></figure></div><p>两个例子</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> byId: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = sensorData.keyBy(r =&gt; r.id)</span><br><span class="line"><span class="keyword">val</span> input: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = ...</span><br><span class="line"><span class="keyword">val</span> keyedStream = input.keyBy(value =&gt; math.max(value._1, value._2))</span><br></pre></td></tr></table></figure></div><h2 id="实现UDF函数，更细粒度的控制流"><a href="#实现UDF函数，更细粒度的控制流" class="headerlink" title="实现UDF函数，更细粒度的控制流"></a>实现UDF函数，更细粒度的控制流</h2><h3 id="函数类-Function-Classes"><a href="#函数类-Function-Classes" class="headerlink" title="函数类(Function Classes)"></a>函数类(Function Classes)</h3><p>Flink暴露了所有udf函数的接口(实现方式为接口或者抽象类)。例如MapFunction, FilterFunction, ProcessFunction等等。</p><p>例子实现了FilterFunction接口</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FilterFilter</span> <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    value.contains(<span class="string">"flink"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(<span class="keyword">new</span> <span class="type">FlinkFilter</span>)</span><br></pre></td></tr></table></figure></div><p>还可以将函数实现成匿名类</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">RichFilterFunction</span>[<span class="type">String</span>] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">      value.contains(<span class="string">"flink"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><p>我们filter的字符串“flink”还可以当作参数传进去。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tweets: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(<span class="keyword">new</span> <span class="type">KeywordFilter</span>(<span class="string">"flink"</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KeywordFilter</span>(<span class="params">keyWord: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    value.contains(keyWord)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="匿名函数-Lambda-Functions"><a href="#匿名函数-Lambda-Functions" class="headerlink" title="匿名函数(Lambda Functions)"></a>匿名函数(Lambda Functions)</h3><p>匿名函数可以实现一些简单的逻辑，但无法实现一些高级功能，例如访问状态等等。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tweets: <span class="type">DataStream</span>[<span class="type">String</span>] = ...</span><br><span class="line"><span class="keyword">val</span> flinkTweets = tweets.filter(_.contains(<span class="string">"flink"</span>))</span><br></pre></td></tr></table></figure></div><h3 id="富函数-Rich-Functions"><a href="#富函数-Rich-Functions" class="headerlink" title="富函数(Rich Functions)"></a>富函数(Rich Functions)</h3><p>我们经常会有这样的需求：在函数处理数据之前，需要做一些初始化的工作；或者需要在处理数据时可以获得函数执行上下文的一些信息；以及在处理完数据时做一些清理工作。而DataStream API就提供了这样的机制。</p><p>DataStream API提供的所有转换操作函数，都拥有它们的“富”版本，并且我们在使用常规函数或者匿名函数的地方来使用富函数。例如下面就是富函数的一些例子，可以看出，只需要在常规函数的前面加上<code>Rich</code>前缀就是富函数了。</p><ul><li>RichMapFunction</li><li>RichFlatMapFunction</li><li>RichFilterFunction</li><li>…</li></ul><p>当我们使用富函数时，我们可以实现两个额外的方法：</p><ul><li>open()方法是rich function的初始化方法，当一个算子例如map或者filter被调用之前open()会被调用。open()函数通常用来做一些只需要做一次即可的初始化工作。</li><li>close()方法是生命周期中的最后一个调用的方法，通常用来做一些清理工作。</li></ul><p>另外，getRuntimeContext()方法提供了函数的RuntimeContext的一些信息，例如函数执行的并行度，当前子任务的索引，当前子任务的名字。同时还它还包含了访问<strong>分区状态</strong>的方法。下面看一个例子：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyFlatMap</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>[<span class="type">Int</span>, (<span class="type">Int</span>, <span class="type">Int</span>)] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> subTaskIndex = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(configuration: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    subTaskIndex = getRuntimeContext.getIndexOfThisSubtask</span><br><span class="line">    <span class="comment">// 做一些初始化工作</span></span><br><span class="line">    <span class="comment">// 例如建立一个和HDFS的连接</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(in: <span class="type">Int</span>, out: <span class="type">Collector</span>[(<span class="type">Int</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (in % <span class="number">2</span> == subTaskIndex) &#123;</span><br><span class="line">      out.collect((subTaskIndex, in))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 清理工作，断开和HDFS的连接。</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><p>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。所有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.addSink(<span class="keyword">new</span> <span class="type">MySink</span>(xxxx))</span><br></pre></td></tr></table></figure></div><p>官方提供了一部分的框架的sink。除此以外，需要用户自定义实现sink。</p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>Kafka版本为0.11</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka-0.11_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>Kafka版本为2.0以上</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>主函数中添加sink：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> union = high</span><br><span class="line">  .union(low)</span><br><span class="line">  .map(_.temperature.toString)</span><br><span class="line"></span><br><span class="line">union.addSink(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FlinkKafkaProducer011</span>[<span class="type">String</span>](</span><br><span class="line">    <span class="string">"localhost:9092"</span>,</span><br><span class="line">    <span class="string">"test"</span>,</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.bahir<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-redis_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>定义一个redis的mapper类，用于定义保存到redis时调用的命令：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRedisMapper</span> <span class="keyword">extends</span> <span class="title">RedisMapper</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getCommandDescription</span></span>: <span class="type">RedisCommandDescription</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">RedisCommandDescription</span>(<span class="type">RedisCommand</span>.<span class="type">HSET</span>, <span class="string">"sensor_temperature"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValueFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    t.temperature.toString</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKeyFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = t.id</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>在主函数中调用：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>在主函数中调用：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> httpHosts = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">HttpHost</span>]()</span><br><span class="line">httpHosts.add(<span class="keyword">new</span> <span class="type">HttpHost</span>(<span class="string">"localhost"</span>, <span class="number">9200</span>))</span><br><span class="line"><span class="keyword">val</span> esSinkBuilder = <span class="keyword">new</span> <span class="type">ElasticsearchSink</span>.<span class="type">Builder</span>[<span class="type">SensorReading</span>](</span><br><span class="line">  httpHosts,</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ElasticsearchSinkFunction</span>[<span class="type">SensorReading</span>] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(t: <span class="type">SensorReading</span>,</span><br><span class="line">                         runtimeContext: <span class="type">RuntimeContext</span>,</span><br><span class="line">                         requestIndexer: <span class="type">RequestIndexer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">"saving data: "</span> + t)</span><br><span class="line">      <span class="keyword">val</span> json = <span class="keyword">new</span> util.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line">      json.put(<span class="string">"data"</span>, t.toString)</span><br><span class="line">      <span class="keyword">val</span> indexRequest = <span class="type">Requests</span></span><br><span class="line">        .indexRequest()</span><br><span class="line">        .index(<span class="string">"sensor"</span>)</span><br><span class="line">        .`<span class="class"><span class="keyword">type</span>`(<span class="params">"readingData"</span>)</span></span><br><span class="line"><span class="class">        .<span class="title">source</span>(<span class="params">json</span>)</span></span><br><span class="line"><span class="class">      <span class="title">requestIndexer</span>.<span class="title">add</span>(<span class="params">indexRequest</span>)</span></span><br><span class="line"><span class="class">      <span class="title">println</span>(<span class="params">"saved successfully"</span>)</span></span><br><span class="line"><span class="class">    &#125;</span></span><br><span class="line"><span class="class">  &#125;)</span></span><br><span class="line"><span class="class"><span class="title">dataStream</span>.<span class="title">addSink</span>(<span class="params">esSinkBuilder.build(</span>))</span></span><br></pre></td></tr></table></figure></div><h3 id="JDBC自定义sink"><a href="#JDBC自定义sink" class="headerlink" title="JDBC自定义sink"></a>JDBC自定义sink</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.44<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>添加MyJdbcSink</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyJdbcSink</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> conn: <span class="type">Connection</span> = _</span><br><span class="line">  <span class="keyword">var</span> insertStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="keyword">var</span> updateStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="comment">// open 主要是创建连接</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">super</span>.open(parameters)</span><br><span class="line">    conn = <span class="type">DriverManager</span>.getConnection(</span><br><span class="line">      <span class="string">"jdbc:mysql://localhost:3306/test"</span>,</span><br><span class="line">      <span class="string">"root"</span>,</span><br><span class="line">      <span class="string">"123456"</span>)</span><br><span class="line">    insertStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"INSERT INTO temperatures (sensor, temp) VALUES (?, ?)"</span></span><br><span class="line">    )</span><br><span class="line">    updateStmt = conn.prepareStatement(</span><br><span class="line">      <span class="string">"UPDATE temperatures SET temp = ? WHERE sensor = ?"</span></span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用连接，执行sql</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: <span class="type">SensorReading</span>,</span><br><span class="line">                      context: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    updateStmt.setDouble(<span class="number">1</span>, value.temperature)</span><br><span class="line">    updateStmt.setString(<span class="number">2</span>, value.id)</span><br><span class="line">    updateStmt.execute()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (updateStmt.getUpdateCount == <span class="number">0</span>) &#123;</span><br><span class="line">      insertStmt.setString(<span class="number">1</span>, value.id)</span><br><span class="line">      insertStmt.setDouble(<span class="number">2</span>, value.temperature)</span><br><span class="line">      insertStmt.execute()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    insertStmt.close()</span><br><span class="line">    updateStmt.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>在main方法中增加，把明细保存到mysql中</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.addSink(<span class="keyword">new</span> <span class="type">MyJdbcSink</span>())</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第五章，Flink-DataStream-API&quot;&gt;&lt;a href=&quot;#第五章，Flink-DataStream-API&quot; class=&quot;headerlink&quot; title=&quot;第五章，Flink DataStream API&quot;&gt;&lt;/a&gt;第五章，Flink Data
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列04第一个Flink程序</title>
    <link href="https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9704%E7%AC%AC%E4%B8%80%E4%B8%AAFlink%E7%A8%8B%E5%BA%8F/"/>
    <id>https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9704%E7%AC%AC%E4%B8%80%E4%B8%AAFlink%E7%A8%8B%E5%BA%8F/</id>
    <published>2020-06-27T15:27:31.000Z</published>
    <updated>2020-06-27T15:28:02.624Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第四章，编写第一个Flink程序"><a href="#第四章，编写第一个Flink程序" class="headerlink" title="第四章，编写第一个Flink程序"></a>第四章，编写第一个Flink程序</h1><h2 id="在IDEA中编写Flink程序"><a href="#在IDEA中编写Flink程序" class="headerlink" title="在IDEA中编写Flink程序"></a>在IDEA中编写Flink程序</h2><p>本项目使用的Flink版本为最新版本，也就是1.10.0。现在提供maven项目的配置文件。</p><ol><li>使用Intellij IDEA创建一个Maven新项目</li><li>勾选<code>Create from archetype</code>，然后点击<code>Add Archetype</code>按钮</li><li><code>GroupId</code>中输入<code>org.apache.flink</code>，<code>ArtifactId</code>中输入<code>flink-quickstart-scala</code>，<code>Version</code>中输入<code>1.10.0</code>，然后点击<code>OK</code></li><li>点击向右箭头，出现下拉列表，选中<code>flink-quickstart-scala:1.10.0</code>，点击<code>Next</code></li><li><code>Name</code>中输入<code>FlinkTutorial</code>，<code>GroupId</code>中输入<code>com.atguigu</code>，<code>ArtifactId</code>中输入<code>FlinkTutorial</code>，点击<code>Next</code></li><li>最好使用IDEA默认的Maven工具：Bundled（Maven 3），点击<code>Finish</code>，等待一会儿，项目就创建好了</li></ol><p>编写<code>WordCount.scala</code>程序</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">scala</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StreamingJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Main program method */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) : <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get the execution environment</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">      .getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get input data by connecting to the socket</span></span><br><span class="line">    <span class="keyword">val</span> text: <span class="type">DataStream</span>[<span class="type">String</span>] = env</span><br><span class="line">      .socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>, '\n')</span><br><span class="line"></span><br><span class="line">    <span class="comment">// parse the data, group it, window it, and aggregate the counts</span></span><br><span class="line">    <span class="keyword">val</span> windowCounts = text</span><br><span class="line">      .flatMap &#123; w =&gt; w.split(<span class="string">"\\s"</span>) &#125;</span><br><span class="line">      .map &#123; w =&gt; <span class="type">WordWithCount</span>(w, <span class="number">1</span>) &#125;</span><br><span class="line">      .keyBy(<span class="string">"word"</span>)</span><br><span class="line">      .timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line">      .sum(<span class="string">"count"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// print the results with a single thread, rather than in parallel</span></span><br><span class="line">    windowCounts</span><br><span class="line">      .print()</span><br><span class="line">      .setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"Socket Window WordCount"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Data type for words with count */</span></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">WordWithCount</span>(<span class="params">word: <span class="type">String</span>, count: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class">&#125;</span></span><br></pre></td></tr></table></figure></div><p>打开一个终端（Terminal），运行以下命令</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nc -lk 9999</span><br></pre></td></tr></table></figure></div><p>接下来使用<code>IDEA</code>运行就可以了。</p><h2 id="下载Flink运行时环境，提交Jar包的运行方式"><a href="#下载Flink运行时环境，提交Jar包的运行方式" class="headerlink" title="下载Flink运行时环境，提交Jar包的运行方式"></a>下载Flink运行时环境，提交Jar包的运行方式</h2><p>下载链接：<a href="http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/flink/flink-1.10.1/flink-1.10.1-bin-scala_2.11.tgz</a></p><p>然后解压</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar xvfz flink-1.10.0-bin-scala_2.11.tgz</span><br></pre></td></tr></table></figure></div><p>启动Flink集群</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd flink-1.10.0</span><br><span class="line">$ .&#x2F;bin&#x2F;start-cluster.sh</span><br></pre></td></tr></table></figure></div><p>可以打开Flink WebUI查看集群状态：<a href="http://localhost:8081" target="_blank" rel="noopener">http://localhost:8081</a></p><p>在<code>IDEA</code>中使用<code>maven package</code>打包。</p><p>提交打包好的<code>JAR</code>包</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd flink-1.10.0</span><br><span class="line">$ .&#x2F;bin&#x2F;flink run 打包好的JAR包的绝对路径</span><br></pre></td></tr></table></figure></div><p>停止Flink集群</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;bin&#x2F;stop-cluster.sh</span><br></pre></td></tr></table></figure></div><p>查看标准输出日志的位置，在<code>log</code>文件夹中。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cd flink-1.10.0&#x2F;log</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第四章，编写第一个Flink程序&quot;&gt;&lt;a href=&quot;#第四章，编写第一个Flink程序&quot; class=&quot;headerlink&quot; title=&quot;第四章，编写第一个Flink程序&quot;&gt;&lt;/a&gt;第四章，编写第一个Flink程序&lt;/h1&gt;&lt;h2 id=&quot;在IDEA中编写F
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink系列03Flink运行架构</title>
    <link href="https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9703Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84/"/>
    <id>https://masteryang4.github.io/2020/06/27/flink%E7%B3%BB%E5%88%9703Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84/</id>
    <published>2020-06-27T15:26:18.000Z</published>
    <updated>2020-06-27T15:27:16.346Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第三章，Flink运行架构"><a href="#第三章，Flink运行架构" class="headerlink" title="第三章，Flink运行架构"></a>第三章，Flink运行架构</h1><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>Flink是一个用于有状态的并行数据流处理的分布式系统。它由多个进程构成，这些进程一般会分布运行在不同的机器上。对于分布式系统来说，面对的常见问题有：集群中资源的分配和管理、进程协调调度、持久化和高可用的数据存储，以及故障恢复。</p><p>对于这些分布式系统的经典问题，业内已有比较成熟的解决方案和服务。所以Flink并不会自己去处理所有的问题，而是利用了现有的集群架构和服务，这样它就可以把精力集中在核心工作——分布式数据流处理上了。Flink与一些集群资源管理工具有很好的集成，比如Apache Mesos、YARN和Kubernetes；同时，也可以配置为独立（stand-alone）集群运行。Flink自己并不提供持久化的分布式存储，而是直接利用了已有的分布式文件系统（比如HDFS）或者对象存储（比如S3）。对于高可用的配置，Flink需要依靠Apache ZooKeeper来完成。</p><p>在本节中，我们将介绍Flink的不同组件，以及在运行程序时它们如何相互作用。我们会讨论部署Flink应用程序的两种模式，并且了解每种模式下分发和执行任务的方式。最后，我们还会解释一下Flink的高可用性模式是如何工作的。</p><h3 id="Flink运行时组件"><a href="#Flink运行时组件" class="headerlink" title="Flink运行时组件"></a>Flink运行时组件</h3><p>Flink运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）。因为Flink是用Java和Scala实现的，所以所有组件都会运行在Java虚拟机（JVMs）上。每个组件的职责如下：</p><ul><li>作业管理器（JobManager）是控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。JobManager会先接收到要执行的应用程序。这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</li><li>ResourceManager主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger插槽是Flink中定义的处理资源单元。Flink为不同的环境和资源管理工具提供了不同资源管理器（ResourceManager），比如YARN、Mesos、K8s，以及standalone部署。当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。另外，ResourceManager还负责终止空闲的TaskManager，释放计算资源。</li><li>任务管理器（TaskManager）是Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。任务的执行和插槽的概念会在“任务执行”一节做具体讨论。</li><li>分发器（Dispatcher）可以跨作业运行，它为应用提交提供了REST接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。由于是REST接口，所以Dispatcher可以作为集群的一个HTTP接入点，这样就能够不受防火墙阻挡。Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。</li></ul><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0301.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0301.png" class="lazyload"></a></p><blockquote><p>上图是从一个较为高层级的视角，来看应用中各组件的交互协作。如果部署的集群环境不同（例如YARN，Mesos，Kubernetes，standalone等），其中一些步骤可以被省略，或是有些组件会运行在同一个JVM进程中。</p></blockquote><h3 id="应用部署"><a href="#应用部署" class="headerlink" title="应用部署"></a>应用部署</h3><p>Flink应用程序可以用以下两种不同的方式部署：</p><p><em>框架（Framework）方式</em></p><p>在这个模式下，Flink应用被打包成一个Jar文件，并由客户端提交给一个运行服务（running service）。这个服务可以是一个Flink的Dispatcher，也可以是一个Flink的JobManager，或是Yarn的ResourceManager。如果application被提交给一个JobManager，则它会立即开始执行这个application。如果application被提交给了一个Dispatcher，或是Yarn ResourceManager，则它会启动一个JobManager，然后将application交给它，再由JobManager开始执行此应用。</p><p><em>库（Library）方式</em></p><p>在这个模式下，Flink Application 会被打包在一个容器（container） 镜像里，例如一个Docker 镜像。此镜像包含了运行JobManager和ResourceManager的代码。当一个容器从镜像启动后，它会自动启动ResourceManager和JobManager，并提交打包好的应用。另一种方法是：将应用打包到镜像后，只用于部署TaskManager容器。从镜像启动的容器会自动启动一个TaskManager，然后连接ResourceManager并注册它的slots。这些镜像的启动以及失败重启，通常都会由一个外部的资源管理器管理（比如Kubernetes）。</p><p>框架模式遵循了传统的任务提交方式，从客户端提交到Flink运行服务。而在库模式下，没有运行的Flink服务。它是将Flink作为一个库，与应用程序一同打包到了一个容器镜像。这种部署方式在微服务架构中较为常见。我们会在“运行管理流式应用程序”一节对这个话题做详细讨论。</p><h3 id="任务执行"><a href="#任务执行" class="headerlink" title="任务执行"></a>任务执行</h3><p>一个TaskManager可以同时执行多个任务（tasks）。这些任务可以是同一个算子（operator）的子任务（数据并行），也可以是来自不同算子的（任务并行），甚至可以是另一个不同应用程序的（作业并行）。TaskManager提供了一定数量的处理插槽（processing slots），用于控制可以并行执行的任务数。一个slot可以执行应用的一个分片，也就是应用中每一个算子的一个并行任务。图3-2展示了TaskManagers，slots，tasks以及operators之间的关系：</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0302.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0302.png" class="lazyload"></a></p><p>最左边是一个“作业图”（JobGraph），包含了5个算子——它是应用程序的非并行表示。其中算子A和C是数据源（source），E是输出端（sink）。C和E并行度为2，而其他的算子并行度为4。因为最高的并行度是4，所以应用需要至少四个slot来执行任务。现在有两个TaskManager，每个又各有两个slot，所以我们的需求是满足的。JobManager将JobGraph转化为“执行图”（ExecutionGraph），并将任务分配到四个可用的slot上。对于有4个并行任务的算子，它的task会分配到每个slot上。而对于并行度为2的operator C和E，它们的任务被分配到slot 1.1、2.1 以及 slot 1.2、2.2。将tasks调度到slots上，可以让多个tasks跑在同一个TaskManager内，也就可以是的tasks之间的数据交换更高效。然而将太多任务调度到同一个TaskManager上会导致TaskManager过载，继而影响效率。之后我们会在“控制任务调度”一节继续讨论如何控制任务的调度。</p><p>TaskManager在同一个JVM中以多线程的方式执行任务。线程较进程会更轻量级，但是线程之间并没有对任务进行严格隔离。所以，单个任务的异常行为有可能会导致整个TaskManager进程挂掉，当然也同时包括运行在此进程上的所有任务。通过为每个TaskManager配置单独的slot，就可以将应用在TaskManager上相互隔离开来。TaskManager内部有多线程并行的机制，而且在一台主机上可以部署多个TaskManager，所以Flink在资源配置上非常灵活，在部署应用时可以充分权衡性能和资源的隔离。我们将会在第九章对Flink集群的配置和搭建继续做详细讨论。</p><h3 id="高可用配置"><a href="#高可用配置" class="headerlink" title="高可用配置"></a>高可用配置</h3><p>流式应用程序一般被设计为7 x 24小时运行。所以很重要的一点是：即使出现了进程挂掉的情况，应用仍需要继续保持运行。为了从故障恢复，系统首先需要重启进程、然后重启应用并恢复它的状态。接下来，我们就来了解Flink如何重启失败的进程。</p><p><em>TaskManager故障</em></p><p>如前所述，Flink需要足够数目的slot，来执行一个应用的所有任务。假设一个Flink环境有4个TaskManager，每个提供2个插槽，那么流应用程序执行的最高并行度为8。如果其中一个TaskManager挂掉了，那么可用的slots会降到6。在这种情况下，JobManager会请求ResourceManager提供更多的slots。如果此请求无法满足——例如应用跑在一个standalone集群——那么JobManager在有足够的slots之前，无法重启应用。应用的重启策略决定了JobManager的重启频率，以及两次重启尝试之间的时间间隔。</p><p><em>JobManager故障</em></p><p>比TaskManager故障更严重的问题是JobManager故障。JobManager控制整个流应用程序的执行，并维护执行中的元数据——例如指向已完成检查点的指针。若是对应的JobManager挂掉，则流程序无法继续运行。所以这就导致在Flink应用中，JobManager是单点故障。为了解决这个问题，Flink提供了高可用模式。在原先的JobManager挂掉后，可以将一个作业的状态和元数据迁移到另一个JobManager，并继续执行。</p><p>Flink的高可用模式基于Apache ZooKeeper，我们知道，ZooKeeper是用来管理需要协调和共识的分布式服务的系统。Flink主要利用ZooKeeper来进行领导者（leader）的选举，并把它作为一个高可用和持久化的数据存储。当在高可用模式下运行时，JobManager会将JobGraph以及所有需要的元数据（例如应用程序的jar文件），写入到一个远程的持久化存储系统中。而且，JobManager会将指向存储位置的指针，写入到ZooKeeper的数据存储中。在执行一个应用的过程中，JobManager会接收每个独立任务检查点的状态句柄（也就是存储位置）。当一个检查点完成时（所有任务已经成功地将它们的状态写入到远程存储）， JobManager把状态句柄写入远程存储，并将指向这个远程存储的指针写入ZooKeeper。这样，一个JobManager挂掉之后再恢复，所需要的所有数据信息已经都保存在了远程存储，而ZooKeeper里存有指向此存储位置的指针。图3-3描述了这个设计：</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0303.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0303.png" class="lazyload"></a></p><p>当一个JobManager失败，所有属于这个应用的任务都会自动取消。一个新的JobManager接管工作，会执行以下操作：</p><ul><li>从ZooKeeper请求存储位置（storage location），从远端存储获取JobGraph，Jar文件，以及应用最近一次检查点（checkpoint）的状态句柄（state handles）</li><li>从ResourceManager请求slots，用来继续运行应用</li><li>重启应用，并将所有任务的状态，重设为最近一次已完成的检查点</li></ul><p>如果我们是在容器环境里运行应用（如Kubernetes），故障的JobManager或TaskManager 容器通常会由容器服务自动重启。当运行在YARN或Mesos之上时，JobManager或TaskManager进程会由Flink的保留进程自动触发重启。而在standalone模式下，Flink并未提供重启故障进程的工具。所以，此模式下我们可以增加备用（standby）的 JobManager和TaskManager，用于接管故障的进程。我们将会在“高可用配置”一节中做进一步讨论。</p><h2 id="Flink中的数据传输"><a href="#Flink中的数据传输" class="headerlink" title="Flink中的数据传输"></a>Flink中的数据传输</h2><p>运行中的应用任务，会持续不断地交换数据。TaskManager负责将数据从“发送任务”（sending tasks）传递到“接收任务”（receiving tasks）。TaskManager的网络组件会在缓冲区中收集数据，然后再将其发送，也就是说，数据不是逐条发送的，而是在缓冲区中“攒”成了一批。这种技术是有效利用网络资源和实现高吞吐量的基础，机制类似于网络或磁盘I/O协议中使用的缓冲技术。</p><blockquote><p>通过缓冲区来传递数据，意味着Flink的处理模型是基于微批的。</p></blockquote><p>每个TaskManager都有一个网络缓冲池（默认大小为32KB），用于发送和接收数据。如果发送任务和接收任务运行在不同的TaskManager进程中，那么它们会通过操作系统的网络栈来进行通信。流应用程序需要以管道方式传递数据，所以每对TaskManager之间都需要维护一个永久TCP连接，用来交换数据。在无序连接模式下，每个发送任务都需要能向任何接收任务传递数据。所以我们发现，TaskManager需要为每一个接收任务设置一个专用的网络缓冲区，因为其中的每一个任务都需要接收数据。图3-4展示了这种架构。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0304.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0304.png" class="lazyload"></a></p><p>如图3-4所示，四个发送任务中的每一个都需要至少四个网络缓冲区，用来向每个接收任务发送数据，而每个接收任务也需要至少四个缓冲区来接收数据。需要发送到另一个TaskManager的缓冲数据，会复用同一网络连接。为了实现平滑的管道数据传输，TaskManager必须能够提供足够的缓冲，来同时为所有传出和传入连接提供服务。对于无序或广播连接，每个发送任务都需要为每个接收任务提供一个缓冲；所以，所需缓冲区的数量是相关算子任务数量的平方。Flink网络缓冲区的默认配置足以满足中小型应用；对于更大的应用场景，就需要按照“主内存和网络缓冲区”一节中的叙述调整配置了。</p><p>当发送任务和接收任务在同一个TaskManager进程中运行时，发送任务会将传出的数据序列化，放入字节缓冲区，并在缓冲区填满后将其放入队列。接收任务从队列中提取缓冲数据并对其进行反序列化。因此，在同一个TaskManager上运行的任务，它们之间的数据传输不会导致网络通信。</p><p>Flink采用不同的技术来降低任务之间的通信成本。在下面的部分中，我们会简要讨论基于信任度（Credit）的流控制和任务链。</p><h3 id="基于信任度（credit）的流控制"><a href="#基于信任度（credit）的流控制" class="headerlink" title="基于信任度（credit）的流控制"></a>基于信任度（credit）的流控制</h3><p>通过网络连接来发送每条数据的效率很低，会导致很大的开销。为了充分利用网络连接的带宽，就需要进行缓冲了。在流处理的上下文中，缓冲的一个缺点是会增加延迟，因为数据需要在缓冲区中进行收集，而不是立即发送。</p><p>Flink实现了一个基于信任度的流量控制机制，其工作原理如下。接收任务授予发送任务一些“信任度”（credit），也就是为了接收其数据而保留的网络缓冲区数。当发送者收到一个信任度通知，它就会按照被授予的信任度，发送尽可能多的缓冲数据，并且同时发送目前积压数据的大小——也就是已填满并准备发送的网络缓冲的数量。接收者用保留的缓冲区处理发来的数据，并对发送者传来的积压量进行综合考量，为其所有连接的发送者确定下一个信用度授权的优先级。</p><p>基于信用度的流控制可以减少延迟，因为发送者可以在接收者有足够的资源接受数据时立即发送数据。此外，在数据倾斜的情况下，这样分配网络资源是一种很有效的机制，因为信用度是根据发送者积压数据量的规模授予的。因此，基于信用的流量控制是Flink实现高吞吐量和低延迟的重要组成部分。</p><h3 id="任务链（Task-Chaining）"><a href="#任务链（Task-Chaining）" class="headerlink" title="任务链（Task Chaining）"></a>任务链（Task Chaining）</h3><p>Flink采用了一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将两个或多个算子设为相同的并行度，并通过本地转发（local forward）的方式进行连接。图3-5所示的算子管道满足这些要求。它由三个算子组成，这些算子的任务并行度都被设为2，并且通过本地转发方式相连接。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0305.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0305.png" class="lazyload"></a></p><p>图3-6展示了管道以任务链方式运行的过程。算子的函数被融合成了一个单一的任务，由一个线程执行。由函数生成的数据通过一个简单的方法调用移交给下一个函数；这样在函数之间直接传递数据，基本上没有序列化和通信成本。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0306.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0306.png" class="lazyload"></a></p><p>任务链可以显著降低本地任务之间的通信成本，但也有一些场景，在没有链接的情况下运行管道操作是有意义的。例如，如果任务链中某个函数执行的开销巨大，那就可以将一条长的任务链管道断开，或者将一条链断开为两个任务，从而可以将这个开销大的函数调度到不同的槽（slots）中。图3-7显示了在没有任务链的情况下相同管道操作的执行情况。所有函数都由独立的单个任务来评估，每个任务都在专有的线程中运行。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0307.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0307.png" class="lazyload"></a></p><p>任务链在Flink中默认会启用。在“控制任务链”一节中，我们展示了如何禁用应用程序的任务链，以及如何控制各个算子的链接行为。</p><h2 id="事件时间（Event-Time）处理"><a href="#事件时间（Event-Time）处理" class="headerlink" title="事件时间（Event-Time）处理"></a>事件时间（Event-Time）处理</h2><p>在“时间语义”一节，我们重点强调了时间语义在流处理应用中的重要性，并且解释了处理时间（processing time）和事件时间（event time）的不同。处理时间比较好理解，因为它是基于处理器本地时间的；但同时，它会带来比较混乱、不一致、并且不可重现的结果。相比之下，事件时间语义能够产生可重现且一致的结果，这也是许多流处理场景希望解决的一大难题。但是，与处理时间应用程序相比，事件时间应用程序会更复杂，需要额外的配置。另外，支持事件时间的流处理器，也比纯粹在处理时间中运行的系统内部更为复杂。</p><p>Flink为常见的事件时间处理操作提供了直观且易于使用的原语，同时暴露了表达性很强的API，用户可以使用自定义算子实现更高级的事件时间应用程序。很好地理解Flink的内部时间处理，对于实现这样的高级应用程序会有很大帮助，有时也是必需的。上一章介绍了Flink利用两个概念来支持事件时间语义：记录时间戳（timestamps）和水位线（watermarks）。接下来，我们将描述Flink如何在内部实现并处理时间戳和水位线，进而支持具有事件时间语义的流式应用程序。</p><h3 id="时间戳（Timestamps）"><a href="#时间戳（Timestamps）" class="headerlink" title="时间戳（Timestamps）"></a>时间戳（Timestamps）</h3><p>由Flink事件时间流应用程序处理的所有记录都必须伴有时间戳。时间戳将数据与特定时间点相关联，通常就是数据所表示的事件发生的时间点。而只要时间戳大致跟数据流保持一致，基本上随着数据流的前进而增大，应用程序就可以自由选择时间戳的含义。不过正如“时间语义”一节中所讨论的，在现实场景中，时间戳基本上都是乱序的，所以采用“事件时间”而非“处理事件”往往会显得更为重要。</p><p>当Flink以事件时间模式处理数据流时，它会根据数据记录的时间戳来处理基于时间的算子。例如，时间窗口算子根据相关时间戳将数据分配给不同的时间窗口。Flink将时间戳编码为16字节的长整型值，并将其作为元数据附加到数据记录中。它的内置运算符会将这个长整型值解释为一个具有毫秒精度的Unix时间戳，也就是1970-01-01-00:00:00.000以来的毫秒数。当然，如果用户进行了自定义，那么运算符可以有自己的解释，例如，可以将精度调整到微秒。</p><h3 id="水位线-Watermarks"><a href="#水位线-Watermarks" class="headerlink" title="水位线(Watermarks)"></a>水位线(Watermarks)</h3><p>除了时间戳，基于事件时间的Flink应用程序还必须支持水位线（watermark）。在基于事件时间的应用中，水位线用于生成每个任务的当前事件时间。基于时间的算子使用这个“当前事件时间”来触发计算和处理操作。例如，一个时间窗口任务（time-window task）会在任务的事件时间超出窗口的关闭边界时，完成窗口计算，并输出计算结果。</p><p>在Flink中，水位线被实现为一条特殊的数据记录，它里面以长整型值保存了一个时间戳。水位线在带有时间戳的数据流中，跟随着其它数据一起流动，如图3-8所示。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0308.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0308.png" class="lazyload"></a></p><p>水位线有两个基本属性：</p><ul><li>必须单调递增，以确保任务的事件时间时钟在向前推进，而不是在后退。</li><li>它们与数据的时间戳相关。带有时间戳T的水位线表示，所有后续数据的时间戳都应该大于T。</li></ul><p>上面的第二个属性用于处理带有乱序时间戳的数据流，比如图3-8中时间戳3和5的数据。基于时间的算子任务会收集和处理数据（这些数据可能具有乱序的时间戳），并在事件时间时钟到达某个时刻时完成计算。这个时刻就表示数据收集的截止，具有之前时间戳的数据应该都已经到达、不再需要了；而其中的事件时间时钟，正是由当前接收到的水位线来指示的。如果任务再接收到的数据违反了watermark的这一属性，也就是时间戳小于以前接收到的水位线时，它所属的那部分计算可能已经完成了。这种数据被称为延迟数据（late records）。Flink提供了处理延迟数据的不同方式，我们会在“处理延迟数据”一节中讨论。</p><p>水位线还有一个很有趣的特性，它允许应用程序自己来平衡结果的完整性和延迟。如果水位线与数据的时间戳非常接近，那么我们可以得到较低的处理延迟，因为任务在完成计算之前只会短暂地等待更多数据到达。而同时，结果的完整性可能会受到影响，因为相关数据可能因为迟到而被视为“延迟数据”，这样就不会包含在结果中。相反，非常保守的水位线提供了足够的时间去等待所有数据到达，这样会增加处理延迟，但提高了结果的完整性。</p><h3 id="watermark的传递和事件时间"><a href="#watermark的传递和事件时间" class="headerlink" title="watermark的传递和事件时间"></a>watermark的传递和事件时间</h3><p>在本节中，我们将讨论算子如何处理水位线。Flink把watermark作为一条特殊的数据来实现，它也会由算子任务接收和发送。任务会有一个内部的时间服务，它会维护定时器，并在收到watermark时触发。任务可以在计时器服务中注册定时器，以便在将来特定的时间点执行计算。例如，窗口算子为每个活动窗口注册一个定时器，当事件时间超过窗口的结束时间时，该计时器将清除窗口的状态。</p><p>当任务收到watermark时，将执行以下操作：</p><ul><li>任务根据watermark的时间戳更新其内部事件时钟。</li><li>任务的时间服务会将所有过期的计时器标识出来，它们的时间小于当前的事件时间。对于每个过期的计时器，任务调用一个回调函数，该函数可以执行计算并发送结果。</li><li>任务会发出一个带有更新后的事件时间的watermark。</li></ul><blockquote><p>Flink限制通过DataStream API访问时间戳和watermark。函数不能读取或修改数据的时间戳和watermark，但底层的“处理函数”（process functions）除外，它们可以读取当前处理数据的时间戳、请求算子的当前事件时间，还可以注册定时器。通常的函数都不会暴露这些可以设置时间戳、操作任务事件时间时钟、或者发出水位线的API。而基于时间的数据流算子任务则会配置发送出的数据的时间戳，以确保它们能够与已到达的水位线平齐。例如，窗口计算完成后，时间窗口的算子任务会将窗口的结束时间作为时间戳附加到将要发送出的结果数据上，然后再使用触发窗口计算的时间戳发出watermark。</p></blockquote><p>现在，让我们更详细地解释一下任务在接收到新的watermark时，如何继续发送watermark并更新其事件时钟。正如我们在“数据并发和任务并发”中所了解的，Flink将数据流拆分为多个分区，并通过单独的算子任务并行地处理每个分区。每个分区都是一个流，里面包含了带着时间戳的数据和watermark。一个算子与它前置或后续算子的连接方式有多种情况，所以它对应的任务可以从一个或多个“输入分区”接收数据和watermark，同时也可以将数据和watermark发送到一个或多个“输出分区”。接下来，我们将详细描述一个任务如何向多个输出任务发送watermark，以及如何通过接收到的watermark来驱动事件时间时钟前进。</p><p>任务为每个输入分区维护一个分区水位线（watermark）。当从一个分区接收到watermark时，它会比较新接收到的值和当前水位值，然后将相应的分区watermark更新为两者的最大值。然后，任务会比较所有分区watermark的大小，将其事件时钟更新为所有分区watermark的最小值。如果事件时间时钟前进了，任务就将处理所有被触发的定时器操作，并向所有连接的输出分区发送出相应的watermark，最终将新的事件时间广播给所有下游任务。</p><p>图3-9显示了具有四个输入分区和三个输出分区的任务如何接收watermark、更新分区watermark和事件时间时钟，以及向下游发出watermark。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0309.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0309.png" class="lazyload"></a></p><p>具有两个或多个输入流（如Union或CoFlatMap）的算子任务（参见“多流转换”一节）也会以所有分区watermark的最小值作为事件时间时钟。它们并不区分不同输入流的分区watermark，所以两个输入流的数据都是基于相同的事件时间时钟进行处理的。当然我们可以想到，如果应用程序的各个输入流的事件时间不一致，那么这种处理方式可能会导致问题。</p><p>Flink的水位处理和传递算法，确保了算子任务发出的时间戳和watermark是“对齐”的。不过它依赖一个条件，那就是所有分区都会提供不断增长的watermark。一旦一个分区不再推进水位线的上升，或者完全处于空闲状态、不再发送任何数据和watermark，任务的事件时间时钟就将停滞不前，任务的定时器也就无法触发了。对于基于时间的算子来说，它们需要依赖时钟的推进来执行计算和清除状态，这种情况显然就会有问题。如果任务没有定期从所有输入任务接收到新的watermark，那么基于时间的算子的处理延迟和状态空间的大小都会显著增加。</p><p>对于具有两个输入流而且watermark明显不同的算子，也会出现类似的情况。具有两个输入流的任务的事件时间时钟，将会同较慢的那条流的watermark保持一致，而通常较快流的数据或者中间结果会在state中缓冲，直到事件时间时钟达到这条流的watermark，才会允许处理它们。</p><h3 id="时间戳的分配和水位线的产生"><a href="#时间戳的分配和水位线的产生" class="headerlink" title="时间戳的分配和水位线的产生"></a>时间戳的分配和水位线的产生</h3><p>我们已经解释了什么是时间戳和水位线，以及它们是如何由Flink内部处理的；然而我们还没有讨论它们的产生。流应用程序接收到数据流时，通常就会先分配时间戳并生成水位线（watermark）。因为时间戳的选择是由不同的应用程序决定的，而且watermark取决于时间戳和流的特性，所以应用程序必须首先显式地分配时间戳并生成watermark。Flink流应用程序可以通过三种方式分配时间戳和生成watermark：</p><ul><li>在数据源（source）处分配：当数据流被摄入到应用程序中时，可以由“源函数”SourceFunction分配和生成时间戳和watermark。SourceFunction可以产生并发送一个数据流；数据会与相关的时间戳一起发送出去，而watermark可以作为一条特殊数据在任何时间点发出。如果SourceFunction（暂时）不再发出watermark，它可以声明自己处于“空闲”（idle）状态。Flink会在后续算子的水位计算中，把空闲的SourceFunction产生的流分区排除掉。source的这一空闲机制，可以用来解决前面提到的水位不再上升的问题。源函数（Source Function）在“实现自定义源函数”一节中进行了更详细的讨论。</li><li>定期分配：在Flink中，DataStream API提供一个名为AssignerWithPeriodicWatermarks的用户定义函数，它可以从每个数据中提取时间戳，并被定期调用以生成当前watermark。提取出的时间戳被分配给相应的数据，而生成的watermark也会添加到流中。这个函数将在“分配时间戳和生成水位线”一节中讨论。</li><li>间断分配：AssignerWithPunctuatedWatermarks是另一个用户定义的函数，它同样会从每个数据中提取一个时间戳。它可以用于生成特殊输入数据中的watermark。与AssignerWithPeriodicWatermarks相比，此函数可以（但不是必须）从每个记录中提取watermark。我们在“分配时间戳和生成水位线”一节中同样讨论了该函数。</li></ul><p>用户定义的时间戳分配函数并没有严格的限制，通常会放在尽可能靠近source算子的位置，因为当经过一些算子处理后，数据及其时间戳的顺序就更加难以解释了。所以尽管我们可以在流应用程序的中段覆盖已有的时间戳和watermark——Flink通过用户定义的函数提供了这种灵活性，但这显然并不是推荐的做法。</p><h2 id="状态管理"><a href="#状态管理" class="headerlink" title="状态管理"></a>状态管理</h2><p>在第2章中，我们已经知道大多数流应用程序都是有状态的。许多算子会不断地读取和更新状态，例如在窗口中收集的数据、读取输入源的位置，或者像机器学习模型那样的用户定制化的算子状态。 Flink用同样的方式处理所有的状态，无论是内置的还是用户自定义的算子。本节我们将会讨论Flink支持的不同类型的状态，并解释“状态后端”是如何存储和维护状态的。</p><p>一般来说，由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状态。你可以认为状态就是一个本地变量，可以被任务的业务逻辑访问。图3-10显示了任务与其状态之间的交互。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0310.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0310.png" class="lazyload"></a></p><p>任务会接收一些输入数据。在处理数据时，任务可以读取和更新状态，并根据输入数据和状态计算结果。最简单的例子，就是统计接收到多少条数据的任务。当任务收到新数据时，它会访问状态以获取当前的计数，然后让计数递增，更新状态并发送出新的计数。</p><p>应用程序里，读取和写入状态的逻辑一般都很简单直接，而有效可靠的状态管理会复杂一些。这包括如何处理很大的状态——可能会超过内存，并且保证在发生故障时不会丢失任何状态。幸运的是，Flink会帮我们处理这相关的所有问题，包括状态一致性、故障处理以及高效存储和访问，以便开发人员可以专注于应用程序的逻辑。</p><p>在Flink中，状态始终与特定算子相关联。为了使运行时的Flink了解算子的状态，算子需要预先注册其状态。总的说来，有两种类型的状态：算子状态（operator state）和键控状态（keyed state），它们有着不同的范围访问，我们将在下面展开讨论。</p><h3 id="算子状态"><a href="#算子状态" class="headerlink" title="算子状态"></a>算子状态</h3><p>算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由相同或不同算子的另一个任务访问。图3-11显示了任务如何访问算子状态。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0311.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0311.png" class="lazyload"></a></p><p>Flink为算子状态提供三种基本数据结构：</p><h4 id="列表状态（List-state）"><a href="#列表状态（List-state）" class="headerlink" title="列表状态（List state）"></a>列表状态（List state）</h4><p>将状态表示为一组数据的列表。</p><h4 id="联合列表状态（Union-list-state）"><a href="#联合列表状态（Union-list-state）" class="headerlink" title="联合列表状态（Union list state）"></a>联合列表状态（Union list state）</h4><p>也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故障时，或者从保存点（savepoint）启动应用程序时如何恢复。我们将在后面继续讨论。</p><h4 id="广播状态（Broadcast-state）"><a href="#广播状态（Broadcast-state）" class="headerlink" title="广播状态（Broadcast state）"></a>广播状态（Broadcast state）</h4><p>如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特殊情况最适合应用广播状态。在保存检查点和重新调整算子并行度时，会用到这个特性。这两部分内容将在本章后面讨论。</p><h3 id="键控状态（Keyed-State）"><a href="#键控状态（Keyed-State）" class="headerlink" title="键控状态（Keyed State）"></a>键控状态（Keyed State）</h3><p>顾名思义，键控状态是根据输入数据流中定义的键（key）来维护和访问的。Flink为每个键值维护一个状态实例，并将具有相同键的所有数据，都分区到同一个算子任务中，这个任务会维护和处理这个key对应的状态。当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的key。因此，具有相同key的所有数据都会访问相同的状态。图3-12显示了任务如何与键控状态进行交互。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0312.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0312.png" class="lazyload"></a></p><p>我们可以将键控状态看成是在算子所有并行任务上，对键进行分区（或分片）之后的一个键值映射（key-value map）。 Flink为键控状态提供不同的数据结构，用于确定map中每个key存储的值的类型。我们简单了解一下最常见的键控状态。</p><h4 id="值状态（Value-state）"><a href="#值状态（Value-state）" class="headerlink" title="值状态（Value state）"></a>值状态（Value state）</h4><p>为每个键存储一个任意类型的单个值。复杂数据结构也可以存储为值状态。</p><h4 id="列表状态（List-state）-1"><a href="#列表状态（List-state）-1" class="headerlink" title="列表状态（List state）"></a>列表状态（List state）</h4><p>为每个键存储一个值的列表。列表里的每个数据可以是任意类型。</p><h4 id="映射状态（Map-state）"><a href="#映射状态（Map-state）" class="headerlink" title="映射状态（Map state）"></a>映射状态（Map state）</h4><p>为每个键存储一个键值映射（map）。map的key和value可以是任意类型。</p><p>状态的数据结构可以让Flink实现更有效的状态访问。我们将在“在运行时上下文（RuntimeContext）中声明键控状态”中做进一步讨论。</p><h3 id="状态后端（State-Backends）"><a href="#状态后端（State-Backends）" class="headerlink" title="状态后端（State Backends）"></a>状态后端（State Backends）</h3><p>每传入一条数据，有状态的算子任务都会读取和更新状态。由于有效的状态访问对于处理数据的低延迟至关重要，因此每个并行任务都会在本地维护其状态，以确保快速的状态访问。状态到底是如何被存储、访问以及维护的？这件事由一个可插入的组件决定，这个组件就叫做状态后端（state backend）。状态后端主要负责两件事：本地的状态管理，以及将检查点（checkpoint）状态写入远程存储。</p><p>对于本地状态管理，状态后端会存储所有键控状态，并确保所有的访问都被正确地限定在当前键范围。 Flink提供了默认的状态后端，会将键控状态作为内存中的对象进行管理，将它们存储在JVM堆上。另一种状态后端则会把状态对象进行序列化，并将它们放入RocksDB中，然后写入本地硬盘。第一种方式可以提供非常快速的状态访问，但它受内存大小的限制；而访问RocksDB状态后端存储的状态速度会较慢，但其状态可以增长到非常大。</p><p>状态检查点的写入也非常重要，这是因为Flink是一个分布式系统，而状态只能在本地维护。 TaskManager进程（所有任务在其上运行）可能在任何时间点挂掉。因此，它的本地存储只能被认为是不稳定的。状态后端负责将任务的状态检查点写入远程的持久存储。写入检查点的远程存储可以是分布式文件系统，也可以是数据库。不同的状态后端在状态检查点的写入机制方面有所不同。例如，RocksDB状态后端支持增量的检查点，这对于非常大的状态来说，可以显著减少状态检查点写入的开销。</p><p>我们将在“选择状态后端”一节中更详细地讨论不同的状态后端及其优缺点。</p><h3 id="调整有状态算子的并行度"><a href="#调整有状态算子的并行度" class="headerlink" title="调整有状态算子的并行度"></a>调整有状态算子的并行度</h3><p>流应用程序的一个常见要求是，为了增大或较小输入数据的速率，需要灵活地调整算子的并行度。对于无状态算子而言，并行度的调整没有任何问题，但更改有状态算子的并行度显然就没那么简单了，因为它们的状态需要重新分区并分配给更多或更少的并行任务。 Flink支持四种模式来调整不同类型的状态。</p><p>具有键控状态的算子通过将键重新分区为更少或更多任务来缩放并行度。不过，并行度调整时任务之间会有一些必要的状态转移。为了提高效率，Flink并不会对单独的key做重新分配，而是用所谓的“键组”（key group）把键管理起来。键组是key的分区形式，同时也是Flink为任务分配key的方式。图3-13显示了如何在键组中重新分配键控状态。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0313.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0313.png" class="lazyload"></a></p><p>具有算子列表状态的算子，会通过重新分配列表中的数据项目来进行并行度缩放。从概念上讲，所有并行算子任务的列表项目会被收集起来，并将其均匀地重新分配给更少或更多的任务。如果列表条目少于算子的新并行度，则某些任务将以空状态开始。图3-14显示了算子列表状态的重新分配。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0314.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0314.png" class="lazyload"></a></p><p>具有算子联合列表状态的算子，会通过向每个任务广播状态的完整列表，来进行并行度的缩放。然后，任务可以选择要使用的状态项和要丢弃的状态项。图3-15显示了如何重新分配算子联合列表状态。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0315.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0315.png" class="lazyload"></a></p><p>具有算子广播状态的算子，通过将状态复制到新任务，来增大任务的并行度。这是没问题的，因为广播状态保证了所有任务都具有相同的状态。而对于缩小并行度的情况，我们可以直接取消剩余任务，因为状态是相同的，已经被复制并且不会丢失。图3-16显示了算子广播状态的重新分配。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0316.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0316.png" class="lazyload"></a></p><h2 id="检查点，保存点和状态恢复"><a href="#检查点，保存点和状态恢复" class="headerlink" title="检查点，保存点和状态恢复"></a>检查点，保存点和状态恢复</h2><p>Flink是一个分布式数据处理系统，因此必须有一套机制处理各种故障，比如被杀掉的进程，故障的机器和中断的网络连接。任务都是在本地维护状态的，所以Flink必须确保状态不会丢失，并且在发生故障时能够保持一致。</p><p>在本节中，我们将介绍Flink的检查点（checkpoint）和恢复机制，这保证了“精确一次”（exactly-once）的状态一致性。我们还会讨论Flink独特的保存点（savepoint）功能，这是一个“瑞士军刀”式的工具，可以解决许多操作数据流时面对的问题。</p><h3 id="一致的检查点（Checkpoints）"><a href="#一致的检查点（Checkpoints）" class="headerlink" title="一致的检查点（Checkpoints）"></a>一致的检查点（Checkpoints）</h3><p>Flink的恢复机制的核心，就是应用状态的一致检查点。有状态流应用的一致检查点，其实就是所有任务状态在某个时间点的一份拷贝，而这个时间点应该是所有任务都恰好处理完一个相同的输入数据的时候。这个过程可以通过一致检查点的一个简单算法步骤来解释。这个算法的步骤是：</p><ul><li>暂停所有输入流的摄取，也就是不再接收新数据的输入。</li><li>等待所有正在处理的数据计算完毕，这意味着结束时，所有任务都已经处理了所有输入数据。</li><li>通过将每个任务的状态复制到远程持久存储，来得到一个检查点。所有任务完成拷贝操作后，检查点就完成了。</li><li>恢复所有输入流的摄取。</li></ul><p>需要注意，Flink实现的并不是这种简单的机制。我们将在本节后面介绍Flink更精妙的检查点算法。</p><p>图3-17显示了一个简单应用中的一致检查点。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0317.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0317.png" class="lazyload"></a></p><p>上面的应用程序中具有单一的输入源（source）任务，输入数据就是一组不断增长的数字的流——1,2,3等。数字流被划分为偶数流和奇数流。求和算子（sum）的两个任务会分别实时计算当前所有偶数和奇数的总和。源任务会将其输入流的当前偏移量存储为状态，而求和任务则将当前的总和值存储为状态。在图3-17中，Flink在输入偏移量为5时，将检查点写入了远程存储，当前的总和为6和9。</p><h3 id="从一致检查点中恢复状态"><a href="#从一致检查点中恢复状态" class="headerlink" title="从一致检查点中恢复状态"></a>从一致检查点中恢复状态</h3><p>在执行流应用程序期间，Flink会定期检查状态的一致检查点。如果发生故障，Flink将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程。图3-18显示了恢复过程。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0318.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0318.png" class="lazyload"></a></p><p>应用程序从检查点的恢复分为三步：</p><ul><li>重新启动整个应用程序。</li><li>将所有的有状态任务的状态重置为最近一次的检查点。</li><li>恢复所有任务的处理。</li></ul><p>这种检查点的保存和恢复机制可以为应用程序状态提供“精确一次”（exactly-once）的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一来所有的输入流就都会被重置到检查点完成时的位置。至于数据源是否可以重置它的输入流，这取决于其实现方式和消费流数据的外部接口。例如，像Apache Kafka这样的事件日志系统可以提供流上之前偏移位置的数据，所以我们可以将源重置到之前的偏移量，重新消费数据。而从套接字（socket）消费数据的流就不能被重置了，因为套接字的数据一旦被消费就会丢弃掉。因此，对于应用程序而言，只有当所有的输入流消费的都是可重置的数据源时，才能确保在“精确一次”的状态一致性下运行。</p><p>从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同。然后它就会开始消费并处理检查点和发生故障之间的所有数据。尽管这意味着Flink会对一些数据处理两次（在故障之前和之后），我们仍然可以说这个机制实现了精确一次的一致性语义，因为所有算子的状态都已被重置，而重置后的状态下还不曾看到这些数据。</p><p>我们必须指出，Flink的检查点保存和恢复机制仅仅可以重置流应用程序的内部状态。对于应用中的一些的输出（sink）算子，在恢复期间，某些结果数据可能会多次发送到下游系统，比如事件日志、文件系统或数据库。对于某些存储系统，Flink提供了具有精确一次输出功能的sink函数，比如，可以在检查点完成时提交发出的记录。另一种适用于许多存储系统的方法是幂等更新。在“应用程序一致性保证”一节中，我们还会详细讨论如何解决应用程序端到端的精确一次一致性问题。</p><h3 id="Flink的检查点算法"><a href="#Flink的检查点算法" class="headerlink" title="Flink的检查点算法"></a>Flink的检查点算法</h3><p>Flink的恢复机制，基于它的一致性检查点。前面我们已经了解了从流应用中创建检查点的简单方法——先暂停应用，保存检查点，然后再恢复应用程序，这种方法很好理解，但它的理念是“停止一切”，这对于即使是中等延迟要求的应用程序而言也是不实用的。所以Flink没有这么简单粗暴，而是基于Chandy-Lamport算法实现了分布式快照的检查点保存。该算法并不会暂停整个应用程序，而是将检查点的保存与数据处理分离，这样就可以实现在其它任务做检查点状态保存状态时，让某些任务继续进行而不受影响。接下来我们将解释此算法的工作原理。</p><p>Flink的检查点算法用到了一种称为“检查点分界线”（checkpoint barrier）的特殊数据形式。与水位线（watermark）类似，检查点分界线由source算子注入到常规的数据流中，它的位置是限定好的，不能超过其他数据，也不能被后面的数据超过。检查点分界线带有检查点ID，用来标识它所属的检查点；这样，这个分界线就将一条流逻辑上分成了两部分。分界线之前到来的数据导致的状态更改，都会被包含在当前分界线所属的检查点中；而基于分界线之后的数据导致的所有更改，就会被包含在之后的检查点中。</p><p>我们用一个简单的流应用程序作为示例，来一步一步解释这个算法。该应用程序有两个源（source）任务，每个任务都消费一个增长的数字流。源任务的输出被划分为两部分：偶数和奇数的流。每个分区由一个任务处理，该任务计算所有收到的数字的总和，并将更新的总和转发给输出（sink）任务。这个应用程序的结构如图3-19所示。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0319.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0319.png" class="lazyload"></a></p><p>JobManager会向每个数据源（source）任务发送一条带有新检查点ID的消息，通过这种方式来启动检查点，如图3-20所示。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0320.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0320.png" class="lazyload"></a></p><p>当source任务收到消息时，它会暂停发出新的数据，在状态后端触发本地状态的检查点保存，并向所有传出的流分区广播带着检查点ID的分界线（barriers）。状态后端在状态检查点完成后会通知任务，而任务会向JobManager确认检查点完成。在发出所有分界线后，source任务就可以继续常规操作，发出新的数据了。通过将分界线注入到输出流中，源函数（source function）定义了检查点在流中所处的位置。图3-21显示了两个源任务将本地状态保存到检查点，并发出检查点分界线之后的流应用程序。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0321.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0321.png" class="lazyload"></a></p><p>源任务发出的检查点分界线（barrier），将被传递给所连接的任务。与水位线（watermark）类似，barrier会被广播到所有连接的并行任务，以确保每个任务从它的每个输入流中都能接收到。当任务收到一个新检查点的barrier时，它会等待这个检查点的所有输入分区的barrier到达。在等待的过程中，任务并不会闲着，而是会继续处理尚未提供barrier的流分区中的数据。对于那些barrier已经到达的分区，如果继续有新的数据到达，它们就不会被立即处理，而是先缓存起来。这个等待所有分界线到达的过程，称为“分界线对齐”（barrier alignment），如图3-22所示。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0322.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0322.png" class="lazyload"></a></p><p>当任务从所有输入分区都收到barrier时，它就会在状态后端启动一个检查点的保存，并继续向所有下游连接的任务广播检查点分界线，如图3-23所示。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0323.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0323.png" class="lazyload"></a></p><p>所有的检查点barrier都发出后，任务就开始处理之前缓冲的数据。在处理并发出所有缓冲数据之后，任务就可以继续正常处理输入流了。图3-24显示了此时的应用程序。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0324.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0324.png" class="lazyload"></a></p><p>最终，检查点分界线会到达输出（sink）任务。当sink任务接收到barrier时，它也会先执行“分界线对齐”，然后将自己的状态保存到检查点，并向JobManager确认已接收到barrier。一旦从应用程序的所有任务收到一个检查点的确认信息，JobManager就会将这个检查点记录为已完成。图3-25显示了检查点算法的最后一步。这样，当发生故障时，我们就可以用已完成的检查点恢复应用程序了。</p><p><a href="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0325.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://confucianzuoyuan.github.io/flink-tutorial/images/spaf_0325.png" class="lazyload"></a></p><h3 id="检查点的性能影响"><a href="#检查点的性能影响" class="headerlink" title="检查点的性能影响"></a>检查点的性能影响</h3><p>Flink的检查点算法可以在不停止整个应用程序的情况下，生成一致的分布式检查点。但是，它可能会增加应用程序的处理延迟。Flink对此有一些调整措施，可以在某些场景下显得对性能的影响没那么大。</p><p>当任务将其状态保存到检查点时，它其实处于一个阻塞状态，而此时新的输入会被缓存起来。由于状态可能变得非常大，而且检查点需要通过网络将数据写入远程存储系统，检查点的写入很容易就会花费几秒到几分钟的时间——这对于要求低延迟的应用程序而言，显然是不可接受的。在Flink的设计中，真正负责执行检查点写入的，其实是状态后端。具体怎样复制任务的状态，取决于状态后端的实现方式。例如，文件系统（FileSystem）状态后端和RocksDB状态后端都支持了异步（asynchronous）检查点。触发检查点操作时，状态后端会先创建状态的本地副本。本地拷贝完成后，任务就将继续常规的数据处理，这往往并不会花费太多时间。一个后台线程会将本地快照异步复制到远程存储，并在完成检查点后再回来通知任务。异步检查点的机制，显著减少了任务继续处理数据之前的等待时间。此外，RocksDB状态后端还实现了增量的检查点，这样可以大大减少要传输的数据量。</p><p>为了减少检查点算法对处理延迟的影响，另一种技术是调整分界线对齐的步骤。对于需要非常低的延迟、并且可以容忍“至少一次”（at-least-once）状态保证的应用程序，Flink可以将检查点算法配置为，在等待barrier对齐期间处理所有到达的数据，而不是把barrier已经到达的那些分区的数据缓存起来。当检查点的所有barrier到达，算子任务就会将状态写入检查点——当然，现在的状态中，就可能包括了一些“提前”的更改，这些更改由本该属于下一个检查点的数据到来时触发。如果发生故障，从检查点恢复时，就将再次处理这些数据：这意味着检查点现在提供的是“至少一次”（at-least-once）而不是“精确一次”（exactly-once）的一致性保证。</p><h3 id="保存点（Savepoints）"><a href="#保存点（Savepoints）" class="headerlink" title="保存点（Savepoints）"></a>保存点（Savepoints）</h3><p>Flink的恢复算法是基于状态检查点的。Flink根据可配置的策略，定期保存并自动丢弃检查点。检查点的目的是确保在发生故障时可以重新启动应用程序，所以当应用程序被显式地撤销（cancel）时，检查点会被删除掉。除此之外，应用程序状态的一致性快照还可用于除故障恢复之外的更多功能。</p><p>Flink中一个最有价值，也是最独特的功能是保存点（savepoints）。原则上，创建保存点使用的算法与检查点完全相同，因此保存点可以认为就是具有一些额外元数据的检查点。 Flink不会自动创建保存点，因此用户（或者外部调度程序）必须明确地触发创建操作。同样，Flink也不会自动清理保存点。第10章将会具体介绍如何触发和处理保存点。</p><h4 id="使用保存点"><a href="#使用保存点" class="headerlink" title="使用保存点"></a>使用保存点</h4><p>有了应用程序和与之兼容的保存点，我们就可以从保存点启动应用程序了。这会将应用程序的状态初始化为保存点的状态，并从保存点创建时的状态开始运行应用程序。虽然看起来这种行为似乎与用检查点从故障中恢复应用程序完全相同，但实际上故障恢复只是一种特殊情况，它只是在相同的集群上以相同的配置启动相同的应用程序。而从保存点启动应用程序会更加灵活，这就可以让我们做更多事情了。</p><ul><li>可以从保存点启动不同但兼容的应用程序。这样一来，我们就可以及时修复应用程序中的逻辑bug，并让流式应用的源尽可能多地提供之前发生的事件，然后重新处理，以便修复之前的计算结果。修改后的应用程序还可用于运行A / B测试，或者具有不同业务逻辑的假设场景。这里要注意，应用程序和保存点必须兼容才可以这么做——也就是说，应用程序必须能够加载保存点的状态。</li><li>可以使用不同的并行度来启动相同的应用程序，可以将应用程序的并行度增大或减小。</li><li>可以在不同的集群上启动同样的应用程序。这非常有意义，意味着我们可以将应用程序迁移到较新的Flink版本或不同的集群上去。</li><li>可以使用保存点暂停应用程序，稍后再恢复。这样做的意义在于，可以为更高优先级的应用程序释放集群资源，或者在输入数据不连续生成时释放集群资源。</li><li>还可以将保存点设置为某一版本，并归档（archive）存储应用程序的状态。</li></ul><p>保存点是非常强大的功能，所以许多用户会定期创建保存点以便能够及时退回之前的状态。我们见到的各种场景中，保存点一个最有趣的应用是不断将流应用程序迁移到更便宜的数据中心上去。</p><h4 id="从保存点启动应用程序"><a href="#从保存点启动应用程序" class="headerlink" title="从保存点启动应用程序"></a>从保存点启动应用程序</h4><p>前面提到的保存点的所有用例，都遵循相同的模式。那就是首先创建正在运行的应用程序的保存点，然后在一个新启动的应用程序中用它来恢复状态。之前我们已经知道，保存点的创建和检查点非常相似，而接下来我们就将介绍对于一个从保存点启动的应用程序，Flink如何初始化其状态。</p><p>应用程序由多个算子组成。每个算子可以定义一个或多个键控状态和算子状态。算子由一个或多个算子任务并行执行。因此，一个典型的应用程序会包含多个状态，这些状态分布在多个算子任务中，这些任务可以运行在不同的TaskManager进程上。</p><p>图3-26显示了一个具有三个算子的应用程序，每个算子执行两个算子任务。一个算子（OP-1）具有单一的算子状态（OS-1），而另一个算子（OP-2）具有两个键控状态（KS-1和KS-2）。当保存点创建时，会将所有任务的状态复制到持久化的存储位置。</p><p>保存点中的状态拷贝会以算子标识符（operator ID）和状态名称（state name）组织起来。算子ID和状态名称必须能够将保存点的状态数据，映射到一个正在启动的应用程序的算子状态。从保存点启动应用程序时，Flink会将保存点的数据重新分配给相应的算子任务。</p><blockquote><p>请注意，保存点不包含有关算子任务的信息。这是因为当应用程序以不同的并行度启动时，任务数量可能会更改。</p></blockquote><p>如果我们要从保存点启动一个修改过的应用程序，那么保存点中的状态只能映射到符合标准的应用程序——它里面的算子必须具有相应的ID和状态名称。默认情况下，Flink会自动分配唯一的算子ID。然而，一个算子的ID，是基于它之前算子的ID确定性地生成的。因此，算子的ID会在其前序算子改变时改变，比如，当我们添加了新的或移除掉一个算子时，前序算子ID改变，当前算子ID就会变化。所以对于具有默认算子ID的应用程序而言，如果想在不丢失状态的前提下升级，就会受到极大的限制。因此，我们强烈建议在程序中为算子手动分配唯一ID，而不是依靠Flink的默认分配。我们将在“指定唯一的算子标识符”一节中详细说明如何分配算子标识符。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第三章，Flink运行架构&quot;&gt;&lt;a href=&quot;#第三章，Flink运行架构&quot; class=&quot;headerlink&quot; title=&quot;第三章，Flink运行架构&quot;&gt;&lt;/a&gt;第三章，Flink运行架构&lt;/h1&gt;&lt;h2 id=&quot;系统架构&quot;&gt;&lt;a href=&quot;#系统架构&quot;
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"/>
    
    
      <category term="教程" scheme="https://masteryang4.github.io/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="大数据" scheme="https://masteryang4.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="flink" scheme="https://masteryang4.github.io/tags/flink/"/>
    
  </entry>
  
</feed>
